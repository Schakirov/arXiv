2021-12-12 2021-12-18 </br></br>
<a href='http://arxiv.org/pdf/2112.05282.pdf'>2112.05282</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV) &nbsp&nbsp 14.8081баллов, №1</br>
<b>RamBoAttack: A Robust Query Efficient Deep Neural Network Decision\n  Exploit</b></br>
Authors: , Vo, Viet <font color="green">Quoc</font>, Abbasnejad, Ehsan, Ranasinghe, Damith C.</br>
  Machine learning models are critically susceptible to evasion attacks from adversarial examples. Generally, adversarial examples, modified inputs deceptively similar to the original input, are constructed under whitebox settings by adversaries with full access to the model. However, recent attacks have shown a remarkable reduction in query numbers to craft adversarial examples using blackbox attacks. Particularly, alarming is the ability to exploit the classification decision from the access interface of a trained model provided by a growing number of Machine Learning as a Service providers including <font color="#00be00">Google</font>, Microsoft, IBM and used by a plethora of applications incorporating these models. The ability of an adversary to exploit only the predicted label from a model to craft adversarial examples is distinguished as a decision-based attack. In our study, we first deep dive into recent <font color="#00be00">state-of-the-art</font> decision-based attacks in ICLR and SP to highlight the costly nature of discovering low distortion adversarial employing gradient estimation methods. We develop a robust query efficient attack capable of avoiding entrapment in a local minimum and misdirection from noisy gradients seen in gradient estimation methods. The attack method we propose, RamBoAttack, exploits the notion of Randomized Block Coordinate Descent to explore the hidden classifier manifold, targeting perturbations to manipulate only localized input features to address the issues of gradient estimation methods. Importantly, the RamBoAttack is more robust to the different sample inputs available to an adversary and the targeted class. Overall, for a given target class, RamBoAttack is demonstrated to be more robust at achieving a lower distortion within a given query budget. We curate our extensive results using the large-scale high-resolution ImageNet dataset and open-source our attack, test samples and artifacts on <font color="#00be00">GitHub</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.05251.pdf'>2112.05251</a> &nbsp&nbsp (cs:RO, cs:AI, cs:ML) &nbsp&nbsp 12.9042баллов, №2</br>
<b>Error-Aware Imitation Learning from Teleoperation Data for Mobile\n  Manipulation</b></br>
Authors: , Wong, Josiah, Tung, Albert, Kurenkov, Andrey, Mandlekar, Ajay, <font color="green">Fei-Fei, Li</font>, Savarese, Silvio, Mart&#xed;n-Mart&#xed;n, Roberto</br>
  In<font color="#960096"> mobile </font>manipulation (MM), robots can both navigate within and interact with their environment and are thus able to complete many more tasks than robots only capable of navigation or manipulation. In this work, we explore how to apply imitation learning (IL) to learn continuous visuo-motor policies for MM tasks. Much prior work has shown that IL can train visuo-motor policies for either manipulation or navigation domains, but few works have applied IL to the MM domain. Doing this is challenging for two reasons: on the data side, current interfaces make collecting high-quality human demonstrations difficult, and on the learning side, policies trained on limited data can suffer from covariate shift when deployed. To address these problems, we first propose Mobile Manipulation RoboTurk (MoMaRT), a novel teleoperation framework allowing simultaneous navigation and manipulation of mobile manipulators, and collect a first-of-its-kind large scale dataset in a realistic simulated kitchen setting. We then propose a learned error detection system to address the covariate shift by detecting when an agent is in a potential failure state. We train performant IL policies and error detectors from this data, and achieve over 45% task success rate and 85% error detection success rate across multiple multi-stage tasks when trained on expert data. Codebase, datasets, visualization, and more available at <font color="#006400">http</font>s://sites.<font color="#00be00">google</font>.com/view/il-for-mm/home. </br></br>

<a href='http://arxiv.org/pdf/2112.06749.pdf'>2112.06749</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 12.0060баллов, №3</br>
<b>Step-unrolled Denoising Autoencoders for Text Generation</b></br>
Authors: , Savinov, Nikolay, Chung, Junyoung, Binkowski, Mikolaj, Elsen, Erich, <font color="green">Oord, A</font>aron van den</br>
  In this paper we propose a new generative model of text, Step-unrolled Denoising Autoencoder (SUNDAE), that does not rely on autoregressive models. Similarly to denoising diffusion techniques, SUNDAE is repeatedly applied on a sequence of tokens, starting from random inputs and improving them each time until convergence. We present a simple new improvement operator that converges in fewer iterations than diffusion methods, while qualitatively producing better samples on natural language datasets. SUNDAE achieves <font color="#00be00">state-of-the-art</font> results (among non-autoregressive methods) on the WMT\'14 English-to-German translation task and good qualitative results on unconditional language modeling on the Colossal Cleaned Common Crawl dataset and a dataset of Python code from <font color="#00be00">GitHub</font>. The non-autoregressive nature of SUNDAE opens up possibilities beyond left-to-right prompted generation, by filling in arbitrary blank patterns in a template. </br></br>

<a href='http://arxiv.org/pdf/2112.05843.pdf'>2112.05843</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 12.0033баллов, №4</br>
<b>Am I Me or You? <font color="#00be00">State-of-the-Art</font> Dialogue Models Cannot Maintain an\n  Identity</b></br>
Authors: , Shuster, Kurt, Urbanek, Jack, Szlam, Arthur, <font color="green">Weston, Jason</font></br>
  <font color="#00be00">State-of-the-art</font> dialogue models still often stumble with regards to factual accuracy and self-contradiction. Anecdotally, they have been observed to fail to maintain character identity throughout discourse; and more specifically, may take on the role of their interlocutor. In this work we formalize and quantify this deficiency, and show experimentally through human evaluations that this is indeed a problem. In contrast, we show that discriminative models trained specifically to recognize who is speaking can perform well; and further, these can be used as automated metrics. Finally, we evaluate a wide variety of mitigation methods, including changes to model architecture, training protocol, and decoding strategy. Our best models reduce mistaken identity issues by nearly 65% according to human annotators, while simultaneously improving engagingness. Despite these results, we find that maintaining character identity still remains a challenging problem. </br></br>

<a href='http://arxiv.org/pdf/2112.07774.pdf'>2112.07774</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 10.7462баллов, №5</br>
<b>Assessing Human Interaction in Virtual Reality With Continually Learning\n  Prediction Agents Based on <font color="#00be00">Reinforcement Learning</font> Algorithms: A Pilot Study</b></br>
Authors: , Brenneis, Dylan J. A., Parker, Adam S., Johanson, Michael Bradley, Butcher, Andrew, Davoodi, Elnaz, Acker, Leslie, <font color="green">Botvinick, M</font>atthew M., Modayil, Joseph, White, Adam, Pilarski, Patrick M.</br>
  Artificial intelligence systems increasingly involve continual learning to enable flexibility in general situations that are not encountered during system training. Human interaction with autonomous systems is broadly studied, but research has hitherto under-explored interactions that occur while the system is actively learning, and can noticeably change its behaviour in minutes. In this pilot study, we investigate how the interaction between a human and a continually learning prediction agent develops as the agent develops competency. Additionally, we compare two different agent architectures to assess how representational choices in agent design affect the human-agent interaction. We develop a virtual reality environment and a time-based prediction task wherein learned predictions from a <font color="#00be00">reinforcement learning</font> (RL) algorithm augment human predictions. We assess how a participant\'s performance and behaviour in this task differs across agent types, using both quantitative and qualitative analyses. Our findings suggest that human trust of the system may be influenced by early interactions with the agent, and that trust in turn affects strategic behaviour, but limitations of the pilot study rule out any conclusive statement. We identify trust as a key feature of interaction to focus on when considering RL-based technologies, and make several <font color="#be00be">recommendat</font>ions for modification to this study in preparation for a larger-scale investigation. A video summary of this paper can be found at <font color="#006400">http</font>s://youtu.be/oVYJdnBqTwQ . </br></br>

<a href='http://arxiv.org/pdf/2112.06905.pdf'>2112.06905</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 10.6095баллов, №6</br>
<b>GLaM: Efficient Scaling of Language Models with Mixture-of-Experts</b></br>
Authors: , Du, Nan, Huang, Yanping, Dai, Andrew M., Tong, Simon, Lepikhin, Dmitry, Xu, Yuanzhong, Krikun, Maxim, Zhou, Yanqi, Yu, Adams Wei, Firat, Orhan, Zoph, Barret, Fedus, Liam, Bosma, Maarten, Zhou, Zongwei, Wang, Tao, Wang, Yu Emma, Webster, Kellie, Pellat, Marie, Robinson, Kevin, Meier-Hellstern, Kathy, Duke, Toju, Dixon, Lucas, Zhang, Kun, Le, <font color="green">Quoc</font> V, Wu, Yonghui, Chen, Zhifeng, Cui, Claire</br>
  Scaling language models with more data, compute and parameters has driven significant progress in natural language processing. For example, thanks to scaling,<font color="#00be00"> GPT</font>-3 was able to achieve strong results on in-context learning tasks. However, training these large dense models requires significant amounts of computing resources. In this paper, we propose and develop a family of language models named GLaM (Generalist Language Model), which uses a sparsely activated mixture-of-experts architecture to scale the model capacity while also incurring substantially less training cost compared to dense variants. The largest GLaM has 1.2 trillion parameters, which is approximately 7x larger than GPT-3. It consumes only 1/3 of the energy used to train GPT-3 and requires half of the computation flops for inference, while still achieving better overall <font color="#00be00">zero-shot</font> and <font color="#009600">one-shot</font> performance across 29 NLP tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.05749.pdf'>2112.05749</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 10.4781баллов, №7</br>
<b>Label, Verify, Correct: A Simple Few Shot <font color="#be00be">Object Detection</font> Method</b></br>
Authors: , Kaul, Prannay, Xie, Weidi, <font color="green">Zisserman, A</font>ndrew</br>
  The objective of this paper is <font color="#00be00">few-shot</font> <font color="#be00be">object detection</font> (FSOD) -- the task of expanding an object detector for a new category given only a few instances for training. We introduce a simple pseudo-labelling method to source high-quality pseudo-annotations from the training set, for each new category, vastly increasing the number of training instances and reducing class imbalance; our method finds previously unlabelled instances. Na\\&quot;ively training with model predictions yields sub-optimal performance; we present two novel methods to improve the precision of the pseudo-labelling process: first, we introduce a verification technique to remove candidate detections with incorrect class labels; second, we train a specialised model to correct poor quality bounding boxes. After these two novel steps, we obtain a large set of high-quality pseudo-annotations that allow our final detector to be trained end-to-end. Additionally, we demonstrate our method maintains base class performance, and the utility of simple augmentations in FSOD. While benchmarking on PASCAL VOC and MS-COCO, our method achieves <font color="#00be00">state-of-the-art</font> or second-best performance compared to existing approaches across all number of shots. </br></br>

<a href='http://arxiv.org/pdf/2112.00861.pdf'>2112.00861</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 10.3920баллов, №8</br>
<b>A General Language Assistant as a Laboratory for Alignment</b></br>
Authors: , Askell, Amanda, Bai, Yuntao, Chen, Anna, Drain, Dawn, Ganguli, Deep, Henighan, Tom, Jones, Andy, Joseph, Nicholas, Mann, Ben, DasSarma, Nova, Elhage, Nelson, Hatfield-Dodds, Zac, Hernandez, Danny, Kernion, Jackson, Ndousse, Kamal, Olsson, Catherine, <font color="green">Amodei, Dario</font>, Brown, Tom, Clark, Jack, McCandlish, Sam, Olah, Chris, Kaplan, Jared</br>
  Given the broad capabilities of large language models, it should be possible to work towards a general-purpose, text-based assistant that is aligned with human values, meaning that it is helpful, honest, and harmless. As an initial foray in this direction we study simple baseline techniques and evaluations, such as prompting. We find that the benefits from modest interventions increase with model size, generalize to a variety of alignment evaluations, and do not compromise the performance of large models. Next we investigate scaling trends for several training objectives relevant to alignment, comparing imitation learning, binary discrimination, and ranked preference modeling. We find that ranked preference modeling performs much better than imitation learning, and often scales more favorably with model size. In contrast, binary discrimination typically performs and scales very similarly to imitation learning. Finally we study a `preference model pre-training\' stage of training, with the goal of improving <font color="#00be00">sample efficien</font>cy when finetuning on human preferences. </br></br>

<a href='http://arxiv.org/pdf/2112.09118.pdf'>2112.09118</a> &nbsp&nbsp (cs:AI, cs:CL) &nbsp&nbsp 10.3708баллов, №9</br>
<b>Towards Unsupervised Dense Information <font color="#be00be">Retrieval</font> with Contrastive\n  Learning</b></br>
Authors: , Izacard, Gautier, Caron, Mathilde, Hosseini, Lucas, Riedel, Sebastian, Bojanowski, Piotr, <font color="green">Joulin, A</font>rmand, Grave, Edouard</br>
  Information <font color="#be00be">retrieval</font> is an important component in natural language processing, for knowledge intensive tasks such as question answering and fact checking. Recently, information retrieval has seen the emergence of dense retrievers, based on neural networks, as an alternative to classical sparse methods based on term-frequency. These models have obtained <font color="#00be00">state-of-the-art</font> results on datasets and tasks where large training sets are available. However, they do not transfer well to new domains or applications with no training data, and are often <font color="#00be00">outperform</font>ed by term-frequency methods such as BM25 which are not supervised. Thus, a natural question is whether it is possible to train dense retrievers without supervision. In this work, we explore the limits of contrastive learning as a way to train unsupervised dense retrievers, and show that it leads to strong retrieval performance. More precisely, we show on the BEIR benchmark that our model outperforms BM25 on 11 out of 15 datasets. Furthermore, when a few thousands examples are available, we show that fine-tuning our model on these leads to strong improvements compared to BM25. Finally, when used as pre-training before fine-tuning on the MS-MARCO dataset, our technique obtains state-of-the-art results on the BEIR benchmark. </br></br>

<a href='http://arxiv.org/pdf/2112.09133.pdf'>2112.09133</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 10.1941баллов, №10</br>
<b>Masked Feature Prediction for Self-Supervised Visual Pre-Training</b></br>
Authors: , Wei, Chen, Fan, Haoqi, Xie, Saining, Wu, Chao-Yuan, <font color="green">Yuille</font>, Alan, Feichtenhofer, Christoph</br>
  We present Masked Feature Prediction (MaskFeat) for self-supervised pre-training of video models. Our approach first randomly masks out a portion of the input sequence and then predicts the feature of the masked regions. We study five different types of features and find Histograms of Oriented Gradients (HOG), a hand-crafted feature descriptor, works particularly well in terms of both performance and efficiency. We observe that the local contrast normalization in HOG is essential for good results, which is in line with earlier work using HOG for visual recognition. Our approach can learn abundant visual knowledge and drive large-scale <font color="#00be00">Transformer</font>-based models. Without using extra model weights or supervision, MaskFeat pre-trained on unlabeled videos achieves unprecedented results of 86.7% with MViT-L on Kinetics-400, 88.3% on Kinetics-600, 80.4% on Kinetics-700, 38.8 mAP on AVA, and 75.0% on SSv2. MaskFeat further generalizes to image input, which can be <font color="#be00be">interpret</font>ed as a video with a single frame and obtains <font color="#960096">competitive</font> results on ImageNet. </br></br>

<a href='http://arxiv.org/pdf/2112.08670.pdf'>2112.08670</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 10.1515баллов, №11</br>
<b>Amortized Noisy Channel Neural Machine Translation</b></br>
Authors: , Pang, Richard Yuanzhe, He, He, Cho, <font color="green">Kyunghyun</font></br>
  Noisy channel models have been especially effective in neural machine translation (NMT). However, recent approaches like &quot;beam search and rerank&quot; (BSR) incur significant computation overhead during inference, making <font color="#009600">real-world</font> application infeasible. We aim to build an amortized noisy channel NMT model such that greedily decoding from it would generate translations that maximize the same reward as translations generated using BSR. We attempt three approaches: knowledge distillation, 1-step-deviation imitation learning, and Q learning. The first approach obtains the noisy channel signal from a pseudo-corpus, and the latter two approaches aim to optimize toward a noisy-channel MT reward directly. All three approaches speed up inference by 1-2 orders of magnitude. For all three approaches, the generated translations fail to achieve rewards comparable to BSR, but the translation quality approximated by BLEU is similar to the quality of BSR-produced translations. </br></br>

<a href='http://arxiv.org/pdf/2112.08346.pdf'>2112.08346</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 10.1381баллов, №12</br>
<b>Simple Text Detoxification by Identifying a Linear Toxic Subspace in\n  Language Model Embeddings</b></br>
Authors: , Wa<font color="green">ng, Andr</font>ew, Sudhakar, Mohit, Ji, Yangfeng</br>
  Large pre-trained language models are often trained on large volumes of internet data, some of which may contain toxic or abusive language. Consequently, language models encode toxic information, which makes the <font color="#009600">real-world</font> usage of these language models limited. Current methods aim to prevent toxic features from appearing generated text. We hypothesize the existence of a low-dimensional toxic subspace in the latent space of pre-trained language models, the existence of which suggests that toxic features follow some underlying pattern and are thus removable. To construct this toxic subspace, we propose a method to generalize toxic directions in the latent space. We also provide a methodology for constructing parallel datasets using a context based word masking system. Through our experiments, we show that when the toxic subspace is removed from a set of sentence representations, almost no toxic representations remain in the result. We demonstrate empirically that the subspace found using our method generalizes to multiple toxicity corpora, indicating the existence of a low-dimensional toxic subspace. </br></br>

<a href='http://arxiv.org/pdf/2112.08914.pdf'>2112.08914</a> &nbsp&nbsp (cs:ML, cs:CL) &nbsp&nbsp 9.9450баллов, №13</br>
<b>Characterizing and addressing the issue of oversmoothing in neural\n  autoregressive sequence modeling</b></br>
Authors: , Kulikov, Ilia, Eremeev, Maksim, Cho, <font color="green">Kyunghyun</font></br>
  Neural autoregressive sequence models smear the probability among many possible sequences including degenerate ones, such as empty or repetitive sequences. In this work, we tackle one specific case where the model assigns a high probability to unreasonably short sequences. We define the oversmoothing rate to quantify this issue. After confirming the high degree of oversmoothing in neural machine translation, we propose to explicitly minimize the oversmoothing rate during training. We conduct a set of experiments to study the effect of the proposed regularization on both model distribution and decoding performance. We use a neural machine translation task as the testbed and consider three different datasets of varying size. Our experiments reveal three major findings. First, we can control the oversmoothing rate of the model by tuning the strength of the regularization. Second, by enhancing the oversmoothing loss contribution, the probability and the rank of &lt;eos&gt; token decrease heavily at positions where it is not supposed to be. Third, the proposed regularization impacts the outcome of beam search especially when a large beam is used. The degradation of translation quality (measured in BLEU) with a large beam significantly lessens with lower oversmoothing rate, but the degradation compared to smaller beam sizes remains to exist. From these observations, we conclude that the high degree of oversmoothing is the main reason behind the degenerate case of overly probable short sequences in a neural autoregressive model. </br></br>

<a href='http://arxiv.org/pdf/2112.08289.pdf'>2112.08289</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 9.7829баллов, №14</br>
<b>Decomposing Natural Logic Inferences in Neural NLI</b></br>
Authors: , Rozanova, Julia, Ferreira, Deborah, Valentino, Marco, Thayaparan, Mokanrarangan, <font color="green">Freitas</font>, Andre</br>
  In the interest of <font color="#be00be">interpret</font>ing neural NLI models and their reasoning strategies, we carry out a systematic probing study which investigates whether these models capture the crucial semantic features central to natural logic: monotonicity and concept inclusion. Correctly identifying valid inferences in downward-monotone contexts is a known stumbling block for NLI performance, subsuming linguistic phenomena such as negation scope and generalized quantifiers. To understand this difficulty, we emphasize monotonicity as a property of a context and examine the extent to which models capture monotonicity information in the contextual embeddings which are intermediate to their decision making process. Drawing on the recent advancement of the probing paradigm, we compare the presence of monotonicity features across various models. We find that monotonicity information is notably weak in the representations of popular NLI models which achieve high scores on benchmarks, and observe that previous improvements to these models based on fine-tuning strategies have introduced stronger monotonicity features together with their improved performance on challenge sets. </br></br>

<a href='http://arxiv.org/pdf/2111.08279.pdf'>2111.08279</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 9.4689баллов, №15</br>
<b>Keypoint Message Passing for Video-based Person <font color="#be00be">Re-Identification</font></b></br>
Authors: , Chen, Di, Doeri<font color="green">ng, Andr</font>eas, Zhang, Shanshan, Yang, Jian, Gall, Juergen, Schiele, Bernt</br>
  Video-based person <font color="#be00be">re-identification</font> (re-ID) is an important technique in visual <font color="#be00be">surveillance</font> systems which aims to match video snippets of people captured by different cameras. Existing methods are mostly based on convolutional neural networks (CNNs), whose building blocks either process local neighbor pixels at a time, or, when 3D convolutions are used to model temporal information, suffer from the misalignment problem caused by person movement. In this paper, we propose to overcome the limitations of normal convolutions with a human-oriented graph method. Specifically, features located at person joint keypoints are extracted and connected as a spatial-temporal graph. These keypoint features are then updated by message passing from their connected nodes with a graph convolutional network (GCN). During training, the GCN can be attached to any CNN-based person re-ID model to assist representation learning on feature maps, whilst it can be dropped after training for better inference speed. Our method brings significant improvements over the CNN-based baseline model on the MARS dataset with generated person keypoints and a newly annotated dataset: PoseTrackReID. It also defines a new <font color="#00be00">state-of-the-art</font> method in terms of top-1 accuracy and mean average precision in comparison to prior works. </br></br>

<a href='http://arxiv.org/pdf/2112.06809.pdf'>2112.06809</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 8.8853баллов, №16</br>
<b><font color="#be00be">Tracking</font> and Long-Term Identification Using Non-Visual Markers</b></br>
Authors: , Camilleri, Michael P. J., Zhang, Li, <font color="green">Zisserman, A</font>ndrew, Williams, Christopher K. I.</br>
  Our objective is to track and identify mice in a cluttered home-cage environment, as a precursor to automated behaviour recognition for biological research. This is a very challenging problem due to (i) the lack of distinguishing visual features for each mouse, and (ii) the close confines of the scene with constant occlusion, making standard visual <font color="#be00be">tracking</font> approaches unusable. However, a coarse estimate of each mouse\'s location is available from a unique RFID implant, so there is the potential to optimally combine information from (weak) tracking with coarse information on identity.   To achieve our objective, we make the following key contributions: (a) the formulation of the identification problem as an assignment problem (solved using Integer Linear Programming), and (b) a novel probabilistic model of the affinity between tracklets and RFID data. The latter is a crucial part of the model, as it provides a principled probabilistic treatment of <font color="#be00be">object detection</font>s given coarse localisation. Our approach achieves 77% accuracy on this identification problem, and is able to reject spurious detections when the animals are hidden. </br></br>

<a href='http://arxiv.org/pdf/2112.08654.pdf'>2112.08654</a> &nbsp&nbsp (cs:ML, cs:CV) &nbsp&nbsp 6.7157баллов, №17</br>
<b>Learning to Prompt for Continual Learning</b></br>
Authors: , Wang, Zifeng, Zhang, Zizhao, Lee, Chen-Yu, Zhang, Han, Sun, Ruoxi, Ren, Xiaoqi, Su, Guolong, Perot, Vincent, Dy, Jennifer, Pfister, Tomas</br>
  The mainstream paradigm behind continual learning has been to adapt the model parameters to non-stationary data distributions, where catastrophic forgetting is the central challenge. Typical methods rely on a rehearsal buffer or known task identity at test time to retrieve learned knowledge and address forgetting, while this work presents a new paradigm for continual learning that aims to train a more succinct memory system without accessing task identity at test time. Our method learns to dynamically prompt (L2P) a pre-trained model to learn tasks sequentially under different task transitions. In our proposed framework, prompts are small learnable parameters, which are maintained in a memory space. The objective is to optimize prompts to instruct the model prediction and explicitly manage task-invariant and task-specific knowledge while maintaining model plasticity. We conduct comprehensive experiments under popular image classification benchmarks with different challenging continual learning settings, where L2P consistently <font color="#00be00">outperform</font>s prior <font color="#00be00">state-of-the-art</font> methods. <font color="#00be00">Surprisin</font>gly, L2P achieves <font color="#960096">competitive</font> results against rehearsal-based methods even without a rehearsal buffer and is directly applicable to challenging task-agnostic continual learning. <font color="#00be00">Source code</font> is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/<font color="#00be00">google</font>-research/l2p. </br></br>

<a href='http://arxiv.org/pdf/2112.05493.pdf'>2112.05493</a> &nbsp&nbsp (cs:ML, cs:CV) &nbsp&nbsp 4.9437баллов, №18</br>
<b>Network Compression via Central Filter</b></br>
Authors: , Duan, Yuanzhi, Hu, Xiaofang, Zhou, Yue, Liu, Qiang, Duan, Shukai</br>
  Neural network pruning has remarkable performance for reducing the complexity of deep network models. Recent network pruning methods usually focused on removing unimportant or redundant filters in the network. In this paper, by exploring the similarities between feature maps, we propose a novel filter pruning method, Central Filter (CF), which suggests that a filter is approximately equal to a set of other filters after appropriate adjustments. Our method is based on the discovery that the average similarity between feature maps changes very little, regardless of the number of input images. Based on this finding, we establish similarity graphs on feature maps and calculate the closeness centrality of each node to select the Central Filter. Moreover, we design a method to directly adjust weights in the next layer corresponding to the Central Filter, effectively minimizing the error caused by pruning. Through experiments on various benchmark networks and datasets, CF yields <font color="#00be00">state-of-the-art</font> performance. For example, with ResNet-56, CF reduces approximately 39.7% of FLOPs by removing 47.1% of the parameters, with even 0.33% accuracy improvement on CIFAR-10. With <font color="#00be00">GoogLe</font>Net, CF reduces approximately 63.2% of FLOPs by removing 55.6% of the parameters, with only a small loss of 0.35% in top-1 accuracy on CIFAR-10. With ResNet-50, CF reduces approximately 47.9% of FLOPs by removing 36.9% of the parameters, with only a small loss of 1.07% in top-1 accuracy on ImageNet. The codes can be available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/8ubpshLR23/Central-Filter. </br></br>

<a href='http://arxiv.org/pdf/2112.08191.pdf'>2112.08191</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 4.7975баллов, №19</br>
<b>Lesan -- Machine Translation for Low Resource Languages</b></br>
Authors: , Hadgu, Asmelash Teka, Aregawi, Abel, Beaudoin, Adam</br>
  Millions of people around the world can not access content on the Web because most of the content is not readily available in their language. Machine translation (MT) systems have the potential to change this for many languages. Current MT systems provide very accurate results for high resource language pairs, e.g., German and English. However, for many low resource languages, MT is still under active research. The key challenge is lack of datasets to build these systems. We present Lesan, an MT system for low resource languages. Our pipeline solves the key bottleneck to low resource MT by leveraging online and offline sources, a custom OCR system for Ethiopic and an automatic alignment module. The final step in the pipeline is a sequence to sequence model that takes parallel corpus as input and gives us a translation model. Lesan\'s translation model is based on the <font color="#00be00">Transformer</font> architecture. After constructing a base model, back translation, is used to leverage monolingual corpora. Currently Lesan supports translation to and from Tigrinya, Amharic and English. We perform extensive human evaluation and show that Lesan <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> systems such as <font color="#00be00">Google</font> Translate and Microsoft Translator across all six pairs. Lesan is freely available and has served more than 10 million translations so far. At the moment, there are only 217 Tigrinya and 15,009 Amharic Wikipedia articles. We believe that Lesan will contribute towards democratizing access to the Web through MT for millions of people. </br></br>

<a href='http://arxiv.org/pdf/2112.07031.pdf'>2112.07031</a> &nbsp&nbsp (cs:ML, cs:RO) &nbsp&nbsp 4.2874баллов, №20</br>
<b>Teaching a Robot to Walk Using <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Dibachi, Jack, Azoulay, Jacob</br>
  Classical control techniques such as PID and LQR have been used effectively in maintaining a system state, but these techniques become more difficult to implement when the model dynamics increase in complexity and sensitivity. For adaptive robotic locomotion tasks with several degrees of freedom, this task becomes infeasible with classical control techniques. Instead, <font color="#00be00">reinforcement learning</font> can train optimal walking policies with ease. We apply deep Q-learning and augmented random search (ARS) to teach a simulated two-dimensional bipedal robot how to walk using the <font color="#00be00">OpenAI</font> Gym BipedalWalker-v3 environment. Deep Q-learning did not yield a high reward policy, often prematurely converging to suboptimal local maxima likely due to the coarsely discretized action space. ARS, however, resulted in a better trained robot, and produced an optimal policy which officially &quot;solves&quot; the BipedalWalker-v3 problem. Various naive policies, including a random policy, a manually encoded inch forward policy, and a stay still policy, were used as benchmarks to evaluate the proficiency of the learning algorithm results. </br></br>

<a href='http://arxiv.org/pdf/2112.07011.pdf'>2112.07011</a> &nbsp&nbsp (cs:CL, cs:SD) &nbsp&nbsp 4.0207баллов, №21</br>
<b>Event Based Time-Vectors for auditory features extraction: a\n  neuromorphic approach for low power audio recognition</b></br>
Authors: , Rasetto, Marco, Dominguez-Morales, Juan P., Jimenez-Fernandez, Angel, Benosman, Ryad</br>
  In recent years tremendous efforts have been done to advance the <font color="#00be00">state of the art</font> for Natural Language Processing (NLP) and audio recognition. However, these efforts often translated in increased power consumption and memory requirements for bigger and more complex models. These solutions falls short of the constraints of IoT devices which need low power, low memory efficient computation, and therefore they fail to meet the growing demand of efficient edge computing. Neuromorphic systems have proved to be excellent candidates for low-power low-latency computation in a multitude of applications. For this reason we present a neuromorphic architecture, capable of unsupervised auditory feature recognition. We then validate the network on a subset of <font color="#00be00">Google</font>\'s Speech Commands dataset. </br></br>

<a href='http://arxiv.org/pdf/2112.08643.pdf'>2112.08643</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 3.6227баллов, №22</br>
<b>TransZero++: Cross Attribute-Guided <font color="#00be00">Transformer</font> for <font color="#00be00">Zero-Shot</font> Learning</b></br>
Authors: , Chen, Shiming, Hong, Ziming, Xie, Guo-Sen, Zhao, Jian, You, Xinge, Yan, Shuicheng, Shao, Ling</br>
  <font color="#00be00">Zero-shot</font> learning (ZSL) tackles the novel class recognition problem by transferring semantic knowledge from seen classes to unseen ones. Existing attention-based models have struggled to learn inferior region features in a single image by solely using unidirectional attention, which ignore the transferability and discriminative attribute localization of visual features. In this paper, we propose a cross attribute-guided <font color="#00be00">Transformer</font> network, termed TransZero++, to refine visual features and learn accurate attribute localization for semantic-augmented visual embedding representations in ZSL. TransZero++ consists of an attribute$\\rightarrow$visual Transformer sub-net (AVT) and a visual$\\rightarrow$attribute Transformer sub-net (VAT). Specifically, AVT first takes a feature augmentation encoder to alleviate the cross-dataset problem, and improves the transferability of visual features by reducing the entangled relative geometry relationships among region features. Then, an attribute$\\rightarrow$visual decoder is employed to localize the image regions most relevant to each attribute in a given image for attribute-based visual feature representations. Analogously, VAT uses the similar feature augmentation encoder to refine the visual features, which are further applied in visual$\\rightarrow$attribute decoder to learn visual-based attribute features. By further introducing semantical collaborative losses, the two attribute-guided transformers teach each other to learn semantic-augmented visual embeddings via semantical collaborative learning. Extensive experiments show that TransZero++ achieves the new <font color="#00be00">state-of-the-art</font> results on three challenging ZSL benchmarks. The codes are available at: \\url{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/shiming-chen/TransZero_pp}. </br></br>

<a href='http://arxiv.org/pdf/2112.07899.pdf'>2112.07899</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 3.5765баллов, №23</br>
<b>Large Dual Encoders Are Generalizable Retrievers</b></br>
Authors: , Ni, Jianmo, Qu, Chen, Lu, Jing, Dai, Zhuyun, &#xc1;brego, Gustavo Hern&#xe1;ndez, Ma, Ji, Zhao, Vincent Y., Luan, Yi, Hall, Keith B., Chang, Ming-Wei, Yang, Yinfei</br>
  It has been shown that dual encoders trained on one domain often fail to generalize to other domains for <font color="#be00be">retrieval</font> tasks. One widespread belief is that the bottleneck layer of a dual encoder, where the final score is simply a dot-product between a query vector and a passage vector, is too limited to make dual encoders an effective retrieval model for out-of-domain generalization. In this paper, we challenge this belief by scaling up the size of the dual encoder model {\\em while keeping the bottleneck embedding size fixed.} With multi-stage training, <font color="#00be00">surprisin</font>gly, scaling up the model size brings significant improvement on a variety of retrieval tasks, especially for out-of-domain generalization. Experimental results show that our dual encoders, \\textbf{G}eneralizable \\textbf{T}5-based dense \\textbf{R}etrievers (GTR), <font color="#00be00">outperform</font> %ColBERT~\\cite{khattab2020colbert} and existing sparse and dense retrievers on the BEIR dataset~\\cite{thakur2021beir} significantly. Most surprisingly, our ablation study finds that GTR is very data efficient, as it only needs 10\\% of MS Marco supervised data to achieve the best out-of-domain performance. All the GTR models are released at <font color="#006400">http</font>s://tfhub.dev/<font color="#00be00">google</font>/collections/gtr/1. </br></br>

<a href='http://arxiv.org/pdf/2112.06018.pdf'>2112.06018</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 3.5733баллов, №24</br>
<b>Control-Tutored <font color="#00be00">Reinforcement Learning</font>: Towards the Integration of\n  Data-Driven and Model-Based Control</b></br>
Authors: , De Lellis, F., Coraggio, M., Russo, G., Musolesi, M., di Bernardo, M.</br>
  We present an architecture where a feedback controller derived on an approximate model of the environment assists the learning process to enhance its data efficiency. This architecture, which we term as Control-Tutored Q-learning (CTQL), is presented in two alternative flavours. The former is based on defining the reward function so that a Boolean condition can be used to determine when the control tutor policy is adopted, while the latter, termed as probabilistic CTQL (pCTQL), is instead based on executing calls to the tutor with a certain probability during learning. Both approaches are validated, and thoroughly benchmarked against Q-Learning, by considering the stabilization of an inverted pendulum as defined in <font color="#00be00">OpenAI</font> Gym as a representative problem. </br></br>

<a href='http://arxiv.org/pdf/2112.06424.pdf'>2112.06424</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 3.5618баллов, №25</br>
<b>A Benchmark for Low-Switching-Cost <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Xu, Shusheng, Liang, Yancheng, Li, Yunfei, Du, Simon Shaolei, Wu, Yi</br>
  A ubiquitous requirement in many practical <font color="#00be00">reinforcement learning</font> (RL) applications, including <font color="#640064">medic</font>al treatment, <font color="#be00be">recommendat</font>ion system, education and robotics, is that the deployed policy that actually interacts with the environment cannot change frequently. Such an RL setting is called low-switching-cost RL, i.e., achieving the highest reward while reducing the number of policy switches during training. Despite the recent trend of <font color="#be00be">theor</font>etical studies aiming to design provably efficient RL algorithms with low switching costs, none of the existing approaches have been thoroughly evaluated in popular RL testbeds. In this paper, we systematically studied a wide collection of policy-switching approaches, including theoretically guided criteria, policy-difference-based methods, and non-adaptive baselines. Through extensive experiments on a medical treatment environment, the Atari games, and robotic control tasks, we present the first empirical benchmark for low-switching-cost RL and report novel findings on how to decrease the switching cost while maintain a similar <font color="#00be00">sample efficien</font>cy to the case without the low-switching-cost constraint. We hope this benchmark could serve as a starting point for developing more practically effective low-switching-cost RL algorithms. We release our code and complete results in <font color="#006400">http</font>s://sites.<font color="#00be00">google</font>.com/view/low-switching-cost-rl. </br></br>

<a href='http://arxiv.org/pdf/2112.08647.pdf'>2112.08647</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 3.5362баллов, №26</br>
<b>QAHOI: Query-Based Anchors for Human-Object Interaction Detection</b></br>
Authors: , Chen, Junwen, Yanai, Keiji</br>
  Human-object interaction (HOI) detection as a downstream of <font color="#be00be">object detection</font> tasks requires localizing pairs of humans and objects and extracting the semantic relationships between humans and objects from an image. Recently, one-stage approaches have become a new trend for this task due to their high efficiency. However, these approaches focus on detecting possible interaction points or filtering human-object pairs, ignoring the variability in the location and size of different objects at spatial scales. To address this problem, we propose a <font color="#00be00">transformer</font>-based method, QAHOI (Query-Based Anchors for Human-Object Interaction detection), which leverages a multi-scale architecture to extract features from different spatial scales and uses query-based anchors to predict all the elements of an HOI instance. We further investigate that a powerful backbone significantly increases accuracy for QAHOI, and QAHOI with a transformer-based backbone <font color="#00be00">outperform</font>s recent <font color="#00be00">state-of-the-art</font> methods by large margins on the HICO-DET benchmark. The <font color="#00be00">source code</font> is available at $\\href{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/cjw2021/QAHOI}{\\text{this https URL}}$. </br></br>

<a href='http://arxiv.org/pdf/2112.06658.pdf'>2112.06658</a> &nbsp&nbsp (cs:ML, cs:CV) &nbsp&nbsp 3.5080баллов, №27</br>
<b>Learning to Learn Transferable Attack</b></br>
Authors: , Fang, Shuman, Li, Jie, Lin, Xianming, Ji, Rongrong</br>
  Transfer <font color="#be00be">adversarial att</font>ack is a non-trivial black-box adversarial attack that aims to craft adversarial perturbations on the surrogate model and then apply such perturbations to the victim model. However, the transferability of perturbations from existing methods is still limited, since the adversarial perturbations are easily overfitting with a single surrogate model and specific data pattern. In this paper, we propose a Learning to Learn Transferable Attack (LLTA) method, which makes the adversarial perturbations more generalized via learning from both data and model augmentation. For data augmentation, we adopt simple random resizing and padding. For model augmentation, we randomly alter the back propagation instead of the forward propagation to eliminate the effect on the model prediction. By treating the attack of both specific data and a modified model as a task, we expect the adversarial perturbations to adopt enough tasks for generalization. To this end, the meta-learning algorithm is further introduced during the iteration of perturbation generation. Empirical results on the widely-used dataset demonstrate the effectiveness of our attack method with a 12.85% higher success rate of transfer attack compared with the <font color="#00be00">state-of-the-art</font> methods. We also evaluate our method on the <font color="#009600">real-world</font> online system, i.e., <font color="#00be00">Google</font> Cloud Vision API, to further show the practical potentials of our method. </br></br>

<a href='http://arxiv.org/pdf/2112.05230.pdf'>2112.05230</a> &nbsp&nbsp (cs:CV, cs:CL) &nbsp&nbsp 3.4474баллов, №28</br>
<b>Injecting Semantic Concepts into End-to-End Image Captioning</b></br>
Authors: , Fang, Zhiyuan, Wang, Jianfeng, Hu, Xiaowei, Liang, Lin, Gan, Zhe, Wang, Lijuan, Yang, Yezhou, Liu, Zicheng</br>
  Tremendous progress has been made in recent years in developing better image captioning models, yet most of them rely on a separate object detector to extract regional features. Recent vision-language studies are shifting towards the detector-free trend by leveraging grid representations for more flexible model training and faster inference speed. However, such development is primarily focused on image understanding tasks, and remains less investigated for the caption generation task. In this paper, we are concerned with a better-performing detector-free image captioning model, and propose a pure vision <font color="#00be00">transformer</font>-based image captioning model, dubbed as ViTCAP, in which grid representations are used without extracting the regional features. For improved performance, we introduce a novel Concept Token Network (CTN) to predict the semantic concepts and then incorporate them into the end-to-end captioning. In particular, the CTN is built on the basis of a vision transformer and is designed to predict the concept tokens through a classification task, from which the rich semantic information contained greatly benefits the captioning task. Compared with the previous detector-based models, ViTCAP drastically simplifies the architectures and at the same time achieves <font color="#960096">competitive</font> performance on various challenging image captioning datasets. In particular, ViTCAP reaches 138.1 CIDEr scores on COCO-caption Karpathy-split, 93.8 and 108.6 CIDEr scores on nocaps, and <font color="#00be00">Google</font>-CC captioning datasets, respectively. </br></br>

<a href='http://arxiv.org/pdf/2112.08117.pdf'>2112.08117</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 3.4468баллов, №29</br>
<b>Vision <font color="#00be00">Transformer</font> Based Video Hashing <font color="#be00be">Retrieval</font> for Tracing the Source\n  of Fake Videos</b></br>
Authors: , Pei, Pengfei, Zhao, Xianfeng, Li, Jinchuan, Cao, Yun, Yi, Xiaowei</br>
  Conventional fake video detection methods outputs a possibility value or a suspected mask of tampering images. However, such unexplainable results cannot be used as convincing evidence. So it is better to trace the sources of fake videos. The traditional hashing methods are used to retrieve semantic-similar images, which can\'t discriminate the nuances of the image. Specifically, the sources tracing compared with traditional video <font color="#be00be">retrieval</font>. It is a challenge to find the real one from similar source videos. We designed a novel loss Hash Triplet Loss to solve the problem that the videos of people are very similar: the same scene with different angles, similar scenes with the same person. We propose Vision <font color="#00be00">Transformer</font> based models named Video Tracing and Tampering Localization (VTL). In the first stage, we train the hash centers by ViTHash (VTL-T). Then, a fake video is inputted to ViTHash, which outputs a hash code. The hash code is used to retrieve the source video from hash centers. In the second stage, the source video and fake video are inputted to generator (VTL-L). Then, the suspect regions are masked to provide auxiliary information. Moreover, we constructed two datasets: DFTL and DAVIS2016-TL. Experiments on DFTL clearly show the superiority of our framework in sources tracing of similar videos. In particular, the VTL also achieved comparable performance with <font color="#00be00">state-of-the-art</font> methods on DAVIS2016-TL. Our <font color="#00be00">source code</font> and datasets have been released on <font color="#00be00">GitHub</font>: \\url{<font color="#006400">http</font>s://github.com/lajlksdf/vtl}. </br></br>

<a href='http://arxiv.org/pdf/2112.08932.pdf'>2112.08932</a> &nbsp&nbsp (cs:ML, cs:AI, cs:RO) &nbsp&nbsp 3.3775баллов, №30</br>
<b>Learning from Guided Play: A Scheduled <font color="#00be00">Hierarchical</font> Approach for\n  Improving Exploration in Adversarial Imitation Learning</b></br>
Authors: , Ablett, Trevor, Chan, Bryan, Kelly, Jonathan</br>
  Effective exploration continues to be a significant challenge that prevents the deployment of <font color="#00be00">reinforcement learning</font> for many physical systems. This is particularly true for systems with continuous and high-dimensional state and action spaces, such as robotic manipulators. The challenge is accentuated in the <font color="#00be00">sparse reward</font>s setting, where the low-level state information required for the design of dense rewards is unavailable. Adversarial imitation learning (AIL) can partially overcome this barrier by leveraging expert-generated demonstrations of optimal behaviour and providing, essentially, a replacement for dense reward information. Unfortunately, the availability of expert demonstrations does not necessarily improve an agent\'s capability to explore effectively and, as we empirically show, can lead to inefficient or stagnated learning. We present Learning from Guided Play (LfGP), a framework in which we leverage expert demonstrations of, in addition to a main task, multiple auxiliary tasks. Subsequently, a <font color="#00be00">hierarchical</font> model is used to learn each task reward and policy through a modified AIL procedure, in which exploration of all tasks is enforced via a scheduler composing different tasks together. This affords many benefits: learning efficiency is improved for main tasks with challenging bottleneck transitions, expert data becomes reusable between tasks, and transfer learning through the reuse of learned auxiliary task models becomes possible. Our experimental results in a challenging multitask robotic manipulation domain indicate that our method compares favourably to supervised imitation learning and to a <font color="#00be00">state-of-the-art</font> AIL method. Code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/utiasSTARS/lfgp. </br></br>

<a href='http://arxiv.org/pdf/2112.07620.pdf'>2112.07620</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 3.3248баллов, №31</br>
<b>Tree-based Focused Web Crawling with <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Kontogiannis, Andreas, Kelesis, Dimitrios, Pollatos, Vasilis, Paliouras, Georgios, Giannakopoulos, George</br>
  A focused crawler aims at discovering as many web pages relevant to a target topic as possible, while avoiding irrelevant ones; i.e. maximizing the harvest rate. <font color="#00be00">Reinforcement Learning</font> (RL) has been utilized to optimize the crawling process, yet it deals with huge state and action spaces, which can constitute a serious challenge. In this paper, we propose TRES, an end-to-end RL-empowered framework for focused crawling. Unlike other approaches, we properly model a crawling environment as a Markov Decision Process, by representing the state as a subgraph of the Web and actions as its expansion edges. TRES adopts a keyword expansion strategy based on the cosine similarity of keyword embeddings. To learn a reward function, we propose a deep neural network, called KwBiLSTM, leveraging the discovered keywords. To reduce the time complexity of selecting a best action, we propose Tree-Frontier, a two-fold decision tree, which also speeds up training by discretizing the state and action spaces. Experimentally, we show that TRES <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> methods in terms of harvest rate by at least 58%, while it has <font color="#960096">competitive</font> results in the domain maximization. Our implementation code can be found on <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/ddaedalus/TRES. </br></br>

<a href='http://arxiv.org/pdf/2112.07746.pdf'>2112.07746</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 3.3145баллов, №32</br>
<b>CEM-GD: Cross-Entropy Method with Gradient Descent Planner for\n  Model-Based <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Huang, Kevin, Lale, Sahin, Rosolia, Ugo, Shi, Yuanyuan, Anandkumar, Anima</br>
  Current <font color="#00be00">state-of-the-art</font> model-based <font color="#00be00">reinforcement learning</font> algorithms use trajectory sampling methods, such as the Cross-Entropy Method (CEM), for planning in continuous control settings. These zeroth-order optimizers require sampling a large number of trajectory rollouts to select an optimal action, which scales poorly for large prediction horizons or high dimensional action spaces. First-order methods that use the gradients of the rewards with respect to the actions as an update can mitigate this issue, but suffer from local optima due to the non-convex optimization landscape. To overcome these issues and achieve the best of both worlds, we propose a novel planner, Cross-Entropy Method with Gradient Descent (CEM-GD), that combines first-order methods with CEM. At the beginning of execution, CEM-GD uses CEM to sample a significant amount of trajectory rollouts to explore the optimization landscape and avoid poor local minima. It then uses the top trajectories as initialization for gradient descent and applies gradient updates to each of these trajectories to find the optimal action sequence. At each subsequent time step, however, CEM-GD samples much fewer trajectories from CEM before applying gradient updates. We show that as the dimensionality of the planning problem increases, CEM-GD maintains desirable performance with a constant small number of samples by using the gradient information, while avoiding local optima using initially well-sampled trajectories. Furthermore, CEM-GD achieves better performance than CEM on a variety of continuous control benchmarks in <font color="#006400">MuJoCo</font> with 100x fewer samples per time step, resulting in around 25% less computation time and 10% less memory usage. The implementation of CEM-GD is available at $\\href{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/KevinHuang8/CEM-GD}{\\text{https://github.com/KevinHuang8/CEM-GD}}$. </br></br>

<a href='http://arxiv.org/pdf/2112.07374.pdf'>2112.07374</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 3.2657баллов, №33</br>
<b>Geometry-Contrastive <font color="#00be00">Transformer</font> for Generalized 3D Pose Transfer</b></br>
Authors: , Chen, Haoyu, Tang, Hao, Yu, Zitong, Sebe, Nicu, Zhao, Guoying</br>
  We present a customized 3D mesh <font color="#00be00">Transformer</font> model for the pose transfer task. As the 3D pose transfer essentially is a deformation procedure dependent on the given meshes, the intuition of this work is to perceive the geometric inconsistency between the given meshes with the powerful self-attention mechanism. Specifically, we propose a novel geometry-contrastive Transformer that has an efficient 3D structured perceiving ability to the global geometric inconsistencies across the given meshes. Moreover, locally, a simple yet efficient central geodesic contrastive loss is further proposed to improve the regional geometric-inconsistency learning. At last, we present a latent isometric regularization module together with a novel semi-synthesized dataset for the cross-dataset 3D pose transfer task towards unknown spaces. The massive experimental results prove the efficacy of our approach by showing <font color="#00be00">state-of-the-art</font> quantitative performances on SMPL-NPT, FAUST and our new proposed dataset SMG-3D datasets, as well as promising qualitative results on MG-cloth and SMAL datasets. It\'s demonstrated that our method can achieve robust 3D pose transfer and be generalized to challenging meshes from unknown spaces on cross-dataset tasks. The code and dataset are made available. Code is available: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/mikecheninoulu/CGT. </br></br>

<a href='http://arxiv.org/pdf/2112.06782.pdf'>2112.06782</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 3.2118баллов, №34</br>
<b>GCNDepth: Self-supervised Monocular Depth Estimation based on Graph\n  Convolutional Network</b></br>
Authors: , Masoumian, Armin, Rashwan, Hatem A., Abdulwahab, Saddam, Cristiano, Julian, Puig, Domenec</br>
  Depth estimation is a challenging task of 3D reconstruction to enhance the accuracy sensing of environment awareness. This work brings a new solution with a set of improvements, which increase the quantitative and qualitative understanding of depth maps compared to existing methods. Recently, a convolutional neural network (CNN) has demonstrated its extraordinary ability in estimating depth maps from monocular videos. However, traditional CNN does not support topological structure and they can work only on regular image regions with determined size and weights. On the other hand, graph convolutional networks (GCN) can handle the convolution on non-Euclidean data and it can be applied to irregular image regions within a topological structure. Therefore, in this work in order to preserve object geometric appearances and distributions, we aim at exploiting GCN for a self-supervised depth estimation model. Our model consists of two parallel auto-encoder networks: the first is an auto-encoder that will depend on ResNet-50 and extract the feature from the input image and on multi-scale GCN to estimate the depth map. In turn, the second network will be used to estimate the ego-motion vector (i.e., 3D pose) between two consecutive frames based on ResNet-18. Both the estimated 3D pose and depth map will be used for constructing a target image. A combination of loss functions related to photometric, projection, and smoothness is used to cope with bad depth prediction and preserve the discontinuities of the objects. In particular, our method provided comparable and promising results with a high prediction accuracy of 89% on the publicly KITTI and Make3D datasets along with a reduction of 40% in the number of trainable parameters compared to the <font color="#00be00">state of the art</font> solutions. The <font color="#00be00">source code</font> is <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/ArminMasoumian/GCNDepth.git </br></br>

<a href='http://arxiv.org/pdf/2112.05999.pdf'>2112.05999</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 3.1642баллов, №35</br>
<b>Curvature-guided dynamic scale networks for Multi-view Stereo</b></br>
Authors: , Giang, Khang Truong, Song, Soohwan, Jo, Sungho</br>
  Multi-view stereo (MVS) is a crucial task for precise 3D reconstruction. Most recent studies tried to improve the performance of matching cost volume in MVS by designing aggregated 3D cost volumes and their regularization. This paper focuses on learning a robust feature extraction network to enhance the performance of matching costs without heavy computation in the other steps. In particular, we present a dynamic scale feature extraction network, namely, CDSFNet. It is composed of multiple novel convolution layers, each of which can select a proper patch scale for each pixel guided by the normal curvature of the image surface. As a result, CDFSNet can estimate the optimal patch scales to learn discriminative features for accurate matching computation between reference and source images. By combining the robust extracted features with an appropriate cost formulation strategy, our resulting MVS architecture can estimate depth maps more precisely. Extensive experiments showed that the proposed method <font color="#00be00">outperform</font>s other <font color="#00be00">state-of-the-art</font> methods on complex outdoor scenes. It significantly improves the completeness of reconstructed models. As a result, the method can process higher resolution inputs within faster run-time and lower memory than other MVS methods. Our <font color="#00be00">source code</font> is available at url{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/TruongKhang/cds-mvsnet}. </br></br>

<a href='http://arxiv.org/pdf/2112.07156.pdf'>2112.07156</a> &nbsp&nbsp (cs:ML, cs:SD) &nbsp&nbsp 3.1058баллов, №36</br>
<b>ImportantAug: a data augmentation agent for speech</b></br>
Authors: , Trinh, Viet Anh, Kavaki, Hassan Salami, Mandel, Michael I</br>
  We introduce ImportantAug, a technique to augment training data for speech classification and recognition models by adding noise to unimportant regions of the speech and not to important regions. Importance is predicted for each utterance by a data augmentation agent that is trained to maximize the amount of noise it adds while minimizing its impact on recognition performance. The effectiveness of our method is illustrated on version two of the <font color="#00be00">Google</font> Speech Commands (GSC) dataset. On the standard GSC test set, it achieves a 23.3% relative error rate reduction compared to conventional noise augmentation which applies noise to speech without regard to where it might be most effective. It also provides a 25.4% error rate reduction compared to a baseline without data augmentation. Additionally, the proposed ImportantAug <font color="#00be00">outperform</font>s the conventional noise augmentation and the baseline on two test sets with additional noise added. </br></br>

<a href='http://arxiv.org/pdf/2112.06103.pdf'>2112.06103</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 3.0759баллов, №37</br>
<b>Improving Vision <font color="#00be00">Transformer</font>s for Incremental Learning</b></br>
Authors: , Yu, Pei, Chen, Yinpeng, Jin, Ying, Liu, Zicheng</br>
  This paper studies using Vision <font color="#00be00">Transformer</font>s (ViT) in class incremental learning. <font color="#00be00">Surprisin</font>gly, naive application of ViT to replace convolutional neural networks (CNNs) results in performance degradation. Our analysis reveals three issues of naively using ViT: (a) ViT has very slow convergence when class number is small, (b) more bias towards new classes is observed in ViT than CNN-based models, and (c) the proper learning rate of ViT is too low to learn a good classifier. Base on this analysis, we show these issues can be simply addressed by using existing techniques: using convolutional stem, balanced finetuning to correct bias, and higher learning rate for the classifier. Our simple solution, named ViTIL (ViT for Incremental Learning), achieves the new <font color="#00be00">state-of-the-art</font> for all three class incremental learning setups by a clear margin, providing a strong baseline for the research community. For instance, on ImageNet-1000, our ViTIL achieves 69.20% top-1 accuracy for the protocol of 500 initial classes with 5 incremental steps (100 new classes for each), <font color="#00be00">outperform</font>ing LUCIR+DDE by 1.69%. For more challenging protocol of 10 incremental steps (100 new classes), our method outperforms PODNet by 7.27% (65.13% vs. 57.86%). </br></br>

<a href='http://arxiv.org/pdf/2112.08326.pdf'>2112.08326</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 2.9451баллов, №38</br>
<b>Is &quot;my favorite new movie&quot; my favorite movie? Probing the Understanding\n  of Recursive Noun Phrases</b></br>
Authors: , Lyu, Qing, Zheng, Hua, Li, Daoxin, Zhang, Li, Apidianaki, Marianna, Callison-Burch, Chris</br>
  Recursive noun phrases (NPs) have interesting semantic properties. For example, &quot;my favorite new movie&quot; is not necessarily &quot;my favorite movie&quot;, whereas &quot;my new favorite movie&quot; is. This is common sense to humans, yet it is unknown whether pre-trained language models have such knowledge. We introduce the Recursive Noun Phrase Challenge (RNPC), a challenge set targeting the understanding of recursive NPs. When evaluated on our dataset, <font color="#00be00">state-of-the-art</font> <font color="#00be00">Transformer</font> models only achieve around chance performance. Still, we show that such knowledge is learnable with appropriate data. We further probe the models for relevant linguistic features that can be learned from our tasks, including modifier semantic category and modifier scope. Finally, models trained on RNPC achieve strong <font color="#00be00">zero-shot</font> performance on an extrinsic Harm Detection task, showing the usefulness of the understanding of recursive NPs in downstream applications. All code and data will be released at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/veronica320/Recursive-NPs. </br></br>

<a href='http://arxiv.org/pdf/2112.09097.pdf'>2112.09097</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp 2.8520баллов, №39</br>
<b>Learning and Analyzing Generation Order for Undirected Sequence Models</b></br>
Authors: , Jiang, Yichen, Bansal, Mohit</br>
  Undirected neural sequence models have achieved performance <font color="#960096">competitive</font> with the <font color="#00be00">state-of-the-art</font> directed sequence models that generate monotonically from left to right in machine translation tasks. In this work, we train a policy that learns the generation order for a pre-trained, undirected translation model via <font color="#00be00">reinforcement learning</font>. We show that the translations decoded by our learned orders achieve higher BLEU scores than the outputs decoded from left to right or decoded by the learned order from Mansimov et al. (2019) on the WMT\'14 German-English translation task. On examples with a maximum source and target length of 30 from De-En, WMT\'16 English-Romanian, and WMT\'21 English-<font color="#be00be">Chinese</font> translation tasks, our learned order <font color="#00be00">outperform</font>s all heuristic generation orders on four out of six tasks. We next carefully analyze the learned order patterns via qualitative and quantitative analysis. We show that our policy generally follows an outer-to-inner order, predicting the left-most and right-most positions first, and then moving toward the middle while skipping less important words at the beginning. Furthermore, the policy usually predicts positions for a single syntactic constituent structure in consecutive steps. We believe our findings could provide more insights on the mechanism of undirected generation models and encourage further research in this direction. Our code is <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/jiangycTarheel/undirected-generation </br></br>

<a href='http://arxiv.org/pdf/2111.00210.pdf'>2111.00210</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV, cs:RO) &nbsp&nbsp 2.7696баллов, №40</br>
<b>Mastering Atari Games with Limited Data</b></br>
Authors: , Ye, Weirui, Liu, Shaohuai, Kurutach, Thanard, Abbeel, Pieter, Gao, Yang</br>
  <font color="#00be00">Reinforcement learning</font> has achieved great success in many applications. However, <font color="#00be00">sample efficien</font>cy remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. Recently, there has been significant progress in sample efficient image-based RL algorithms; however, consistent <font color="#00be00">human-level</font> performance on the Atari game benchmark remains an elusive goal. We propose a sample efficient model-based visual RL algorithm built on MuZero, which we name EfficientZero. Our method achieves 194.3% mean human performance and 109.0% median performance on the Atari 100k benchmark with only two hours of real-time game experience and <font color="#00be00">outperform</font>s the state SAC in some tasks on the DMControl 100k benchmark. This is the first time an algorithm achieves super-human performance on Atari games with such little data. EfficientZero\'s performance is also close to DQN\'s performance at 200 million frames while we consume 500 times less data. EfficientZero\'s low sample complexity and high performance can bring RL closer to <font color="#009600">real-world</font> applicability. We implement our algorithm in an easy-to-understand manner and it is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/YeWR/EfficientZero. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community. </br></br>

<a href='http://arxiv.org/pdf/2112.08366.pdf'>2112.08366</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 2.7246баллов, №41</br>
<b>AGMI: Attention-Guided Multi-omics Integration for <font color="#00be00">Drug</font> Response\n  Prediction with Graph Neural Networks</b></br>
Authors: , Ruiwei, Feng, Yufeng, Xie, Minshan, Lai, Danny, Chen, Ji, Cao, Jian, Wu</br>
  Accurate <font color="#00be00">drug</font> response prediction (DRP) is a crucial yet challenging task in precision <font color="#640064">medic</font>ine. This paper presents a novel Attention-Guided Multi-omics Integration (AGMI) approach for DRP, which first constructs a Multi-edge Graph (MeG) for each cell line, and then aggregates multi-omics features to predict drug response using a novel structure, called Graph edge-aware Network (GeNet). For the first time, our AGMI approach explores gene constraint based multi-omics integration for DRP with the whole-genome using GNNs. Empirical experiments on the CCLE and GDSC datasets show that our AGMI largely <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> DRP methods by 8.3%--34.2% on four metrics. Our data and code are available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/yivan-WYYGDSG/AGMI. </br></br>

<a href='http://arxiv.org/pdf/2112.08340.pdf'>2112.08340</a> &nbsp&nbsp (cs:CL, cs:ML, stat:ML) &nbsp&nbsp 2.7081баллов, №42</br>
<b>GenIE: Generative Information Extraction</b></br>
Authors: , Josifoski, Martin, De Cao, Nicola, Peyrard, Maxime, West, Robert</br>
  Structured and grounded representation of text is typically formalized by closed information extraction, the problem of extracting an exhaustive set of (subject, relation, object) triplets that are consistent with a predefined set of entities and relations from a knowledge base schema. Most existing works are pipelines prone to error accumulation, and all approaches are only applicable to unrealistically small numbers of entities and relations. We introduce GenIE (generative information extraction), the first end-to-end autoregressive formulation of closed information extraction. GenIE naturally exploits the language knowledge from the pre-trained <font color="#00be00">transformer</font> by autoregressively generating relations and entities in textual form. Thanks to a new bi-level constrained generation strategy, only triplets consistent with the predefined knowledge base schema are produced. Our experiments show that GenIE is <font color="#00be00">state-of-the-art</font> on closed information extraction, generalizes from fewer training data points than baselines, and scales to a previously unmanageable number of entities and relations. With this work, closed information extraction becomes practical in realistic scenarios, providing new opportunities for downstream tasks. Finally, this work paves the way towards a unified end-to-end approach to the core tasks of information extraction. Code and models available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/epfl-dlab/GenIE. </br></br>

<a href='http://arxiv.org/pdf/2112.06451.pdf'>2112.06451</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 2.7034баллов, №43</br>
<b>Semantically Contrastive Learning for Low-light Image Enhancement</b></br>
Authors: , Liang, Dong, Li, Ling, Wei, Mingqiang, Yang, Shuo, Zhang, Liyan, Yang, Wenhan, Du, Yun, Zhou, Huiyu</br>
  Low-light image enhancement (LLE) remains challenging due to the unfavorable prevailing low-contrast and weak-visibility problems of single RGB images. In this paper, we respond to the intriguing learning-related question -- if leveraging both accessible unpaired over/underexposed images and high-level semantic guidance, can improve the performance of cutting-edge LLE models? Here, we propose an effective semantically contrastive learning paradigm for LLE (namely SCL-LLE). Beyond the existing LLE wisdom, it casts the image enhancement task as multi-task joint learning, where LLE is converted into three constraints of contrastive learning, semantic brightness consistency, and feature preservation for simultaneously ensuring the exposure, texture, and color consistency. SCL-LLE allows the LLE model to learn from unpaired positives (normal-light)/negatives (over/underexposed), and enables it to interact with the scene semantics to regularize the image enhancement network, yet the interaction of high-level semantic knowledge and the low-level signal prior is seldom investigated in previous methods. Training on readily available open data, extensive experiments demonstrate that our method surpasses the <font color="#00be00">state-of-the-art</font>s LLE models over six independent cross-scenes datasets. Moreover, SCL-LLE\'s potential to benefit the downstream semantic <font color="#be00be">segmentation</font> under extremely dark conditions is discussed. <font color="#00be00">Source Code</font>: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/LingLIx/SCL-LLE. </br></br>

<a href='http://arxiv.org/pdf/2112.00342.pdf'>2112.00342</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 2.6531баллов, №44</br>
<b>Confidence Propagation Cluster: Unleash Full Potential of Object\n  Detectors</b></br>
Authors: , Shen, Yichun, Jiang, Wanli, Xu, Zhen, Li, Rundong, Kwon, Junghyun, Li, Siyi</br>
  It has been a long history that most <font color="#be00be">object detection</font> methods obtain objects by using the non-maximum suppression (NMS) and its improved versions like Soft-NMS to remove redundant bounding boxes. We challenge those NMS-based methods from three aspects: 1) The bounding box with highest confidence value may not be the true positive having the biggest overlap with the ground-truth box. 2) Not only suppression is required for redundant boxes, but also confidence enhancement is needed for those true positives. 3) Sorting candidate boxes by confidence values is not necessary so that full parallelism is achievable.   In this paper, inspired by belief propagation (BP), we propose the Confidence Propagation Cluster (CP-Cluster) to replace NMS-based methods, which is fully parallelizable as well as better in accuracy. In CP-Cluster, we borrow the message passing mechanism from BP to penalize redundant boxes and enhance true positives simultaneously in an iterative way until convergence. We verified the effectiveness of CP-Cluster by applying it to various mainstream detectors such as FasterRCNN, SSD, FCOS, YOLOv3, YOLOv5, Centernet etc. Experiments on MS COCO show that our plug and play method, without retraining detectors, is able to steadily improve average mAP of all those <font color="#00be00">state-of-the-art</font> models with a clear margin from 0.2 to 1.9 respectively when compared with NMS-based methods. <font color="#00be00">Source code</font> is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/shenyi0220/CP-Cluster </br></br>

<a href='http://arxiv.org/pdf/2112.08696.pdf'>2112.08696</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 2.6511баллов, №45</br>
<b><font color="#00be00">Few-Shot</font> Semantic <font color="#be00be">Parsing</font> with Language Models Trained On Code</b></br>
Authors: , Shin, Richard, Van Durme, Benjamin</br>
  Large language models, prompted with in-context examples, can perform semantic <font color="#be00be">parsing</font> with little training data. They do better when we formulate the problem as paraphrasing into canonical utterances, which cast the underlying meaning representations into a controlled natural language-like representation. Intuitively, such models can more easily output canonical utterances as they are closer to the natural language used for pre-training. More recently, models also pre-trained on code, like <font color="#00be00">OpenAI</font> Codex, have risen in prominence. Since accurately modeling code requires understanding of executable semantics. such models may prove more adept at semantic parsing. In this paper, we test this hypothesis and find that Codex performs better at semantic parsing than equivalent<font color="#00be00"> GPT</font>-3 models. We find that unlike GPT-3, Codex performs similarly when targeting meaning representations directly, perhaps as meaning representations used in semantic parsing are structured similar to code. </br></br>

<a href='http://arxiv.org/pdf/2112.07493.pdf'>2112.07493</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 2.6349баллов, №46</br>
<b>EABlock: A Declarative Entity Alignment Block for <font color="#960096">Knowledge Graph</font>\n  Creation Pipelines</b></br>
Authors: , Jozashoori, Samaneh, Sakor, Ahmad, Iglesias, Enrique, Vidal, Maria-Esther</br>
  Despite encoding enormous amount of rich and valuable data, existing data sources are mostly created independently, being a significant challenge to their integration. Mapping languages, e.g., RML and R2RML, facilitate declarative specification of the process of applying meta-data and integrating data into a <font color="#960096">knowledge graph</font>. Mapping rules can also include knowledge extraction functions in addition to expressing correspondences among data sources and a unified schema. Combining mapping rules and functions represents a powerful formalism to specify pipelines for integrating data into a knowledge graph transparently. <font color="#00be00">Surprisin</font>gly, these formalisms are not fully adapted, and many knowledge graphs are created by executing ad-hoc programs to pre-process and integrate data. In this paper, we present EABlock, an approach integrating Entity Alignment (EA) as part of RML mapping rules. EABlock includes a block of functions performing entity recognition from textual attributes and link the recognized entities to the corresponding resources in Wikidata, DBpedia, and domain specific thesaurus, e.g., UMLS. EABlock provides agnostic and efficient techniques to evaluate the functions and transfer the mappings to facilitate its application in any RML-compliant engine. We have empirically evaluated EABlock performance, and results indicate that EABlock speeds up knowledge graph creation pipelines that require entity recognition and linking in <font color="#00be00">state-of-the-art</font> RML-compliant engines. EABlock is also <font color="#00be00">publicly available</font> as a tool through a <font color="#00be00">GitHub</font> repository(<font color="#006400">http</font>s://github.com/SDM-TIB/EABlock) and a DOI(https://doi.org/10.5281/zenodo.5779773). </br></br>

<a href='http://arxiv.org/pdf/2112.05375.pdf'>2112.05375</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 2.5712баллов, №47</br>
<b>Rethinking the Two-Stage Framework for Grounded Situation Recognition</b></br>
Authors: , Wei, Meng, Chen, Long, Ji, Wei, Yue, Xiaoyu, Chua, Tat-Seng</br>
  Grounded Situation Recognition (GSR), i.e., recognizing the salient activity (or verb) category in an image (e.g., buying) and detecting all corresponding semantic roles (e.g., agent and goods), is an essential step towards &quot;human-like&quot; event understanding. Since each verb is associated with a specific set of semantic roles, all existing GSR methods resort to a two-stage framework: predicting the verb in the first stage and detecting the semantic roles in the second stage. However, there are obvious drawbacks in both stages: 1) The widely-used cross-entropy (XE) loss for object recognition is insufficient in verb classification due to the large intra-class variation and high inter-class similarity among daily activities. 2) All semantic roles are detected in an autoregressive manner, which fails to model the complex semantic relations between different roles. To this end, we propose a novel SituFormer for GSR which consists of a Coarse-to-Fine Verb Model (CFVM) and a <font color="#00be00">Transformer</font>-based Noun Model (TNM). CFVM is a two-step verb prediction model: a coarse-grained model trained with XE loss first proposes a set of verb candidates, and then a fine-grained model trained with triplet loss re-ranks these candidates with enhanced verb features (not only separable but also discriminative). TNM is a transformer-based semantic role detection model, which detects all roles parallelly. Owing to the global relation modeling ability and flexibility of the transformer decoder, TNM can fully explore the statistical dependency of the roles. Extensive validations on the challenging SWiG benchmark show that SituFormer achieves a new <font color="#00be00">state-of-the-art</font> performance with significant gains under various metrics. Code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/kellyiss/SituFormer. </br></br>

<a href='http://arxiv.org/pdf/2112.08754.pdf'>2112.08754</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 2.5319баллов, №48</br>
<b>CLIN-X: pre-trained language models and a study on cross-task transfer\n  for concept extraction in the <font color="#be00be">clinic</font>al domain</b></br>
Authors: , Lange, Lukas, Adel, Heike, Str&#xf6;tgen, Jannik, Klakow, Dietrich</br>
  The field of natural language processing (NLP) has recently seen a large change towards using pre-trained language models for solving almost any task. Despite showing great improvements in benchmark datasets for various tasks, these models often perform sub-optimal in non-standard domains like the <font color="#be00be">clinic</font>al domain where a large gap between pre-training documents and target documents is observed. In this paper, we aim at closing this gap with domain-specific training of the language model and we investigate its effect on a diverse set of downstream tasks and settings. We introduce the pre-trained CLIN-X (Clinical XLM-R) language models and show how CLIN-X <font color="#00be00">outperform</font>s other pre-trained <font color="#00be00">transformer</font> models by a large margin for ten clinical concept extraction tasks from two languages. In addition, we demonstrate how the transformer model can be further improved with our proposed task- and language-agnostic model architecture based on ensembles over random splits and cross-sentence context. Our studies in <font color="#be00be">low-resource</font> and transfer settings reveal stable model performance despite a lack of annotated data with improvements of up to 47 F1points when only 250 labeled sentences are available. Our results highlight the importance of specialized language models as CLIN-X for concept extraction in non-standard domains, but also show that our task-agnostic model architecture is robust across the tested tasks and languages so that domain- or task-specific adaptations are not required. The CLIN-Xlanguage models and <font color="#00be00">source code</font> for fine-tuning and transferring the model are <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/boschresearch/clin\\_x/ and the huggingface model hub. </br></br>

<a href='http://arxiv.org/pdf/2112.05923.pdf'>2112.05923</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 2.5072баллов, №49</br>
<b>ElegantRL-Podracer: Scalable and Elastic Library for Cloud-Native Deep\n  <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Liu, Xiao-Yang, Li, Zechu, Yang, Zhuoran, Zheng, Jiahao, Wang, Zhaoran, Walid, Anwar, Guo, Jian, Jordan, Michael I.</br>
  Deep <font color="#00be00">reinforcement learning</font> (DRL) has revolutionized learning and actuation in applications such as game playing and robotic control. The cost of data collection, i.e., generating transitions from agent-environment interactions, remains a major challenge for wider DRL adoption in complex <font color="#009600">real-world</font> problems. Following a cloud-native paradigm to train DRL agents on a GPU cloud platform is a promising solution. In this paper, we present a scalable and elastic library ElegantRL-podracer for cloud-native deep reinforcement learning, which efficiently supports millions of GPU cores to carry out massively parallel training at multiple levels. At a high-level, ElegantRL-podracer employs a tournament-based ensemble scheme to orchestrate the training process on hundreds or even thousands of GPUs, scheduling the interactions between a leaderboard and a training pool with hundreds of pods. At a low-level, each pod simulates agent-environment interactions in parallel by fully utilizing nearly 7,000 GPU CUDA cores in a single GPU. Our ElegantRL-podracer library features high scalability, elasticity and accessibility by following the development principles of containerization, microservices and MLOps. Using an NVIDIA DGX SuperPOD cloud, we conduct extensive experiments on various tasks in locomotion and stock trading and show that ElegantRL-podracer substantially <font color="#00be00">outperform</font>s RLlib. Our codes are available on <font color="#00be00">GitHub</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.06494.pdf'>2112.06494</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 2.4715баллов, №50</br>
<b>Native <font color="#be00be">Chinese</font> Reader: A Dataset Towards Native-Level Chinese Machine\n  Reading Comprehension</b></br>
Authors: , Xu, Shusheng, Liu, Yichen, Yi, Xiaoyu, Zhou, Siyuan, Li, Huizi, Wu, Yi</br>
  We present Native <font color="#be00be">Chinese</font> Reader (NCR), a new machine reading comprehension (MRC) dataset with particularly long articles in both modern and classical Chinese. NCR is collected from the exam questions for the Chinese course in China\'s high schools, which are designed to evaluate the language proficiency of native Chinese youth. Existing Chinese MRC datasets are either domain-specific or focusing on short contexts of a few hundreds of characters in modern Chinese only. By contrast, NCR contains 8390 documents with an average length of 1024 characters covering a wide range of Chinese writing <font color="#be00be">style</font>s, including modern articles, classical literature and classical poetry. A total of 20477 questions on these documents also require strong reasoning abilities and common sense to figure out the correct answers. We implemented multiple baseline models using popular Chinese pre-trained models and additionally launched an online competition using our dataset to examine the limit of current methods. The best model achieves 59% test accuracy while human evaluation shows an average accuracy of 79%, which indicates a significant performance gap between current MRC models and native Chinese speakers. We release the dataset at <font color="#006400">http</font>s://sites.<font color="#00be00">google</font>.com/view/native-chinese-reader/. </br></br>

<a href='http://arxiv.org/pdf/2112.06374.pdf'>2112.06374</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 2.4593баллов, №51</br>
<b>Learning Generalizable Vision-Tactile Robotic Grasping Strategy for\n  Deformable Objects via <font color="#00be00">Transformer</font></b></br>
Authors: , Han, Yunhai, Batra, Rahul, Boyd, Nathan, Zhao, Tuo, She, Yu, Hutchinson, Seth, Zhao, Ye</br>
  Reliable robotic grasping, especially with deformable objects, (e.g. fruit), remains a challenging task due to underactuated contact interactions with a gripper, unknown object dynamics, and variable object geometries. In this study, we propose a <font color="#00be00">Transformer</font>-based robotic grasping framework for rigid grippers that leverage tactile and visual information for safe object grasping. Specifically, the Transformer models learn physical feature embeddings with sensor feedback through performing two pre-defined explorative actions (pinching and sliding) and predict a final grasping outcome through a multilayer perceptron (MLP) with a given grasping strength. Using these predictions, the gripper is commanded with a safe grasping strength for the grasping tasks via inference. Compared with convolutional recurrent networks, the Transformer models can capture the long-term dependencies across the image sequences and process the spatial-temporal features simultaneously. We first benchmark the proposed Transformer models on a public dataset for slip detection. Following that, we show that the Transformer models <font color="#00be00">outperform</font> a CNN+LSTM model in terms of grasping accuracy and computational efficiency. We also collect our own fruit grasping dataset and conduct the online grasping experiments using the proposed framework for both seen and unseen fruits. Our codes and dataset are made public on <font color="#00be00">GitHub</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.08663.pdf'>2112.08663</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 2.3873баллов, №52</br>
<b>MAVE: A Product Dataset for Multi-source Attribute Value Extraction</b></br>
Authors: , Yang, Li, Wang, Qifan, Yu, Zac, Kulkarni, Anand, Sanghai, Sumit, Shu, Bin, Elsas, Jon, Kanagal, Bhargav</br>
  Attribute value extraction refers to the task of identifying values of an attribute of interest from product information. Product attribute values are essential in many <font color="#be00be">e-commerce</font> scenarios, such as <font color="#be00be">customer</font> service robots, product ranking, <font color="#be00be">retrieval</font> and <font color="#be00be">recommendat</font>ions. While in the <font color="#009600">real world</font>, the attribute values of a product are usually incomplete and vary over time, which greatly hinders the practical applications. In this paper, we introduce MAVE, a new dataset to better facilitate research on product attribute value extraction. MAVE is composed of a curated set of 2.2 million products from Amazon pages, with 3 million attribute-value annotations across 1257 unique categories. MAVE has four main and unique advantages: First, MAVE is the largest product attribute value extraction dataset by the number of attribute-value examples. Second, MAVE includes multi-source representations from the product, which captures the full product information with high attribute coverage. Third, MAVE represents a more diverse set of attributes and values relative to what previous datasets cover. Lastly, MAVE provides a very challenging <font color="#00be00">zero-shot</font> test set, as we empirically illustrate in the experiments. We further propose a novel approach that effectively extracts the attribute value from the multi-source product information. We conduct extensive experiments with several baselines and show that MAVE is an effective dataset for attribute value extraction task. It is also a very challenging task on zero-shot attribute extraction. Data is available at {\\it \\url{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/<font color="#00be00">google</font>-research-datasets/MAVE}}. </br></br>

<a href='http://arxiv.org/pdf/2112.07262.pdf'>2112.07262</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp 2.3374баллов, №53</br>
<b>Inductive Semi-supervised Learning Through Optimal Transport</b></br>
Authors: , Hamri, Mourad El, Bennani, Youn&#xe8;s, Falih, Issam</br>
  In this paper, we tackle the inductive semi-supervised learning problem that aims to obtain label predictions for out-of-sample data. The proposed approach, called Optimal Transport Induction (OTI), extends efficiently an optimal transport based transductive algorithm (OTP) to inductive tasks for both binary and multi-class settings. A series of experiments are conducted on several datasets in order to compare the proposed approach with <font color="#00be00">state-of-the-art</font> methods. Experiments demonstrate the effectiveness of our approach. We make our code <font color="#00be00">publicly available</font> (Code is available at: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/MouradElHamri/OTI). </br></br>

<a href='http://arxiv.org/pdf/2112.09081.pdf'>2112.09081</a> &nbsp&nbsp (cs:CV, cs:AI, cs:RO) &nbsp&nbsp 2.3267баллов, №54</br>
<b>CrossLoc: Scalable Aerial Localization Assisted by Multimodal Synthetic\n  Data</b></br>
Authors: , Yan, Qi, Zheng, Jianhao, Reding, Simon, Li, Shanci, Doytchinov, Iordan</br>
  We present a visual localization system that learns to estimate camera poses in the <font color="#009600">real world</font> with the help of synthetic data. Despite significant progress in recent years, most learning-based approaches to visual localization target at a single domain and require a dense database of geo-tagged images to function well. To mitigate the data scarcity issue and improve the scalability of the neural localization models, we introduce TOPO-DataGen, a versatile synthetic data generation tool that traverses smoothly between the real and virtual world, hinged on the geographic camera viewpoint. New large-scale sim-to-real benchmark datasets are proposed to showcase and evaluate the utility of the said synthetic data. Our experiments reveal that synthetic data generically enhances the neural network performance on real data. Furthermore, we introduce CrossLoc, a cross-modal visual representation learning approach to <font color="#be00be">pose estimation</font> that makes full use of the scene coordinate ground truth via self-supervision. Without any extra data, CrossLoc significantly <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> methods and achieves substantially higher real-data <font color="#00be00">sample efficien</font>cy. Our code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/TOPO-EPFL/CrossLoc. </br></br>

<a href='http://arxiv.org/pdf/2112.08907.pdf'>2112.08907</a> &nbsp&nbsp (cs:AI, cs:CL) &nbsp&nbsp 2.3230баллов, №55</br>
<b>Inherently Explainable <font color="#00be00">Reinforcement Learning</font> in Natural Language</b></br>
Authors: , Peng, Xiangyu, Riedl, Mark O., Ammanabrolu, Prithviraj</br>
  We focus on the task of creating a <font color="#00be00">reinforcement learning</font> agent that is inherently explainable -- with the ability to produce immediate local explanations by thinking out loud while performing a task and analyzing entire trajectories post-hoc to produce causal explanations. This <font color="#00be00">Hierarchical</font>ly Explainable Reinforcement Learning agent (HEX-RL), operates in Interactive Fictions, text-based game environments in which an agent perceives and acts upon the world using textual natural language. These games are usually structured as puzzles or quests with long-term dependencies in which an agent must complete a sequence of actions to succeed -- providing ideal environments in which to test an agent\'s ability to explain its actions. Our agent is designed to treat explainability as a first-class citizen, using an extracted symbolic <font color="#960096">knowledge graph</font>-based state representation coupled with a Hierarchical Graph Attention mechanism that points to the facts in the internal graph representation that most influenced the choice of actions. Experiments show that this agent provides significantly improved explanations over strong baselines, as rated by human participants generally unfamiliar with the environment, while also matching <font color="#00be00">state-of-the-art</font> task performance. </br></br>

<a href='http://arxiv.org/pdf/2111.00134.pdf'>2111.00134</a> &nbsp&nbsp (cs:NE, cs:AI, cs:ML) &nbsp&nbsp 2.2784баллов, №56</br>
<b>Context Meta-<font color="#00be00">Reinforcement Learning</font> via Neuromodulation</b></br>
Authors: , Ben-Iwhiwhu, Eseoghene, Dick, Jeffery, Ketz, Nicholas A., Pilly, Praveen K., Soltoggio, Andrea</br>
  Meta-<font color="#00be00">reinforcement learning</font> (meta-RL) algorithms enable agents to adapt quickly to tasks from few samples in dynamic environments. Such a feat is achieved through dynamic representations in an agent\'s policy network (obtained via reasoning about task context, model parameter updates, or both). However, obtaining rich dynamic representations for fast adaptation beyond simple benchmark problems is challenging due to the burden placed on the policy network to accommodate different policies. This paper addresses the challenge by introducing neuromodulation as a modular component to augment a standard policy network that regulates neuronal activities in order to produce efficient dynamic representations for task adaptation. The proposed extension to the policy network is evaluated across multiple discrete and continuous control environments of increasing complexity. To prove the generality and benefits of the extension in meta-RL, the neuromodulated network was applied to two <font color="#00be00">state-of-the-art</font> meta-RL algorithms (CAVIA and PEARL). The result demonstrates that meta-RL augmented with neuromodulation produces significantly better result and richer dynamic representations in comparison to the baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.08193.pdf'>2112.08193</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 2.2576баллов, №57</br>
<b>N3H-Core: Neuron-designed Neural Network Accelerator via <font color="#be00be">FPGA</font>-based\n  Heterogeneous Computing Cores</b></br>
Authors: , Gong, Yu, Xu, Zhihan, He, Zhezhi, Zhang, Weifeng, Tu, Xiaobing, Liang, Xiaoyao, Jiang, Li</br>
  Accelerating the neural network inference by <font color="#be00be">FPGA</font> has emerged as a popular option, since the reconfigurability and high performance computing capability of FPGA intrinsically satisfies the computation demand of the fast-evolving neural algorithms. However, the popular neural accelerators on FPGA (e.g., Xilinx DPU) mainly utilize the DSP resources for constructing their processing units, while the rich LUT resources are not well exploited. Via the software-hardware co-design approach, in this work, we develop an FPGA-based heterogeneous computing system for neural network acceleration. From the hardware perspective, the proposed accelerator consists of DSP- and LUT-based GEneral Matrix-Multiplication (GEMM) computing cores, which forms the entire computing system in a heterogeneous fashion. The DSP- and LUT-based GEMM cores are computed w.r.t a unified Instruction Set Architecture (ISA) and unified buffers. Along the data flow of the neural network inference path, the computation of the convolution/fully-connected layer is split into two portions, handled by the DSP- and LUT-based GEMM cores asynchronously. From the software perspective, we mathematically and systematically model the latency and resource utilization of the proposed heterogeneous accelerator, regarding varying system design configurations. Through leveraging the <font color="#00be00">reinforcement learning</font> technique, we construct a framework to achieve end-to-end selection and optimization of the design specification of target heterogeneous accelerator, including workload split strategy, mixed-precision quantization scheme, and resource allocation of DSP- and LUT-core. In virtue of the proposed design framework and heterogeneous computing system, our design <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> Mix&amp;Match design with latency reduced by 1.12-1.32x with higher inference accuracy. The N3H-core is open-sourced at: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/elliothe/N3H_Core. </br></br>

<a href='http://arxiv.org/pdf/2112.05328.pdf'>2112.05328</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 2.2529баллов, №58</br>
<b>Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0</b></br>
Authors: , Lee, Joosung, Han, Kijong</br>
  This paper presents our work on the Situated Interactive MultiModal Conversations 2.0 challenge held at Dialog State <font color="#be00be">Tracking</font> Challenge 10. SIMMC 2.0 includes 4 subtasks, and we introduce our multimodal approaches for the subtask \\#1, \\#2 and the generation of subtask \\#4. SIMMC 2.0 dataset is a multimodal dataset containing image and text information, which is more challenging than the problem of only text-based conversations because it must be solved by understanding the relationship between image and text. Therefore, since there is a limit to solving only text models such as<font color="#00be00"> BERT </font>or<font color="#00be00"> GPT</font>2, we propose a multimodal model combining image and text. We first pretrain the multimodal model to understand the relationship between image and text, then finetune our model for each task. We achieve the 3rd best performance in subtask \\#1, \\#2 and a runner-up in the generation of subtask \\#4. The <font color="#00be00">source code</font> is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/rungjoo/simmc2.0. </br></br>

<a href='http://arxiv.org/pdf/2112.06346.pdf'>2112.06346</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 2.2489баллов, №59</br>
<b>ValueNet: A New Dataset for Human Value Driven Dialogue System</b></br>
Authors: , Qiu, Liang, Zhao, Yizhou, Li, Jinchao, Lu, Pan, Peng, Baolin, Gao, Jianfeng, Zhu, Song-Chun</br>
  Building a socially intelligent agent involves many challenges, one of which is to teach the agent to speak guided by its value like a human. However, value-driven chatbots are still understudied in the area of dialogue systems. Most existing datasets focus on commonsense reasoning or social norm modeling. In this work, we present a new large-scale human value dataset called ValueNet, which contains human attitudes on 21,374 text scenarios. The dataset is organized in ten dimensions that conform to the basic human value <font color="#be00be">theor</font>y in intercultural research. We further develop a <font color="#00be00">Transformer</font>-based value <font color="#be00be">regression</font> model on ValueNet to learn the utility distribution. Comprehensive empirical results show that the learned value model could benefit a wide range of dialogue tasks. For example, by teaching a generative agent with <font color="#00be00">reinforcement learning</font> and the rewards from the value model, our method attains <font color="#00be00">state-of-the-art</font> performance on the personalized dialog generation dataset: Persona-Chat. With values as additional features, existing <font color="#be00be">emotion</font> recognition models enable capturing rich human emotions in the context, which further improves the empathetic response generation performance in the EmpatheticDialogues dataset. To the best of our knowledge, ValueNet is the first large-scale text dataset for human value modeling, and we are the first one trying to incorporate a value model into emotionally intelligent dialogue systems. The dataset is available at <font color="#006400">http</font>s://liang-qiu.<font color="#00be00">github</font>.io/ValueNet/. </br></br>

<a href='http://arxiv.org/pdf/2112.08327.pdf'>2112.08327</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 2.2483баллов, №60</br>
<b>Evaluating Pretrained <font color="#00be00">Transformer</font> Models for Entity Linking in\n  Task-Oriented Dialog</b></br>
Authors: , Jayanthi, Sai Muralidhar, Embar, Varsha, Raghunathan, Karthik</br>
  The wide applicability of pretrained <font color="#00be00">transformer</font> models (PTMs) for natural language tasks is well demonstrated, but their ability to comprehend short phrases of text is less explored. To this end, we evaluate different PTMs from the lens of unsupervised Entity Linking in task-oriented dialog across 5 characteristics -- syntactic, semantic, short-forms, numeric and phonetic. Our results demonstrate that several of the PTMs produce sub-par results when compared to traditional techniques, albeit <font color="#960096">competitive</font> to other neural baselines. We find that some of their shortcomings can be addressed by using PTMs fine-tuned for text-similarity tasks, which illustrate an improved ability in comprehending semantic and syntactic correspondences, as well as some improvements for short-forms, numeric and phonetic variations in entity mentions. We perform qualitative analysis to understand nuances in their predictions and discuss scope for further improvements. Code can be found at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/murali1996/el_tod </br></br>

<a href='http://arxiv.org/pdf/2112.07916.pdf'>2112.07916</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 2.2163баллов, №61</br>
<b>LongT5: Efficient Text-To-Text <font color="#00be00">Transformer</font> for Long Sequences</b></br>
Authors: , Guo, Mandy, Ainslie, Joshua, Uthus, David, Ontanon, Santiago, Ni, Jianmo, Sung, Yun-Hsuan, Yang, Yinfei</br>
  Recent work has shown that either (1) increasing the input length or (2) increasing model size can improve the performance of <font color="#00be00">Transformer</font>-based neural models. In this paper, we present a new model, called LongT5, with which we explore the effects of scaling both the input length and model size at the same time. Specifically, we integrated attention ideas from long-input transformers (ETC), and adopted pre-training strategies from <font color="#be00be">summarization</font> pre-training (PEGASUS) into the scalable T5 architecture. The result is a new attention mechanism we call {\\em Transient Global} (TGlobal), which mimics ETC\'s local/global attention mechanism, but without requiring additional side-inputs. We are able to achieve <font color="#00be00">state-of-the-art</font> results on several summarization tasks and <font color="#00be00">outperform</font> the original T5 models on question answering tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.08879.pdf'>2112.08879</a> &nbsp&nbsp (cs:CV, cs:CL) &nbsp&nbsp 2.1865баллов, №62</br>
<b>Looking Outside the Box to Ground Language in 3D Scenes</b></br>
Authors: , Jain, Ayush, Gkanatsios, Nikolaos, Mediratta, Ishita, Fragkiadaki, Katerina</br>
  Existing language grounding models often use object proposal bottlenecks: a pre-trained detector proposes objects in the scene and the model learns to select the answer from these box proposals, without attending to the original image or 3D <font color="#be00be">point cloud</font>. Object detectors are typically trained on a fixed vocabulary of objects and attributes that is often too restrictive for open-domain language grounding, where an utterance may refer to visual entities at various levels of abstraction, such as a chair, the leg of a chair, or the tip of the front leg of a chair. We propose a model for grounding language in 3D scenes that bypasses box proposal bottlenecks with three main innovations: i) Iterative attention across the language stream, the point cloud feature stream and 3D box proposals. ii) <font color="#00be00">Transformer</font> decoders with non-parametric entity queries that decode 3D boxes for object and part referentials. iii) Joint supervision from 3D object annotations and language grounding annotations, by treating <font color="#be00be">object detection</font> as grounding of referential utterances comprised of a list of candidate category labels. These innovations result in significant quantitative gains (up to +9% absolute improvement on the SR3D benchmark) over previous approaches on popular 3D language grounding benchmarks. We ablate each of our innovations to show its contribution to the performance of the model. When applied on language grounding on 2D images with minor changes, it performs on par with the <font color="#00be00">state-of-the-art</font> while converges in half of the GPU time. The code and checkpoints will be made available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/nickgkan/beauty_detr </br></br>

<a href='http://arxiv.org/pdf/2112.07867.pdf'>2112.07867</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 2.1718баллов, №63</br>
<b>Interscript: A dataset for interactive learning of scripts through error\n  feedback</b></br>
Authors: , Tandon, Niket, Madaan, Aman, Clark, Peter, Sakaguchi, Keisuke, Yang, Yiming</br>
  How can an end-user provide feedback if a deployed structured prediction model generates inconsistent output, ignoring the structural complexity of human language? This is an emerging topic with recent progress in synthetic or constrained settings, and the next big leap would require testing and tuning models in <font color="#009600">real-world</font> settings. We present a new dataset, Interscript, containing user feedback on a deployed model that generates complex everyday tasks. Interscript contains 8,466 data points -- the input is a possibly erroneous script and a user feedback, and the output is a modified script. We posit two use-cases of \\ours that might significantly advance the <font color="#00be00">state-of-the-art</font> in interactive learning. The dataset is available at: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/allenai/interscript. </br></br>

<a href='http://arxiv.org/pdf/2112.07057.pdf'>2112.07057</a> &nbsp&nbsp (cs:NE, cs:ML) &nbsp&nbsp 2.1697баллов, №64</br>
<b>NEORL: NeuroEvolution Optimization with <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Radaideh, Majdi I., Du, Katelin, Seurin, Paul, Seyler, Devin, Gu, Xubo, Wang, Haijia, Shirvan, Koroush</br>
  We present an open-source Python framework for NeuroEvolution Optimization with <font color="#00be00">Reinforcement Learning</font> (NEORL) developed at the Massachusetts Institute of Technology. NEORL offers a global optimization interface of <font color="#00be00">state-of-the-art</font> algorithms in the field of evolutionary computation, neural networks through reinforcement learning, and hybrid neuroevolution algorithms. NEORL features diverse set of algorithms, user-friendly interface, parallel computing support, automatic hyperparameter tuning, detailed documentation, and demonstration of applications in mathematical and <font color="#009600">real-world</font> engineering optimization. NEORL encompasses various optimization problems from combinatorial, continuous, mixed discrete/continuous, to high-dimensional, expensive, and constrained engineering optimization. NEORL is tested in variety of engineering applications relevant to low carbon energy research in addressing solutions to <font color="#be00be">climate</font> change. The examples include nuclear reactor control and fuel cell power production. The results demonstrate NEORL <font color="#960096">competitive</font>ness against other algorithms and optimization frameworks in the literature, and a potential tool to solve large-scale optimization problems. More examples and benchmarking of NEORL can be found here: <font color="#006400">http</font>s://neorl.readthedocs.io/en/latest/index.html </br></br>

<a href='http://arxiv.org/pdf/2112.04145.pdf'>2112.04145</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 2.1670баллов, №65</br>
<b>A Review for Deep <font color="#00be00">Reinforcement Learning</font> in Atari:Benchmarks,\n  Challenges, and Solutions</b></br>
Authors: , Fan, Jiajun</br>
  The Arcade Learning Environment (ALE) is proposed as an evaluation platform for empirically assessing the generality of agents across dozens of Atari 2600 games. ALE offers various challenging problems and has drawn significant attention from the deep <font color="#00be00">reinforcement learning</font> (RL) community. From Deep Q-Networks (DQN) to Agent57, RL agents seem to achieve superhuman performance in ALE. However, is this the case? In this paper, to explore this problem, we first review the current evaluation metrics in the Atari benchmarks and then reveal that the current evaluation criteria of achieving superhuman performance are inappropriate, which underestimated the human performance relative to what is possible. To handle those problems and promote the development of RL research, we propose a novel Atari benchmark based on human world records (HWR), which puts forward higher requirements for RL agents on both final performance and learning efficiency. Furthermore, we summarize the <font color="#00be00">state-of-the-art</font> (SOTA) methods in Atari benchmarks and provide benchmark results over new evaluation metrics based on human world records. We concluded that at least four open challenges hinder RL agents from achieving superhuman performance from those new benchmark results. Finally, we also discuss some promising ways to handle those problems. </br></br>

<a href='http://arxiv.org/pdf/2112.07338.pdf'>2112.07338</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 2.1644баллов, №66</br>
<b>Temporal <font color="#00be00">Transformer</font> Networks with Self-Supervision for Action\n  Recognition</b></br>
Authors: , Zhang, Yongkang, Li, Jun, Wu, Guoming, Zhang, Han, Shi, Zhiping, Liu, Zhaoxun, Wu, Zizhang, Jiang, Na</br>
  In recent years, 2D Convolutional Networks-based video action recognition has encouragingly gained wide popularity; However, constrained by the lack of long-range non-linear temporal relation modeling and reverse motion information modeling, the performance of existing models is, therefore, undercut seriously. To address this urgent problem, we introduce a startling Temporal <font color="#00be00">Transformer</font> Network with Self-supervision (TTSN). Our high-performance TTSN mainly consists of a temporal transformer module and a temporal sequence self-supervision module. Concisely speaking, we utilize the efficient temporal transformer module to model the non-linear temporal dependencies among non-local frames, which significantly enhances complex motion feature representations. The temporal sequence self-supervision module we employ unprecedentedly adopts the streamlined strategy of &quot;random batch random channel&quot; to reverse the sequence of video frames, allowing robust extractions of motion information representation from inversed temporal dimensions and improving the generalization capability of the model. Extensive experiments on three widely used datasets (HMDB51, UCF101, and Something-something V1) have conclusively demonstrated that our proposed TTSN is promising as it successfully achieves <font color="#00be00">state-of-the-art</font> performance for action recognition. </br></br>

<a href='http://arxiv.org/pdf/2112.07175.pdf'>2112.07175</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 2.1572баллов, №67</br>
<b>Co-training <font color="#00be00">Transformer</font> with Videos and Images Improves Action\n  Recognition</b></br>
Authors: , Zhang, Bowen, Yu, Jiahui, Fifty, Christopher, Han, Wei, Dai, Andrew M., Pang, Ruoming, Sha, Fei</br>
  In learning action recognition, models are typically pre-trained on object recognition with images, such as ImageNet, and later fine-tuned on target action recognition with videos. This approach has achieved good empirical performance especially with recent <font color="#00be00">transformer</font>-based video architectures. While recently many works aim to design more advanced transformer architectures for action recognition, less effort has been made on how to train video transformers. In this work, we explore several training paradigms and present two findings. First, video transformers benefit from joint training on diverse video datasets and label spaces (e.g., Kinetics is appearance-focused while SomethingSomething is motion-focused). Second, by further co-training with images (as single-frame videos), the video transformers learn even better video representations. We term this approach as Co-training Videos and Images for Action Recognition (CoVeR). In particular, when pretrained on ImageNet-21K based on the TimeSFormer architecture, CoVeR improves Kinetics-400 Top-1 Accuracy by 2.4%, Kinetics-600 by 2.3%, and SomethingSomething-v2 by 2.3%. When pretrained on larger-scale image datasets following previous <font color="#00be00">state-of-the-art</font>, CoVeR achieves best results on Kinetics-400 (87.2%), Kinetics-600 (87.9%), Kinetics-700 (79.8%), SomethingSomething-v2 (70.9%), and Moments-in-Time (46.1%), with a simple spatio-temporal video transformer. </br></br>

<a href='http://arxiv.org/pdf/2112.07074.pdf'>2112.07074</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 2.1319баллов, №68</br>
<b>Towards a Unified Foundation Model: Jointly Pre-Training <font color="#00be00">Transformer</font>s on\n  Unpaired Images and Text</b></br>
Authors: , Li, Qing, Gong, Boqing, Cui, Yin, Kondratyuk, Dan, Du, Xianzhi, Yang, Ming-Hsuan, Brown, Matthew</br>
  In this paper, we explore the possibility of building a unified foundation model that can be adapted to both vision-only and text-only tasks. Starting from<font color="#00be00"> BERT </font>and ViT, we design a unified <font color="#00be00">transformer</font> consisting of modality-specific tokenizers, a shared transformer encoder, and task-specific output heads. To efficiently pre-train the proposed model jointly on unpaired images and text, we propose two novel techniques: (i) We employ the separately-trained BERT and ViT models as teachers and apply knowledge distillation to provide additional, accurate supervision signals for the joint training; (ii) We propose a novel gradient masking strategy to balance the parameter updates from the image and text pre-training losses. We evaluate the jointly pre-trained transformer by fine-tuning it on image classification tasks and natural language understanding tasks, respectively. The experiments show that the resultant unified foundation transformer works <font color="#00be00">surprisin</font>gly well on both the vision-only and text-only tasks, and the proposed knowledge distillation and gradient masking strategy can effectively lift the performance to approach the level of separately-trained models. </br></br>

<a href='http://arxiv.org/pdf/2112.08443.pdf'>2112.08443</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 2.1159баллов, №69</br>
<b>Event-Aware Multimodal Mobility Nowcasting</b></br>
Authors: , Wang, Zhaonan, Jiang, Renhe, Xue, Hao, Salim, Flora D., Song, Xuan, Shibasaki, Ryosuke</br>
  As a decisive part in the success of Mobility-as-a-Service (MaaS), spatio-temporal predictive modeling for crowd movements is a challenging task particularly considering scenarios where societal events drive mobility behavior deviated from the normality. While tremendous progress has been made to model high-level spatio-temporal regularities with deep learning, most, if not all of the existing methods are neither aware of the dynamic interactions among multiple transport modes nor adaptive to unprecedented volatility brought by potential societal events. In this paper, we are therefore motivated to improve the canonical spatio-temporal network (ST-Net) from two perspectives: (1) design a heterogeneous mobility information network (HMIN) to explicitly represent intermodality in multimodal mobility; (2) propose a memory-augmented dynamic filter generator (MDFG) to generate sequence-specific parameters in an on-the-fly fashion for various scenarios. The enhanced event-aware spatio-temporal network, namely EAST-Net, is evaluated on several <font color="#009600">real-world</font> datasets with a wide variety and coverage of societal events. Both quantitative and qualitative experimental results verify the superiority of our approach compared with the <font color="#00be00">state-of-the-art</font> baselines. Code and data are published on <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/underdoc-wang/EAST-Net. </br></br>

<a href='http://arxiv.org/pdf/2112.07606.pdf'>2112.07606</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 2.0769баллов, №70</br>
<b>Semantic Answer Type and Relation Prediction Task (SMART 2021)</b></br>
Authors: , Mihindukulasooriya, Nandana, Dubey, Mohnish, Gliozzo, Alfio, Lehmann, Jens, Ngomo, Axel-Cyrille Ngonga, Usbeck, Ricardo, Rossiello, Gaetano, Kumar, Uttam</br>
  Each year the International Semantic Web Conference organizes a set of Semantic Web Challenges to establish competitions that will advance <font color="#00be00">state-of-the-art</font> solutions in some problem domains. The Semantic Answer Type and Relation Prediction Task (SMART) task is one of the ISWC 2021 Semantic Web challenges. This is the second year of the challenge after a successful SMART 2020 at ISWC 2020. This year\'s version focuses on two sub-tasks that are very important to Knowledge Base Question Answering (KBQA): Answer Type Prediction and Relation Prediction. Question type and answer type prediction can play a key role in knowledge base question answering systems providing insights about the expected answer that are helpful to generate correct queries or rank the answer candidates. More concretely, given a question in natural language, the first task is, to predict the answer type using a target ontology (e.g., DBpedia or Wikidata. Similarly, the second task is to identify relations in the natural language query and link them to the relations in a target ontology. This paper discusses the task descriptions, benchmark datasets, and evaluation metrics. For more information, please visit <font color="#006400">http</font>s://smart-task.<font color="#00be00">github</font>.io/2021/. </br></br>

<a href='http://arxiv.org/pdf/2112.09106.pdf'>2112.09106</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 2.0684баллов, №71</br>
<b>RegionCLIP: Region-based Language-Image Pretraining</b></br>
Authors: , Zhong, Yiwu, Yang, Jianwei, Zhang, Pengchuan, Li, Chunyuan, Codella, Noel, Li, Liunian Harold, Zhou, Luowei, Dai, Xiyang, Yuan, Lu, Li, Yin, Gao, Jianfeng</br>
  Contrastive language-image pretraining (CLIP) using image-text pairs has achieved impressive results on image classification in both <font color="#00be00">zero-shot</font> and transfer learning settings. However, we show that directly applying such models to recognize image regions for <font color="#be00be">object detection</font> leads to poor performance due to a domain shift: CLIP was trained to match an image as a whole to a text description, without capturing the fine-grained alignment between image regions and text spans. To mitigate this issue, we propose a new method called RegionCLIP that significantly extends CLIP to learn region-level visual representations, thus enabling fine-grained alignment between image regions and textual concepts. Our method leverages a CLIP model to match image regions with template captions and then pretrains our model to align these region-text pairs in the feature space. When transferring our pretrained model to the open-vocabulary object detection tasks, our method significantly <font color="#00be00">outperform</font>s the <font color="#00be00">state of the art</font> by 3.8 AP50 and 2.2 AP for novel categories on COCO and LVIS datasets, respectively. Moreoever, the learned region representations support zero-shot inference for object detection, showing promising results on both COCO and LVIS datasets. Our code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/microsoft/RegionCLIP. </br></br>

<a href='http://arxiv.org/pdf/2112.08275.pdf'>2112.08275</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 2.0619баллов, №72</br>
<b>SeqFormer: a Frustratingly Simple Model for Video Instance <font color="#be00be">Segmentation</font></b></br>
Authors: , Wu, Junfeng, Jiang, Yi, Zhang, Wenqing, Bai, Xiang, Bai, Song</br>
  In this work, we present SeqFormer, a frustratingly simple model for video instance <font color="#be00be">segmentation</font>. SeqFormer follows the principle of vision <font color="#00be00">transformer</font> that models instance relationships among video frames. Nevertheless, we observe that a stand-alone instance query suffices for capturing a time sequence of instances in a video, but attention mechanisms should be done with each frame independently. To achieve this, SeqFormer locates an instance in each frame and aggregates temporal information to learn a powerful representation of a video-level instance, which is used to predict the mask sequences on each frame dynamically. Instance <font color="#be00be">tracking</font> is achieved naturally without tracking branches or post-processing. On the YouTube-VIS dataset, SeqFormer achieves 47.4 AP with a ResNet-50 backbone and 49.0 AP with a ResNet-101 backbone without bells and whistles. Such achievement significantly exceeds the previous <font color="#00be00">state-of-the-art</font> performance by 4.6 and 4.4, respectively. In addition, integrated with the recently-proposed Swin transformer, SeqFormer achieves a much higher AP of 59.3. We hope SeqFormer could be a strong baseline that fosters future research in video instance segmentation, and in the meantime, advances this field with a more robust, accurate, neat model. The code and the pre-trained models are <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/wjf5203/SeqFormer. </br></br>

<a href='http://arxiv.org/pdf/2111.02671.pdf'>2111.02671</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 2.0247баллов, №73</br>
<b>GraphSearchNet: Enhancing GNNs via Capturing Global Dependency for\n  Semantic Code Search</b></br>
Authors: , Liu, Shangqing, Xie, Xiaofei, Siow, Jingkai, Ma, Lei, Meng, Guozhu, Liu, Yang</br>
  Code search aims to retrieve the accurate code fragments based on a natural language query to improve the software productivity and quality. However, automated deep code search is still challenging due to the semantic gap between the program and the natural language query. Most existing deep learning-based approaches for code search rely on the sequential text eg., feeding the program and the query as a flat sequence of tokens to learn the program semantics and the structural information for both program and the query is not fully considered. Furthermore, the widely adopted Graph Neural Networks (GNNs) have proved the effectiveness in learning program semantics, however they also suffer from capturing the global dependency between any pair of nodes in the constructed graph, which hinder the model learning capacity.   In this paper, to address these challenges, we design a novel neural network framework, named GraphSearchNet, to enable an effective and accurate <font color="#00be00">source code</font> search by jointly learning rich semantics of both source code and natural language queries. Specifically, we propose to encode both source code and queries into two separated graphs with Bidirectional GGNN to capture the local structural information of the programs and queries. We further enhance it by utilizing the effective multi-head attention mechanism to supplement the global dependency that BiGGNN missed to improve the model learning capacity. The extensive experiments on both Java and Python language from the public benchmark illustrate that GraphSearchNet <font color="#00be00">outperform</font>s current <font color="#00be00">state-of-the-art</font> works by a significant margin. We further conduct a quantitative analysis based on the real queries to further illustrate the effectiveness of our approach. </br></br>

<a href='http://arxiv.org/pdf/2111.07529.pdf'>2111.07529</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.9970баллов, №74</br>
<b>Object Propagation via Inter-Frame Attentions for Temporally Stable\n  Video Instance <font color="#be00be">Segmentation</font></b></br>
Authors: , Chakravarthy, Anirudh S, Jang, Won-Dong, Lin, Zudi, Wei, Donglai, Bai, Song, Pfister, Hanspeter</br>
  Video instance <font color="#be00be">segmentation</font> aims to detect, segment, and track objects in a video. Current approaches extend image-level segmentation algorithms to the temporal domain. However, this results in temporally inconsistent masks. In this work, we identify the mask quality due to temporal stability as a performance bottleneck. Motivated by this, we propose a video instance segmentation method that alleviates the problem due to missing detections. Since this cannot be solved simply using spatial information, we leverage temporal context using inter-frame attentions. This allows our network to refocus on missing objects using box predictions from the neighbouring frame, thereby overcoming missing detections. Our method significantly <font color="#00be00">outperform</font>s previous <font color="#00be00">state-of-the-art</font> algorithms using the Mask R-CNN backbone, by achieving 36.0% mAP on the YouTube-VIS benchmark. Additionally, our method is completely online and requires no future frames. Our code is <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/anirudh-chakravarthy/ObjProp. </br></br>

<a href='http://arxiv.org/pdf/2112.06011.pdf'>2112.06011</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.9932баллов, №75</br>
<b>Improving the Transferability of Adversarial Examples with\n  Resized-Diverse-Inputs, Diversity-Ensemble and Region Fitting</b></br>
Authors: , Zou, Junhua, Pan, Zhisong, Qiu, Junyang, Liu, Xin, Rui, Ting, Li, Wei</br>
  We introduce a three stage pipeline: resized-diverse-inputs (RDIM), diversity-ensemble (DEM) and region fitting, that work together to generate transferable adversarial examples. We first explore the internal relationship between existing attacks, and propose RDIM that is capable of exploiting this relationship. Then we propose DEM, the multi-scale version of RDIM, to generate multi-scale gradients. After the first two steps we transform value fitting into region fitting across iterations. RDIM and region fitting do not require extra running time and these three steps can be well integrated into other attacks. Our best attack fools six black-box defenses with a 93% success rate on average, which is higher than the <font color="#00be00">state-of-the-art</font> gradient-based attacks. Besides, we rethink existing attacks rather than simply stacking new methods on the old ones to get better performance. It is expected that our findings will serve as the beginning of exploring the internal relationship between attack methods. Codes are available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/278287847/DEM. </br></br>

<a href='http://arxiv.org/pdf/2112.01349.pdf'>2112.01349</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.9734баллов, №76</br>
<b>MegBA: A High-Performance and Distributed Library for Large-Scale Bundle\n  Adjustment</b></br>
Authors: , Ren, Jie, Liang, Wenteng, Yan, Ran, Mai, Luo, Liu, Shiwen, Liu, Xiao</br>
  Large-scale Bundle Adjustment (BA) is the key for many 3D vision applications (e.g., Structure-from-Motion and SLAM). Though important, large-scale BA is still poorly supported by existing BA libraries (e.g., Ceres and g2o). These libraries under-utilise accelerators (i.e., GPUs), and they lack algorithms to distribute BA computation constrained by the memory on a single device.   In this paper, we propose MegBA, a high-performance and distributed library for large-scale BA. MegBA has a novel end-to-end vectorised BA algorithm that can fully exploit the massive parallel cores on GPUs, thus speeding up the entire BA computation. It also has a novel distributed BA algorithm that can automatically partition BA problems, and solve BA sub-problems using distributed GPUs. The GPUs synchronise intermediate solving state using network-efficient collective communication, and the synchronisation is designed to minimise communication cost. MegBA has a memory-efficient GPU runtime and exposes g2o-compatible APIs. Experiments show that MegBA can out-perform <font color="#00be00">state-of-the-art</font> BA libraries (i.e., Ceres and DeepLM) by up to 47.6x and 6.4x respectively, in public large-scale BA benchmarks. The code of MegBA is available at: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/MegviiRobot/MegBA. </br></br>

<a href='http://arxiv.org/pdf/2112.08455.pdf'>2112.08455</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.9663баллов, №77</br>
<b>Dense Video Captioning Using Unsupervised Semantic Information</b></br>
Authors: , Estevam, Valter, Laroca, Rayson, Pedrini, Helio, Menotti, David</br>
  We introduce a method to learn unsupervised semantic visual information based on the premise that complex events (e.g., minutes) can be decomposed into simpler events (e.g., a few seconds), and that these simple events are shared across several complex events. We split a long video into short frame sequences to extract their latent representation with three-dimensional convolutional neural networks. A <font color="#be00be">clustering</font> method is used to group representations producing a visual codebook (i.e., a long video is represented by a sequence of integers given by the cluster labels). A dense representation is learned by encoding the co-occurrence probability matrix for the codebook entries. We demonstrate how this representation can leverage the performance of the dense video captioning task in a scenario with only visual features. As a result of this approach, we are able to replace the audio signal in the Bi-Modal <font color="#00be00">Transformer</font> (BMT) method and produce temporal proposals with comparable performance. Furthermore, we concatenate the visual signal with our descriptor in a vanilla transformer method to achieve <font color="#00be00">state-of-the-art</font> performance in captioning compared to the methods that explore only visual features, as well as a <font color="#960096">competitive</font> performance with multi-modal methods. Our code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/valterlej/dvcusi. </br></br>

<a href='http://arxiv.org/pdf/2112.05851.pdf'>2112.05851</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.9638баллов, №78</br>
<b>Short and Long Range Relation Based Spatio-Temporal <font color="#00be00">Transformer</font> for\n  Micro-Expression Recognition</b></br>
Authors: , Zhang, Liangfei, Hong, Xiaopeng, Arandjelovic, Ognjen, Zhao, Guoying</br>
  Being spontaneous, micro-expressions are useful in the inference of a person\'s true <font color="#be00be">emotion</font>s even if an attempt is made to conceal them. Due to their short duration and low intensity, the recognition of micro-expressions is a difficult task in affective computing. The early work based on handcrafted spatio-temporal features which showed some promise, has recently been superseded by different deep learning approaches which now compete for the <font color="#00be00">state of the art</font> performance. Nevertheless, the problem of capturing both local and global spatio-temporal patterns remains challenging. To this end, herein we propose a novel spatio-temporal <font color="#00be00">transformer</font> architecture -- to the best of our knowledge, the first purely transformer based approach (i.e. void of any convolutional network use) for micro-expression recognition. The architecture comprises a spatial encoder which learns spatial patterns, a temporal aggregator for temporal dimension analysis, and a classification head. A comprehensive evaluation on three widely used spontaneous micro-expression data sets, namely SMIC-HS, CASME II and SAMM, shows that the proposed approach consistently <font color="#00be00">outperform</font>s the state of the art, and is the first framework in the published literature on micro-expression recognition to achieve the unweighted F1-score greater than 0.9 on any of the aforementioned data sets. </br></br>

<a href='http://arxiv.org/pdf/2112.06625.pdf'>2112.06625</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.9552баллов, №79</br>
<b><font color="#00be00">Lifelong</font> Hyper-Policy Optimization with Multiple Importance Sampling\n  Regularization</b></br>
Authors: , Liotet, Pierre, Vidaich, Francesco, Metelli, Alberto Maria, Restelli, Marcello</br>
  Learning in a <font color="#00be00">lifelong</font> setting, where the dynamics continually evolve, is a hard challenge for current <font color="#00be00">reinforcement learning</font> algorithms. Yet this would be a much needed feature for practical applications. In this paper, we propose an approach which learns a hyper-policy, whose input is time, that outputs the parameters of the policy to be queried at that time. This hyper-policy is trained to maximize the estimated future performance, efficiently reusing past data by means of importance sampling, at the cost of introducing a controlled bias. We combine the future performance estimate with the past performance to mitigate catastrophic forgetting. To avoid overfitting the collected data, we derive a differentiable variance bound that we embed as a penalization term. Finally, we empirically validate our approach, in comparison with <font color="#00be00">state-of-the-art</font> algorithms, on realistic environments, including water resource management and trading. </br></br>

<a href='http://arxiv.org/pdf/2112.09129.pdf'>2112.09129</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.9513баллов, №80</br>
<b>Decoupling and Recoupling Spatiotemporal Representation for RGB-D-based\n  Motion Recognition</b></br>
Authors: , Zhou, Benjia, Wang, Pichao, Wan, Jun, Liang, Yanyan, Wang, Fan, Zhang, Du, Lei, Zhen, Li, Hao, Jin, Rong</br>
  Decoupling spatiotemporal representation refers to decomposing the spatial and temporal features into dimension-independent factors. Although previous RGB-D-based motion recognition methods have achieved promising performance through the tightly coupled multi-modal spatiotemporal representation, they still suffer from (i) optimization difficulty under small data setting due to the tightly spatiotemporal-entangled modeling;(ii) information redundancy as it usually contains lots of marginal information that is weakly relevant to classification; and (iii) low interaction between multi-modal spatiotemporal information caused by insufficient late fusion. To alleviate these drawbacks, we propose to decouple and recouple spatiotemporal representation for RGB-D-based motion recognition. Specifically, we disentangle the task of learning spatiotemporal representation into 3 sub-tasks: (1) Learning high-quality and dimension independent features through a decoupled spatial and temporal modeling network. (2) Recoupling the decoupled representation to establish stronger space-time dependency. (3) Introducing a Cross-modal Adaptive Posterior Fusion (CAPF) mechanism to capture cross-modal spatiotemporal information from RGB-D data. Seamless combination of these novel designs forms a robust spatialtemporal representation and achieves better performance than <font color="#00be00">state-of-the-art</font> methods on four public motion datasets. Our code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/damo-cv/MotionRGBD. </br></br>

<a href='http://arxiv.org/pdf/2112.08438.pdf'>2112.08438</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.9171баллов, №81</br>
<b>Programmatic Reward Design by Example</b></br>
Authors: , Zhou, Weichao, Li, Wenchao</br>
  Reward design is a fundamental problem in <font color="#00be00">reinforcement learning</font> (RL). A misspecified or poorly designed reward can result in low <font color="#00be00">sample efficien</font>cy and undesired behaviors. In this paper, we propose the idea of \\textit{programmatic reward design}, i.e. using programs to specify the reward functions in RL environments. Programs allow human engineers to express sub-goals and complex task scenarios in a structured and <font color="#be00be">interpret</font>able way. The challenge of programmatic reward design, however, is that while humans can provide the high-level structures, properly setting the low-level details, such as the right amount of reward for a specific sub-task, remains difficult. A major contribution of this paper is a probabilistic framework that can infer the best candidate programmatic reward function from expert demonstrations. Inspired by recent generative-adversarial approaches, our framework {searches for the most likely programmatic reward function under which the optimally generated trajectories cannot be differentiated from the demonstrated trajectories}. Experimental results show that programmatic reward functions learned using this framework can significantly <font color="#00be00">outperform</font> those learned using existing reward learning algorithms, and enable RL agents to achieve <font color="#00be00">state-of-the-art</font> performance on highly complex tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.06502.pdf'>2112.06502</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.9160баллов, №82</br>
<b>DGL-GAN: Discriminator Guided Learning for GAN Compression</b></br>
Authors: , Tian, Yuesong, Shen, Li, Tao, Dacheng, Li, Zhifeng, Liu, Wei</br>
  Generative Adversarial Networks (GANs) with high computation costs, e.g., BigGAN and <font color="#be00be">Style</font>GAN2, have achieved remarkable results in synthesizing high resolution and diverse images with high fidelity from random noises. Reducing the computation cost of GANs while keeping generating photo-realistic images is an urgent and challenging field for their broad applications on computational resource-limited devices. In this work, we propose a novel yet simple {\\bf D}iscriminator {\\bf G}uided {\\bf L}earning approach for compressing vanilla {\\bf GAN}, dubbed {\\bf DGL-GAN}. Motivated by the phenomenon that the teacher discriminator may contain some meaningful information, we transfer the knowledge merely from the teacher discriminator via the adversarial function. We show DGL-GAN is valid since empirically, learning from the teacher discriminator could facilitate the performance of student GANs, verified by extensive experimental findings. Furthermore, we propose a two-stage training strategy for training DGL-GAN, which can largely stabilize its training process and achieve superior performance when we apply DGL-GAN to compress the two most representative large-scale vanilla GANs, i.e., StyleGAN2 and BigGAN. Experiments show that DGL-GAN achieves <font color="#00be00">state-of-the-art</font> (SOTA) results on both StyleGAN2 (FID 2.92 on FFHQ with nearly $1/3$ parameters of StyleGAN2) and BigGAN (IS 93.29 and FID 9.92 on ImageNet with nearly $1/4$ parameters of BigGAN) and also <font color="#00be00">outperform</font>s several existing vanilla GAN compression techniques. Moreover, DGL-GAN is also effective in boosting the performance of original uncompressed GANs, original uncompressed StyleGAN2 boosted with DGL-GAN achieves FID 2.65 on FFHQ, which achieves a new state-of-the-art performance. Code and models are available at \\url{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/yuesongtian/DGL-GAN}. </br></br>

<a href='http://arxiv.org/pdf/2112.01527.pdf'>2112.01527</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 1.9055баллов, №83</br>
<b>Masked-attention Mask <font color="#00be00">Transformer</font> for Universal Image <font color="#be00be">Segmentation</font></b></br>
Authors: , Cheng, Bowen, Misra, Ishan, Schwing, Alexander G., Kirillov, Alexander, Girdhar, Rohit</br>
  Image <font color="#be00be">segmentation</font> is about grouping pixels with different semantics, e.g., category or instance membership, where each choice of semantics defines a task. While only the semantics of each task differ, current research focuses on designing specialized architectures for each task. We present Masked-attention Mask <font color="#00be00">Transformer</font> (Mask2Former), a new architecture capable of addressing any image segmentation task (panoptic, instance or semantic). Its key components include masked attention, which extracts localized features by constraining cross-attention within predicted mask regions. In addition to reducing the research effort by at least three times, it <font color="#00be00">outperform</font>s the best specialized architectures by a significant margin on four popular datasets. Most notably, Mask2Former sets a new <font color="#00be00">state-of-the-art</font> for panoptic segmentation (57.8 PQ on COCO), instance segmentation (50.1 AP on COCO) and semantic segmentation (57.7 mIoU on ADE20K). </br></br>

<a href='http://arxiv.org/pdf/2112.05485.pdf'>2112.05485</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.8842баллов, №84</br>
<b>Visual <font color="#00be00">Transformer</font>s with Primal Object Queries for Multi-Label Image\n  Classification</b></br>
Authors: , Yazici, Vacit Oguz, van de Weijer, Joost, Yu, Longlong</br>
  Multi-label image classification is about predicting a set of class labels that can be considered as orderless sequential data. <font color="#00be00">Transformer</font>s process the sequential data as a whole, therefore they are inherently good at set prediction. The first vision-based transformer model, which was proposed for the <font color="#be00be">object detection</font> task introduced the concept of object queries. Object queries are learnable positional encodings that are used by attention modules in decoder layers to decode the object classes or bounding boxes using the region of interests in an image. However, inputting the same set of object queries to different decoder layers hinders the training: it results in lower performance and delays convergence. In this paper, we propose the usage of primal object queries that are only provided at the start of the transformer decoder stack. In addition, we improve the mixup technique proposed for multi-label classification. The proposed transformer model with primal object queries improves the <font color="#00be00">state-of-the-art</font> class wise F1 metric by 2.1% and 1.8%; and speeds up the convergence by 79.0% and 38.6% on MS-COCO and NUS-WIDE datasets respectively. </br></br>

<a href='http://arxiv.org/pdf/2112.06253.pdf'>2112.06253</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV) &nbsp&nbsp 1.8770баллов, №85</br>
<b>Up to 100x Faster Data-free Knowledge Distillation</b></br>
Authors: , Fang, Gongfan, Mo, Kanya, Wang, Xinchao, Song, Jie, Bei, Shitao, Zhang, Haofei, Song, Mingli</br>
  Data-free knowledge distillation (DFKD) has recently been attracting increasing attention from research communities, attributed to its capability to compress a model only using synthetic data. Despite the encouraging results achieved, <font color="#00be00">state-of-the-art</font> DFKD methods still suffer from the inefficiency of data synthesis, making the data-free training process extremely time-consuming and thus inapplicable for large-scale tasks. In this work, we introduce an efficacious scheme, termed as FastDFKD, that allows us to accelerate DFKD by a factor of orders of magnitude. At the heart of our approach is a novel strategy to reuse the shared common features in training data so as to synthesize different data instances. Unlike prior methods that optimize a set of data independently, we propose to learn a meta-synthesizer that seeks common features as the initialization for the fast data synthesis. As a result, FastDFKD achieves data synthesis within only a few steps, significantly enhancing the efficiency of data-free training. Experiments over CIFAR, NYUv2, and ImageNet demonstrate that the proposed FastDFKD achieves 10$\\times$ and even 100$\\times$ acceleration while preserving performances on par with <font color="#00be00">state of the art</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.06109.pdf'>2112.06109</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.8599баллов, №86</br>
<b>Injecting Numerical Reasoning Skills into Knowledge Base Question\n  Answering Models</b></br>
Authors: , Feng, Yu, Zhang, Jing, Zhang, Xiaokang, Liu, Lemao, Li, Cuiping, Chen, Hong</br>
  Embedding-based methods are popular for Knowledge Base Question Answering (KBQA), but few current models have numerical reasoning skills and thus struggle to answer ordinal constrained questions. This paper proposes a new embedding-based KBQA framework which particularly takes numerical reasoning into account. We present Numerical<font color="#00be00">Transformer</font> on top of NSM, a <font color="#00be00">state-of-the-art</font> embedding-based KBQA model, to create NT-NSM. To enable better training, we propose two pre-training tasks with explicit numerical-oriented loss functions on two generated training datasets and a template-based data augmentation method for enriching ordinal constrained QA dataset. Extensive experiments on KBQA benchmarks demonstrate that with the help of our training algorithm, NT-NSM is empowered with numerical reasoning skills and substantially <font color="#00be00">outperform</font>s the baselines in answering ordinal constrained questions. </br></br>

<a href='http://arxiv.org/pdf/2111.06266.pdf'>2111.06266</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.8534баллов, №87</br>
<b>AlphaDDA: Game artificial intelligence with dynamic difficulty\n  adjustment using <font color="#00be00">AlphaZero</font></b></br>
Authors: , Fujita, Kazuhisa</br>
  Artificial intelligence (AI) has achieved superhuman performance in board games such as Go, chess, and Othello (Reversi). In other words, AI has become too strong an opponent for human players in such games. In this context, it is difficult for a human player to enjoy playing the games with the AI. To keep human players entertained and immersed in a game, the AI is required to dynamically balance its skill with that of the human player. To address this issue, we propose AlphaDDA, an <font color="#00be00">AlphaZero</font>-based AI with dynamic difficulty adjustment (DDA). AlphaDDA consists of a deep neural network (DNN) and a Monte Carlo tree search, as in AlphaZero. AlphaDDA estimates the value of the game state from only the board state using the DNN and changes its skill according to the value. AlphaDDA can adjust its skill using only the state of a game without any prior knowledge regarding an opponent. In this study, AlphaDDA plays Connect4, Othello, and 6x6 Othello, which is Othello using a 6x6 size board, with other AI agents. The other AI agents are AlphaZero, Monte Carlo tree search, the minimax algorithm, and a random player. This study shows that AlphaDDA can balance its skill with that of the other AI agents, except for a random player. The DDA ability of AlphaDDA is derived from an accurate estimation of the value from the state of a game. We believe that the AlphaDDA approach can be used for any game in which the DNN can estimate the value from the state. </br></br>

<a href='http://arxiv.org/pdf/2112.08370.pdf'>2112.08370</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV) &nbsp&nbsp 1.8517баллов, №88</br>
<b><font color="#00be00">Lifelong</font> Generative Modelling Using Dynamic Expansion Graph Model</b></br>
Authors: , Ye, Fei, Bors, Adrian G.</br>
  Variational Autoencoders (VAEs) suffer from degenerated performance, when learning several successive tasks. This is caused by catastrophic forgetting. In order to address the knowledge loss, VAEs are using either Generative Replay (GR) mechanisms or Expanding Network Architectures (ENA). In this paper we study the forgetting behaviour of VAEs using a joint GR and ENA methodology, by deriving an upper bound on the negative marginal log-likelihood. This <font color="#be00be">theor</font>etical analysis provides new insights into how VAEs forget the previously learnt knowledge during <font color="#00be00">lifelong</font> learning. The analysis indicates the best performance achieved when considering model mixtures, under the ENA framework, where there are no restrictions on the number of components. However, an ENA-based approach may require an excessive number of parameters. This motivates us to propose a novel Dynamic Expansion Graph Model (DEGM). DEGM expands its architecture, according to the novelty associated with each new databases, when compared to the information already learnt by the network from previous tasks. DEGM training optimizes knowledge structuring, characterizing the joint probabilistic representations corresponding to the past and more recently learned tasks. We demonstrate that DEGM guarantees optimal performance for each task while also minimizing the required number of parameters. Supplementary materials (SM) and <font color="#00be00">source code</font> are available in <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/dtuzi123/Expansion-Graph-Model. </br></br>

<a href='http://arxiv.org/pdf/2111.05011.pdf'>2111.05011</a> &nbsp&nbsp (cs:ML, cs:SD) &nbsp&nbsp 1.8510баллов, №89</br>
<b>RAVE: A variational autoencoder for fast and high-quality neural audio\n  synthesis</b></br>
Authors: , Caillon, Antoine, Esling, Philippe</br>
  Deep generative models applied to audio have improved by a large margin the <font color="#00be00">state-of-the-art</font> in many speech and<font color="#be00be"> music </font>related tasks. However, as raw waveform modelling remains an inherently difficult task, audio generative models are either computationally intensive, rely on low sampling rates, are complicated to control or restrict the nature of possible signals. Among those models, Variational AutoEncoders (VAE) give control over the generation by exposing latent variables, although they usually suffer from low synthesis quality. In this paper, we introduce a Realtime Audio Variational autoEncoder (RAVE) allowing both fast and high-quality audio waveform synthesis. We introduce a novel two-stage training procedure, namely representation learning and adversarial fine-tuning. We show that using a post-training analysis of the latent space allows a direct control between the reconstruction fidelity and the representation compactness. By leveraging a multi-band decomposition of the raw waveform, we show that our model is the first able to generate 48kHz audio signals, while simultaneously running 20 times faster than real-time on a standard laptop CPU. We evaluate synthesis quality using both quantitative and qualitative subjective experiments and show the superiority of our approach compared to existing models. Finally, we present applications of our model for timbre transfer and signal compression. All of our <font color="#00be00">source code</font> and audio examples are <font color="#00be00">publicly available</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.05646.pdf'>2112.05646</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.8422баллов, №90</br>
<b>Mask-invariant<font color="#be00be"> Face </font>Recognition through Template-level Knowledge\n  Distillation</b></br>
Authors: , Huber, Marco, Boutros, Fadi, Kirchbuchner, Florian, Damer, Naser</br>
  The emergence of the global COVID-19 pandemic poses new challenges for biometrics. Not only are contactless biometric identification options becoming more important, but<font color="#be00be"> face </font>recognition has also recently been confronted with the frequent wearing of masks. These masks affect the performance of previous face recognition systems, as they hide important identity information. In this paper, we propose a mask-invariant face recognition solution (MaskInv) that utilizes template-level knowledge distillation within a training paradigm that aims at producing embeddings of masked faces that are similar to those of non-masked faces of the same identities. In addition to the distilled knowledge, the student network benefits from additional guidance by margin-based identity classification loss, ElasticFace, using masked and non-masked faces. In a step-wise ablation study on two real masked face databases and five mainstream databases with synthetic masks, we prove the rationalization of our MaskInv approach. Our proposed solution <font color="#00be00">outperform</font>s previous <font color="#00be00">state-of-the-art</font> (SOTA) academic solutions in the recent MFRC-21 challenge in both scenarios, masked vs masked and masked vs non-masked, and also outperforms the previous solution on the MFR2 dataset. Furthermore, we demonstrate that the proposed model can still perform well on unmasked faces with only a minor loss in verification performance. The code, the trained models, as well as the evaluation protocol on the synthetically masked data are <font color="#00be00">publicly available</font>: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/fdbtrs/Masked-Face-Recognition-KD. </br></br>

<a href='http://arxiv.org/pdf/2112.07381.pdf'>2112.07381</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 1.8401баллов, №91</br>
<b>You Only Need One Model for Open-domain Question Answering</b></br>
Authors: , Lee, Haejun, Kedia, Akhil, Lee, Jongwon, Paranjape, Ashwin, Manning, Christopher D., Woo, Kyoung-Gu</br>
  Recent works for Open-domain Question Answering refer to an external knowledge base using a retriever model, optionally rerank the passages with a separate reranker model and generate an answer using an another reader model. Despite performing related tasks, the models have separate parameters and are weakly-coupled during training. In this work, we propose casting the retriever and the reranker as hard-attention mechanisms applied sequentially within the <font color="#00be00">transformer</font> architecture and feeding the resulting computed representations to the reader. In this singular model architecture the hidden representations are progressively refined from the retriever to the reranker to the reader, which is more efficient use of model capacity and also leads to better gradient flow when we train it in an end-to-end manner. We also propose a pre-training methodology to effectively train this architecture. We evaluate our model on Natural Questions and TriviaQA open datasets and for a fixed parameter budget, our model <font color="#00be00">outperform</font>s the previous <font color="#00be00">state-of-the-art</font> model by 1.0 and 0.7 exact match scores. </br></br>

<a href='http://arxiv.org/pdf/2112.07443.pdf'>2112.07443</a> &nbsp&nbsp (cs:CL, cs:CV) &nbsp&nbsp 1.8339баллов, №92</br>
<b>Text Classification Models for Form Entity Linking</b></br>
Authors: , Villota, Mar&#xed;a, Dom&#xed;nguez, C&#xe9;sar, Heras, J&#xf3;nathan, Mata, Eloy, Pascual, Vico</br>
  Forms are a widespread type of template-based document used in a great variety of fields including, among others, administration, <font color="#640064">medic</font>ine, <font color="#be00be">financ</font>e, or insurance. The automatic extraction of the information included in these documents is greatly demanded due to the increasing volume of forms that are generated in a daily basis. However, this is not a straightforward task when working with scanned forms because of the great diversity of templates with different location of form entities, and the quality of the scanned documents. In this context, there is a feature that is shared by all forms: they contain a collection of interlinked entities built as key-value (or label-value) pairs, together with other entities such as headers or images. In this work, we have tacked the problem of entity linking in forms by combining image processing techniques and a text classification model based on the<font color="#00be00"> BERT </font>architecture. This approach achieves <font color="#00be00">state-of-the-art</font> results with a F1-score of 0.80 on the FUNSD dataset, a 5% improvement regarding the best previous method. The code of this project is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/mavillot/FUNSD-Entity-Linking. </br></br>

<a href='http://arxiv.org/pdf/2112.05683.pdf'>2112.05683</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.8136баллов, №93</br>
<b>Boosting Active Learning via Improving Test Performance</b></br>
Authors: , Wang, Tianyang, Li, Xingjian, Yang, Pengkun, Hu, Guosheng, Zeng, Xiangrui, Huang, Siyu, Xu, Cheng-Zhong, Xu, Min</br>
  Central to active learning (AL) is what data should be selected for annotation. Existing works attempt to select highly uncertain or informative data for annotation. Nevertheless, it remains unclear how selected data impacts the test performance of the task model used in AL. In this work, we explore such an impact by <font color="#be00be">theor</font>etically proving that selecting unlabeled data of higher gradient norm leads to a lower upper bound of test loss, resulting in a better test performance. However, due to the lack of label information, directly computing gradient norm for unlabeled data is infeasible. To address this challenge, we propose two schemes, namely expected-gradnorm and entropy-gradnorm. The former computes the gradient norm by constructing an expected empirical loss while the latter constructs an unsupervised loss with entropy. Furthermore, we integrate the two schemes in a universal AL framework. We evaluate our method on classical image classification and semantic <font color="#be00be">segmentation</font> tasks. To demonstrate its competency in domain applications and its robustness to noise, we also validate our method on a cellular imaging analysis task, namely cryo-Electron <font color="#be00be">Tomography</font> subtomogram classification. Results demonstrate that our method achieves superior performance against the <font color="#00be00">state-of-the-art</font>. Our <font color="#00be00">source code</font> is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/xulabs/aitom </br></br>

<a href='http://arxiv.org/pdf/2112.07282.pdf'>2112.07282</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.8104баллов, №94</br>
<b>SNF: Filter Pruning via Searching the Proper Number of Filters</b></br>
Authors: , Liu, Pengkun, Yue, Yaru, Guo, Yanjun, Tao, Xingxiang, Zhou, Xiaoguang</br>
  Convolutional Neural Network (CNN) has an amount of parameter redundancy, filter pruning aims to remove the redundant filters and provides the possibility for the application of CNN on terminal devices. However, previous works pay more attention to designing evaluation criteria of filter importance and then prune less important filters with a fixed pruning rate or a fixed number to reduce convolutional neural networks\' redundancy. It does not consider how many filters to reserve for each layer is the most reasonable choice. From this perspective, we propose a new filter pruning method by searching the proper number of filters (SNF). SNF is dedicated to searching for the most reasonable number of reserved filters for each layer and then pruning filters with specific criteria. It can tailor the most suitable network structure at different FLOPs. Filter pruning with our method leads to the <font color="#00be00">state-of-the-art</font> (SOTA) accuracy on CIFAR-10 and achieves <font color="#960096">competitive</font> performance on ImageNet ILSVRC-2012.SNF based on the ResNet-56 network achieves an increase of 0.14% in Top-1 accuracy at 52.94% FLOPs reduction on CIFAR-10. Pruning ResNet-110 on CIFAR-10 also improves the Top-1 accuracy of 0.03% when reducing 68.68% FLOPs. For ImageNet, we set the pruning rates as 52.10% FLOPs, and the Top-1 accuracy only has a drop of 0.74%. The codes can be available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/pk-l/SNF. </br></br>

<a href='http://arxiv.org/pdf/2112.07637.pdf'>2112.07637</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.7983баллов, №95</br>
<b>Exploring Neural Models for Query-Focused <font color="#be00be">Summarization</font></b></br>
Authors: , Vig, Jesse, Fabbri, Alexander R., Kry&#x15b;ci&#x144;ski, Wojciech, Wu, Chien-Sheng, Liu, Wenhao</br>
  Query-focused <font color="#be00be">summarization</font> (QFS) aims to produce summaries that answer particular questions of interest, enabling greater user control and personalization. While recently released datasets, such as QMSum or AQuaMuSe, facilitate research efforts in QFS, the field lacks a comprehensive study of the broad space of applicable modeling methods. In this paper we conduct a systematic exploration of neural approaches to QFS, considering two general classes of methods: two-stage extractive-abstractive solutions and end-to-end models. Within those categories, we investigate existing methods and present two model extensions that achieve <font color="#00be00">state-of-the-art</font> performance on the QMSum dataset by a margin of up to 3.38 ROUGE-1, 3.72 ROUGE-2, and 3.28 ROUGE-L. Through quantitative experiments we highlight the trade-offs between different model configurations and explore the transfer abilities between summarization tasks. Code and checkpoints are made <font color="#00be00">publicly available</font>: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/salesforce/query-focused-sum. </br></br>

<a href='http://arxiv.org/pdf/2112.08593.pdf'>2112.08593</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 1.7952баллов, №96</br>
<b>Goal-Directed Story Generation: Augmenting Generative Language Models\n  with <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Alabdulkarim, Amal, Li, Winston, Martin, Lara J., Riedl, Mark O.</br>
  The advent of large pre-trained generative language models has provided a common framework for AI story generation via sampling the model to create sequences that continue the story. However, sampling alone is insufficient for story generation. In particular, it is hard to direct a language model to create stories to reach a specific goal event. We present two automated techniques grounded in deep <font color="#00be00">reinforcement learning</font> and reward shaping to control the plot of computer-generated stories. The first utilizes proximal policy optimization to fine-tune an existing <font color="#00be00">transformer</font>-based language model to generate text continuations but also be goal-seeking. The second extracts a <font color="#960096">knowledge graph</font> from the unfolding story, which is used by a policy network with graph attention to select a candidate continuation generated by a language model. We report on automated metrics pertaining to how often stories achieve a given goal event as well as human participant rankings of coherence and overall story quality compared to baselines and ablations. </br></br>

<a href='http://arxiv.org/pdf/2112.08688.pdf'>2112.08688</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.7870баллов, №97</br>
<b>Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks</b></br>
Authors: , Asai, Akari, Gardner, Matt, Hajishirzi, Hannaneh</br>
  <font color="#be00be">Retrieval</font>-augmented generation models have shown <font color="#00be00">state-of-the-art</font> performance across many knowledge-intensive NLP tasks such as open question answering and fact verification. These models are trained to generate the final output given the retrieved passages, which can be irrelevant to the original query, leading to learning spurious cues or answer memorization. This work introduces a method to incorporate evidentiality of passages -- whether a passage contains correct evidence to support the output -- into training the generator. We introduce a multi-task learning framework to jointly generate the final output and predict the evidentiality of each passage, leveraging a new task-agnostic method to obtain {\\it silver} evidentiality labels for supervision. Our experiments on five datasets across three knowledge-intensive tasks show that our new evidentiality-guided generator significantly <font color="#00be00">outperform</font>s its direct counterpart with the same-size model and advances the <font color="#00be00">state of the art</font> on FaVIQ-Ambig. We attribute these improvements to both the auxiliary multi-task learning and silver evidentiality mining techniques. </br></br>

<a href='http://arxiv.org/pdf/2112.05236.pdf'>2112.05236</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.7716баллов, №98</br>
<b>KartalOl: Transfer learning using deep neural network for iris\n  <font color="#be00be">segmentation</font> and localization: New dataset for iris segmentation</b></br>
Authors: , Khiarak, Jalil Nourmohammadi, Nasab, Samaneh Salehi, Jaryani, Farhang, Moafinejad, Seyed Naeim, Pourmohamad, Rana, Amini, Yasin, Noshad, Morteza</br>
  Iris <font color="#be00be">segmentation</font> and localization in unconstrained environments is challenging due to long distances, illumination variations, limited user cooperation, and moving subjects. To address this problem, we present a U-Net with a pre-trained MobileNetV2 deep neural network method. We employ the pre-trained weights given with MobileNetV2 for the ImageNet dataset and fine-tune it on the iris recognition and localization domain. Further, we have introduced a new dataset, called KartalOl, to better evaluate detectors in iris recognition scenarios. To provide domain adaptation, we fine-tune the MobileNetV2 model on the provided data for NIR-ISL 2021 from the CASIA-Iris-Asia, CASIA-Iris-M1, and CASIA-Iris-Africa and our dataset. We also augment the data by performing left-right flips, rotation, zoom, and brightness. We chose the binarization threshold for the binary masks by iterating over the images in the provided dataset. The proposed method is tested and trained in CASIA-Iris-Asia, CASIA-Iris-M1, CASIA-Iris-Africa, along the KartalOl dataset. The experimental results highlight that our method surpasses <font color="#00be00">state-of-the-art</font> methods on mobile-based benchmarks. The codes and evaluation results are <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/Jalilnkh/KartalOl-NIR-ISL2021031301. </br></br>

<a href='http://arxiv.org/pdf/2112.06375.pdf'>2112.06375</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.7699баллов, №99</br>
<b>Embracing Single Stride 3D Object Detector with Sparse <font color="#00be00">Transformer</font></b></br>
Authors: , Fan, Lue, Pang, Ziqi, Zhang, Tianyuan, Wang, Yu-Xiong, Zhao, Hang, Wang, Feng, Wang, Naiyan, Zhang, Zhaoxiang</br>
  In <font color="#be00be">LiDAR</font>-based 3D <font color="#be00be">object detection</font> for autonomous driving, the ratio of the object size to input scene size is significantly smaller compared to 2D detection cases. Overlooking this difference, many 3D detectors directly follow the common practice of 2D detectors, which downsample the feature maps even after quantizing the <font color="#be00be">point cloud</font>s. In this paper, we start by rethinking how such multi-stride stereotype affects the LiDAR-based 3D object detectors. Our experiments point out that the downsampling operations bring few advantages, and lead to inevitable information loss. To remedy this issue, we propose Single-stride Sparse <font color="#00be00">Transformer</font> (SST) to maintain the original resolution from the beginning to the end of the network. Armed with transformers, our method addresses the problem of insufficient receptive field in single-stride architectures. It also cooperates well with the sparsity of point clouds and naturally avoids expensive computation. Eventually, our SST achieves <font color="#00be00">state-of-the-art</font> results on the large scale Waymo Open Dataset. It is worth mentioning that our method can achieve exciting performance (83.8 LEVEL 1 AP on validation split) on small object (<font color="#be00be">pedestrian</font>) detection due to the characteristic of single stride. Codes will be released at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/TuSimple/SST </br></br>

<a href='http://arxiv.org/pdf/2112.08995.pdf'>2112.08995</a> &nbsp&nbsp (cs:SD, cs:CL, cs:CV) &nbsp&nbsp 1.7590баллов, №100</br>
<b>Connecting the Dots between Audio and Text without Parallel Data through\n  Visual Knowledge Transfer</b></br>
Authors: , Zhao, Yanpeng, Hessel, Jack, Yu, Youngjae, Lu, Ximing, Zellers, Rowan, Choi, Yejin</br>
  Machines that can represent and describe environmental soundscapes have practical potential, e.g., for audio tagging and captioning systems. Prevailing learning paradigms have been relying on parallel audio-text data, which is, however, scarcely available on the web. We propose VIP-ANT that induces \\textbf{A}udio-\\textbf{T}ext alignment without using any parallel audio-text data. Our key idea is to share the image modality between bi-modal image-text representations and bi-modal image-audio representations; the image modality functions as a pivot and connects audio and text in a tri-modal embedding space implicitly.   In a difficult <font color="#00be00">zero-shot</font> setting with no paired audio-text data, our model demonstrates <font color="#00be00">state-of-the-art</font> zero-shot performance on the ESC50 and US8K audio classification tasks, and even surpasses the supervised <font color="#00be00">state of the art</font> for Clotho caption <font color="#be00be">retrieval</font> (with audio queries) by 2.2\\% R@1. We further investigate cases of minimal audio-text supervision, finding that, e.g., just a few hundred supervised audio-text pairs increase the zero-shot audio classification accuracy by 8\\% on US8K. However, to match human parity on some zero-shot tasks, our empirical scaling experiments suggest that we would need about $2^{21} \\approx 2M$ supervised audio-caption pairs. Our work opens up new avenues for learning audio-text connections with little to no parallel audio-text data. </br></br>

<a href='http://arxiv.org/pdf/2112.08567.pdf'>2112.08567</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.7527баллов, №101</br>
<b>HampDTI: a heterogeneous graph automatic meta-path learning method for\n  <font color="#00be00">drug</font>-target interaction prediction</b></br>
Authors: , Wang, Hongzhun, Huang, Feng, Zhang, Wen</br>
  Motivation: Identifying <font color="#00be00">drug</font>-target interactions (DTIs) is a key step in drug repositioning. In recent years, the accumulation of a large number of genomics and pharmacology data has formed mass drug and target related heterogeneous networks (HNs), which provides new opportunities of developing HN-based computational models to accurately predict DTIs. The HN implies lots of useful information about DTIs but also contains irrelevant data, and how to make the best of heterogeneous networks remains a challenge. Results: In this paper, we propose a heterogeneous graph automatic meta-path learning based DTI prediction method (HampDTI). HampDTI automatically learns the important meta-paths between drugs and targets from the HN, and generates meta-path graphs. For each meta-path graph, the features learned from drug <font color="#00be00">molecule</font> graphs and target protein sequences serve as the node attributes, and then a node-type specific graph convolutional network (NSGCN) which efficiently considers node type information (drugs or targets) is designed to learn embeddings of drugs and targets. Finally, the embeddings from multiple meta-path graphs are combined to predict novel DTIs. The experiments on benchmark datasets show that our proposed HampDTI achieves superior performance compared with <font color="#00be00">state-of-the-art</font> DTI prediction methods. More importantly, HampDTI identifies the important meta-paths for DTI prediction, which could explain how drugs connect with targets in HNs. </br></br>

<a href='http://arxiv.org/pdf/2112.02466.pdf'>2112.02466</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.7328баллов, №102</br>
<b>Pose-guided Feature Disentangling for Occluded Person <font color="#be00be">Re-identification</font>\n  Based on <font color="#00be00">Transformer</font></b></br>
Authors: , Wang, Tao, Liu, Hong, Song, Pinhao, Guo, Tianyu, Shi, Wei</br>
  Occluded person <font color="#be00be">re-identification</font> is a challenging task as human body parts could be occluded by some obstacles (e.g. trees, cars, and <font color="#be00be">pedestrian</font>s) in certain scenes. Some existing pose-guided methods solve this problem by aligning body parts according to graph matching, but these graph-based methods are not intuitive and complicated. Therefore, we propose a <font color="#00be00">transformer</font>-based Pose-guided Feature Disentangling (PFD) method by utilizing pose information to clearly disentangle semantic components (e.g. human body or joint parts) and selectively match non-occluded parts correspondingly. First, Vision Transformer (ViT) is used to extract the patch features with its strong capability. Second, to preliminarily disentangle the pose information from patch information, the matching and distributing mechanism is leveraged in Pose-guided Feature Aggregation (PFA) module. Third, a set of learnable semantic views are introduced in transformer decoder to implicitly enhance the disentangled body part features. However, those semantic views are not guaranteed to be related to the body without additional supervision. Therefore, Pose-View Matching (PVM) module is proposed to explicitly match visible body parts and automatically separate occlusion features. Fourth, to better prevent the interference of occlusions, we design a Pose-guided Push Loss to emphasize the features of visible body parts. Extensive experiments over five challenging datasets for two tasks (occluded and holistic Re-ID) demonstrate that our proposed PFD is superior promising, which performs favorably against <font color="#00be00">state-of-the-art</font> methods. Code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/WangTaoAs/PFD_Net </br></br>

<a href='http://arxiv.org/pdf/2112.07571.pdf'>2112.07571</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.7263баллов, №103</br>
<b>Epigenomic language models powered by Cerebras</b></br>
Authors: , Trotter, Meredith V., Nguyen, Cuong Q., Young, Stephen, Woodruff, Rob T., Branson, Kim M.</br>
  Large scale self-supervised pre-training of <font color="#00be00">Transformer</font> language models has advanced the field of Natural Language Processing and shown promise in cross-application to the biological `languages\' of proteins and DNA. Learning effective representations of DNA sequences using large genomic sequence corpuses may accelerate the development of models of gene regulation and function through transfer learning. However, to accurately model cell type-specific gene regulation and function, it is necessary to consider not only the information contained in DNA nucleotide sequences, which is mostly invariant between cell types, but also how the local chemical and structural `epigenetic state\' of chromosomes varies between cell types. Here, we introduce a Bidirectional Encoder Representations from Transformers (BERT) model that learns representations based on both DNA sequence and paired epigenetic state inputs, which we call Epigenomic<font color="#00be00"> BERT </font>(or EBERT). We pre-train EBERT with a masked language model objective across the entire human genome and across 127 cell types. Training this complex model with a previously prohibitively large dataset was made possible for the first time by a partnership with Cerebras Systems, whose CS-1 system powered all pre-training experiments. We show EBERT\'s transfer learning potential by demonstrating strong performance on a cell type-specific transcription factor binding prediction task. Our fine-tuned model exceeds <font color="#00be00">state of the art</font> performance on 4 of 13 evaluation datasets from ENCODE-DREAM benchmarks and earns an overall rank of 3rd on the challenge leaderboard. We explore how the inclusion of epigenetic data and task specific feature augmentation impact transfer learning performance. </br></br>

<a href='http://arxiv.org/pdf/2112.08810.pdf'>2112.08810</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.7160баллов, №104</br>
<b>Pure Noise to the Rescue of Insufficient Data: Improving Imbalanced\n  Classification by Training on Random Noise Images</b></br>
Authors: , Zada, Shiran, Benou, Itay, Irani, Michal</br>
  Despite remarkable progress on visual recognition tasks, deep neural-nets still struggle to generalize well when training data is scarce or highly imbalanced, rendering them extremely vulnerable to <font color="#009600">real-world</font> examples. In this paper, we present a <font color="#00be00">surprisin</font>gly simple yet highly effective method to mitigate this limitation: using pure noise images as additional training data. Unlike the common use of additive noise or adversarial noise for data augmentation, we propose an entirely different perspective by directly training on pure random noise images. We present a new Distribution-Aware Routing Batch Normalization layer (DAR-BN), which enables training on pure noise images in addition to natural images within the same network. This encourages generalization and suppresses overfitting. Our proposed method significantly improves imbalanced classification performance, obtaining <font color="#00be00">state-of-the-art</font> results on a large variety of long-tailed image classification datasets (CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, Places-LT, and CelebA-5). Furthermore, our method is extremely simple and easy to use as a general new augmentation tool (on top of existing augmentations), and can be incorporated in any training scheme. It does not require any specialized data generation or training procedures, thus keeping training fast and efficient </br></br>

<a href='http://arxiv.org/pdf/2111.14056.pdf'>2111.14056</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.7143баллов, №105</br>
<b>Towards Robust and Automatic Hyper-Parameter Tunning</b></br>
Authors: , Tuli, Mathieu, Hosseini, Mahdi S., Plataniotis, Konstantinos N.</br>
  The task of hyper-parameter optimization (HPO) is burdened with heavy computational costs due to the intractability of optimizing both a model\'s weights and its hyper-parameters simultaneously. In this work, we introduce a new class of HPO method and explore how the low-rank factorization of the convolutional weights of intermediate layers of a convolutional neural network can be used to define an analytical response surface for optimizing hyper-parameters, using only training data. We quantify how this surface behaves as a surrogate to model performance and can be solved using a trust-region search algorithm, which we call autoHyper. The algorithm <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> such as <font color="#be00be">Bayes</font>ian Optimization and generalizes across model, optimizer, and dataset selection. Our code can be found at \\url{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/MathieuTuli/autoHyper}. </br></br>

<a href='http://arxiv.org/pdf/2112.07966.pdf'>2112.07966</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.6933баллов, №106</br>
<b>Modality-Aware Triplet Hard Mining for <font color="#00be00">Zero-shot</font> Sketch-Based Image\n  <font color="#be00be">Retrieval</font></b></br>
Authors: , Huang, Zongheng, Sun, YiFan, Han, Chuchu, Gao, Changxin, Sang, Nong</br>
  This paper tackles the <font color="#00be00">Zero-Shot</font> Sketch-Based Image <font color="#be00be">Retrieval</font> (ZS-SBIR) problem from the viewpoint of cross-modality metric learning. This task has two characteristics: 1) the zero-shot setting requires a metric space with good within-class compactness and the between-class discrepancy for recognizing the novel classes and 2) the sketch query and the photo gallery are in different modalities. The metric learning viewpoint benefits ZS-SBIR from two aspects. First, it facilitates improvement through recent good practices in deep metric learning (DML). By combining two fundamental learning approaches in DML, e.g., classification training and pairwise training, we set up a strong baseline for ZS-SBIR. Without bells and whistles, this baseline achieves <font color="#960096">competitive</font> retrieval accuracy. Second, it provides an insight that properly suppressing the modality gap is critical. To this end, we design a novel method named Modality-Aware Triplet Hard Mining (MATHM). MATHM enhances the baseline with three types of pairwise learning, e.g., a cross-modality sample pair, a within-modality sample pair, and their combination.\\We also design an adaptive weighting method to balance these three components during training dynamically. Experimental results confirm that MATHM brings another round of significant improvement based on the strong baseline and sets up new <font color="#00be00">state-of-the-art</font> performance. For example, on the TU-Berlin dataset, we achieve 47.88+2.94% mAP@all and 58.28+2.34% Prec@100. Code will be <font color="#00be00">publicly available</font> at: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/huangzongheng/MATHM. </br></br>

<a href='http://arxiv.org/pdf/2112.08614.pdf'>2112.08614</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.6885баллов, №107</br>
<b>KAT: A Knowledge Augmented <font color="#00be00">Transformer</font> for Vision-and-Language</b></br>
Authors: , Gui, Liangke, Wang, Borui, Huang, Qiuyuan, Hauptmann, Alex, Bisk, Yonatan, Gao, Jianfeng</br>
  The primary focus of recent work with largescale <font color="#00be00">transformer</font>s has been on optimizing the amount of information packed into the model\'s parameters. In this work, we ask a different question: Can multimodal transformers leverage explicit knowledge in their reasoning? Existing, primarily unimodal, methods have explored approaches under the paradigm of knowledge <font color="#be00be">retrieval</font> followed by answer prediction, but leave open questions about the quality and relevance of the retrieved knowledge used, and how the reasoning processes over implicit and explicit knowledge should be integrated. To address these challenges, we propose a novel model - Knowledge Augmented Transformer (KAT) - which achieves a strong <font color="#00be00">state-of-the-art</font> result (+6 points absolute) on the open-domain multimodal task of OK-VQA. Our approach integrates implicit and explicit knowledge in an end to end encoder-decoder architecture, while still jointly reasoning over both knowledge sources during answer generation. An additional benefit of explicit knowledge integration is seen in improved <font color="#be00be">interpret</font>ability of model predictions in our analysis. </br></br>

<a href='http://arxiv.org/pdf/2112.07013.pdf'>2112.07013</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 1.6799баллов, №108</br>
<b>PantheonRL: A MARL Library for Dynamic Training Interactions</b></br>
Authors: , Sarkar, Bidipta, Talati, Aditi, Shih, Andy, Sadigh, Dorsa</br>
  We present PantheonRL, a multiagent <font color="#00be00">reinforcement learning</font> software package for dynamic training interactions such as round-robin, adaptive, and ad-hoc training. Our package is designed around flexible agent objects that can be easily configured to support different training interactions, and handles fully general multiagent environments with mixed rewards and n agents. Built on top of StableBaselines3, our package works directly with existing powerful deep RL algorithms. Finally, PantheonRL comes with an intuitive yet functional web user interface for configuring experiments and launching multiple asynchronous jobs. Our package can be found at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/Stanford-ILIAD/PantheonRL. </br></br>

<a href='http://arxiv.org/pdf/2112.06054.pdf'>2112.06054</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.6748баллов, №109</br>
<b>Deterministic and Discriminative Imitation (D2-Imitation): Revisiting\n  Adversarial Imitation for <font color="#00be00">Sample Efficien</font>cy</b></br>
Authors: , Sun, Mingfei, Devlin, Sam, Hofmann, Katja, Whiteson, Shimon</br>
  <font color="#00be00">Sample efficien</font>cy is crucial for imitation learning methods to be applicable in <font color="#009600">real-world</font> applications. Many studies improve sample efficiency by extending adversarial imitation to be off-policy regardless of the fact that these off-policy extensions could either change the original objective or involve complicated optimization. We revisit the foundation of adversarial imitation and propose an off-policy sample efficient approach that requires no adversarial training or min-max optimization. Our formulation capitalizes on two key insights: (1) the similarity between the Bellman equation and the stationary state-action distribution equation allows us to derive a novel temporal difference (TD) learning approach; and (2) the use of a deterministic policy simplifies the TD learning. Combined, these insights yield a practical algorithm, Deterministic and Discriminative Imitation (D2-Imitation), which operates by first partitioning samples into two replay buffers and then learning a deterministic policy via off-policy <font color="#00be00">reinforcement learning</font>. Our empirical results show that D2-Imitation is effective in achieving good sample efficiency, <font color="#00be00">outperform</font>ing several off-policy extension approaches of adversarial imitation on many control tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.06052.pdf'>2112.06052</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp 1.6622баллов, №110</br>
<b>U-shaped <font color="#00be00">Transformer</font> with Frequency-Band Aware Attention for Speech\n  Enhancement</b></br>
Authors: , Li, Yi, Sun, Yang, Naqvi, Syed Mohsen</br>
  The <font color="#00be00">state-of-the-art</font> <font color="#be00be">speech enhancement</font> has limited performance in speech estimation accuracy. Recently, in deep learning, the <font color="#00be00">Transformer</font> shows the potential to exploit the long-range dependency in speech by self-attention. Therefore, it is introduced in speech enhancement to improve the speech estimation accuracy from a noise mixture. However, to address the computational cost issue in Transformer with self-attention, the axial attention is the option i.e., to split a 2D attention into two 1D attentions. Inspired by the axial attention, in the proposed method we calculate the attention map along both time- and frequency-axis to generate time and frequency sub-attention maps. Moreover, different from the axial attention, the proposed method provides two parallel multi-head attentions for time- and frequency-axis. Furthermore, it is proven in the literature that the lower frequency-band in speech, generally, contains more desired information than the higher frequency-band, in a noise mixture. Therefore, the frequency-band aware attention is proposed i.e., high frequency-band attention (HFA), and low frequency-band attention (LFA). The U-shaped Transformer is also first time introduced in the proposed method to further improve the speech estimation accuracy. The extensive evaluations over four public datasets, confirm the efficacy of the proposed method. </br></br>

<a href='http://arxiv.org/pdf/2112.09012.pdf'>2112.09012</a> &nbsp&nbsp (cs:AI, cs:ML, cs:RO) &nbsp&nbsp 1.6589баллов, №111</br>
<b>Centralizing State-Values in Dueling Networks for Multi-Robot\n  <font color="#00be00">Reinforcement Learning</font> Mapless Navigation</b></br>
Authors: , Marchesini, Enrico, Farinelli, Alessandro</br>
  We study the problem of multi-robot mapless navigation in the popular Centralized Training and Decentralized Execution (CTDE) paradigm. This problem is challenging when each robot considers its path without explicitly sharing observations with other robots and can lead to non-stationary issues in Deep <font color="#00be00">Reinforcement Learning</font> (DRL). The typical CTDE algorithm factorizes the joint action-value function into individual ones, to favor cooperation and achieve decentralized execution. Such factorization involves constraints (e.g., monotonicity) that limit the emergence of novel behaviors in an individual as each agent is trained starting from a joint action-value. In contrast, we propose a novel architecture for CTDE that uses a centralized state-value network to compute a joint state-value, which is used to inject global state information in the value-based updates of the agents. Consequently, each model computes its gradient update for the weights, considering the overall state of the environment. Our idea follows the insights of Dueling Networks as a separate estimation of the joint state-value has both the advantage of improving <font color="#00be00">sample efficien</font>cy, while providing each robot information whether the global state is (or is not) valuable. Experiments in a robotic navigation task with 2 4, and 8 robots, confirm the superior performance of our approach over prior CTDE methods (e.g., VDN, QMIX). </br></br>

<a href='http://arxiv.org/pdf/2112.06776.pdf'>2112.06776</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.6304баллов, №112</br>
<b>Keyphrase Generation Beyond the Boundaries of Title and Abstract</b></br>
Authors: , Garg, Krishna, Chowdhury, Jishnu Ray, Caragea, Cornelia</br>
  Keyphrase generation aims at generating phrases (keyphrases) that best describe a given document. In scholarly domains, current approaches to this task are neural approaches and have largely worked with only the title and abstract of the articles. In this work, we explore whether the integration of additional data from semantically similar articles or from the full text of the given article can be helpful for a neural keyphrase generation model. We discover that adding sentences from the full text particularly in the form of summary of the article can significantly improve the generation of both types of keyphrases that are either present or absent from the title and abstract. The experimental results on the three acclaimed models along with one of the latest <font color="#00be00">transformer</font> models suitable for longer documents, Longformer Encoder-Decoder (LED) validate the observation. We also present a new large-scale scholarly dataset FullTextKP for keyphrase generation, which we use for our experiments. Unlike prior large-scale datasets, FullTextKP includes the full text of the articles alongside title and abstract. We will release the <font color="#00be00">source code</font> to stimulate research on the proposed ideas. </br></br>

<a href='http://arxiv.org/pdf/2112.07459.pdf'>2112.07459</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.6273баллов, №113</br>
<b>Scale-Aware Neural <font color="#00be00">Architecture Search</font> for Multivariate Time Series\n  Forecasting</b></br>
Authors: , Chen, Donghui, Chen, Ling, Shang, Zongjiang, Zhang, Youdong, Wen, Bo, Yang, Chenghu</br>
  Multivariate time series (MTS) forecasting has attracted much attention in many intelligent applications. It is not a trivial task, as we need to consider both intra-variable dependencies and inter-variable dependencies. However, existing works are designed for specific scenarios, and require much domain knowledge and expert efforts, which is difficult to transfer between different scenarios. In this paper, we propose a scale-aware neural <font color="#00be00">architecture search</font> framework for MTS forecasting (SNAS4MTF). A multi-scale decomposition module transforms raw time series into multi-scale sub-series, which can preserve multi-scale temporal patterns. An adaptive graph learning module infers the different inter-variable dependencies under different time scales without any prior knowledge. For MTS forecasting, a search space is designed to capture both intra-variable dependencies and inter-variable dependencies at each time scale. The multi-scale decomposition, adaptive graph learning, and neural architecture search modules are jointly learned in an end-to-end framework. Extensive experiments on two <font color="#009600">real-world</font> datasets demonstrate that SNAS4MTF achieves a promising performance compared with the <font color="#00be00">state-of-the-art</font> methods. </br></br>

<a href='http://arxiv.org/pdf/2112.07869.pdf'>2112.07869</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 1.6221баллов, №114</br>
<b>Fine-Tuning Large Neural Language Models for Bio<font color="#640064">medic</font>al Natural Language\n  Processing</b></br>
Authors: , Tinn, Robert, Cheng, Hao, Gu, Yu, Usuyama, Naoto, Liu, Xiaodong, Naumann, Tristan, Gao, Jianfeng, Poon, Hoifung</br>
  Motivation: A perennial challenge for bio<font color="#640064">medic</font>al researchers and <font color="#be00be">clinic</font>al practitioners is to stay abreast with the rapid growth of publications and medical notes. Natural language processing (NLP) has emerged as a promising direction for taming information overload. In particular, large neural language models facilitate transfer learning by pretraining on unlabeled text, as exemplified by the successes of<font color="#00be00"> BERT </font>models in various NLP applications. However, fine-tuning such models for an end task remains challenging, especially with small labeled datasets, which are common in biomedical NLP.   Results: We conduct a systematic study on fine-tuning stability in biomedical NLP. We show that finetuning performance may be sensitive to pretraining settings, especially in <font color="#be00be">low-resource</font> domains. Large models have potential to attain better performance, but increasing model size also exacerbates finetuning instability. We thus conduct a comprehensive exploration of techniques for addressing fine-tuning instability. We show that these techniques can substantially improve fine-tuning performance for lowresource biomedical NLP applications. Specifically, freezing lower layers is helpful for standard BERT-BASE models, while layerwise decay is more effective for BERT-LARGE and ELECTRA models. For low-resource text similarity tasks such as BIOSSES, reinitializing the top layer is the optimal strategy. Overall, domainspecific vocabulary and pretraining facilitate more robust models for fine-tuning. Based on these findings, we establish new <font color="#00be00">state of the art</font> on a wide range of biomedical NLP applications.   Availability and implementation: To facilitate progress in biomedical NLP, we release our <font color="#00be00">state-of-the-art</font> pretrained and fine-tuned models: <font color="#006400">http</font>s://aka.ms/BLURB. </br></br>

<a href='http://arxiv.org/pdf/2112.06904.pdf'>2112.06904</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.6193баллов, №115</br>
<b>HVH: Learning a Hybrid Neural Volumetric Representation for Dynamic Hair\n  Performance Capture</b></br>
Authors: , Wang, Ziyan, Nam, Giljoo, Stuyck, Tuur, Lombardi, Stephen, Zollhoefer, Michael, Hodgins, Jessica, Lassner, Christoph</br>
  Capturing and rendering life-like hair is particularly challenging due to its fine geometric structure, the complex physical interaction and its non-trivial visual appearance.Yet, hair is a critical component for believable avatars. In this paper, we address the aforementioned problems: 1) we use a novel, volumetric hair representation that is com-posed of thousands of primitives. Each primitive can be rendered efficiently, yet realistically, by building on the latest advances in neural rendering. 2) To have a reliable control signal, we present a novel way of <font color="#be00be">tracking</font> hair on the strand level. To keep the computational effort manageable, we use guide hairs and classic techniques to expand those into a dense hood of hair. 3) To better enforce temporal consistency and generalization ability of our model, we further optimize the 3D scene flow of our representation with multi-view optical flow, using volumetric ray marching. Our method can not only create realistic renders of recorded multi-view sequences, but also create renderings for new hair configurations by providing new control signals. We compare our method with existing work on viewpoint synthesis and drivable animation and achieve <font color="#00be00">state-of-the-art</font> results. Please check out our project website at <font color="#006400">http</font>s://ziyanw1.<font color="#00be00">github</font>.io/hvh/. </br></br>

<a href='http://arxiv.org/pdf/2112.08587.pdf'>2112.08587</a> &nbsp&nbsp (cs:CV, cs:AI, cs:CL, cs:ML) &nbsp&nbsp 1.6148баллов, №116</br>
<b>SGEITL: Scene Graph Enhanced Image-Text Learning for Visual Commonsense\n  Reasoning</b></br>
Authors: , Wang, Zhecan, You, Haoxuan, Li, Liunian Harold, Zareian, Alireza, Park, Suji, Liang, Yiqing, Chang, Kai-Wei, Chang, Shih-Fu</br>
  Answering complex questions about images is an ambitious goal for machine intelligence, which requires a joint understanding of images, text, and commonsense knowledge, as well as a strong reasoning ability. Recently, multimodal <font color="#00be00">Transformer</font>s have made great progress in the task of Visual Commonsense Reasoning (VCR), by jointly understanding visual objects and text tokens through layers of cross-modality attention. However, these approaches do not utilize the rich structure of the scene and the interactions between objects which are essential in answering complex commonsense questions. We propose a Scene Graph Enhanced Image-Text Learning (SGEITL) framework to incorporate visual scene graphs in commonsense reasoning. To exploit the scene graph structure, at the model structure level, we propose a multihop graph transformer for regularizing attention interaction among hops. As for pre-training, a scene-graph-aware pre-training method is proposed to leverage structure knowledge extracted in the visual scene graph. Moreover, we introduce a method to train and generate domain-relevant visual scene graphs using textual annotations in a weakly-supervised manner. Extensive experiments on VCR and other tasks show a significant performance boost compared with the <font color="#00be00">state-of-the-art</font> methods and prove the efficacy of each proposed component. </br></br>

<a href='http://arxiv.org/pdf/2112.06392.pdf'>2112.06392</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.6099баллов, №117</br>
<b>Decoupling <font color="#be00be">Object Detection</font> from Human-Object Interaction Recognition</b></br>
Authors: , Jin, Ying, Chen, Yinpeng, Wang, Lijuan, Wang, Jianfeng, Yu, Pei, Liang, Lin, Hwang, Jenq-Neng, Liu, Zicheng</br>
  We propose DEFR, a DEtection-FRee method to recognize Human-Object Interactions (HOI) at image level without using object location or human pose. This is challenging as the detector is an integral part of existing methods. In this paper, we propose two findings to boost the performance of the detection-free approach, which significantly <font color="#00be00">outperform</font>s the detection-assisted <font color="#00be00">state of the art</font>s. Firstly, we find it crucial to effectively leverage the semantic correlations among HOI classes. Remarkable gain can be achieved by using language embeddings of HOI labels to initialize the linear classifier, which encodes the structure of HOIs to guide training. Further, we propose Log-Sum-Exp Sign (LSE-Sign) loss to facilitate multi-label learning on a long-tailed dataset by balancing gradients over all classes in a softmax format. Our detection-free approach achieves 65.6 mAP in HOI classification on HICO, outperforming the detection-assisted state of the art (SOTA) by 18.5 mAP, and 52.7 mAP in <font color="#009600">one-shot</font> classes, surpassing the SOTA by 27.3 mAP. Different from previous work, our classification model (DEFR) can be directly used in HOI detection without any additional training, by connecting to an off-the-shelf object detector whose bounding box output is converted to binary masks for DEFR. <font color="#00be00">Surprisin</font>gly, such a simple connection of two decoupled models achieves SOTA performance (32.35 mAP). </br></br>

<a href='http://arxiv.org/pdf/2112.08493.pdf'>2112.08493</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.5963баллов, №118</br>
<b><font color="#be00be">Style</font>MC: Multi-Channel Based Fast Text-Guided Image Generation and\n  Manipulation</b></br>
Authors: , Kocasari, Umut, Dirik, Alara, Tiftikci, Mert, Yanardag, Pinar</br>
  Discovering meaningful directions in the latent space of GANs to manipulate semantic attributes typically requires large amounts of labeled data. Recent work aims to overcome this limitation by leveraging the power of Contrastive Language-Image Pre-training (CLIP), a joint text-image model. While promising, these methods require several hours of preprocessing or training to achieve the desired manipulations. In this paper, we present <font color="#be00be">Style</font>MC, a fast and efficient method for text-driven image generation and manipulation. StyleMC uses a CLIP-based loss and an identity loss to manipulate images via a single text prompt without significantly affecting other attributes. Unlike prior work, StyleMC requires only a few seconds of training per text prompt to find stable global directions, does not require prompt engineering and can be used with any pre-trained StyleGAN2 model. We demonstrate the effectiveness of our method and compare it to <font color="#00be00">state-of-the-art</font> methods. Our code can be found at <font color="#006400">http</font>://catlab-team.<font color="#00be00">github</font>.io/stylemc. </br></br>

<a href='http://arxiv.org/pdf/2112.06693.pdf'>2112.06693</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.5918баллов, №119</br>
<b>Hypernet-Ensemble Learning of <font color="#be00be">Segmentation</font> Probability for <font color="#640064">Medic</font>al Image\n  Segmentation with Ambiguous Labels</b></br>
Authors: , Hong, Sungmin, Bonkhoff, Anna K., Hoopes, Andrew, Bretzner, Martin, Schirmer, Markus D., Giese, Anne-Katrin, Dalca, Adrian V., Golland, Polina, Rost, Natalia S.</br>
  Despite the superior performance of Deep Learning (DL) on numerous <font color="#be00be">segmentation</font> tasks, the DL-based approaches are notoriously overconfident about their prediction with highly polarized label probability. This is often not desirable for many applications with the inherent label ambiguity even in human annotations. This challenge has been addressed by leveraging multiple annotations per image and the segmentation uncertainty. However, multiple per-image annotations are often not available in a <font color="#009600">real-world</font> application and the uncertainty does not provide full control on segmentation results to users. In this paper, we propose novel methods to improve the segmentation probability estimation without sacrificing performance in a real-world scenario that we have only one ambiguous annotation per image. We marginalize the estimated segmentation probability maps of networks that are encouraged to under-/over-segment with the varying Tversky loss without penalizing balanced segmentation. Moreover, we propose a unified hypernetwork ensemble method to alleviate the computational burden of training multiple networks. Our approaches successfully estimated the segmentation probability maps that reflected the underlying structures and provided the intuitive control on segmentation for the challenging 3D <font color="#640064">medic</font>al image segmentation. Although the main focus of our proposed methods is not to improve the binary segmentation performance, our approaches marginally <font color="#00be00">outperform</font>ed the <font color="#00be00">state-of-the-art</font>s. The codes are available at \\url{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/sh4174/HypernetEnsemble}. </br></br>

<a href='http://arxiv.org/pdf/2112.08702.pdf'>2112.08702</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.5902баллов, №120</br>
<b>Learning to Share in Multi-Agent <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Yi, Yuxuan, Li, Ge, Wang, Yaowei, Lu, Zongqing</br>
  In this paper, we study the problem of networked multi-agent <font color="#00be00">reinforcement learning</font> (MARL), where a number of agents are deployed as a partially connected network and each interacts only with nearby agents. Networked MARL requires all agents make decision in a decentralized manner to optimize a global objective with restricted communication between neighbors over the network. Inspired by the fact that \\textit{sharing} plays a key role in human\'s learning of cooperation, we propose LToS, a <font color="#00be00">hierarchical</font>ly decentralized MARL framework that enables agents to learn to dynamically share reward with neighbors so as to encourage agents to cooperate on the global objective. For each agent, the high-level policy learns how to share reward with neighbors to decompose the global objective, while the low-level policy learns to optimize local objective induced by the high-level policies in the neighborhood. The two policies form a bi-level optimization and learn alternately. We empirically demonstrate that LToS <font color="#00be00">outperform</font>s existing methods in both social dilemma and networked MARL scenario. </br></br>

<a href='http://arxiv.org/pdf/2112.07924.pdf'>2112.07924</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.5828баллов, №121</br>
<b>Knowledge-Grounded Dialogue Generation with a Unified Knowledge\n  Representation</b></br>
Authors: , Li, Yu, Peng, Baolin, Shen, Yelong, Mao, Yi, Liden, Lars, Yu, Zhou, Gao, Jianfeng</br>
  Knowledge-grounded dialogue systems are challenging to build due to the lack of training data and heterogeneous knowledge sources. Existing systems perform poorly on unseen topics due to limited topics covered in the training data. In addition, heterogeneous knowledge sources make it challenging for systems to generalize to other tasks because knowledge sources in different knowledge representations require different knowledge encoders. To address these challenges, we present PLUG, a language model that homogenizes different knowledge sources to a unified knowledge representation for knowledge-grounded dialogue generation tasks. PLUG is pre-trained on a dialogue generation task conditioned on a unified essential knowledge representation. It can generalize to different downstream knowledge-grounded dialogue generation tasks with a few training examples. The empirical evaluation on two benchmarks shows that our model generalizes well across different knowledge-grounded tasks. It can achieve comparable performance with <font color="#00be00">state-of-the-art</font> methods under a fully-supervised setting and significantly <font color="#00be00">outperform</font>s other methods in <font color="#00be00">zero-shot</font> and <font color="#00be00">few-shot</font> settings. </br></br>

<a href='http://arxiv.org/pdf/2112.06771.pdf'>2112.06771</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 1.5699баллов, №122</br>
<b>Value Function Factorisation with Hypergraph Convolution for Cooperative\n  Multi-agent <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Bai, Yunpeng, Gong, Chen, Zhang, Bin, Fan, Guoliang, Hou, Xinwen</br>
  Cooperation between agents in a multi-agent system (MAS) has become a hot topic in recent years, and many algorithms based on centralized training with decentralized execution (CTDE), such as VDN and QMIX, have been proposed. However, these methods disregard the information hidden in the individual action values. In this paper, we propose HyperGraph CoNvolution MIX (HGCN-MIX), a method that combines hypergraph convolution with value decomposition. By treating action values as signals, HGCN-MIX aims to explore the relationship between these signals via a self-learning hypergraph. Experimental results present that HGCN-MIX matches or surpasses <font color="#00be00">state-of-the-art</font> techniques in the StarCraft II multi-agent challenge (SMAC) benchmark on various situations, notably those with a number of agents. </br></br>

<a href='http://arxiv.org/pdf/2112.05779.pdf'>2112.05779</a> &nbsp&nbsp (cs:AI, cs:ET, cs:ML, cs:NE) &nbsp&nbsp 1.5626баллов, №123</br>
<b>Quantum <font color="#00be00">Architecture Search</font> via Continual <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Ye, Esther, Chen, Samuel Yen-Chi</br>
  Quantum computing has promised significant improvement in solving difficult computational tasks over classical computers. Designing quantum circuits for practical use, however, is not a trivial objective and requires expert-level knowledge. To aid this endeavor, this paper proposes a machine learning-based method to construct quantum circuit architectures. Previous works have demonstrated that classical deep <font color="#00be00">reinforcement learning</font> (DRL) algorithms can successfully construct quantum circuit architectures without encoded physics knowledge. However, these DRL-based works are not generalizable to settings with changing device noises, thus requiring considerable amounts of training resources to keep the RL models up-to-date. With this in mind, we incorporated continual learning to enhance the performance of our algorithm. In this paper, we present the Probabilistic Policy Reuse with deep Q-learning (PPR-DQL) framework to tackle this circuit design challenge. By conducting numerical simulations over various noise patterns, we demonstrate that the RL agent with PPR was able to find the quantum gate sequence to generate the two-qubit Bell state faster than the agent that was trained from scratch. The proposed framework is general and can be applied to other quantum gate synthesis or control problems -- including the automatic calibration of quantum devices. </br></br>

<a href='http://arxiv.org/pdf/2112.07165.pdf'>2112.07165</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.5520баллов, №124</br>
<b>Discovering Explanatory Sentences in Legal Case Decisions Using\n  Pre-trained Language Models</b></br>
Authors: , Savelka, Jaromir, Ashley, Kevin D.</br>
  Legal texts routinely use concepts that are difficult to understand. Lawyers elaborate on the meaning of such concepts by, among other things, carefully investigating how have they been used in past. Finding text snippets that mention a particular concept in a useful way is tedious, time-consuming, and, hence, expensive. We assembled a data set of 26,959 sentences, coming from legal case decisions, and labeled them in terms of their usefulness for explaining selected legal concepts. Using the dataset we study the effectiveness of <font color="#00be00">transformer</font>-based models pre-trained on large language corpora to detect which of the sentences are useful. In light of models\' predictions, we analyze various linguistic properties of the explanatory sentences as well as their relationship to the legal concept that needs to be explained. We show that the transformer-based models are capable of learning <font color="#00be00">surprisin</font>gly sophisticated features and <font color="#00be00">outperform</font> the prior approaches to the task. </br></br>

<a href='http://arxiv.org/pdf/2112.08181.pdf'>2112.08181</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.5132баллов, №125</br>
<b><font color="#00be00">Hierarchical</font> Variational Memory for <font color="#00be00">Few-shot</font> Learning Across Domains</b></br>
Authors: , Du, Yingjun, Zhen, Xiantong, Shao, Ling, Snoek, Cees G. M.</br>
  Neural memory enables fast adaptation to new tasks with just a few training samples. Existing memory models store features only from the single last layer, which does not generalize well in presence of a domain shift between training and test distributions. Rather than relying on a flat memory, we propose a <font color="#00be00">hierarchical</font> alternative that stores features at different semantic levels. We introduce a hierarchical prototype model, where each level of the prototype fetches corresponding information from the hierarchical memory. The model is endowed with the ability to flexibly rely on features at different semantic levels if the domain shift circumstances so demand. We meta-learn the model by a newly derived hierarchical variational inference framework, where hierarchical memory and prototypes are jointly optimized. To explore and exploit the importance of different semantic levels, we further propose to learn the weights associated with the prototype at each level in a data-driven way, which enables the model to adaptively choose the most generalizable features. We conduct thorough ablation studies to demonstrate the effectiveness of each component in our model. The new <font color="#00be00">state-of-the-art</font> performance on cross-domain and <font color="#960096">competitive</font> performance on traditional <font color="#00be00">few-shot</font> classification further substantiates the benefit of hierarchical variational memory. </br></br>

<a href='http://arxiv.org/pdf/2112.07873.pdf'>2112.07873</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.5085баллов, №126</br>
<b>Tracing Text Provenance via Context-Aware Lexical Substitution</b></br>
Authors: , Yang, Xi, Zhang, Jie, Chen, Kejiang, Zhang, Weiming, Ma, Zehua, Wang, Feng, Yu, Nenghai</br>
  Text content created by humans or language models is often stolen or misused by adversaries. Tracing text provenance can help claim the ownership of text content or identify the malicious users who distribute misleading content like machine-generated <font color="#be00be">fake news</font>. There have been some attempts to achieve this, mainly based on watermarking techniques. Specifically, traditional text watermarking methods embed watermarks by slightly altering text format like line spacing and font, which, however, are fragile to cross-media transmissions like OCR. Considering this, natural language watermarking methods represent watermarks by replacing words in original sentences with synonyms from handcrafted lexical resources (e.g., WordNet), but they do not consider the substitution\'s impact on the overall sentence\'s meaning. Recently, a <font color="#00be00">transformer</font>-based network was proposed to embed watermarks by modifying the unobtrusive words (e.g., function words), which also impair the sentence\'s logical and semantic coherence. Besides, one well-trained network fails on other different types of text content. To address the limitations mentioned above, we propose a natural language watermarking scheme based on context-aware lexical substitution (LS). Specifically, we employ<font color="#00be00"> BERT </font>to suggest LS candidates by inferring the semantic relatedness between the candidates and the original sentence. Based on this, a selection strategy in terms of synchronicity and substitutability is further designed to test whether a word is exactly suitable for carrying the watermark signal. Extensive experiments demonstrate that, under both objective and subjective metrics, our watermarking scheme can well preserve the semantic integrity of original sentences and has a better transferability than existing methods. Besides, the proposed LS approach <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> approach on the Stanford Word Substitution Benchmark. </br></br>

<a href='http://arxiv.org/pdf/2112.06127.pdf'>2112.06127</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.4933баллов, №127</br>
<b><font color="#009600">Real-world</font> challenges for <font color="#00be00">reinforcement learning</font> in building control</b></br>
Authors: , Nagy, Zoltan, Nweye, Kingsley</br>
  Building upon prior research that highlighted the need for standardizing environments for building control research, and inspired by recently introduced benchmarks for real life <font color="#00be00">reinforcement learning</font> control, here we propose a non-exhaustive nine <font color="#009600">real world</font> challenges for reinforcement learning building controller. We argue that building control research should be expressed in this framework in addition to providing a standardized environment for repeatability. Advanced controllers such as model predictive control and reinforcement learning control have both advantages and disadvantages that prevent them from being implemented in real world buildings. Comparisons between the two are seldom, and often biased. By focusing on the benchmark problems and challenges, we can investigate the performance of the controllers under a variety of situations and generate a fair comparison. Lastly, we call for a more interdisciplinary effort of the research community to address the real world challenges, and unlock the potentials of advanced building controllers. </br></br>

<a href='http://arxiv.org/pdf/2112.05329.pdf'>2112.05329</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.4868баллов, №128</br>
<b>FaceFormer: Speech-Driven 3D<font color="#be00be"> Facial </font>Animation with <font color="#00be00">Transformer</font>s</b></br>
Authors: , Fan, Yingruo, Lin, Zhaojiang, Saito, Jun, Wang, Wenping, Komura, Taku</br>
  Speech-driven 3D<font color="#be00be"> facial </font>animation is challenging due to the complex geometry of human faces and the limited availability of 3D audio-visual data. Prior works typically focus on learning phoneme-level features of short audio windows with limited context, occasionally resulting in inaccurate lip movements. To tackle this limitation, we propose a <font color="#00be00">Transformer</font>-based autoregressive model, FaceFormer, which encodes the long-term audio context and autoregressively predicts a sequence of animated 3D<font color="#be00be"> face </font>meshes. To cope with the data scarcity issue, we integrate the self-supervised pre-trained speech representations. Also, we devise two biased attention mechanisms well suited to this specific task, including the biased cross-modal multi-head (MH) attention and the biased causal MH self-attention with a periodic positional encoding strategy. The former effectively aligns the audio-motion modalities, whereas the latter offers abilities to generalize to longer audio sequences. Extensive experiments and a perceptual user study show that our approach <font color="#00be00">outperform</font>s the existing <font color="#00be00">state-of-the-art</font>s. The code will be made available. </br></br>

<a href='http://arxiv.org/pdf/2112.07431.pdf'>2112.07431</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.4795баллов, №129</br>
<b>Uncertainty Estimation via Response Scaling for Pseudo-mask Noise\n  Mitigation in Weakly-supervised Semantic <font color="#be00be">Segmentation</font></b></br>
Authors: , Li, Yi, Duan, Yiqun, Kuang, Zhanghui, Chen, Yimin, Zhang, Wayne, Li, Xiaomeng</br>
  Weakly-Supervised Semantic <font color="#be00be">Segmentation</font> (WSSS) segments objects without a heavy burden of dense annotation. While as a price, generated pseudo-masks exist obvious noisy pixels, which result in sub-optimal segmentation models trained over these pseudo-masks. But rare studies notice or work on this problem, even these noisy pixels are inevitable after their improvements on pseudo-mask. So we try to improve WSSS in the aspect of noise mitigation. And we observe that many noisy pixels are of high confidence, especially when the response range is too wide or narrow, presenting an uncertain status. Thus, in this paper, we simulate noisy variations of response by scaling the prediction map multiple times for uncertainty estimation. The uncertainty is then used to weight the segmentation loss to mitigate noisy supervision signals. We call this method URN, abbreviated from Uncertainty estimation via Response scaling for Noise mitigation. Experiments validate the benefits of URN, and our method achieves <font color="#00be00">state-of-the-art</font> results at 71.2% and 41.5% on PASCAL VOC 2012 and MS COCO 2014 respectively, without extra models like saliency detection. Code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/XMed-Lab/URN. </br></br>

<a href='http://arxiv.org/pdf/2112.07837.pdf'>2112.07837</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.4777баллов, №130</br>
<b>CentSmoothie: Central-Smoothing Hypergraph Neural Networks for\n  Predicting <font color="#00be00">Drug</font>-Drug Interactions</b></br>
Authors: , Nguyen, Duc Anh, Nguyen, Canh Hao, Mamitsuka, Hiroshi</br>
  Predicting <font color="#00be00">drug</font>-drug interactions (DDI) is the problem of predicting side effects (unwanted outcomes) of a pair of drugs using drug information and known side effects of many pairs. This problem can be formulated as predicting labels (i.e. side effects) for each pair of nodes in a DDI graph, of which nodes are drugs and edges are interacting drugs with known labels. <font color="#00be00">State-of-the-art</font> methods for this problem are graph neural networks (GNNs), which leverage neighborhood information in the graph to learn node representations. For DDI, however, there are many labels with complicated relationships due to the nature of side effects. Usual GNNs often fix labels as one-hot vectors that do not reflect label relationships and potentially do not obtain the highest performance in the difficult cases of infrequent labels. In this paper, we formulate DDI as a hypergraph where each hyperedge is a triple: two nodes for drugs and one node for a label. We then present CentSmoothie, a hypergraph neural network that learns representations of nodes and labels altogether with a novel central-smoothing formulation. We empirically demonstrate the performance advantages of CentSmoothie in simulations as well as real datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.08560.pdf'>2112.08560</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.4736баллов, №131</br>
<b>Block-Skim: Efficient Question Answering for <font color="#00be00">Transformer</font></b></br>
Authors: , Guan, Yue, Li, Zhengyi, Leng, Jingwen, Lin, Zhouhan, Guo, Minyi, Zhu, Yuhao</br>
  <font color="#00be00">Transformer</font> models have achieved promising results on natural language processing (NLP) tasks including extractive question answering (QA). Common Transformer encoders used in NLP tasks process the hidden states of all input tokens in the context paragraph throughout all layers. However, different from other tasks such as sequence classification, answering the raised question does not necessarily need all the tokens in the context paragraph. Following this motivation, we propose Block-skim, which learns to skim unnecessary context in higher hidden layers to improve and accelerate the Transformer performance. The key idea of Block-Skim is to identify the context that must be further processed and those that could be safely discarded early on during inference. Critically, we find that such information could be sufficiently derived from the self-attention weights inside the Transformer model. We further prune the hidden states corresponding to the unnecessary positions early in lower layers, achieving significant inference-time speedup. To our surprise, we observe that models pruned in this way <font color="#00be00">outperform</font> their full-size counterparts. Block-Skim improves QA models\' accuracy on different datasets and achieves 3 times speedup on BERT-base model. </br></br>

<a href='http://arxiv.org/pdf/2112.06318.pdf'>2112.06318</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.4675баллов, №132</br>
<b>Contextualized Scene Imagination for Generative Commonsense Reasoning</b></br>
Authors: , Wang, PeiFeng, Zamora, Jonathan, Liu, Junfeng, Ilievski, Filip, Chen, Muhao, Ren, Xiang</br>
  Humans use natural language to compose common concepts from their environment into plausible, day-to-day scene descriptions. However, such generative commonsense reasoning (GCSR) skills are lacking in <font color="#00be00">state-of-the-art</font> text generation methods. Descriptive sentences about arbitrary concepts generated by neural text generation models (e.g., pre-trained text-to-text <font color="#00be00">Transformer</font>s) are often grammatically fluent but may not correspond to human common sense, largely due to their lack of mechanisms to capture concept relations, to identify implicit concepts, and to perform generalizable reasoning about unseen concept compositions. In this paper, we propose an Imagine-and-Verbalize (I&amp;V) method, which learns to imagine a relational scene <font color="#960096">knowledge graph</font> (SKG) with relations between the input concepts, and leverage the SKG as a constraint when generating a plausible scene description. We collect and harmonize a set of knowledge resources from different domains and modalities, providing a rich auxiliary supervision signal for I&amp;V. The experiments demonstrate the effectiveness of I&amp;V in improving language models on both concept-to-sentence and concept-to-story generation tasks, while enabling the model to learn well from fewer task examples and generate SKGs that make common sense to human annotators. </br></br>

<a href='http://arxiv.org/pdf/2112.09054.pdf'>2112.09054</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.4488баллов, №133</br>
<b>Pushing the Limits of Rule Reasoning in <font color="#00be00">Transformer</font>s through Natural\n  Language Satisfiability</b></br>
Authors: , Richardson, Kyle, Sabharwal, Ashish</br>
  Investigating the reasoning abilities of <font color="#00be00">transformer</font> models, and discovering new challenging tasks for them, has been a topic of much interest. Recent studies have found these models to be <font color="#00be00">surprisin</font>gly strong at performing deductive reasoning over formal logical <font color="#be00be">theor</font>ies expressed in natural language. A shortcoming of these studies, however, is that they do not take into account that logical theories, when sampled uniformly at random, do not necessarily lead to hard instances. We propose a new methodology for creating challenging algorithmic reasoning datasets that focus on natural language satisfiability (NLSat) problems. The key idea is to draw insights from empirical sampling of hard propositional SAT problems and from complexity-theoretic studies of language. This methodology allows us to distinguish easy from hard instances, and to systematically increase the complexity of existing reasoning benchmarks such as RuleTaker. We find that current transformers, given sufficient training data, are surprisingly robust at solving the resulting NLSat problems of substantially increased difficulty. They also exhibit some degree of scale-invariance - the ability to generalize to problems of larger size and scope. Our results, however, reveal important limitations too: a careful sampling of training data is crucial for building models that generalize to larger problems, and transformer models\' limited scale-invariance suggests they are far from learning robust deductive reasoning algorithms. </br></br>

<a href='http://arxiv.org/pdf/2112.07791.pdf'>2112.07791</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.4385баллов, №134</br>
<b>A Simple But Powerful Graph Encoder for Temporal <font color="#960096">Knowledge Graph</font>\n  Completion</b></br>
Authors: , Ding, Zifeng, Ma, Yunpu, He, Bailan, Tresp, Volker</br>
  While <font color="#960096">knowledge graph</font>s contain rich semantic knowledge of various entities and the relational information among them, temporal knowledge graphs (TKGs) further indicate the interactions of the entities over time. To study how to better model TKGs, automatic temporal knowledge graph completion (TKGC) has gained great interest. Recent TKGC methods aim to integrate advanced deep learning techniques, e.g., attention mechanism and <font color="#00be00">Transformer</font>, to boost model performance. However, we find that compared to adopting various kinds of complex modules, it is more beneficial to better utilize the whole amount of temporal information along the time axis. In this paper, we propose a simple but powerful graph encoder TARGCN for TKGC. TARGCN is parameter-efficient, and it extensively utilizes the information from the whole temporal context. We perform experiments on three benchmark datasets. Our model can achieve a more than 42% relative improvement on GDELT dataset compared with the <font color="#00be00">state-of-the-art</font> model. Meanwhile, it <font color="#00be00">outperform</font>s the strongest baseline on ICEWS05-15 dataset with around 18.5% fewer parameters. </br></br>

<a href='http://arxiv.org/pdf/2112.06560.pdf'>2112.06560</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.4259баллов, №135</br>
<b>HiClass: a Python library for local <font color="#00be00">hierarchical</font> classification\n  compatible with scikit-learn</b></br>
Authors: , Miranda, F&#xe1;bio M., K&#xf6;ehnecke, Niklas, Renard, Bernhard Y.</br>
  HiClass is an open-source Python package for local <font color="#00be00">hierarchical</font> classification fully compatible with scikit-learn. It provides implementations of the most popular machine learning models for local hierarchical classification, including Local Classifier Per Node, Local Classifier Per Parent Node and Local Classifier Per Level. In addition, the library includes tools to evaluate model performance on hierarchical data. The documentation contains installation instructions, interactive notebooks, and a complete description of the API. HiClass is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. <font color="#00be00">Source code</font> and documentation are available at <font color="#006400">http</font>s://gitlab.com/dacs-hpi/hiclass. </br></br>

<a href='http://arxiv.org/pdf/2112.08726.pdf'>2112.08726</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.4205баллов, №136</br>
<b>NeuroLogic A*esque Decoding: Constrained Text Generation with Lookahead\n  Heuristics</b></br>
Authors: , Lu, Ximing, Welleck, Sean, West, Peter, Jiang, Liwei, Kasai, Jungo, Khashabi, Daniel, Bras, Ronan Le, Qin, Lianhui, Yu, Youngjae, Zellers, Rowan, Smith, Noah A., Choi, Yejin</br>
  The dominant paradigm for neural text generation is left-to-right decoding from autoregressive language models. Constrained or controllable generation under complex lexical constraints, however, requires foresight to plan ahead feasible future paths.   Drawing inspiration from the A* search algorithm, we propose NeuroLogic A*esque, a decoding algorithm that incorporates heuristic estimates of future cost. We develop efficient lookahead heuristics that are efficient for large-scale language models, making our method a drop-in replacement for common techniques such as beam search and top-k sampling. To enable constrained generation, we build on NeuroLogic decoding (Lu et al., 2021), combining its flexibility in incorporating logical constraints with A*esque estimates of future constraint satisfaction.   Our approach <font color="#00be00">outperform</font>s <font color="#960096">competitive</font> baselines on five generation tasks, and achieves new <font color="#00be00">state-of-the-art</font> performance on table-to-text generation, constrained machine translation, and keyword-constrained generation. The improvements are particularly notable on tasks that require complex constraint satisfaction or in <font color="#00be00">few-shot</font> or <font color="#00be00">zero-shot</font> settings. NeuroLogic A*esque illustrates the power of decoding for improving and enabling new capabilities of large-scale language models. </br></br>

<a href='http://arxiv.org/pdf/2112.07701.pdf'>2112.07701</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.4075баллов, №137</br>
<b>Conservative and Adaptive Penalty for Model-Based Safe Reinforcement\n  Learning</b></br>
Authors: , Ma, Yecheng Jason, Shen, Andrew, Bastani, Osbert, Jayaraman, Dinesh</br>
  <font color="#00be00">Reinforcement Learning</font> (RL) agents in the <font color="#009600">real world</font> must satisfy safety constraints in addition to maximizing a reward objective. Model-based RL algorithms hold promise for reducing unsafe <font color="#009600">real-world</font> actions: they may synthesize policies that obey all constraints using simulated samples from a learned model. However, imperfect models can result in real-world constraint violations even for actions that are predicted to satisfy all constraints. We propose Conservative and Adaptive Penalty (CAP), a model-based safe RL framework that accounts for potential modeling errors by capturing model uncertainty and adaptively exploiting it to balance the reward and the cost objectives. First, CAP inflates predicted costs using an uncertainty-based penalty. <font color="#be00be">Theor</font>etically, we show that policies that satisfy this conservative cost constraint are guaranteed to also be feasible in the true environment. We further show that this guarantees the safety of all intermediate solutions during RL training. Further, CAP adaptively tunes this penalty during training using true cost feedback from the environment. We evaluate this conservative and adaptive penalty-based approach for model-based safe RL extensively on state and image-based environments. Our results demonstrate substantial gains in sample-efficiency while incurring fewer violations than prior safe RL algorithms. Code is available at: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/Redrew/CAP </br></br>

<a href='http://arxiv.org/pdf/2112.07415.pdf'>2112.07415</a> &nbsp&nbsp (cs:AI, cs:CV) &nbsp&nbsp 1.3959баллов, №138</br>
<b>Stochastic Planner-Actor-Critic for Unsupervised Deformable Image\n  Registration</b></br>
Authors: , Luo, Ziwei, Hu, Jing, Wang, Xin, Hu, Shu, Kong, Bin, Yin, Youbing, Song, Qi, Wu, Xi, Lyu, Siwei</br>
  Large deformations of organs, caused by diverse shapes and nonlinear shape changes, pose a significant challenge for <font color="#640064">medic</font>al image registration. Traditional registration methods need to iteratively optimize an objective function via a specific deformation model along with meticulous parameter tuning, but which have limited capabilities in registering images with large deformations. While deep learning-based methods can learn the complex mapping from input images to their respective deformation field, it is <font color="#be00be">regression</font>-based and is prone to be stuck at local minima, particularly when large deformations are involved. To this end, we present Stochastic Planner-Actor-Critic (SPAC), a novel <font color="#00be00">reinforcement learning</font>-based framework that performs step-wise registration. The key notion is warping a moving image successively by each time step to finally align to a fixed image. Considering that it is challenging to handle high dimensional continuous action and state spaces in the conventional reinforcement learning (RL) framework, we introduce a new concept `Plan\' to the standard Actor-Critic model, which is of low dimension and can facilitate the actor to generate a tractable high dimensional action. The entire framework is based on unsupervised training and operates in an end-to-end manner. We evaluate our method on several 2D and 3D medical image datasets, some of which contain large deformations. Our empirical results highlight that our work achieves consistent, significant gains and <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> methods. </br></br>

<a href='http://arxiv.org/pdf/2112.05425.pdf'>2112.05425</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.3833баллов, №139</br>
<b>Couplformer:Rethinking Vision <font color="#00be00">Transformer</font> with Coupling Attention Map</b></br>
Authors: , Lan, Hai, Wang, Xihao, Wei, Xian</br>
  With the development of the self-attention mechanism, the <font color="#00be00">Transformer</font> model has demonstrated its outstanding performance in the computer vision domain. However, the massive computation brought from the full attention mechanism became a heavy burden for memory consumption. Sequentially, the limitation of memory reduces the possibility of improving the Transformer model. To remedy this problem, we propose a novel memory economy attention mechanism named Couplformer, which decouples the attention map into two sub-matrices and generates the alignment scores from spatial information. A series of different scale image classification tasks are applied to evaluate the effectiveness of our model. The result of experiments shows that on the ImageNet-1k classification task, the Couplformer can significantly decrease 28% memory consumption compared with regular Transformer while accessing sufficient accuracy requirements and <font color="#00be00">outperform</font>ing 0.92% on Top-1 accuracy while occupying the same memory footprint. As a result, the Couplformer can serve as an efficient backbone in visual tasks, and provide a novel perspective on the attention mechanism for researchers. </br></br>

<a href='http://arxiv.org/pdf/2112.07658.pdf'>2112.07658</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.3776баллов, №140</br>
<b>AdaViT: Adaptive Tokens for Efficient Vision <font color="#00be00">Transformer</font></b></br>
Authors: , Yin, Hongxu, Vahdat, Arash, Alvarez, Jose, Mallya, Arun, Kautz, Jan, Molchanov, Pavlo</br>
  We introduce AdaViT, a method that adaptively adjusts the inference cost of vision <font color="#00be00">transformer</font> (ViT) for images of different complexity. AdaViT achieves this by automatically reducing the number of tokens in vision transformers that are processed in the network as inference proceeds. We reformulate Adaptive Computation Time (ACT) for this task, extending halting to discard redundant spatial tokens. The appealing architectural properties of vision transformers enables our adaptive token reduction mechanism to speed up inference without modifying the network architecture or inference hardware. We demonstrate that AdaViT requires no extra parameters or sub-network for halting, as we base the learning of adaptive halting on the original network parameters. We further introduce distributional prior regularization that stabilizes training compared to prior ACT approaches. On the image classification task (ImageNet1K), we show that our proposed AdaViT yields high efficacy in filtering informative spatial features and cutting down on the overall compute. The proposed method improves the throughput of DeiT-Tiny by 62% and DeiT-Small by 38% with only 0.3% accuracy drop, <font color="#00be00">outperform</font>ing prior art by a large margin. </br></br>

<a href='http://arxiv.org/pdf/2112.06510.pdf'>2112.06510</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.3719баллов, №141</br>
<b>Do Data-based Curricula Work?</b></br>
Authors: , Surkov, Maxim K., Mosin, Vladislav D., Yamshchikov, Ivan P.</br>
  Current <font color="#00be00">state-of-the-art</font> NLP systems use large neural networks that require lots of computational resources for training. Inspired by human knowledge acquisition, researchers have proposed <font color="#006400">curriculum learning</font>, - sequencing of tasks (task-based curricula) or ordering and sampling of the datasets (data-based curricula) that facilitate training. This work investigates the benefits of data-based curriculum learning for large modern language models such as<font color="#00be00"> BERT </font>and T5. We experiment with various curricula based on a range of complexity measures and different sampling strategies. Extensive experiments on different NLP tasks show that curricula based on various complexity measures rarely has any benefits while random sampling performs either as well or better than curricula. </br></br>

<a href='http://arxiv.org/pdf/2112.08775.pdf'>2112.08775</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.3636баллов, №142</br>
<b>DProST: 6-DoF Object <font color="#be00be">Pose Estimation</font> Using Space Carving and Dynamic\n  Projective Spatial <font color="#00be00">Transformer</font></b></br>
Authors: , Park, Jaewoo, Cho, Nam Ik</br>
  Predicting the pose of an object is a core computer vision task. Most deep learning-based <font color="#be00be">pose estimation</font> methods require CAD data to use 3D intermediate representations or project 2D appearance. However, these methods cannot be used when CAD data for objects of interest are unavailable. Besides, the existing methods did not precisely reflect the perspective distortion to the learning process. In addition, information loss due to self-occlusion has not been studied well. In this regard, we propose a new pose estimation system consisting of a space carving module that reconstructs a reference 3D feature to replace the CAD data. Moreover, Our new transformation module, Dynamic Projective Spatial <font color="#00be00">Transformer</font> (DProST), transforms a reference 3D feature to reflect the pose while considering perspective distortion. Also, we overcome the self-occlusion problem by a new Bidirectional Z-buffering (BiZ-buffer) method, which extracts both the front view and the self-occluded back view of the object. Lastly, we suggest a Perspective Grid Distance Loss (PGDL), enabling stable learning of the pose estimator without CAD data. Experimental results show that our method <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> method on the LINEMOD dataset and comparable performance on LINEMOD-OCCLUSION dataset even compared to the methods that require CAD data in network training. </br></br>

<a href='http://arxiv.org/pdf/2112.06113.pdf'>2112.06113</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.3557баллов, №143</br>
<b>Learning from the Tangram to Solve Mini Visual Tasks</b></br>
Authors: , Zhao, Yizhou, Qiu, Liang, Lu, Pan, Shi, Feng, Han, Tian, Zhu, Song-Chun</br>
  Current pre-training methods in computer vision focus on natural images in the daily-life context. However, abstract diagrams such as icons and symbols are common and important in the <font color="#009600">real world</font>. This work is inspired by Tangram, a game that requires replicating an abstract pattern from seven dissected shapes. By recording human experience in solving tangram puzzles, we present the Tangram dataset and show that a pre-trained neural model on the Tangram helps solve some mini visual tasks based on low-resolution vision. Extensive experiments demonstrate that our proposed method generates intelligent solutions for aesthetic tasks such as folding clothes and evaluating room layouts. The pre-trained feature extractor can facilitate the convergence of <font color="#00be00">few-shot</font> learning tasks on human handwriting and improve the accuracy in identifying icons by their contours. The Tangram dataset is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/yizhouzhao/Tangram. </br></br>

<a href='http://arxiv.org/pdf/2112.07535.pdf'>2112.07535</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.3380баллов, №144</br>
<b>Scientific Discovery and the Cost of Measurement -- Balancing\n  Information and Cost in <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Bellinger, Colin, Drozdyuk, Andriy, Crowley, Mark, Tamblyn, Isaac</br>
  The use of <font color="#00be00">reinforcement learning</font> (RL) in scientific applications, such as materials design and automated chemistry, is increasing. A major challenge, however, lies in fact that measuring the state of the system is often costly and time consuming in scientific applications, whereas policy learning with RL requires a measurement after each time step. In this work, we make the measurement costs explicit in the form of a costed reward and propose a framework that enables off-the-shelf deep RL algorithms to learn a policy for both selecting actions and determining whether or not to measure the current state of the system at each time step. In this way, the agents learn to balance the need for information with the cost of information. Our results show that when trained under this regime, the Dueling DQN and PPO agents can learn optimal action policies whilst making up to 50\\% fewer state measurements, and recurrent neural networks can produce a greater than 50\\% reduction in measurements. We postulate the these reduction can help to lower the barrier to applying RL to <font color="#009600">real-world</font> scientific applications. </br></br>

<a href='http://arxiv.org/pdf/2112.07874.pdf'>2112.07874</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.3295баллов, №145</br>
<b>Oracle Linguistic Graphs Complement a Pretrained <font color="#00be00">Transformer</font> Language\n  Model: A Cross-formalism Comparison</b></br>
Authors: , Prange, Jakob, Schneider, Nathan, Kong, Lingpeng</br>
  We examine the extent to which, in principle, linguistic graph representations can complement and improve neural language modeling. With an ensemble setup consisting of a pretrained <font color="#00be00">Transformer</font> and ground-truth graphs from one of 7 different formalisms, we find that, overall, semantic constituency structures are most useful to language modeling performance -- outpacing syntactic constituency structures as well as syntactic and semantic dependency structures. Further, effects vary greatly depending on part-of-speech class. In sum, our findings point to promising tendencies in neuro-symbolic language modeling and invite future research quantifying the design choices made by different formalisms. </br></br>

<a href='http://arxiv.org/pdf/2112.06386.pdf'>2112.06386</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.3259баллов, №146</br>
<b>Sparse Structure Learning via Graph Neural Networks for Inductive\n  Document Classification</b></br>
Authors: , Piao, Yinhua, Lee, Sangseon, Lee, Dohoon, Kim, Sun</br>
  Recently, graph neural networks (GNNs) have been widely used for document classification. However, most existing methods are based on static word co-occurrence graphs without sentence-level information, which poses three challenges:(1) word ambiguity, (2) word synonymity, and (3) dynamic contextual dependency. To address these challenges, we propose a novel GNN-based sparse structure learning model for inductive document classification. Specifically, a document-level graph is initially generated by a disjoint union of sentence-level word co-occurrence graphs. Our model collects a set of trainable edges connecting disjoint words between sentences and employs structure learning to sparsely select edges with dynamic contextual dependencies. Graphs with sparse structures can jointly exploit local and global contextual information in documents through GNNs. For inductive learning, the refined document graph is further fed into a general readout function for graph-level classification and optimization in an end-to-end manner. Extensive experiments on several <font color="#009600">real-world</font> datasets demonstrate that the proposed model <font color="#00be00">outperform</font>s most <font color="#00be00">state-of-the-art</font> results, and reveal the necessity to learn sparse structures for each document. </br></br>

<a href='http://arxiv.org/pdf/2112.03735.pdf'>2112.03735</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 1.3223баллов, №147</br>
<b>Adaptive Mimic: Deep <font color="#00be00">Reinforcement Learning</font> of Parameterized Bipedal\n  Walking from Infeasible References</b></br>
Authors: , Zhang, Chong, Wu, Qi, Ma, Liqian, Su, Hongyuan</br>
  Not until recently, robust robot locomotion has been achieved by deep <font color="#00be00">reinforcement learning</font> (DRL). However, for efficient learning of parametrized bipedal walking, developed references are usually required, limiting the performance to that of the references. In this paper, we propose to design an adaptive reward function for imitation learning from the references. The agent is encouraged to mimic the references when its performance is low, while to pursue high performance when it reaches the limit of references. We further demonstrate that developed references can be replaced by low-quality references that are generated without laborious tuning and infeasible to deploy by themselves, as long as they can provide a priori knowledge to expedite the learning process. </br></br>

<a href='http://arxiv.org/pdf/2112.06295.pdf'>2112.06295</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.3045баллов, №148</br>
<b>Towards More Efficient Insertion <font color="#00be00">Transformer</font> with Fractional Positional\n  Encoding</b></br>
Authors: , Zhang, Zhisong, Zhang, Yizhe, Dolan, Bill</br>
  Auto-regressive neural sequence models have been shown to be effective across text generation tasks. However, their left-to-right decoding order prevents generation from being parallelized. Insertion <font color="#00be00">Transformer</font> (Stern et al., 2019) is an attractive alternative that allows outputting multiple tokens in a single generation step. Nevertheless, due to the incompatibility of absolute positional encoding and insertion-based generation schemes, it needs to refresh the encoding of every token in the generated partial hypotheses at each step, which could be costly. We design a novel incremental positional encoding scheme for insertion transformers called Fractional Positional Encoding (FPE), which allows reusing representations calculated in previous steps. Empirical studies on various language generation tasks demonstrate the effectiveness of FPE, which leads to reduction of floating point operations and latency improvements on batched decoding. </br></br>

<a href='http://arxiv.org/pdf/2112.05785.pdf'>2112.05785</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp 1.2971баллов, №149</br>
<b>TempoQR: Temporal Question Reasoning over <font color="#960096">Knowledge Graph</font>s</b></br>
Authors: , Mavromatis, Costas, Subramanyam, Prasanna Lakkur, Ioannidis, Vassilis N., Adeshina, Soji, Howard, Phillip R., Grinberg, Tetiana, Hakim, Nagib, Karypis, George</br>
  <font color="#960096">Knowledge Graph</font> Question Answering (KGQA) involves retrieving facts from a Knowledge Graph (KG) using natural language queries. A KG is a curated set of facts consisting of entities linked by relations. Certain facts include also temporal information forming a Temporal KG (TKG). Although many natural questions involve explicit or implicit time constraints, question answering (QA) over TKGs has been a relatively unexplored area. Existing solutions are mainly designed for simple temporal questions that can be answered directly by a single TKG fact. This paper puts forth a comprehensive embedding-based framework for answering complex questions over TKGs. Our method termed temporal question reasoning (TempoQR) exploits TKG embeddings to ground the question to the specific entities and time scope it refers to. It does so by augmenting the question embeddings with context, entity and time-aware information by employing three specialized modules. The first computes a textual representation of a given question, the second combines it with the entity embeddings for entities involved in the question, and the third generates question-specific time embeddings. Finally, a <font color="#00be00">transformer</font>-based encoder learns to fuse the generated temporal information with the question representation, which is used for answer predictions. Extensive experiments show that TempoQR improves accuracy by 25--45 percentage points on complex temporal questions over <font color="#00be00">state-of-the-art</font> approaches and it generalizes better to unseen question types. </br></br>

<a href='http://arxiv.org/pdf/2112.06741.pdf'>2112.06741</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.2966баллов, №150</br>
<b>Long-tail Recognition via Compositional Knowledge Transfer</b></br>
Authors: , Parisot, Sarah, Esperanca, Pedro M., McDonagh, Steven, Madarasz, Tamas J., Yang, Yongxin, Li, Zhenguo</br>
  In this work, we introduce a novel strategy for long-tail recognition that addresses the tail classes\' <font color="#00be00">few-shot</font> problem via training-free knowledge transfer. Our objective is to transfer knowledge acquired from information-rich common classes to semantically similar, and yet data-hungry, rare classes in order to obtain stronger tail class representations. We leverage the fact that class prototypes and learned cosine classifiers provide two different, complementary representations of class cluster centres in feature space, and use an attention mechanism to select and recompose learned classifier features from common classes to obtain higher quality rare class representations. Our knowledge transfer process is training free, reducing overfitting risks, and can afford continual extension of classifiers to new classes. Experiments show that our approach can achieve significant performance boosts on rare classes while maintaining robust common class performance, <font color="#00be00">outperform</font>ing directly comparable <font color="#00be00">state-of-the-art</font> models. </br></br>

<a href='http://arxiv.org/pdf/2112.04187.pdf'>2112.04187</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 1.2797баллов, №151</br>
<b>Pretrained Cost Model for Distributed Constraint Optimization Problems</b></br>
Authors: , Deng, Yanchen, Kong, Shufeng, An, Bo</br>
  Distributed Constraint Optimization Problems (DCOPs) are an important subclass of combinatorial optimization problems, where information and controls are distributed among multiple autonomous agents. Previously, Machine Learning (ML) has been largely applied to solve combinatorial optimization problems by learning effective heuristics. However, existing ML-based heuristic methods are often not generalizable to different search algorithms. Most importantly, these methods usually require full knowledge about the problems to be solved, which are not suitable for distributed settings where centralization is not realistic due to geographical limitations or <font color="#be00be">privacy</font> concerns. To address the generality issue, we propose a novel directed acyclic graph representation schema for DCOPs and leverage the Graph Attention Networks (GATs) to embed graph representations. Our model, GAT-PCM, is then pretrained with optimally labelled data in an offline manner, so as to construct effective heuristics to boost a broad range of DCOP algorithms where evaluating the quality of a partial assignment is critical, such as local search or back<font color="#be00be">tracking</font> search. Furthermore, to enable decentralized model inference, we propose a distributed embedding schema of GAT-PCM where each agent exchanges only embedded vectors, and show its soundness and complexity. Finally, we demonstrate the effectiveness of our model by combining it with a local search or a backtracking search algorithm. Extensive empirical evaluations indicate that the GAT-PCM-boosted algorithms significantly <font color="#00be00">outperform</font> the <font color="#00be00">state-of-the-art</font> methods in various benchmarks. The pretrained model is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/dyc941126/GAT-PCM. </br></br>

<a href='http://arxiv.org/pdf/2112.07089.pdf'>2112.07089</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 1.2785баллов, №152</br>
<b>Building on Huang et al. GlossBERT for Word Sense Disambiguation</b></br>
Authors: , Patel, Nikhil, Hale, James, Jindal, Kanika, Sharma, Apoorva, Yu, Yichun</br>
  We propose to take on the problem ofWord Sense Disambiguation (WSD). In language, words of the same form can take different meanings depending on context. While humans easily infer the meaning or gloss of such words by their context, machines stumble on this task.As such, we intend to replicated and expand upon the results of Huang et al.GlossBERT, a model which they design to disambiguate these words (Huang et al.,2019). Specifically, we propose the following augmentations: data-set tweaking(alpha hyper-parameter), ensemble methods, and replacement of<font color="#00be00"> BERT </font>with BART andALBERT. The following <font color="#00be00">GitHub</font> repository contains all code used in this report, which extends on the code made available by Huang et al. </br></br>

<a href='http://arxiv.org/pdf/2112.01922.pdf'>2112.01922</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 1.2727баллов, №153</br>
<b>MetaQA: Combining Expert Agents for Multi-Skill Question Answering</b></br>
Authors: , Puerto, Haritz, &#x15e;ahin, G&#xf6;zde G&#xfc;l, Gurevych, Iryna</br>
  The recent explosion of question answering (QA) datasets and models has increased the interest in the generalization of models across multiple domains and formats by either training on multiple datasets or by combining multiple models. Despite the promising results of multi-dataset models, some domains or QA formats may require specific architectures, and thus the adaptability of these models might be limited. In addition, current approaches for combining models disregard cues such as question-answer compatibility. In this work, we propose to combine expert agents with a novel, flexible, and training-efficient architecture that considers questions, answer predictions, and answer-prediction confidence scores to select the best answer among a list of answer candidates. Through quantitative and qualitative experiments we show that our model i) creates a collaboration between agents that <font color="#00be00">outperform</font>s previous multi-agent and multi-dataset approaches in both in-domain and out-of-domain scenarios, ii) is highly data-efficient to train, and iii) can be adapted to any QA format. We release our code and a dataset of answer predictions from expert agents for 16 QA datasets to foster future developments of multi-agent systems on <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/UKPLab/MetaQA. </br></br>

<a href='http://arxiv.org/pdf/2112.08830.pdf'>2112.08830</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp 1.2725баллов, №154</br>
<b>Graph-wise Common Latent Factor Extraction for Unsupervised Graph\n  Representation Learning</b></br>
Authors: , Cooray, Thilini, Cheung, Ngai-Man</br>
  Unsupervised graph-level representation learning plays a crucial role in a variety of tasks such as molecular property prediction and community analysis, especially when data annotation is expensive. Currently, most of the best-performing graph embedding methods are based on Infomax principle. The performance of these methods highly depends on the selection of negative samples and hurt the performance, if the samples were not carefully selected. Inter-graph similarity-based methods also suffer if the selected set of graphs for similarity matching is low in quality. To address this, we focus only on utilizing the current input graph for embedding learning. We are motivated by an observation from <font color="#009600">real-world</font> graph generation processes where the graphs are formed based on one or more global factors which are common to all elements of the graph (e.g., topic of a discussion thread, solubility level of a <font color="#00be00">molecule</font>). We hypothesize extracting these common factors could be highly beneficial. Hence, this work proposes a new principle for unsupervised graph representation learning: Graph-wise Common latent Factor EXtraction (GCFX). We further propose a deep model for GCFX, deepGCFX, based on the idea of reversing the above-mentioned graph generation process which could explicitly extract common latent factors from an input graph and achieve improved results on downstream tasks to the current <font color="#00be00">state-of-the-art</font>. Through extensive experiments and analysis, we demonstrate that, while extracting common latent factors is beneficial for graph-level tasks to alleviate distractions caused by local variations of individual nodes or local neighbourhoods, it also benefits node-level tasks by enabling long-range node dependencies, especially for disassortative graphs. </br></br>

<a href='http://arxiv.org/pdf/2112.07146.pdf'>2112.07146</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.2702баллов, №155</br>
<b>PP-HumanSeg: Connectivity-Aware Portrait <font color="#be00be">Segmentation</font> with a Large-Scale\n  Teleconferencing Video Dataset</b></br>
Authors: , Chu, Lutao, Liu, Yi, Wu, Zewu, Tang, Shiyu, Chen, Guowei, Hao, Yuying, Peng, Juncai, Yu, Zhiliang, Chen, Zeyu, Lai, Baohua, Xiong, Haoyi</br>
  As the COVID-19 pandemic rampages across the world, the demands of video conferencing surge. To this end, real-time portrait <font color="#be00be">segmentation</font> becomes a popular feature to replace backgrounds of conferencing participants. While feature-rich datasets, models and algorithms have been offered for segmentation that extract body postures from life scenes, portrait segmentation has yet not been well covered in a video conferencing context. To facilitate the progress in this field, we introduce an open-source solution named PP-HumanSeg. This work is the first to construct a large-scale video portrait dataset that contains 291 videos from 23 conference scenes with 14K fine-labeled frames and extensions to multi-camera teleconferencing. Furthermore, we propose a novel Semantic Connectivity-aware Learning (SCL) for semantic segmentation, which introduces a semantic connectivity-aware loss to improve the quality of segmentation results from the perspective of connectivity. And we propose an ultra-<font color="#be00be">lightweight</font> model with SCL for practical portrait segmentation, which achieves the best trade-off between IoU and the speed of inference. Extensive evaluations on our dataset demonstrate the superiority of SCL and our model. The <font color="#00be00">source code</font> is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/PaddlePaddle/PaddleSeg. </br></br>

<a href='http://arxiv.org/pdf/2112.06226.pdf'>2112.06226</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.2687баллов, №156</br>
<b>Attention based Broadly Self-guided Network for Low light Image\n  Enhancement</b></br>
Authors: , Chen, Zilong, Liang, Yaling, Du, Minghui</br>
  During the past years,deep convolutional neural networks have achieved impressive success in low-light Image Enhancement.Existing deep learning methods mostly enhance the ability of feature extraction by stacking network structures and deepening the depth of the network.which causes more runtime cost on single image.In order to reduce inference time while fully extracting local features and global features.Inspired by SGN,we propose a Attention based Broadly self-guided network (ABSGN) for <font color="#009600">real world</font> low-light image Enhancement.such a broadly strategy is able to handle the noise at different exposures.The proposed network is validated by many mainstream benchmark.Additional experimental results show that the proposed network <font color="#00be00">outperform</font>s most of <font color="#00be00">state-of-the-art</font> low-light image Enhancement solutions. </br></br>

<a href='http://arxiv.org/pdf/2112.05299.pdf'>2112.05299</a> &nbsp&nbsp (cs:RO, cs:AI) &nbsp&nbsp 1.2685баллов, №157</br>
<b><font color="#00be00">Zero-Shot</font> Uncertainty-Aware Deployment of Simulation Trained Policies on\n  <font color="#009600">Real-World</font> Robots</b></br>
Authors: , Rana, Krishan, Dasagi, Vibhavari, Haviland, Jesse, Talbot, Ben, Milford, MIchael, S&#xfc;nderhauf, Niko</br>
  While deep <font color="#00be00">reinforcement learning</font> (RL) agents have demonstrated incredible potential in attaining dexterous behaviours for robotics, they tend to make errors when deployed in the <font color="#009600">real world</font> due to mismatches between the training and execution environments. In contrast, the classical robotics community have developed a range of controllers that can safely operate across most states in the real world given their explicit derivation. These controllers however lack the dexterity required for complex tasks given limitations in analytical modelling and approximations. In this paper, we propose <font color="#be00be">Bayes</font>ian Controller Fusion (BCF), a novel uncertainty-aware deployment strategy that combines the strengths of deep RL policies and traditional handcrafted controllers. In this framework, we can perform <font color="#00be00">zero-shot</font> sim-to-real transfer, where our uncertainty based formulation allows the robot to reliably act within out-of-distribution states by leveraging the handcrafted controller while gaining the dexterity of the learned system otherwise. We show promising results on two <font color="#009600">real-world</font> continuous control tasks, where BCF <font color="#00be00">outperform</font>s both the standalone policy and controller, surpassing what either can achieve independently. A supplementary video demonstrating our system is provided at <font color="#006400">http</font>s://bit.ly/bcf_deploy. </br></br>

<a href='http://arxiv.org/pdf/2112.05993.pdf'>2112.05993</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.2602баллов, №158</br>
<b>Object Counting: You Only Need to Look at One</b></br>
Authors: , Lin, Hui, Hong, Xiaopeng, Wang, Yabin</br>
  This paper aims to tackle the challenging task of <font color="#009600">one-shot</font> object counting. Given an image containing novel, previously unseen category objects, the goal of the task is to count all instances in the desired category with only one supporting bounding box example. To this end, we propose a counting model by which you only need to Look At One instance (LaoNet). First, a feature correlation module combines the Self-Attention and Correlative-Attention modules to learn both inner-relations and inter-relations. It enables the network to be robust to the inconsistency of rotations and sizes among different instances. Second, a Scale Aggregation mechanism is designed to help extract features with different scale information. Compared with existing <font color="#00be00">few-shot</font> counting methods, LaoNet achieves <font color="#00be00">state-of-the-art</font> results while learning with a high convergence speed. The code will be available soon. </br></br>

<a href='http://arxiv.org/pdf/2112.06370.pdf'>2112.06370</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp 1.2503баллов, №159</br>
<b>Dependency Learning for Legal Judgment Prediction with a Unified\n  Text-to-Text <font color="#00be00">Transformer</font></b></br>
Authors: , Huang, Yunyun, Shen, Xiaoyu, Li, Chuanyi, Ge, Jidong, Luo, Bin</br>
  Given the fact of a case, Legal Judgment Prediction (LJP) involves a series of sub-tasks such as predicting violated law articles, charges and term of penalty. We propose leveraging a unified text-to-text <font color="#00be00">Transformer</font> for LJP, where the dependencies among sub-tasks can be naturally established within the auto-regressive decoder. Compared with previous works, it has three advantages: (1) it fits in the pretraining pattern of masked language models, and thereby can benefit from the semantic prompts of each sub-task rather than treating them as atomic labels, (2) it utilizes a single unified architecture, enabling full parameter sharing across all sub-tasks, and (3) it can incorporate both classification and generative sub-tasks. We show that this unified transformer, albeit pretrained on general-domain text, <font color="#00be00">outperform</font>s pretrained models tailored specifically for the legal domain. Through an extensive set of experiments, we find that the best order to capture dependencies is different from human intuitions, and the most reasonable logical order for humans can be sub-optimal for the model. We further include two more auxiliary tasks: court view generation and article content prediction, showing they can not only improve the prediction accuracy, but also provide <font color="#be00be">interpret</font>able explanations for model outputs even when an error is made. With the best configuration, our model outperforms both previous SOTA and a single-tasked version of the unified transformer by a large margin. </br></br>

<a href='http://arxiv.org/pdf/2112.06398.pdf'>2112.06398</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.2444баллов, №160</br>
<b>Shaping Visual Representations with Attributes for <font color="#00be00">Few-Shot</font> Learning</b></br>
Authors: , Chen, Haoxing, Li, Huaxiong, Li, Yaohui, Chen, Chunlin</br>
  <font color="#00be00">Few-shot</font> recognition aims to recognize novel categories under low-data regimes. Due to the scarcity of images, machines cannot obtain enough effective information, and the generalization ability of the model is extremely weak. By using auxiliary semantic modalities, recent metric-learning based few-shot learning methods have achieved promising performances. However, these methods only augment the representations of support classes, while query images have no semantic modalities information to enhance representations. Instead, we propose attribute-shaped learning (ASL), which can normalize visual representations to predict attributes for query images. And we further devise an attribute-visual attention module (AVAM), which utilizes attributes to generate more discriminative features. Our method enables visual representations to focus on important regions with attributes guidance. Experiments demonstrate that our method can achieve <font color="#960096">competitive</font> results on CUB and SUN benchmarks. Our code is available at {<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/chenhaoxing/ASL}. </br></br>

<a href='http://arxiv.org/pdf/2112.07887.pdf'>2112.07887</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.2440баллов, №161</br>
<b>Knowledge-Rich Self-Supervised Entity Linking</b></br>
Authors: , Zhang, Sheng, Cheng, Hao, Vashishth, Shikhar, Wong, Cliff, Xiao, Jinfeng, Liu, Xiaodong, Naumann, Tristan, Gao, Jianfeng, Poon, Hoifung</br>
  Entity linking faces significant challenges, such as prolific variations and prevalent ambiguities, especially in high-value domains with myriad entities. Standard classification approaches suffer from the annotation bottleneck and cannot effectively handle unseen entities. <font color="#00be00">Zero-shot</font> entity linking has emerged as a promising direction for generalizing to new entities, but it still requires example gold entity mentions during training and canonical descriptions for all entities, both of which are rarely available outside of Wikipedia. In this paper, we explore Knowledge-RIch Self-Supervision ($\\tt KRISS$) for entity linking, by leveraging readily available domain knowledge. In training, it generates self-supervised mention examples on unlabeled text using a domain ontology and trains a contextual encoder using contrastive learning. For inference, it samples self-supervised mentions as prototypes for each entity and conducts linking by mapping the test mention to the most similar prototype. Our approach subsumes zero-shot and <font color="#00be00">few-shot</font> methods, and can easily incorporate entity descriptions and gold mention labels if available. Using bio<font color="#640064">medic</font>ine as a case study, we conducted extensive experiments on seven standard datasets spanning biomedical literature and <font color="#be00be">clinic</font>al notes. Without using any labeled information, our method produces $\\tt KRISSBERT$, a universal entity linker for four million UMLS entities, which attains new <font color="#00be00">state of the art</font>, <font color="#00be00">outperform</font>ing prior self-supervised methods by as much as over 20 absolute points in accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.05393.pdf'>2112.05393</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.2436баллов, №162</br>
<b>A Self-supervised Mixed-curvature Graph Neural Network</b></br>
Authors: , Sun, Li, Zhang, Zhongbao, Ye, Junda, Peng, Hao, Zhang, Jiawei, Su, Sen, Yu, Philip S.</br>
  Graph representation learning received increasing attentions in recent years. Most of existing methods ignore the complexity of the graph structures and restrict graphs in a single constant-curvature representation space, which is only suitable to particular kinds of graph structure indeed. Additionally, these methods follow the supervised or semi-supervised learning paradigm, and thereby notably limit their deployment on the unlabeled graphs in real applications. To address these aforementioned limitations, we take the first attempt to study the self-supervised graph representation learning in the mixed-curvature spaces. In this paper, we present a novel Self-supervised Mixed-curvature Graph Neural Network (SelfMGNN). Instead of working on one single constant-curvature space, we construct a mixed-curvature space via the Cartesian product of multiple Riemannian component spaces and design <font color="#00be00">hierarchical</font> attention mechanisms for learning and fusing the representations across these component spaces. To enable the self-supervisd learning, we propose a novel dual contrastive approach. The mixed-curvature Riemannian space actually provides multiple Riemannian views for the contrastive learning. We introduce a Riemannian projector to reveal these views, and utilize a well-designed Riemannian discriminator for the single-view and cross-view contrastive learning within and across the Riemannian views. Finally, extensive experiments show that SelfMGNN captures the complicated graph structures in reality and <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.02905.pdf'>2112.02905</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.2386баллов, №163</br>
<b>Parameter Efficient Deep Probabilistic Forecasting</b></br>
Authors: , Sprangers, Olivier, Schelter, Sebastian, de Rijke, Maarten</br>
  Probabilistic time series forecasting is crucial in many application domains such as retail, ecommerce, <font color="#be00be">financ</font>e, or biology. With the increasing availability of large volumes of data, a number of neural architectures have been proposed for this problem. In particular, <font color="#00be00">Transformer</font>-based methods achieve <font color="#00be00">state-of-the-art</font> performance on <font color="#009600">real-world</font> benchmarks. However, these methods require a large number of parameters to be learned, which imposes high memory requirements on the computational resources for training such models.   To address this problem, we introduce a novel Bidirectional Temporal Convolutional Network (BiTCN), which requires an order of magnitude less parameters than a common Transformer-based approach. Our model combines two Temporal Convolutional Networks (TCNs): the first network encodes future covariates of the time series, whereas the second network encodes past observations and covariates. We jointly estimate the parameters of an output distribution via these two networks.   Experiments on four real-world datasets show that our method performs on par with four state-of-the-art probabilistic forecasting methods, including a Transformer-based approach and WaveNet, on two point metrics (sMAPE, NRMSE) as well as on a set of range metrics (quantile loss percentiles) in the majority of cases. Secondly, we demonstrate that our method requires significantly less parameters than Transformer-based methods, which means the model can be trained faster with significantly lower memory requirements, which as a consequence reduces the infrastructure cost for deploying these models. </br></br>

<a href='http://arxiv.org/pdf/2112.08723.pdf'>2112.08723</a> &nbsp&nbsp (cs:CL, cs:CV) &nbsp&nbsp 1.2276баллов, №164</br>
<b>Distilled Dual-Encoder Model for Vision-Language Understanding</b></br>
Authors: , Wang, Zekun, Wang, Wenhui, Zhu, Haichao, Liu, Ming, Qin, Bing, Wei, Furu</br>
  We propose a cross-modal attention distillation framework to train a dual-encoder model for vision-language understanding tasks, such as visual reasoning and visual question answering. Dual-encoder models have a faster inference speed than fusion-encoder models and enable the pre-computation of images and text during inference. However, the shallow interaction module used in dual-encoder models is insufficient to handle complex vision-language understanding tasks. In order to learn deep interactions of images and text, we introduce cross-modal attention distillation, which uses the image-to-text and text-to-image attention distributions of a fusion-encoder model to guide the training of our dual-encoder model. In addition, we show that applying the cross-modal attention distillation for both pre-training and fine-tuning stages achieves further improvements. Experimental results demonstrate that the distilled dual-encoder model achieves <font color="#960096">competitive</font> performance for visual reasoning, visual entailment and visual question answering tasks while enjoying a much faster inference speed than fusion-encoder models. Our code and models will be <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/kugwzk/Distilled-DualEncoder. </br></br>

<a href='http://arxiv.org/pdf/2112.07015.pdf'>2112.07015</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.2269баллов, №165</br>
<b>Multi-Expert Human Action Recognition with <font color="#00be00">Hierarchical</font> Super-Class\n  Learning</b></br>
Authors: , Dehkordi, Hojat Asgarian, Nezhad, Ali Soltani, Kashiani, Hossein, Shokouhi, Shahriar Baradaran, Ayatollahi, Ahmad</br>
  In still image human action recognition, existing studies have mainly leveraged extra bounding box information along with class labels to mitigate the lack of temporal information in still images; however, preparing extra data with manual annotation is time-consuming and also prone to human errors. Moreover, the existing studies have not addressed action recognition with long-tailed distribution. In this paper, we propose a two-phase multi-expert classification method for human action recognition to cope with long-tailed distribution by means of super-class learning and without any extra information. To choose the best configuration for each super-class and characterize inter-class dependency between different action classes, we propose a novel Graph-Based Class Selection (GCS) algorithm. In the proposed approach, a coarse-grained phase selects the most relevant fine-grained experts. Then, the fine-grained experts encode the intricate details within each super-class so that the inter-class variation increases. Extensive experimental evaluations are conducted on various public human action recognition datasets, including Stanford40, Pascal VOC 2012 Action, BU101+, and IHAR datasets. The experimental results demonstrate that the proposed method yields promising improvements. To be more specific, in IHAR, Sanford40, Pascal VOC 2012 Action, and BU101+ benchmarks, the proposed approach <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> studies by 8.92%, 0.41%, 0.66%, and 2.11 % with much less computational cost and without any auxiliary annotation information. Besides, it is proven that in addressing action recognition with long-tailed distribution, the proposed method outperforms its counterparts by a significant margin. </br></br>

<a href='http://arxiv.org/pdf/2112.07888.pdf'>2112.07888</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.2222баллов, №166</br>
<b>Event Linking: Grounding Event Mentions to Wikipedia</b></br>
Authors: , Yu, Xiaodong, Yin, Wenpeng, Gupta, Nitish, Roth, Dan</br>
  Comprehending an article requires understanding its constituent events. However, the context where an event is mentioned often lacks the details of this event. Then, where can we obtain more knowledge of this particular event in addition to its context? This work defines Event Linking, a new natural language understanding task at the event level. Event linking tries to link an event mention, appearing in a news article for example, to the most appropriate Wikipedia page. This page is expected to provide rich knowledge about what the event refers to. To standardize the research of this new problem, we contribute in three-fold. First, this is the first work in the community that formally defines event linking task. Second, we collect a dataset for this new task. In specific, we first gather training set automatically from Wikipedia, then create two evaluation sets: one from the Wikipedia domain as well, reporting the in-domain performance; the other from the <font color="#009600">real-world</font> news domain, testing the out-of-domain performance. Third, we propose EveLINK, the first-ever Event Linking approach. Overall, event linking is a considerably challenging task requiring more effort from the community. Data and code are available here: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/CogComp/event-linking. </br></br>

<a href='http://arxiv.org/pdf/2112.07007.pdf'>2112.07007</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.2111баллов, №167</br>
<b>Acceleration techniques for optimization over trained neural network\n  ensembles</b></br>
Authors: , Wang, Keliang, Lozano, Leonardo, Cardonha, Carlos, Bergman, David</br>
  We study optimization problems where the objective function is modeled through feedforward neural networks with rectified linear unit (ReLU) activation. Recent literature has explored the use of a single neural network to model either uncertain or complex elements within an objective function. However, it is well known that ensembles of neural networks produce more stable predictions and have better generalizability than models with single neural networks, which suggests the application of ensembles of neural networks in a decision-making pipeline. We study how to incorporate a neural network ensemble as the objective function of an optimization model and explore computational approaches for the ensuing problem. We present a mixed-integer linear program based on existing popular big-$M$ formulations for optimizing over a single neural network. We develop two acceleration techniques for our model, the first one is a preprocessing procedure to tighten bounds for critical neurons in the neural network while the second one is a set of valid inequalities based on Benders decomposition. Experimental evaluations of our solution methods are conducted on one global optimization problem and two <font color="#009600">real-world</font> data sets; the results suggest that our optimization algorithm <font color="#00be00">outperform</font>s the adaption of an <font color="#00be00">state-of-the-art</font> approach in terms of computational time and optimality gaps. </br></br>

<a href='http://arxiv.org/pdf/2112.06028.pdf'>2112.06028</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 1.2065баллов, №168</br>
<b>Retrosynthetic Planning with Experience-Guided Monte Carlo Tree Search</b></br>
Authors: , Hong, Siqi, Zhuo, Hankz Hankui, Jin, Kebing, Zhou, Zhanwen</br>
  Retrosynthetic planning problem is to analyze a complex <font color="#00be00">molecule</font> and give a synthetic route using simple building blocks. The huge number of chemical reactions leads to a combinatorial explosion of possibilities, and even the experienced chemists could not select the most promising transformations. The current approaches rely on human-defined or machine-trained score functions which have limited chemical knowledge or use expensive estimation methods such as rollout to guide the search. In this paper, we propose {\\tt MCTS}, a novel MCTS-based retrosynthetic planning approach, to deal with retrosynthetic planning problem. Instead of exploiting rollout, we build an Experience Guidance Network to learn knowledge from synthetic experiences during the search. Experiments on benchmark USPTO datasets show that, our {\\tt MCTS} gains significant improvement over <font color="#00be00">state-of-the-art</font> approaches both in efficiency and effectiveness. </br></br>

<a href='http://arxiv.org/pdf/2112.09025.pdf'>2112.09025</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp 1.2036баллов, №169</br>
<b>Deep <font color="#00be00">Reinforcement Learning</font> Policies Learn Shared Adversarial Features\n  Across MDPs</b></br>
Authors: , Korkmaz, Ezgi</br>
  The use of deep neural networks as function approximators has led to striking progress for <font color="#00be00">reinforcement learning</font> algorithms and applications. Yet the knowledge we have on decision boundary geometry and the loss landscape of neural policies is still quite limited. In this paper we propose a framework to investigate the decision boundary and loss landscape similarities across states and across MDPs. We conduct experiments in various games from Arcade Learning Environment, and discover that high sensitivity directions for neural policies are correlated across MDPs. We argue that these high sensitivity directions support the hypothesis that non-robust features are shared across training environments of reinforcement learning agents. We believe our results reveal fundamental properties of the environments used in deep reinforcement learning training, and represent a tangible step towards building robust and reliable deep reinforcement learning agents. </br></br>

<a href='http://arxiv.org/pdf/2112.03806.pdf'>2112.03806</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.1965баллов, №170</br>
<b>OOD-GNN: Out-of-Distribution Generalized Graph Neural Network</b></br>
Authors: , Li, Haoyang, Wang, Xin, Zhang, Ziwei, Zhu, Wenwu</br>
  Graph neural networks (GNNs) have achieved impressive performance when testing and training graph data come from identical distribution. However, existing GNNs lack out-of-distribution generalization abilities so that their performance substantially degrades when there exist distribution shifts between testing and training graph data. To solve this problem, in this work, we propose an out-of-distribution generalized graph neural network (OOD-GNN) for achieving satisfactory performance on unseen testing graphs that have different distributions with training graphs. Our proposed OOD-GNN employs a novel nonlinear graph representation decorrelation method utilizing random Fourier features, which encourages the model to eliminate the statistical dependence between relevant and irrelevant graph representations through iteratively optimizing the sample graph weights and graph encoder. We further present a global weight estimator to learn weights for training graphs such that variables in graph representations are forced to be independent. The learned weights help the graph encoder to get rid of spurious correlations and, in turn, concentrate more on the true connection between learned discriminative graph representations and their ground-truth labels. We conduct extensive experiments to validate the out-of-distribution generalization abilities on two synthetic and 12 <font color="#009600">real-world</font> datasets with distribution shifts. The results demonstrate that our proposed OOD-GNN significantly <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.07259.pdf'>2112.07259</a> &nbsp&nbsp (cs:ML, cs:CL) &nbsp&nbsp 1.1960баллов, №171</br>
<b>TopNet: Learning from Neural Topic Model to Generate Long Stories</b></br>
Authors: , Yang, Yazheng, Pan, Boyuan, Cai, Deng, Sun, Huan</br>
  Long story generation (LSG) is one of the coveted goals in natural language processing. Different from most text generation tasks, LSG requires to output a long story of rich content based on a much shorter text input, and often suffers from information sparsity. In this paper, we propose \\emph{TopNet} to alleviate this problem, by leveraging the recent advances in neural topic modeling to obtain high-quality skeleton words to complement the short input. In particular, instead of directly generating a story, we first learn to map the short text input to a low-dimensional topic distribution (which is pre-assigned by a topic model). Based on this latent topic distribution, we can use the reconstruction decoder of the topic model to sample a sequence of inter-related words as a skeleton for the story. Experiments on two benchmark datasets show that our proposed framework is highly effective in skeleton word selection and significantly <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> models in both automatic evaluation and human evaluation. </br></br>

<a href='http://arxiv.org/pdf/2112.06624.pdf'>2112.06624</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.1935баллов, №172</br>
<b><font color="#be00be">Pedestrian</font> Trajectory Prediction via Spatial Interaction <font color="#00be00">Transformer</font>\n  Network</b></br>
Authors: , Su, Tong, Meng, Yu, Xu, Yan</br>
  As a core technology of the autonomous driving system, <font color="#be00be">pedestrian</font> trajectory prediction can significantly enhance the function of active vehicle safety and reduce road traffic injuries. In traffic scenes, when encountering with oncoming people, pedestrians may make sudden turns or stop immediately, which often leads to complicated trajectories. To predict such unpredictable trajectories, we can gain insights into the interaction between pedestrians. In this paper, we present a novel generative method named Spatial Interaction <font color="#00be00">Transformer</font> (SIT), which learns the spatio-temporal correlation of pedestrian trajectories through attention mechanisms. Furthermore, we introduce the conditional variational autoencoder (CVAE) framework to model the future latent motion states of pedestrians. In particular, the experiments based on large-scale trafc dataset nuScenes [2] show that SIT has an outstanding performance than <font color="#00be00">state-of-the-art</font> (SOTA) methods. Experimental evaluation on the challenging ETH and UCY datasets conrms the robustness of our proposed model </br></br>

<a href='http://arxiv.org/pdf/2112.07875.pdf'>2112.07875</a> &nbsp&nbsp (cs:NE) &nbsp&nbsp 1.1932баллов, №173</br>
<b>Novelty-Driven Binary Particle Swarm Optimisation for Truss Optimisation\n  Problems</b></br>
Authors: , Assimi, Hirad, Neumann, Frank, Wagner, Markus, Li, Xiaodong</br>
  Topology optimisation of trusses can be formulated as a combinatorial and multi-modal problem in which locating distinct optimal designs allows practitioners to choose the best design based on their preferences. Bilevel optimisation has been successfully applied to truss optimisation to consider topology and sizing in upper and lower levels, respectively. We introduce exact enumeration to rigorously analyse the topology search space and remove randomness for small problems. We also propose novelty-driven binary particle swarm optimisation for bigger problems to discover new designs at the upper level by maximising novelty. For the lower level, we employ a reliable evolutionary optimiser to tackle the layout configuration aspect of the problem. We consider truss optimisation problem instances where designers need to select the size of bars from a discrete set with respect to practice code constraints. Our experimental investigations show that our approach <font color="#00be00">outperform</font>s the current <font color="#00be00">state-of-the-art</font> methods and it obtains multiple high-quality solutions. </br></br>

<a href='http://arxiv.org/pdf/2112.04350.pdf'>2112.04350</a> &nbsp&nbsp (cs:RO, cs:CV) &nbsp&nbsp 1.1886баллов, №174</br>
<b><font color="#00be00">Transformer</font> based trajectory prediction</b></br>
Authors: , Postnikov, Aleksey, Gamayunov, Aleksander, Ferrer, Gonzalo</br>
  To plan a safe and efficient route, an autonomous vehicle should anticipate future motions of other agents around it. Motion prediction is an extremely challenging task which recently gained significant attention of the research community. In this work, we present a simple and yet strong baseline for uncertainty aware motion prediction based purely on <font color="#00be00">transformer</font> neural networks, which has shown its effectiveness in conditions of domain change. While being easy-to-implement, the proposed approach achieves <font color="#960096">competitive</font> performance and ranks 1$^{st}$ on the 2021 Shifts Vehicle Motion Prediction Competition. </br></br>

<a href='http://arxiv.org/pdf/2112.05534.pdf'>2112.05534</a> &nbsp&nbsp (cs:RO, cs:CV) &nbsp&nbsp 1.1867баллов, №175</br>
<b>An Embarrassingly Pragmatic Introduction to Vision-based Autonomous\n  Robots</b></br>
Authors: , Conde, Marcos V.</br>
  Autonomous robots are currently one of the most popular Artificial Intelligence problems, having experienced significant advances in the last decade, from Self-driving cars and humanoids to delivery robots and drones. Part of the problem is to get a robot to emulate the perception of human beings, our sense of sight, replacing the eyes with cameras and the <font color="#00be00">brain</font> with mathematical models such as Neural Networks. Developing an AI able to drive a car without human intervention and a small robot to deliver packages in the city may seem like different problems, nevertheless from the point of view of perception and vision, both problems have several similarities. The main solutions we currently find focus on the environment perception through visual information using Computer Vision techniques, Machine Learning, and various algorithms to make the robot understand the environment or scene, move, adapt its trajectory and perform its tasks (maintenance, exploration, etc.) without the need for human intervention. In this work, we develop a small-scale autonomous vehicle from scratch, capable of understanding the scene using only visual information, navigating through industrial environments, detecting people and obstacles, or performing simple maintenance tasks. We review the <font color="#00be00">state-of-the-art</font> of fundamental problems and demonstrate that many methods employed at small-scale are similar to the ones employed in real Self-driving cars from companies like Tesla or Lyft. Finally, we discuss the current state of Robotics and autonomous driving and the technological and ethical limitations that we can find in this field. </br></br>

<a href='http://arxiv.org/pdf/2112.06759.pdf'>2112.06759</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.1789баллов, №176</br>
<b>Hformer: Hybrid CNN-<font color="#00be00">Transformer</font> for Fringe Order Prediction in Phase\n  Unwrapping of Fringe Projection</b></br>
Authors: , Zhu, Xinjun, Han, Zhiqiang, Yuan, Mengkai, Guo, Qinghua, Wang, Hongyi</br>
  Recently, deep learning has attracted more and more attention in phase unwrapping of fringe projection three-dimensional (3D) measurement, with the aim to improve the performance leveraging the powerful Convolutional Neural Network (CNN) models. In this paper, for the first time (to the best of our knowledge), we introduce the <font color="#00be00">Transformer</font> into the phase unwrapping which is different from CNN and propose Hformer model dedicated to phase unwrapping via fringe order prediction. The proposed model has a hybrid CNN-Transformer architecture that is mainly composed of backbone, encoder and decoder to take advantage of both CNN and Transformer. Encoder and decoder with cross attention are designed for the fringe order prediction. Experimental results show that the proposed Hformer model achieves better performance in fringe order prediction compared with the CNN models such as U-Net and DCNN. Moreover, ablation study on Hformer is made to verify the improved feature pyramid networks (FPN) and testing strategy with flipping in the predicted fringe order. Our work opens an alternative way to deep learning based phase unwrapping methods, which are dominated by CNN in fringe projection 3D measurement. </br></br>

<a href='http://arxiv.org/pdf/2112.05291.pdf'>2112.05291</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.1733баллов, №177</br>
<b>LCTR: On Awakening the Local Continuity of <font color="#00be00">Transformer</font> for Weakly\n  Supervised Object Localization</b></br>
Authors: , Chen, Zhiwei, Wang, Changan, Wang, Yabiao, Jiang, Guannan, Shen, Yunhang, Tai, Ying, Wang, Chengjie, Zhang, Wei, Cao, Liujuan</br>
  Weakly supervised object localization (WSOL) aims to learn object localizer solely by using image-level labels. The convolution neural network (CNN) based techniques often result in highlighting the most discriminative part of objects while ignoring the entire object extent. Recently, the <font color="#00be00">transformer</font> architecture has been deployed to WSOL to capture the long-range feature dependencies with self-attention mechanism and multilayer perceptron structure. Nevertheless, transformers lack the locality inductive bias inherent to CNNs and therefore may deteriorate local feature details in WSOL. In this paper, we propose a novel framework built upon the transformer, termed LCTR (Local Continuity TRansformer), which targets at enhancing the local perception capability of global features among long-range feature dependencies. To this end, we propose a relational patch-attention module (RPAM), which considers cross-patch information on a global basis. We further design a cue digging module (CDM), which utilizes local features to guide the learning trend of the model for highlighting the weak local responses. Finally, comprehensive experiments are carried out on two widely used datasets, ie, CUB-200-2011 and ILSVRC, to verify the effectiveness of our method. </br></br>

<a href='http://arxiv.org/pdf/2112.07303.pdf'>2112.07303</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 1.1658баллов, №178</br>
<b>MMO: Meta Multi-Objectivization for Software Configuration Tuning</b></br>
Authors: , Chen, Tao, Li, Miqing</br>
  Software configuration tuning is essential for optimizing a given performance objective (e.g., minimizing latency). Yet, due to the software\'s intrinsically complex configuration landscape and expensive measurement, there has been a rather mild success, particularly in preventing the search from being trapped in local optima. To address this issue, in this paper we take a different perspective. Instead of focusing on improving the optimizer, we work on the level of optimization model and propose a meta multi-objectivization (MMO) model that considers an auxiliary performance objective (e.g., throughput in addition to latency). What makes this model unique is that we do not optimize the auxiliary performance objective, but rather use it to make similarly-performing while different configurations less comparable (i.e. Pareto nondominated to each other), thus preventing the search from being trapped in local optima. Importantly through a new normalization method we show how to effectively use the MMO model without worrying about its weight -- the only yet highly sensitive parameter that can affect its effectiveness. Experiments on 22 cases from 11 <font color="#009600">real-world</font> software systems/environments confirm that our MMO model with the new normalization performs better than its <font color="#00be00">state-of-the-art</font> single-objective counterparts on 82% cases while achieving up to 2.09x speedup. For 67% of the cases, the new normalization also enables the MMO model to <font color="#00be00">outperform</font> the instance when using it with the normalization used in our prior FSE work under pre-tuned best weights, saving a great amount of resources which would be otherwise necessary to find a good weight. We also demonstrate that the MMO model with the new normalization can consolidate Flash, a recent model-based tuning tool, on 68% of the cases with 1.22x speedup in general. </br></br>

<a href='http://arxiv.org/pdf/2111.13330.pdf'>2111.13330</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV) &nbsp&nbsp 1.1614баллов, №179</br>
<b>ArchRepair: Block-Level Architecture-Oriented Repairing for Deep Neural\n  Networks</b></br>
Authors: , Qi, Hua, Wang, Zhijie, Guo, Qing, Chen, Jianlang, Juefei-Xu, Felix, Ma, Lei, Zhao, Jianjun</br>
  Over the past few years, deep neural networks (DNNs) have achieved tremendous success and have been continuously applied in many application domains. However, during the practical deployment in the industrial tasks, DNNs are found to be erroneous-prone due to various reasons such as overfitting, lacking robustness to <font color="#009600">real-world</font> corruptions during practical usage. To address these challenges, many recent attempts have been made to repair DNNs for version updates under practical operational contexts by updating weights (i.e., network parameters) through retraining, fine-tuning, or direct weight fixing at a neural level. In this work, as the first attempt, we initiate to repair DNNs by jointly optimizing the architecture and weights at a higher (i.e., block) level.   We first perform empirical studies to investigate the limitation of whole network-level and layer-level repairing, which motivates us to explore a novel repairing direction for DNN repair at the block level. To this end, we first propose adversarial-aware spectrum analysis for vulnerable block localization that considers the neurons\' status and weights\' gradients in blocks during the forward and backward processes, which enables more accurate candidate block localization for repairing even under a few examples. Then, we further propose the architecture-oriented search-based repairing that relaxes the targeted block to a continuous repairing search space at higher deep feature levels. By jointly optimizing the architecture and weights in that space, we can identify a much better block architecture. We implement our proposed repairing techniques as a tool, named ArchRepair, and conduct extensive experiments to validate the proposed method. The results show that our method can not only repair but also enhance accuracy &amp; robustness, <font color="#00be00">outperform</font>ing the <font color="#00be00">state-of-the-art</font> DNN repair techniques. </br></br>

<a href='http://arxiv.org/pdf/2112.08746.pdf'>2112.08746</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.1590баллов, №180</br>
<b>Unsupervised <font color="#00be00">Reinforcement Learning</font> in Multiple Environments</b></br>
Authors: , Mutti, Mirco, Mancassola, Mattia, Restelli, Marcello</br>
  Several recent works have been dedicated to unsupervised <font color="#00be00">reinforcement learning</font> in a single environment, in which a policy is first pre-trained with unsupervised interactions, and then fine-tuned towards the optimal policy for several downstream supervised tasks defined over the same environment. Along this line, we address the problem of unsupervised reinforcement learning in a class of multiple environments, in which the policy is pre-trained with interactions from the whole class, and then fine-tuned for several tasks in any environment of the class. Notably, the problem is inherently multi-objective as we can trade off the pre-training objective between environments in many ways. In this work, we foster an exploration strategy that is sensitive to the most adverse cases within the class. Hence, we cast the exploration problem as the maximization of the mean of a critical percentile of the state visitation entropy induced by the exploration strategy over the class of environments. Then, we present a policy gradient algorithm, $\\alpha$MEPOL, to optimize the introduced objective through mediated interactions with the class. Finally, we empirically demonstrate the ability of the algorithm in learning to explore challenging classes of continuous environments and we show that reinforcement learning greatly benefits from the pre-trained exploration strategy w.r.t. learning from scratch. </br></br>

<a href='http://arxiv.org/pdf/2112.06238.pdf'>2112.06238</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.1545баллов, №181</br>
<b>HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling\n  Deep Network for Snapshot Compressive Imaging</b></br>
Authors: , Zhang, Xuanyu, Zhang, Yongbing, Xiong, Ruiqin, Sun, Qilin, Zhang, Jian</br>
  Hyperspectral imaging is an essential imaging modality for a wide range of applications, especially in remote sensing, agriculture, and <font color="#640064">medic</font>ine. Inspired by existing hyperspectral cameras that are either slow, expensive, or bulky, reconstructing hyperspectral images (HSIs) from a low-budget snapshot measurement has drawn wide attention. By mapping a truncated numerical optimization algorithm into a network with a fixed number of phases, recent deep unfolding networks (DUNs) for spectral snapshot compressive sensing (SCI) have achieved remarkable success. However, DUNs are far from reaching the scope of industrial applications limited by the lack of cross-phase feature interaction and adaptive parameter adjustment. In this paper, we propose a novel Hyperspectral Explicable Reconstruction and Optimal Sampling deep Network for SCI, dubbed HerosNet, which includes several phases under the ISTA-unfolding framework. Each phase can flexibly simulate the sensing matrix and contextually adjust the step size in the gradient descent step, and <font color="#00be00">hierarchical</font>ly fuse and interact the hidden states of previous phases to effectively recover current HSI frames in the proximal mapping step. Simultaneously, a hardware-friendly optimal binary mask is learned end-to-end to further improve the reconstruction performance. Finally, our HerosNet is validated to <font color="#00be00">outperform</font> the <font color="#00be00">state-of-the-art</font> methods on both simulation and real datasets by large margins. </br></br>

<a href='http://arxiv.org/pdf/2112.05144.pdf'>2112.05144</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.1507баллов, №182</br>
<b>Edge-aware Guidance Fusion Network for RGB Thermal Scene <font color="#be00be">Parsing</font></b></br>
Authors: , Zhou, Wujie, Dong, Shaohua, Xu, Caie, Qian, Yaguan</br>
  RGB thermal scene <font color="#be00be">parsing</font> has recently attracted increasing research interest in the field of computer vision. However, most existing methods fail to perform good boundary extraction for prediction maps and cannot fully use high level features. In addition, these methods simply fuse the features from RGB and thermal modalities but are unable to obtain comprehensive fused features. To address these problems, we propose an edge-aware guidance fusion network (EGFNet) for RGB thermal scene parsing. First, we introduce a prior edge map generated using the RGB and thermal images to capture detailed information in the prediction map and then embed the prior edge information in the feature maps. To effectively fuse the RGB and thermal information, we propose a multimodal fusion module that guarantees adequate cross-modal fusion. Considering the importance of high level semantic information, we propose a global information module and a semantic information module to extract rich semantic information from the high-level features. For decoding, we use simple elementwise addition for cascaded feature fusion. Finally, to improve the parsing accuracy, we apply multitask deep supervision to the semantic and boundary maps. Extensive experiments were performed on benchmark datasets to demonstrate the effectiveness of the proposed EGFNet and its superior performance compared with <font color="#00be00">state of the art</font> methods. The code and results can be found at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/ShaohuaDong2021/EGFNet. </br></br>

<a href='http://arxiv.org/pdf/2112.08313.pdf'>2112.08313</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 1.1422баллов, №183</br>
<b>Measure and Improve Robustness in NLP Models: A Survey</b></br>
Authors: , Wang, Xuezhi, Wang, Haohan, Yang, Diyi</br>
  As NLP models achieved <font color="#00be00">state-of-the-art</font> performances over benchmarks and gained wide applications, it has been increasingly important to ensure the safe deployment of these models in the <font color="#009600">real world</font>, e.g., making sure the models are robust against unseen or challenging scenarios. Despite robustness being an increasingly studied topic, it has been separately explored in applications like vision and NLP, with various definitions, evaluation and mitigation strategies in multiple lines of research. In this paper, we aim to provide a unifying survey of how to define, measure and improve robustness in NLP. We first connect multiple definitions of robustness, then unify various lines of work on identifying robustness failures and evaluating models\' robustness. Correspondingly, we present mitigation strategies that are data-driven, model-driven, and inductive-prior-based, with a more systematic view of how to effectively improve robustness in NLP models. Finally, we conclude by outlining open challenges and future directions to motivate further research in this area. </br></br>

<a href='http://arxiv.org/pdf/2112.08674.pdf'>2112.08674</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.1338баллов, №184</br>
<b>Reframing Human-AI Collaboration for Generating Free-Text Explanations</b></br>
Authors: , Wiegreffe, Sarah, Hessel, Jack, Swayamdipta, Swabha, Riedl, Mark, Choi, Yejin</br>
  Large language models are increasingly capable of generating fluent-appearing text with relatively little task-specific supervision. But can these models accurately explain classification decisions? We consider the task of generating free-text explanations using a small number of human-written examples (i.e., in a <font color="#00be00">few-shot</font> manner). We find that (1) authoring higher-quality examples for prompting results in higher quality generations; and (2) <font color="#00be00">surprisin</font>gly, in a head-to-head comparison, crowdworkers often prefer explanations generated by<font color="#00be00"> GPT</font>-3 to crowdsourced human-written explanations contained within existing datasets. Crowdworker ratings also show, however, that while models produce factual, grammatical, and sufficient explanations, they have room to improve, e.g., along axes such as providing novel information and supporting the label. We create a pipeline that combines GPT-3 with a supervised filter that incorporates humans-in-the-loop via binary acceptability judgments. Despite significant subjectivity intrinsic to judging acceptability, our approach is able to consistently filter GPT-3 generated explanations deemed acceptable by humans. </br></br>

<a href='http://arxiv.org/pdf/2111.07695.pdf'>2111.07695</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.1329баллов, №185</br>
<b>Joint Synthesis of Safety Certificate and Safe Control Policy using\n  Constrained <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Ma, Haitong, Liu, Changliu, Li, Shengbo Eben, Zheng, Sifa, Chen, Jianyu</br>
  Safety is the major consideration in controlling complex dynamical systems using <font color="#00be00">reinforcement learning</font> (RL), where the safety certificate can provide provable safety guarantee. A valid safety certificate is an energy function indicating that safe states are with low energy, and there exists a corresponding safe control policy that allows the energy function to always dissipate. The safety certificate and the safe control policy are closely related to each other and both challenging to synthesize. Therefore, existing learning-based studies treat either of them as prior knowledge to learn the other, which limits their applicability with general unknown dynamics. This paper proposes a novel approach that simultaneously synthesizes the energy-function-based safety certificate and learns the safe control policy with CRL. We do not rely on prior knowledge about either an available model-based controller or a perfect safety certificate. In particular, we formulate a loss function to optimize the safety certificate parameters by minimizing the occurrence of energy increases. By adding this optimization procedure as an outer loop to the Lagrangian-based constrained reinforcement learning (CRL), we jointly update the policy and safety certificate parameters and prove that they will converge to their respective local optima, the optimal safe policy and a valid safety certificate. We evaluate our algorithms on multiple safety-critical benchmark environments. The results show that the proposed algorithm learns provably safe policies with no constraint violation. The validity or feasibility of synthesized safety certificate is also verified numerically. </br></br>

<a href='http://arxiv.org/pdf/2112.08812.pdf'>2112.08812</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 1.1314баллов, №186</br>
<b>Ditch the Gold Standard: Re-evaluating Conversational Question Answering</b></br>
Authors: , Li, Huihan, Gao, Tianyu, Goenka, Manan, Chen, Danqi</br>
  Conversational question answering (CQA) systems aim to provide natural-language answers to users in information-seeking conversations. Existing CQA benchmarks compare models with pre-collected human-human conversations, using ground-truth answers provided in conversational history. It remains unclear whether we can rely on this static evaluation for model development and whether current systems can well generalize to <font color="#009600">real-world</font> human-machine conversations. In this work, we conduct the first large-scale human evaluation of <font color="#00be00">state-of-the-art</font> CQA systems, where human evaluators converse with models and judge the correctness of their answers. We find that the distribution of human-machine conversations differs drastically from that of human-human conversations, and there is a disagreement between human and gold-history evaluation in terms of model ranking. We further investigate how to improve automatic evaluations, and propose a question rewriting mechanism based on predicted history, which better correlates with human judgments. Finally, we discuss the impact of various modeling strategies and future directions towards better conversational question answering systems. </br></br>

<a href='http://arxiv.org/pdf/2112.05237.pdf'>2112.05237</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.1237баллов, №187</br>
<b>Transfer learning using deep neural networks for Ear Presentation Attack\n  Detection: New Database for PAD</b></br>
Authors: , Khiarak, Jalil Nourmohammadi</br>
  Ear recognition system has been widely studied whereas there are just a few ear presentation attack detection methods for ear recognition systems, consequently, there is no <font color="#00be00">publicly available</font> ear presentation attack detection (PAD) database. In this paper, we propose a PAD method using a pre-trained deep neural network and release a new dataset called Warsaw University of Technology Ear Dataset for Presentation Attack Detection (WUT-Ear V1.0). There is no ear database that is captured using<font color="#960096"> mobile </font>devices. Hence, we have captured more than 8500 genuine ear images from 134 subjects and more than 8500 fake ear images using. We made replay-attack and photo print attacks with 3 different mobile devices. Our approach achieves 99.83% and 0.08% for the half total error rate (HTER) and attack presentation classification error rate (APCER), respectively, on the replay-attack database. The captured data is analyzed and visualized statistically to find out its importance and make it a benchmark for further research. The experiments have been found out a secure PAD method for ear recognition system, publicly available ear image, and ear PAD dataset. The codes and evaluation results are publicly available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/Jalilnkh/KartalOl-EAR-PAD. </br></br>

<a href='http://arxiv.org/pdf/2112.05816.pdf'>2112.05816</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.1221баллов, №188</br>
<b>Encoding priors in the <font color="#00be00">brain</font>: a <font color="#00be00">reinforcement learning</font> model for mouse\n  decision making</b></br>
Authors: , Krishnagopal, Sanjukta, Latham, Peter</br>
  In two-alternative forced choice tasks, prior knowledge can improve performance, especially when operating near the psychophysical threshold. For instance, if subjects know that one choice is much more likely than the other, they can make that choice when evidence is weak. A common hypothesis for these kinds of tasks is that the prior is stored in neural activity. Here we propose a different hypothesis: the prior is stored in synaptic strengths. We study the International <font color="#00be00">Brain</font> Laboratory task, in which a grating appears on either the right or left side of a screen, and a mouse has to move a wheel to bring the grating to the center. The grating is often low in contrast which makes the task relatively difficult, and the prior probability that the grating appears on the right is either 80% or 20%, in (unsignaled) blocks of about 50 trials. We model this as a <font color="#00be00">reinforcement learning</font> task, using a feedforward neural network to map states to actions, and adjust the weights of the network to maximize reward, learning via policy gradient. Our model uses an internal state that stores an estimate of the grating and confidence, and follows <font color="#be00be">Bayes</font>ian updates, and can switch between engaged and disengaged states to mimic animal behavior. This model reproduces the main experimental finding - that the psychometric curve with respect to contrast shifts after a block switch in about 10 trials. Also, as seen in the experiments, in our model the difference in neuronal activity in the right and left blocks is small - it is virtually impossible to decode block structure from activity on single trials if noise is about 2%. The hypothesis that priors are stored in weights is difficult to test, but the technology to do so should be available in the not so distant future. </br></br>

<a href='http://arxiv.org/pdf/2112.08653.pdf'>2112.08653</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.1213баллов, №189</br>
<b>Reconsidering the Past: Optimizing Hidden States in Language Models</b></br>
Authors: , Yoshida, Davis, Gimpel, Kevin</br>
  We present Hidden-State Optimization (HSO), a gradient-based method for improving the performance of <font color="#00be00">transformer</font> language models at inference time. Similar to dynamic evaluation (Krause et al., 2018), HSO computes the gradient of the log-probability the language model assigns to an evaluation text, but uses it to update the cached hidden states rather than the model parameters. We test HSO with pretrained Transformer-XL and<font color="#00be00"> GPT</font>-2 language models, finding improvement on the WikiText103 and PG-19 datasets in terms of perplexity, especially when evaluating a model outside of its training distribution. We also demonstrate downstream applicability by showing gains in the recently developed prompt-based <font color="#00be00">few-shot</font> evaluation setting, again with no extra parameters or training data. </br></br>

<a href='http://arxiv.org/pdf/2111.13792.pdf'>2111.13792</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.1186баллов, №190</br>
<b>LAFITE: Towards Language-Free Training for Text-to-Image Generation</b></br>
Authors: , Zhou, Yufan, Zhang, Ruiyi, Chen, Changyou, Li, Chunyuan, Tensmeyer, Chris, Yu, Tong, Gu, Jiuxiang, Xu, Jinhui, Sun, Tong</br>
  One of the major challenges in training text-to-image generation models is the need of a large number of high-quality image-text pairs. While image samples are often easily accessible, the associated text descriptions typically require careful human captioning, which is particularly time- and cost-consuming. In this paper, we propose the first work to train text-to-image generation models without any text data. Our method leverages the well-aligned multi-modal semantic space of the powerful pre-trained CLIP model: the requirement of text-conditioning is seamlessly alleviated via generating text features from image features. Extensive experiments are conducted to illustrate the effectiveness of the proposed method. We obtain <font color="#00be00">state-of-the-art</font> results in the standard text-to-image generation tasks. Importantly, the proposed language-free model <font color="#00be00">outperform</font>s most existing models trained with full image-text pairs. Furthermore, our method can be applied in fine-tuning pre-trained models, which saves both training time and cost in training text-to-image generation models. Our pre-trained model obtains <font color="#960096">competitive</font> results in <font color="#00be00">zero-shot</font> text-to-image generation on the MS-COCO dataset, yet with around only 1% of the model size and training data size relative to the recently proposed large DALL-E model. </br></br>

<a href='http://arxiv.org/pdf/2112.05825.pdf'>2112.05825</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.1012баллов, №191</br>
<b>Revisiting Consistency Regularization for Semi-Supervised Learning</b></br>
Authors: , Fan, Yue, Kukleva, Anna, Schiele, Bernt</br>
  Consistency regularization is one of the most widely-used techniques for semi-supervised learning (SSL). Generally, the aim is to train a model that is invariant to various data augmentations. In this paper, we revisit this idea and find that enforcing invariance by decreasing distances between features from differently augmented images leads to improved performance. However, encouraging equivariance instead, by increasing the feature distance, further improves performance. To this end, we propose an improved consistency regularization framework by a simple yet effective technique, FeatDistLoss, that imposes consistency and equivariance on the classifier and the feature level, respectively. Experimental results show that our model defines a new <font color="#00be00">state of the art</font> for various datasets and settings and <font color="#00be00">outperform</font>s previous work by a significant margin, particularly in low data regimes. Extensive experiments are conducted to analyze the method, and the code will be published. </br></br>

<a href='http://arxiv.org/pdf/2112.06736.pdf'>2112.06736</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.0988баллов, №192</br>
<b>Roof-BERT: Divide Understanding Labour and Join in Work</b></br>
Authors: , Liao, Wei-Lin, Ma, Wei-Yun</br>
  Recent work on enhancing BERT-based language representation models with <font color="#960096">knowledge graph</font>s (KGs) has promising results on multiple NLP tasks. <font color="#00be00">State-of-the-art</font> approaches typically integrate the original input sentences with triples in KGs, and feed the combined representation into a<font color="#00be00"> BERT </font>model. However, as the sequence length of a BERT model is limited, the framework can not contain too much knowledge besides the original input sentences and is thus forced to discard some knowledge. The problem is especially severe for those downstream tasks that input is a long paragraph or even a document, such as QA or reading comprehension tasks. To address the problem, we propose Roof-BERT, a model with two underlying BERTs and a fusion layer on them. One of the underlying BERTs encodes the knowledge resources and the other one encodes the original input sentences, and the fusion layer like a roof integrates both BERTs\' encodings. Experiment results on QA task reveal the effectiveness of the proposed model. </br></br>

<a href='http://arxiv.org/pdf/2112.05150.pdf'>2112.05150</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0955баллов, №193</br>
<b>Deep Recurrent Neural Network with Multi-scale Bi-directional\n  Propagation for Video <font color="#be00be">Deblur</font>ring</b></br>
Authors: , Zhu, Chao, Dong, Hang, Pan, Jinshan, Liang, Boyang, Huang, Yuhao, Fu, Lean, Wang, Fei</br>
  The success of the <font color="#00be00">state-of-the-art</font> video <font color="#be00be">deblur</font>ring methods stems mainly from implicit or explicit estimation of alignment among the adjacent frames for latent video restoration. However, due to the influence of the blur effect, estimating the alignment information from the blurry adjacent frames is not a trivial task. Inaccurate estimations will interfere the following frame restoration. Instead of estimating alignment information, we propose a simple and effective deep Recurrent Neural Network with Multi-scale Bi-directional Propagation (RNN-MBP) to effectively propagate and gather the information from unaligned neighboring frames for better video deblurring. Specifically, we build a Multi-scale Bi-directional Propagation~(MBP) module with two U-Net RNN cells which can directly exploit the inter-frame information from unaligned neighboring hidden states by integrating them in different scales. Moreover, to better evaluate the proposed algorithm and existing state-of-the-art methods on <font color="#009600">real-world</font> blurry scenes, we also create a Real-World Blurry Video Dataset (RBVD) by a well-designed Digital Video Acquisition System (DVAS) and use it as the training and evaluation dataset. Extensive experimental results demonstrate that the proposed RBVD dataset effectively improves the performance of existing algorithms on real-world blurry videos, and the proposed algorithm performs favorably against the state-of-the-art methods on three typical benchmarks. The code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/XJTU-CVLAB-LOWLEVEL/RNN-MBP. </br></br>

<a href='http://arxiv.org/pdf/2112.06133.pdf'>2112.06133</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0944баллов, №194</br>
<b>MVLayoutNet:3D layout reconstruction with multi-view panoramas</b></br>
Authors: , Hu, Zhihua, Duan, Bo, Zhang, Yanfeng, Sun, Mingwei, Huang, Jingwei</br>
  We present MVLayoutNet, an end-to-end network for holistic 3D reconstruction from multi-view panoramas. Our core contribution is to seamlessly combine learned monocular layout estimation and multi-view stereo (MVS) for accurate layout reconstruction in both 3D and image space. We jointly train a layout module to produce an initial layout and a novel MVS module to obtain accurate layout geometry. Unlike standard MVSNet [33], our MVS module takes a newly-proposed layout cost volume, which aggregates multi-view costs at the same depth layer into corresponding layout elements. We additionally provide an attention-based scheme that guides the MVS module to focus on structural regions. Such a design considers both local pixel-level costs and global holistic information for better reconstruction. Experiments show that our method <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font>s in terms of depth rmse by 21.7% and 20.6% on the 2D-3D-S [1] and ZInD [5] datasets. Finally, our method leads to coherent layout geometry that enables the reconstruction of an entire scene. </br></br>

<a href='http://arxiv.org/pdf/2112.08037.pdf'>2112.08037</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0895баллов, №195</br>
<b>LookinGood^{\\pi}: Real-time Person-independent Neural Re-rendering for\n  High-quality Human Performance Capture</b></br>
Authors: , Yang, Xiqi, Yang, Kewei, Chen, Kang, Zhang, Weidong, Xu, Weiwei</br>
  We propose LookinGood^{\\pi}, a novel neural re-rendering approach that is aimed to (1) improve the rendering quality of the low-quality reconstructed results from human performance capture system in real-time; (2) improve the generalization ability of the neural rendering network on unseen people. Our key idea is to utilize the rendered image of reconstructed geometry as the guidance to assist the prediction of person-specific details from few reference images, thus enhancing the re-rendered result. In light of this, we design a two-branch network. A coarse branch is designed to fix some artifacts (i.e. holes, noise) and obtain a coarse version of the rendered input, while a detail branch is designed to predict &quot;correct&quot; details from the warped references. The guidance of the rendered image is realized by blending features from two branches effectively in the training of the detail branch, which improves both the warping accuracy and the details\' fidelity. We demonstrate that our method <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> methods at producing high-fidelity images on unseen people. </br></br>

<a href='http://arxiv.org/pdf/2112.04121.pdf'>2112.04121</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0871баллов, №196</br>
<b>Reverse image filtering using total derivative approximation and\n  accelerated gradient descent</b></br>
Authors: , Galetto, Fernando J., Deng, Guang</br>
  In this paper, we address a new problem of reversing the effect of an image filter, which can be linear or nonlinear. The assumption is that the algorithm of the filter is unknown and the filter is available as a black box. We formulate this inverse problem as minimizing a local patch-based cost function and use total derivative to approximate the gradient which is used in gradient descent to solve the problem. We analyze factors affecting the convergence and quality of the output in the Fourier domain. We also study the application of accelerated gradient descent algorithms in three gradient-free reverse filters, including the one proposed in this paper. We present results from extensive experiments to evaluate the complexity and effectiveness of the proposed algorithm. Results demonstrate that the proposed algorithm <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> in that (1) it is at the same level of complexity as that of the fastest reverse filter, but it can reverse a larger number of filters, and (2) it can reverse the same list of filters as that of the very complex reverse filter, but its complexity is much smaller. </br></br>

<a href='http://arxiv.org/pdf/2112.05221.pdf'>2112.05221</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0834баллов, №197</br>
<b>MantissaCam: Learning Snapshot High-dynamic-range Imaging with\n  Perceptually-based In-pixel Irradiance Encoding</b></br>
Authors: , So, Haley M., Martel, Julien N. P., Dudek, Piotr, Wetzstein, Gordon</br>
  The ability to image high-dynamic-range (HDR) scenes is crucial in many computer vision applications. The dynamic range of conventional sensors, however, is fundamentally limited by their well capacity, resulting in saturation of bright scene parts. To overcome this limitation, emerging sensors offer in-pixel processing capabilities to encode the incident irradiance. Among the most promising encoding schemes is modulo wrapping, which results in a computational photography problem where the HDR scene is computed by an irradiance unwrapping algorithm from the wrapped low-dynamic-range (LDR) sensor image. Here, we design a neural network--based algorithm that <font color="#00be00">outperform</font>s previous irradiance unwrapping methods and, more importantly, we design a perceptually inspired &quot;mantissa&quot; encoding scheme that more efficiently wraps an HDR scene into an LDR sensor. Combined with our reconstruction framework, MantissaCam achieves <font color="#00be00">state-of-the-art</font> results among modulo-type snapshot HDR imaging approaches. We demonstrate the efficacy of our method in simulation and show preliminary results of a prototype MantissaCam implemented with a programmable sensor. </br></br>

<a href='http://arxiv.org/pdf/2112.05417.pdf'>2112.05417</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 1.0818баллов, №198</br>
<b>Unsupervised Editing for Counterfactual Stories</b></br>
Authors: , Chen, Jiangjie, Gan, Chun, Cheng, Sijie, Zhou, Hao, Xiao, Yanghua, Li, Lei</br>
  Creating what-if stories requires reasoning about prior statements and possible outcomes of the changed conditions. One can easily generate coherent endings under new conditions, but it would be challenging for current systems to do it with minimal changes to the original story. Therefore, one major challenge is the trade-off between generating a logical story and rewriting with minimal-edits. In this paper, we propose EDUCAT, an editing-based unsupervised approach for counterfactual story rewriting. EDUCAT includes a target position detection strategy based on estimating causal effects of the what-if conditions, which keeps the causal invariant parts of the story. EDUCAT then generates the stories under fluency, coherence and minimal-edits constraints. We also propose a new metric to alleviate the shortcomings of current automatic metrics and better evaluate the trade-off. We evaluate EDUCAT on a public counterfactual story rewriting benchmark. Experiments show that EDUCAT achieves the best trade-off over unsupervised SOTA methods according to both automatic and human evaluation. The resources of EDUCAT are available at: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/jiangjiechen/EDUCAT. </br></br>

<a href='http://arxiv.org/pdf/2112.05647.pdf'>2112.05647</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 1.0817баллов, №199</br>
<b>Analysis and Prediction of NLP Models Via Task Embeddings</b></br>
Authors: , Sileo, Damien, Moens, Marie-Francine</br>
  Task embeddings are low-dimensional representations that are trained to capture task properties. In this paper, we propose MetaEval, a collection of $101$ NLP tasks. We fit a single <font color="#00be00">transformer</font> to all MetaEval tasks jointly while conditioning it on learned embeddings. The resulting task embeddings enable a novel analysis of the space of tasks. We then show that task aspects can be mapped to task embeddings for new tasks without using any annotated examples.   Predicted embeddings can modulate the encoder for <font color="#00be00">zero-shot</font> inference and <font color="#00be00">outperform</font> a zero-shot baseline on GLUE tasks. The provided multitask setup can function as a benchmark for future transfer learning research. </br></br>

<a href='http://arxiv.org/pdf/2112.08767.pdf'>2112.08767</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.0721баллов, №200</br>
<b>Adaptation and Attention for Neural Video Coding</b></br>
Authors: , Zou, Nannan, Zhang, Honglei, Cricri, Francesco, Youvalari, Ramin G., Tavakoli, Hamed R., Lainema, Jani, Aksu, Emre, Hannuksela, Miska, Rahtu, Esa</br>
  Neural image coding represents now the <font color="#00be00">state-of-the-art</font> image compression approach. However, a lot of work is still to be done in the video domain. In this work, we propose an end-to-end learned video codec that introduces several architectural novelties as well as training novelties, revolving around the concepts of adaptation and attention. Our codec is organized as an intra-frame codec paired with an inter-frame codec. As one architectural novelty, we propose to train the inter-frame codec model to adapt the motion estimation process based on the resolution of the input video. A second architectural novelty is a new neural block that combines concepts from split-attention based neural networks and from DenseNets. Finally, we propose to overfit a set of decoder-side multiplicative parameters at inference time. Through ablation studies and comparisons to prior art, we show the benefits of our proposed techniques in terms of coding gains. We compare our codec to VVC/H.266 and RLVC, which represent the state-of-the-art traditional and end-to-end learned codecs, respectively, and to the top performing end-to-end learned approach in 2021 CLIC competition, E2E_T_OL. Our codec clearly <font color="#00be00">outperform</font>s E2E_T_OL, and compare favorably to VVC and RLVC in some settings. </br></br>

<a href='http://arxiv.org/pdf/2112.06705.pdf'>2112.06705</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.0697баллов, №201</br>
<b>N-SfC: Robust and Fast Shape Estimation from Caustic Images</b></br>
Authors: , Kassubeck, Marc, Kappel, Moritz, Castillo, Susana, Magnor, Marcus</br>
  This paper deals with the highly challenging problem of reconstructing the shape of a refracting object from a single image of its resulting caustic. Due to the ubiquity of transparent refracting objects in everyday life, reconstruction of their shape entails a multitude of practical applications. The recent Shape from Caustics (SfC) method casts the problem as the inverse of a light propagation simulation for synthesis of the caustic image, that can be solved by a differentiable renderer. However, the inherent complexity of light transport through refracting surfaces currently limits the practicability with respect to reconstruction speed and robustness. To address these issues, we introduce Neural-Shape from Caustics (N-SfC), a learning-based extension that incorporates two components into the reconstruction pipeline: a denoising module, which alleviates the computational cost of the light transport simulation, and an optimization process based on learned gradient descent, which enables better convergence using fewer iterations. Extensive experiments demonstrate the effectiveness of our neural extensions in the scenario of quality control in 3D glass printing, where we significantly <font color="#00be00">outperform</font> the current <font color="#00be00">state-of-the-art</font> in terms of computational speed and final surface error. </br></br>

<a href='http://arxiv.org/pdf/2112.06825.pdf'>2112.06825</a> &nbsp&nbsp (cs:CV, cs:AI, cs:CL, cs:ML) &nbsp&nbsp 1.0684баллов, №202</br>
<b>VL-Adapter: Parameter-Efficient Transfer Learning for\n  Vision-and-Language Tasks</b></br>
Authors: , Sung, Yi-Lin, Cho, Jaemin, Bansal, Mohit</br>
  Recently, fine-tuning language models pre-trained on large text corpora have provided huge improvements on vision-and-language (V&amp;L) tasks as well as on pure language tasks. However, fine-tuning the entire parameter set of pre-trained models becomes impractical since the model size is growing rapidly. Hence, in this paper, we introduce adapter-based parameter-efficient transfer learning techniques to V&amp;L models such as VL-BART and VL-T5. We evaluate our methods in a unified multi-task setup on four diverse V&amp;L tasks: VQAv2, GQA, NLVR2 , and MSCOCO image captioning. With careful training and thorough experiments, we benchmark three popular adapter-based methods (Adapter, Hyperformer, Compacter) against the standard full fine-tuning and the recently proposed prompt-tuning approach. We also enhance the efficiency and performance of adapters by sharing their weights to attain knowledge across tasks. Our results demonstrate that training the adapter with the weight-sharing technique (4.4% of total parameters) can match the performance of fine-tuning the entire model. Lastly, we present a comprehensive analysis including the combination of adapter and task-specific prompts and the impact of V&amp;L pre-training on adapters. Our code is available at: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/ylsung/VL_adapter. </br></br>

<a href='http://arxiv.org/pdf/2112.08626.pdf'>2112.08626</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0655баллов, №203</br>
<b>Analysis and Evaluation of Kinect-based Action Recognition Algorithms</b></br>
Authors: , Wang, Lei</br>
  Human action recognition still exists many challenging problems such as different viewpoints, occlusion, lighting conditions, human body size and the speed of action execution, although it has been widely used in different areas. To tackle these challenges, the Kinect depth sensor has been developed to record real time depth sequences, which are insensitive to the color of human clothes and illumination conditions. Many methods on recognizing human action have been reported in the literature such as HON4D, HOPC, RBD and HDG, which use the 4D surface normals, pointclouds, skeleton-based model and depth gradients respectively to capture discriminative information from depth videos or skeleton data. In this research project, the performance of four aforementioned algorithms will be analyzed and evaluated using five benchmark datasets, which cover challenging issues such as noise, change of viewpoints, background clutters and occlusions. We also implemented and improved the HDG algorithm, and applied it in cross-view action recognition using the UWA3D Multiview Activity dataset. Moreover, we used different combinations of individual feature vectors in HDG for performance evaluation. The experimental results show that our improvement of HDG <font color="#00be00">outperform</font>s other three <font color="#00be00">state-of-the-art</font> algorithms for cross-view action recognition. </br></br>

<a href='http://arxiv.org/pdf/2112.07999.pdf'>2112.07999</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0650баллов, №204</br>
<b>Self-Ensembling GAN for Cross-Domain Semantic <font color="#be00be">Segmentation</font></b></br>
Authors: , Xu, Yonghao, He, Fengxiang, Du, Bo, Zhang, Liangpei, Tao, Dacheng</br>
  Deep neural networks (DNNs) have greatly contributed to the performance gains in semantic <font color="#be00be">segmentation</font>. Nevertheless, training DNNs generally requires large amounts of pixel-level labeled data, which is expensive and time-consuming to collect in practice. To mitigate the annotation burden, this paper proposes a self-ensembling generative adversarial network (SE-GAN) exploiting cross-domain data for semantic segmentation. In SE-GAN, a teacher network and a student network constitute a self-ensembling model for generating semantic segmentation maps, which together with a discriminator, forms a GAN. Despite its simplicity, we find SE-GAN can significantly boost the performance of adversarial training and enhance the stability of the model, the latter of which is a common barrier shared by most adversarial training-based methods. We <font color="#be00be">theor</font>etically analyze SE-GAN and provide an $\\mathcal O(1/\\sqrt{N})$ generalization bound ($N$ is the training sample size), which suggests controlling the discriminator\'s hypothesis complexity to enhance the generalizability. Accordingly, we choose a simple network as the discriminator. Extensive and systematic experiments in two standard settings demonstrate that the proposed method significantly <font color="#00be00">outperform</font>s current <font color="#00be00">state-of-the-art</font> approaches. The <font color="#00be00">source code</font> of our model will be available soon. </br></br>

<a href='http://arxiv.org/pdf/2112.08739.pdf'>2112.08739</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 1.0624баллов, №205</br>
<b>Forensic Analysis of Synthetically Generated Scientific Images</b></br>
Authors: , Mandelli, Sara, Cozzolino, Davide, Cardenuto, Joao P., Moreira, Daniel, Bestagini, Paolo, Scheirer, Walter, Rocha, Anderson, Verdoliva, Luisa, Tubaro, Stefano, Delp, Edward J.</br>
  The widespread diffusion of synthetically generated content is a serious threat that needs urgent countermeasures. The generation of synthetic content is not restricted to multimedia data like videos, photographs, or audio sequences, but covers a significantly vast area that can include biological images as well, such as western-blot and microscopic images. In this paper, we focus on the detection of synthetically generated western-blot images. Western-blot images are largely explored in the bio<font color="#640064">medic</font>al literature and it has been already shown how these images can be easily counterfeited with few hope to spot manipulations by visual inspection or by standard forensics detectors. To overcome the absence of a <font color="#00be00">publicly available</font> dataset, we create a new dataset comprising more than 14K original western-blot images and 18K synthetic western-blot images, generated by three different <font color="#00be00">state-of-the-art</font> generation methods. Then, we investigate different strategies to detect synthetic western blots, exploring binary classification methods as well as one-class detectors. In both scenarios, we never exploit synthetic western-blot images at training stage. The achieved results show that synthetically generated western-blot images can be spot with good accuracy, even though the exploited detectors are not optimized over synthetic versions of these scientific images. </br></br>

<a href='http://arxiv.org/pdf/2112.07984.pdf'>2112.07984</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0619баллов, №206</br>
<b>Temporal Action Proposal Generation with Background Constraint</b></br>
Authors: , Yang, Haosen, Wu, Wenhao, Wang, Lining, Jin, Sheng, Xia, Boyang, Yao, Hongxun, Huang, Hujie</br>
  Temporal action proposal generation (TAPG) is a challenging task that aims to locate action instances in untrimmed videos with temporal boundaries. To evaluate the confidence of proposals, the existing works typically predict action score of proposals that are supervised by the temporal Intersection-over-Union (tIoU) between proposal and the ground-truth. In this paper, we innovatively propose a general auxiliary Background Constraint idea to further suppress low-quality proposals, by utilizing the background prediction score to restrict the confidence of proposals. In this way, the Background Constraint concept can be easily plug-and-played into existing TAPG methods (e.g., BMN, GTAD). From this perspective, we propose the Background Constraint Network (BCNet) to further take advantage of the rich information of action and background. Specifically, we introduce an Action-Background Interaction module for reliable confidence evaluation, which models the inconsistency between action and background by attention mechanisms at the frame and clip levels. Extensive experiments are conducted on two popular benchmarks, i.e., ActivityNet-1.3 and THUMOS14. The results demonstrate that our method <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> methods. Equipped with the existing action classifier, our method also achieves remarkable performance on the temporal action localization task. </br></br>

<a href='http://arxiv.org/pdf/2112.07910.pdf'>2112.07910</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0517баллов, №207</br>
<b>Decoupling <font color="#00be00">Zero-Shot</font> Semantic <font color="#be00be">Segmentation</font></b></br>
Authors: , Ding, Jian, Xue, Nan, Xia, Gui-Song, Dai, Dengxin</br>
  <font color="#00be00">Zero-shot</font> semantic <font color="#be00be">segmentation</font> (ZS3) aims to segment the novel categories that have not been seen in the training. Existing works formulate ZS3 as a pixel-level zero-shot classification problem, and transfer semantic knowledge from seen classes to unseen ones with the help of language models pre-trained only with texts. While simple, the pixel-level ZS3 formulation shows the limited capability to integrate vision-language models that are often pre-trained with image-text pairs and currently demonstrate great potential for vision tasks. Inspired by the observation that humans often perform segment-level semantic labeling, we propose to decouple the ZS3 into two sub-tasks: 1) a class-agnostic grouping task to group the pixels into segments. 2) a zero-shot classification task on segments. The former sub-task does not involve category information and can be directly transferred to group pixels for unseen classes. The latter subtask performs at segment-level and provides a natural way to leverage large-scale vision-language models pre-trained with image-text pairs (e.g. CLIP) for ZS3. Based on the decoupling formulation, we propose a simple and effective zero-shot semantic segmentation model, called ZegFormer, which <font color="#00be00">outperform</font>s the previous methods on ZS3 standard benchmarks by large margins, e.g., 35 points on the PASCAL VOC and 3 points on the COCO-Stuff in terms of mIoU for unseen classes. Code will be released at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/dingjiansw101/ZegFormer. </br></br>

<a href='http://arxiv.org/pdf/2112.06714.pdf'>2112.06714</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 1.0513баллов, №208</br>
<b>Learning Semantic-Aligned Feature Representation for Text-based Person\n  Search</b></br>
Authors: , Li, Shiping, Cao, Min, Zhang, Min</br>
  Text-based person search aims to retrieve images of a certain <font color="#be00be">pedestrian</font> by a textual description. The key challenge of this task is to eliminate the inter-modality gap and achieve the feature alignment across modalities. In this paper, we propose a semantic-aligned embedding method for text-based person search, in which the feature alignment across modalities is achieved by automatically learning the semantic-aligned visual features and textual features. First, we introduce two <font color="#00be00">Transformer</font>-based backbones to encode robust feature representations of the images and texts. Second, we design a semantic-aligned feature aggregation network to adaptively select and aggregate features with the same semantics into part-aware features, which is achieved by a multi-head attention module constrained by a cross-modality part alignment loss and a diversity loss. Experimental results on the CUHK-PEDES and Flickr30K datasets show that our method achieves <font color="#00be00">state-of-the-art</font> performances. </br></br>

<a href='http://arxiv.org/pdf/2112.05519.pdf'>2112.05519</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.0472баллов, №209</br>
<b>A Validation Tool for Designing <font color="#00be00">Reinforcement Learning</font> Environments</b></br>
Authors: , Xu, Ruiyang, Chen, Zhengxing</br>
  <font color="#00be00">Reinforcement learning</font> (RL) has gained increasing attraction in the academia and tech industry with launches to a variety of impactful applications and products. Although research is being actively conducted on many fronts (e.g., offline RL, performance, etc.), many RL practitioners<font color="#be00be"> face </font>a challenge that has been largely ignored: determine whether a designed Markov Decision Process (MDP) is valid and meaningful. This study proposes a heuristic-based feature analysis method to validate whether an MDP is well formulated. We believe an MDP suitable for applying RL should contain a set of state features that are both sensitive to actions and predictive in rewards. We tested our method in constructed environments showing that our approach can identify certain invalid environment formulations. As far as we know, performing validity analysis for RL problem formulation is a novel direction. We envision that our tool will serve as a motivational example to help practitioners apply RL in <font color="#009600">real-world</font> problems more easily. </br></br>

<a href='http://arxiv.org/pdf/2112.06351.pdf'>2112.06351</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 1.0446баллов, №210</br>
<b>Neural Point Process for Learning Spatiotemporal Event Dynamics</b></br>
Authors: , Zhou, Zihao, Yang, Xingyi, Rossi, Ryan, Zhao, Handong, Yu, Rose</br>
  Learning the dynamics of spatiotemporal events is a fundamental problem. Neural point processes enhance the expressivity of point process models with deep neural networks. However, most existing methods only consider temporal dynamics without spatial modeling. We propose Deep Spatiotemporal Point Process (DeepSTPP), a deep dynamics model that integrates spatiotemporal point processes. Our method is flexible, efficient, and can accurately forecast irregularly sampled events over space and time. The key construction of our approach is the nonparametric space-time intensity function, governed by a latent process. The intensity function enjoys closed-form integration for the density. The latent process captures the uncertainty of the event sequence. We use amortized variational inference to infer the latent process with deep networks. Using synthetic datasets, we validate our model can accurately learn the true intensity function. On <font color="#009600">real-world</font> benchmark datasets, our model demonstrates superior performance over <font color="#00be00">state-of-the-art</font> baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.05638.pdf'>2112.05638</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 1.0441баллов, №211</br>
<b>DisCo: Effective Knowledge Distillation For Contrastive Learning of\n  Sentence Embeddings</b></br>
Authors: , Wu, Xing, Gao, Chaochen, Wang, Jue, Zang, Liangjun, Wang, Zhongyuan, Hu, Songlin</br>
  Contrastive learning has been proven suitable for learning sentence embeddings and can significantly improve the semantic textual similarity (STS) tasks. Recently, large contrastive learning models, e.g., Sentence-T5, tend to be proposed to learn more powerful sentence embeddings. Though effective, such large models are hard to serve online due to computational resources or time cost limits. To tackle that, knowledge distillation (KD) is commonly adopted, which can compress a large &quot;teacher&quot; model into a small &quot;student&quot; model but generally suffer from some performance loss. Here we propose an enhanced KD framework termed Distill-Contrast (DisCo). The proposed DisCo framework firstly utilizes KD to transfer the capability of a large sentence embedding model to a small student model on large unlabelled data, and then finetunes the student model with contrastive learning on labelled training data. For the KD process in DisCo, we further propose Contrastive Knowledge Distillation (CKD) to enhance the consistencies among teacher model training, KD, and student model finetuning, which can probably improve performance like prompt learning. Extensive experiments on 7 STS benchmarks show that student models trained with the proposed DisCo and CKD suffer from little or even no performance loss and consistently <font color="#00be00">outperform</font> the corresponding counterparts of the same parameter size. Amazingly, our 110M student model can even outperform the latest <font color="#00be00">state-of-the-art</font> (SOTA) model, i.e., Sentence-T5(11B), with only 1% parameters. </br></br>

<a href='http://arxiv.org/pdf/2112.05827.pdf'>2112.05827</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 1.0438баллов, №212</br>
<b>Quality-Aware Multimodal Biometric Recognition</b></br>
Authors: , Soleymani, Sobhan, Dabouei, Ali, Taherkhani, Fariborz, Iranmanesh, Seyed Mehdi, Dawson, Jeremy, Nasrabadi, Nasser M.</br>
  We present a quality-aware multimodal recognition framework that combines representations from multiple biometric traits with varying quality and number of samples to achieve increased recognition accuracy by extracting complimentary identification information based on the quality of the samples. We develop a quality-aware framework for fusing representations of input modalities by weighting their importance using quality scores estimated in a weakly-supervised fashion. This framework utilizes two fusion blocks, each represented by a set of quality-aware and aggregation networks. In addition to architecture modifications, we propose two task-specific loss functions: multimodal separability loss and multimodal compactness loss. The first loss assures that the representations of modalities for a class have comparable magnitudes to provide a better quality estimation, while the multimodal representations of different classes are distributed to achieve maximum discrimination in the embedding space. The second loss, which is considered to regularize the network weights, improves the generalization performance by regularizing the framework. We evaluate the performance by considering three multimodal datasets consisting of face, iris, and fingerprint modalities. The efficacy of the framework is demonstrated through comparison with the <font color="#00be00">state-of-the-art</font> algorithms. In particular, our framework <font color="#00be00">outperform</font>s the rank- and score-level fusion of modalities of BIOMDATA by more than 30% for true acceptance rate at false acceptance rate of $10^{-4}$. </br></br>

<a href='http://arxiv.org/pdf/2112.05253.pdf'>2112.05253</a> &nbsp&nbsp (cs:CV, cs:CL) &nbsp&nbsp 1.0415баллов, №213</br>
<b>MAGMA -- Multimodal Augmentation of Generative Models through\n  Adapter-based Finetuning</b></br>
Authors: , Eichenberg, Constantin, Black, Sidney, Weinbach, Samuel, Parcalabescu, Letitia, Frank, Anette</br>
  Large-scale pretraining is fast becoming the norm in Vision-Language (VL) modeling. However, prevailing VL approaches are limited by the requirement for labeled data and the use of complex multi-step pretraining objectives. We present MAGMA - a simple method for augmenting generative language models with additional modalities using adapter-based finetuning. Building on Frozen, we train a series of VL models that autoregressively generate text from arbitrary combinations of visual and textual input. The pretraining is entirely end-to-end using a single language modeling objective, simplifying optimization compared to previous approaches. Importantly, the language model weights remain unchanged during training, allowing for transfer of encyclopedic knowledge and in-context learning abilities from language pretraining. MAGMA <font color="#00be00">outperform</font>s Frozen on open-ended generative tasks, achieving <font color="#00be00">state of the art</font> results on the OKVQA benchmark and <font color="#960096">competitive</font> results on a range of other popular VL benchmarks, while pretraining on 0.2% of the number of samples used to train SimVLM. </br></br>

<a href='http://arxiv.org/pdf/2112.08796.pdf'>2112.08796</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 1.0386баллов, №214</br>
<b>Saliency Grafting: Innocuous Attribution-Guided Mixup with Calibrated\n  Label Mixing</b></br>
Authors: , Park, Joonhyung, Yang, June Yong, Shin, Jinwoo, Hwang, Sung Ju, Yang, Eunho</br>
  The Mixup scheme suggests mixing a pair of samples to create an augmented training sample and has gained considerable attention recently for improving the generalizability of neural networks. A straightforward and widely used extension of Mixup is to combine with regional dropout-like methods: removing random patches from a sample and replacing it with the features from another sample. Albeit their simplicity and effectiveness, these methods are prone to create harmful samples due to their randomness. To address this issue, \'maximum saliency\' strategies were recently proposed: they select only the most informative features to prevent such a phenomenon. However, they now suffer from lack of sample diversification as they always deterministically select regions with maximum saliency, injecting bias into the augmented data. In this paper, we present, a novel, yet simple Mixup-variant that captures the best of both worlds. Our idea is two-fold. By stochastically sampling the features and \'grafting\' them onto another sample, our method effectively generates diverse yet meaningful samples. Its second ingredient is to produce the label of the grafted sample by mixing the labels in a saliency-calibrated fashion, which rectifies supervision misguidance introduced by the random sampling procedure. Our experiments under CIFAR, Tiny-ImageNet, and ImageNet datasets show that our scheme <font color="#00be00">outperform</font>s the current <font color="#00be00">state-of-the-art</font> augmentation strategies not only in terms of classification accuracy, but is also superior in coping under stress conditions such as data corruption and object occlusion. </br></br>

<a href='http://arxiv.org/pdf/2112.01030.pdf'>2112.01030</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0364баллов, №215</br>
<b>TransMEF: A <font color="#00be00">Transformer</font>-Based Multi-Exposure Image Fusion Framework\n  using Self-Supervised Multi-Task Learning</b></br>
Authors: , Qu, Linhao, Liu, Shaolei, Wang, Manning, Song, Zhijian</br>
  In this paper, we propose TransMEF, a <font color="#00be00">transformer</font>-based multi-exposure image fusion framework that uses self-supervised multi-task learning. The framework is based on an encoder-decoder network, which can be trained on large natural image datasets and does not require ground truth fusion images. We design three self-supervised reconstruction tasks according to the characteristics of multi-exposure images and conduct these tasks simultaneously using multi-task learning; through this process, the network can learn the characteristics of multi-exposure images and extract more generalized features. In addition, to compensate for the defect in establishing long-range dependencies in CNN-based architectures, we design an encoder that combines a CNN module with a transformer module. This combination enables the network to focus on both local and global information. We evaluated our method and compared it to 11 <font color="#960096">competitive</font> traditional and deep learning-based methods on the latest released multi-exposure image fusion benchmark dataset, and our method achieved the best performance in both subjective and objective evaluations. </br></br>

<a href='http://arxiv.org/pdf/2112.06753.pdf'>2112.06753</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.0350баллов, №216</br>
<b>FinRL-Meta: A Universe of Near-Real <font color="#be00be">Market</font> Environments for Data-Driven\n  Deep <font color="#00be00">Reinforcement Learning</font> in Quantitative <font color="#be00be">Financ</font>e</b></br>
Authors: , Liu, Xiao-Yang, Rui, Jingyang, Gao, Jiechao, Yang, Liuqing, Yang, Hongyang, Wang, Zhaoran, Wang, Christina Dan, Guo, Jian</br>
  Deep <font color="#00be00">reinforcement learning</font> (DRL) has shown huge potentials in building <font color="#be00be">financ</font>ial <font color="#be00be">market</font> simulators recently. However, due to the highly complex and dynamic nature of <font color="#009600">real-world</font> markets, raw historical financial data often involve large noise and may not reflect the future of markets, degrading the fidelity of DRL-based market simulators. Moreover, the accuracy of DRL-based market simulators heavily relies on numerous and diverse DRL agents, which increases demand for a universe of market environments and imposes a challenge on simulation speed. In this paper, we present a FinRL-Meta framework that builds a universe of market environments for data-driven financial reinforcement learning. First, FinRL-Meta separates financial data processing from the design pipeline of DRL-based strategy and provides open-source data engineering tools for financial big data. Second, FinRL-Meta provides hundreds of market environments for various trading tasks. Third, FinRL-Meta enables multiprocessing simulation and training by exploiting thousands of GPU cores. Our codes are available online at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/AI4Finance-Foundation/FinRL-Meta. </br></br>

<a href='http://arxiv.org/pdf/2112.06989.pdf'>2112.06989</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.0329баллов, №217</br>
<b>Analyzing a Caching Model</b></br>
Authors: , Sixt, Leon, Liu, Evan Zheran, Pellat, Marie, Wexler, James, Kim, Milad Hashemi Been, Maas, Martin</br>
  Machine Learning has been successfully applied in systems applications such as memory prefetching and caching, where learned models have been shown to <font color="#00be00">outperform</font> heuristics. However, the lack of understanding the inner workings of these models -- <font color="#be00be">interpret</font>ability -- remains a major obstacle for adoption in <font color="#009600">real-world</font> deployments. Understanding a model\'s behavior can help system administrators and developers gain confidence in the model, understand risks, and debug unexpected behavior in production. Interpretability for models used in computer systems poses a particular challenge: Unlike ML models trained on images or text, the input domain (e.g., memory access patterns, program counters) is not immediately interpretable. A major challenge is therefore to explain the model in terms of concepts that are approachable to a human practitioner. By analyzing a <font color="#00be00">state-of-the-art</font> caching model, we provide evidence that the model has learned concepts beyond simple statistics that can be leveraged for explanations. Our work provides a first step towards explanability of system ML models and highlights both promises and challenges of this emerging research area. </br></br>

<a href='http://arxiv.org/pdf/2112.07424.pdf'>2112.07424</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp 1.0314баллов, №218</br>
<b>Conjugated Discrete Distributions for Distributional Reinforcement\n  Learning</b></br>
Authors: , Lindenberg, Bj&#xf6;rn, Nordqvist, Jonas, Lindahl, Karl-Olof</br>
  In this work we continue to build upon recent advances in <font color="#00be00">reinforcement learning</font> for finite Markov processes. A common approach among previous existing algorithms, both single-actor and distributed, is to either clip rewards or to apply a transformation method on Q-functions to handle a large variety of magnitudes in real discounted returns. We <font color="#be00be">theor</font>etically show that one of the most successful methods may not yield an optimal policy if we have a non-deterministic process. As a solution, we argue that distributional reinforcement learning lends itself to remedy this situation completely. By the introduction of a conjugated distributional operator we may handle a large class of transformations for real returns with guaranteed theoretical convergence. We propose an approximating single-actor algorithm based on this operator that trains agents directly on unaltered rewards using a proper distributional metric given by the Cram\\\'er distance. To evaluate its performance in a stochastic setting we train agents on a suite of 55 Atari 2600 games using sticky-actions and obtain <font color="#00be00">state-of-the-art</font> performance compared to other well-known algorithms in the Dopamine framework. </br></br>

<a href='http://arxiv.org/pdf/2111.09976.pdf'>2111.09976</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0301баллов, №219</br>
<b>M2A: Motion Aware Attention for Accurate Video Action Recognition</b></br>
Authors: , Gebotys, Brennan, Wong, Alexander, Clausi, David A.</br>
  Advancements in attention mechanisms have led to significant performance improvements in a variety of areas in machine learning due to its ability to enable the dynamic modeling of temporal sequences. A particular area in computer vision that is likely to benefit greatly from the incorporation of attention mechanisms in video action recognition. However, much of the current research\'s focus on attention mechanisms have been on spatial and temporal attention, which are unable to take advantage of the inherent motion found in videos. Motivated by this, we develop a new attention mechanism called Motion Aware Attention (M2A) that explicitly incorporates motion characteristics. More specifically, M2A extracts motion information between consecutive frames and utilizes attention to focus on the motion patterns found across frames to accurately recognize actions in videos. The proposed M2A mechanism is simple to implement and can be easily incorporated into any neural network backbone architecture. We show that incorporating motion mechanisms with attention mechanisms using the proposed M2A mechanism can lead to a +15% to +26% improvement in top-1 accuracy across different backbone architectures, with only a small increase in computational complexity. We further compared the performance of M2A with other <font color="#00be00">state-of-the-art</font> motion and attention mechanisms on the Something-Something V1 video action recognition benchmark. Experimental results showed that M2A can lead to further improvements when combined with other temporal mechanisms and that it <font color="#00be00">outperform</font>s other motion-only or attention-only mechanisms by as much as +60% in top-1 accuracy for specific classes in the benchmark. </br></br>

<a href='http://arxiv.org/pdf/2112.08006.pdf'>2112.08006</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0260баллов, №220</br>
<b>Consistent Depth Prediction under Various Illuminations using Dilated\n  Cross Attention</b></br>
Authors: , Zhang, Zitian, Xian, Chuhua</br>
  In this paper, we aim to solve the problem of consistent depth prediction in complex scenes under various illumination conditions. The existing indoor datasets based on RGB-D sensors or virtual rendering have two critical limitations - sparse depth maps (NYU Depth V2) and non-realistic illumination (SUN CG, SceneNet RGB-D). We propose to use internet 3D indoor scenes and manually tune their illuminations to render photo-realistic RGB photos and their corresponding depth and BRDF maps, obtaining a new indoor depth dataset called Vari dataset. We propose a simple convolutional block named DCA by applying depthwise separable dilated convolution on encoded features to process global information and reduce parameters. We perform cross attention on these dilated features to retain the consistency of depth prediction under different illuminations. Our method is evaluated by comparing it with current <font color="#00be00">state-of-the-art</font> methods on Vari dataset and a significant improvement is observed in our experiments. We also conduct the ablation study, finetune our model on NYU Depth V2 and also evaluate on <font color="#009600">real-world</font> data to further validate the effectiveness of our DCA block. The code, pre-trained weights and Vari dataset are open-sourced. </br></br>

<a href='http://arxiv.org/pdf/2112.07742.pdf'>2112.07742</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 1.0235баллов, №221</br>
<b>Classifying Emails into Human vs Machine Category</b></br>
Authors: , Kang, Changsung, Shang, Hongwei, Langlois, Jean-Marc</br>
  It is an essential product requirement of Yahoo Mail to distinguish between personal and machine-generated emails. The old production classifier in Yahoo Mail was based on a simple logistic <font color="#be00be">regression</font> model. That model was trained by aggregating features at the SMTP address level. We propose building deep learning models at the message level. We built and trained four individual CNN models: (1) a content model with subject and content as input; (2) a sender model with sender email address and name as input; (3) an action model by analyzing email recipients\' action patterns and correspondingly generating target labels based on senders\' opening/deleting behaviors; (4) a salutation model by utilizing senders\' &quot;explicit salutation&quot; signal as positive labels. Next, we built a final full model after exploring different combinations of the above four models. Experimental results on editorial data show that our full model improves the adjusted-recall from 70.5% to 78.8% compared to the old production model, while at the same time lifts the precision from 94.7% to 96.0%. Our full model also significantly beats the <font color="#00be00">state-of-the-art</font><font color="#00be00"> Bert </font>model at this task. This full model has been deployed into the current production system (Yahoo Mail 6). </br></br>

<a href='http://arxiv.org/pdf/2112.07313.pdf'>2112.07313</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 1.0206баллов, №222</br>
<b>Autonomous Navigation and Configuration of Integrated Access Backhauling\n  for UAV Base Station Using <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Zhang, Hongyi, Li, Jingya, Qi, Zhiqiang, Lin, Xingqin, Aronsson, Anders, Bosch, Jan, Olsson, Helena Holmstr&#xf6;m</br>
  Fast and reliable connectivity is essential to enhancing situational awareness and operational efficiency for public safety mission-critical (MC) users. In emergency or disaster circumstances, where existing cellular network coverage and capacity may not be available to meet MC communication demands, deployable-network-based solutions such as cells-on-wheels/wings can be utilized swiftly to ensure reliable connection for MC users. In this paper, we consider a scenario where a macro base station (BS) is destroyed due to a natural disaster and an unmanned aerial vehicle carrying BS (UAV-BS) is set up to provide temporary coverage for users in the disaster area. The UAV-BS is integrated into the<font color="#960096"> mobile </font>network using the 5G integrated access and backhaul (IAB) technology. We propose a framework and signalling procedure for applying machine learning to this use case. A deep <font color="#00be00">reinforcement learning</font> algorithm is designed to jointly optimize the access and backhaul antenna tilt as well as the three-dimensional location of the UAV-BS in order to best serve the on-ground MC users while maintaining a good backhaul connection. Our result shows that the proposed algorithm can autonomously navigate and configure the UAV-BS to improve the throughput and reduce the drop rate of MC users. </br></br>

<a href='http://arxiv.org/pdf/2112.05892.pdf'>2112.05892</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0188баллов, №223</br>
<b>COMPOSER: Compositional Learning of Group Activity in Videos</b></br>
Authors: , Zhou, Honglu, Kadav, Asim, Shamsian, Aviv, Geng, Shijie, Lai, Farley, Zhao, Long, Liu, Ting, Kapadia, Mubbasir, Graf, Hans Peter</br>
  Group Activity Recognition (GAR) detects the activity performed by a group of actors in a short video clip. The task requires the compositional understanding of scene entities and relational reasoning between them. We approach GAR by modeling the video as a series of tokens that represent the multi-scale semantic concepts in the video. We propose COMPOSER, a Multiscale <font color="#00be00">Transformer</font> based architecture that performs attention-based reasoning over tokens at each scale and learns group activity compositionally. In addition, we only use the keypoint modality which reduces scene biases and improves the generalization ability of the model. We improve the multi-scale representations in COMPOSER by <font color="#be00be">clustering</font> the intermediate scale representations, while maintaining consistent cluster assignments between scales. Finally, we use techniques such as auxiliary prediction and novel data augmentations (e.g., Actor Dropout) to aid model training. We demonstrate the model\'s strength and <font color="#be00be">interpret</font>ability on the challenging Volleyball dataset. COMPOSER achieves a new <font color="#00be00">state-of-the-art</font> 94.5% accuracy with the keypoint-only modality. COMPOSER <font color="#00be00">outperform</font>s the latest GAR methods that rely on RGB signals, and performs favorably compared against methods that exploit multiple modalities. Our code will be available. </br></br>

<a href='http://arxiv.org/pdf/2112.06596.pdf'>2112.06596</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0117баллов, №224</br>
<b>SAC-GAN: Structure-Aware Image-to-Image Composition for Self-Driving</b></br>
Authors: , Zhou, Hang, Mahdavi-Amiri, Ali, Ma, Rui, Zhang, Hao</br>
  We present a compositional approach to image augmentation for self-driving applications. It is an end-to-end neural network that is trained to seamlessly compose an object (e.g., a vehicle or <font color="#be00be">pedestrian</font>) represented as a cropped patch from an object image, into a background scene image. As our approach emphasizes more on semantic and structural coherence of the composed images, rather than their pixel-level RGB accuracies, we tailor the input and output of our network with structure-aware features and design our network losses accordingly. Specifically, our network takes the semantic layout features from the input scene image, features encoded from the edges and silhouette in the input object patch, as well as a latent code as inputs, and generates a 2D spatial affine transform defining the translation and scaling of the object patch. The learned parameters are further fed into a differentiable spatial <font color="#00be00">transformer</font> network to transform the object patch into the target image, where our model is trained adversarially using an affine transform discriminator and a layout discriminator. We evaluate our network, coined SAC-GAN for structure-aware composition, on prominent self-driving datasets in terms of quality, composability, and generalizability of the composite images. Comparisons are made to <font color="#00be00">state-of-the-art</font> alternatives, confirming superiority of our method. </br></br>

<a href='http://arxiv.org/pdf/2112.08359.pdf'>2112.08359</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0097баллов, №225</br>
<b>3D Question Answering</b></br>
Authors: , Ye, Shuquan, Chen, Dongdong, Han, Songfang, Liao, Jing</br>
  Visual Question Answering (VQA) has witnessed tremendous progress in recent years. However, most efforts only focus on the 2D image question answering tasks. In this paper, we present the first attempt at extending VQA to the 3D domain, which can facilitate artificial intelligence\'s perception of 3D <font color="#009600">real-world</font> scenarios. Different from image based VQA, 3D Question Answering (3DQA) takes the color <font color="#be00be">point cloud</font> as input and requires both appearance and 3D geometry comprehension ability to answer the 3D-related questions. To this end, we propose a novel <font color="#00be00">transformer</font>-based 3DQA framework \\textbf{``3DQA-TR&quot;}, which consists of two encoders for exploiting the appearance and geometry information, respectively. The multi-modal information of appearance, geometry, and the linguistic question can finally attend to each other via a 3D-Linguistic<font color="#00be00"> Bert </font>to predict the target answers. To verify the effectiveness of our proposed 3DQA framework, we further develop the first 3DQA dataset \\textbf{``ScanQA&quot;}, which builds on the ScanNet dataset and contains $\\sim$6K questions, $\\sim$30K answers for $806$ scenes. Extensive experiments on this dataset demonstrate the obvious superiority of our proposed 3DQA framework over existing VQA frameworks, and the effectiveness of our major designs. Our code and dataset will be made <font color="#00be00">publicly available</font> to facilitate the research in this direction. </br></br>

<a href='http://arxiv.org/pdf/2112.09127.pdf'>2112.09127</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 1.0071баллов, №226</br>
<b>ICON: Implicit Clothed humans Obtained from Normals</b></br>
Authors: , Xiu, Yuliang, Yang, Jinlong, Tzionas, Dimitrios, Black, Michael J.</br>
  Current methods for learning realistic and animatable 3D clothed avatars need either posed 3D scans or 2D images with carefully controlled user poses. In contrast, our goal is to learn the avatar from only 2D images of people in unconstrained poses. Given a set of images, our method estimates a detailed 3D surface from each image and then combines these into an animatable avatar. Implicit functions are well suited to the first task, as they can capture details like hair or clothes. Current methods, however, are not robust to varied human poses and often produce 3D surfaces with broken or disembodied limbs, missing details, or non-human shapes. The problem is that these methods use global feature encoders that are sensitive to global pose. To address this, we propose ICON (&quot;Implicit Clothed humans Obtained from Normals&quot;), which uses local features, instead. ICON has two main modules, both of which exploit the SMPL(-X) body model. First, ICON infers detailed clothed-human normals (front/back) conditioned on the SMPL(-X) normals. Second, a visibility-aware implicit surface regressor produces an iso-surface of a human occupancy field. Importantly, at inference time, a feedback loop alternates between refining the SMPL(-X) mesh using the inferred clothed normals and then refining the normals. Given multiple reconstructed frames of a subject in varied poses, we use SCANimate to produce an animatable avatar from them. Evaluation on the AGORA and CAPE datasets shows that ICON <font color="#00be00">outperform</font>s the <font color="#00be00">state of the art</font> in reconstruction, even with heavily limited training data. Additionally, it is much more robust to out-of-distribution samples, e.g., in-the-wild poses/images and out-of-frame cropping. ICON takes a step towards robust 3D clothed human reconstruction from in-the-wild images. This enables creating avatars directly from video with personalized and natural pose-dependent cloth deformation. </br></br>

<a href='http://arxiv.org/pdf/2112.06745.pdf'>2112.06745</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 1.0005баллов, №227</br>
<b>A Survey of Unsupervised Domain Adaptation for Visual Recognition</b></br>
Authors: , Zhang, Youshan</br>
  While huge volumes of unlabeled data are generated and made available in many domains, the demand for automated understanding of visual data is higher than ever before. Most existing machine learning models typically rely on massive amounts of labeled training data to achieve high performance. Unfortunately, such a requirement cannot be met in <font color="#009600">real-world</font> applications. The number of labels is limited and manually annotating data is expensive and time-consuming. It is often necessary to transfer knowledge from an existing labeled domain to a new domain. However, model performance degrades because of the differences between domains (domain shift or dataset bias). To overcome the burden of annotation, Domain Adaptation (DA) aims to mitigate the domain shift problem when transferring knowledge from one domain into another similar but different domain. Unsupervised DA (UDA) deals with a labeled source domain and an unlabeled target domain. The principal objective of UDA is to reduce the domain discrepancy between the labeled source data and unlabeled target data and to learn domain-invariant representations across the two domains during training. In this paper, we first define UDA problem. Secondly, we overview the <font color="#00be00">state-of-the-art</font> methods for different categories of UDA from both traditional methods and deep learning based methods. Finally, we collect frequently used benchmark datasets and report results of the state-of-the-art methods of UDA on visual recognition problem. </br></br>

<a href='http://arxiv.org/pdf/2112.08466.pdf'>2112.08466</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.9953баллов, №228</br>
<b>ErAConD : Error Annotated Conversational Dialog Dataset for Grammatical\n  Error Correction</b></br>
Authors: , Yuan, Xun, Pham, Derek, Davidson, Sam, Yu, Zhou</br>
  Currently available grammatical error correction (GEC) datasets are compiled using well-formed written text, limiting the applicability of these datasets to other domains such as informal writing and dialog. In this paper, we present a novel parallel GEC dataset drawn from open-domain chatbot conversations; this dataset is, to our knowledge, the first GEC dataset targeted to a conversational setting. To demonstrate the utility of the dataset, we use our annotated data to fine-tune a <font color="#00be00">state-of-the-art</font> GEC model, resulting in a 16 point increase in model precision. This is of particular importance in a GEC model, as model precision is considered more important than recall in GEC tasks since false positives could lead to serious confusion in language learners. We also present a detailed annotation scheme which ranks errors by perceived impact on comprehensibility, making our dataset both reproducible and extensible. Experimental results show the effectiveness of our data in improving GEC model performance in conversational scenario. </br></br>

<a href='http://arxiv.org/pdf/2112.06402.pdf'>2112.06402</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.9946баллов, №229</br>
<b>MotionBenchMaker: A Tool to Generate and Benchmark Motion Planning\n  Datasets</b></br>
Authors: , Chamzas, Constantinos, Quintero-Pe&#xf1;a, Carlos, Kingston, Zachary, Orthey, Andreas, Rakita, Daniel, Gleicher, Michael, Toussaint, Marc, Kavraki, Lydia E.</br>
  Recently, there has been a wealth of development in motion planning for robotic manipulation new motion planners are continuously proposed, each with their own unique strengths and weaknesses. However, evaluating new planners is challenging and researchers often create their own ad-hoc problems for benchmarking, which is time-consuming, prone to bias, and does not directly compare against other <font color="#00be00">state-of-the-art</font> planners. We present MotionBenchMaker, an open-source tool to generate benchmarking datasets for realistic robot manipulation problems. MotionBenchMaker is designed to be an extensible, easy-to-use tool that allows users to both generate datasets and benchmark them by comparing motion planning algorithms. Empirically, we show the benefit of using MotionBenchMaker as a tool to procedurally generate datasets which helps in the fair evaluation of planners. We also present a suite of 40 prefabricated datasets, with 5 different commonly used robots in 8 environments, to serve as a common ground to accelerate motion planning research. </br></br>

<a href='http://arxiv.org/pdf/2112.06132.pdf'>2112.06132</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV) &nbsp&nbsp 0.9943баллов, №230</br>
<b>PRNet: A Periodic Residual Learning Network for Crowd Flow Forecasting</b></br>
Authors: , Wang, Chengxin, Liang, Yuxuan, Tan, Gary</br>
  Crowd flow forecasting, e.g., predicting the crowds entering or leaving certain regions, is of great importance to <font color="#009600">real-world</font> urban applications. One of the key properties of crowd flow data is periodicity: a pattern that occurs at regular time intervals, such as a weekly pattern. To capture such periodicity, existing studies either explicitly model it based on the periodic hidden states or implicitly learn it by feeding all periodic segments into neural networks. In this paper, we devise a novel periodic residual learning network (PRNet) for better modeling the periodicity in crowd flow data. Differing from existing methods, PRNet frames the crowd flow forecasting as a periodic residual learning problem by modeling the deviation between the input (the previous time period) and the output (the future time period). As compared to predicting highly dynamic crowd flows directly, learning such stationary deviation is much easier, which thus facilitates the model training. Besides, the learned deviation enables the network to produce the residual between future conditions and its corresponding weekly observations at each time interval, and therefore contributes to substantially better predictions. We further propose a <font color="#be00be">lightweight</font> Spatial-Channel Enhanced Encoder to build more powerful region representations, by jointly capturing global spatial correlations and temporal dependencies. Experimental results on two real-world datasets demonstrate that PRNet <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> methods in terms of both accuracy and robustness. </br></br>

<a href='http://arxiv.org/pdf/2112.08634.pdf'>2112.08634</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.9928баллов, №231</br>
<b>FRUIT: Faithfully Reflecting Updated Information in Text</b></br>
Authors: , Logan IV, Robert L., Passos, Alexandre, Singh, Sameer, Chang, Ming-Wei</br>
  Textual knowledge bases such as Wikipedia require considerable effort to keep up to date and consistent. While automated writing assistants could potentially ease this burden, the problem of suggesting edits grounded in external knowledge has been under-explored. In this paper, we introduce the novel generation task of *faithfully reflecting updated information in text*(FRUIT) where the goal is to update an existing article given new evidence. We release the FRUIT-WIKI dataset, a collection of over 170K distantly supervised data produced from pairs of Wikipedia snapshots, along with our data generation pipeline and a gold evaluation set of 914 instances whose edits are guaranteed to be supported by the evidence. We provide benchmark results for popular generation systems as well as EDIT5 -- a T5-based approach tailored to editing we introduce that establishes the <font color="#00be00">state of the art</font>. Our analysis shows that developing models that can update articles faithfully requires new capabilities for neural generation models, and opens doors to many new applications. </br></br>

<a href='http://arxiv.org/pdf/2112.07723.pdf'>2112.07723</a> &nbsp&nbsp (cs:RO, cs:CV) &nbsp&nbsp 0.9922баллов, №232</br>
<b>Autonomous Navigation System from Simultaneous Localization and Mapping</b></br>
Authors: , Caracciolo, Micheal, Casciotti, Owen, Lloyd, Christopher, Sola-Thomas, Ernesto, Weaver, Matthew, Bielby, Kyle, Sarker, Md Abdul Baset, Imtiaz, Masudul H.</br>
  This paper presents the development of a Simultaneous Localization and Mapping (SLAM) based Autonomous Navigation system. The motivation for this study was to find a solution for navigating interior spaces autonomously. Interior navigation is challenging as it can be forever evolving. Solving this issue is necessary for multitude of services, like cleaning, the health industry, and in manufacturing industries. The focus of this paper is the description of the SLAM-based software architecture developed for this proposed autonomous system. A potential application of this system, oriented to a smart wheelchair, was evaluated. Current interior navigation solutions require some sort of guiding line, like a black line on the floor. With this proposed solution, interiors do not require renovation to accommodate this solution. The <font color="#00be00">source code</font> of this application has been made open source so that it could be re-purposed for a similar application. Also, this open-source project is envisioned to be improved by the broad open-source community upon past its current state. </br></br>

<a href='http://arxiv.org/pdf/2111.12503.pdf'>2111.12503</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.9916баллов, №233</br>
<b>Extracting Triangular 3D Models, Materials, and Lighting From Images</b></br>
Authors: , Munkberg, Jacob, Hasselgren, Jon, Shen, Tianchang, Gao, Jun, Chen, Wenzheng, Evans, Alex, M&#xfc;ller, Thomas, Fidler, Sanja</br>
  We present an efficient method for joint optimization of topology, materials and lighting from multi-view image observations. Unlike recent multi-view reconstruction approaches, which typically produce entangled 3D representations encoded in neural networks, we output triangle meshes with spatially-varying materials and environment lighting that can be deployed in any traditional graphics engine unmodified. We leverage recent work in differentiable rendering, coordinate-based networks to compactly represent volumetric texturing, alongside differentiable marching tetrahedrons to enable gradient-based optimization directly on the surface mesh. Finally, we introduce a differentiable formulation of the split sum approximation of environment lighting to efficiently recover all-frequency lighting. Experiments show our extracted models used in advanced scene editing, material decomposition, and high quality view interpolation, all running at interactive rates in triangle-based renderers (rasterizers and path tracers). Project website: <font color="#006400">http</font>s://nvlabs.<font color="#00be00">github</font>.io/nvdiffrec/ . </br></br>

<a href='http://arxiv.org/pdf/2112.05505.pdf'>2112.05505</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.9892баллов, №234</br>
<b>DeepRLS: A Recurrent Network Architecture with Least Squares Implicit\n  Layers for Non-blind Image Deconvolution</b></br>
Authors: , Koshelev, Iaroslav, Selikhanovych, Daniil, Lefkimmiatis, Stamatios</br>
  In this work, we study the problem of non-blind image deconvolution and propose a novel recurrent network architecture that leads to very <font color="#960096">competitive</font> restoration results of high image quality. Motivated by the computational efficiency and robustness of existing large scale linear solvers, we manage to express the solution to this problem as the solution of a series of adaptive non-negative least-squares problems. This gives rise to our proposed Recurrent Least Squares Deconvolution Network (RLSDN) architecture, which consists of an implicit layer that imposes a linear constraint between its input and output. By design, our network manages to serve two important purposes simultaneously. The first is that it implicitly models an effective image prior that can adequately characterize the set of natural images, while the second is that it recovers the corresponding maximum a posteriori (MAP) estimate. Experiments on <font color="#00be00">publicly available</font> datasets, comparing recent <font color="#00be00">state-of-the-art</font> methods, show that our proposed RLSDN approach achieves the best reported performance both for grayscale and color images for all tested scenarios. Furthermore, we introduce a novel training strategy that can be adopted by any network architecture that involves the solution of linear systems as part of its pipeline. Our strategy eliminates completely the need to unroll the iterations required by the linear solver and, thus, it reduces significantly the memory footprint during training. Consequently, this enables the training of deeper network architectures which can further improve the reconstruction results. </br></br>

<a href='http://arxiv.org/pdf/2112.07513.pdf'>2112.07513</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.9871баллов, №235</br>
<b>CORE-Text: Improving Scene Text Detection with Contrastive Relational\n  Reasoning</b></br>
Authors: , Lin, Jingyang, Pan, Yingwei, Lai, Rongfeng, Yang, Xuehang, Chao, Hongyang, Yao, Ting</br>
  Localizing text instances in natural scenes is regarded as a fundamental challenge in computer vision. Nevertheless, owing to the extremely varied aspect ratios and scales of text instances in real scenes, most conventional text detectors suffer from the sub-text problem that only localizes the fragments of text instance (i.e., sub-texts). In this work, we quantitatively analyze the sub-text problem and present a simple yet effective design, COntrastive RElation (CORE) module, to mitigate that issue. CORE first leverages a vanilla relation block to model the relations among all text proposals (sub-texts of multiple text instances) and further enhances relational reasoning via instance-level sub-text discrimination in a contrastive manner. Such way naturally learns instance-aware representations of text proposals and thus facilitates scene text detection. We integrate the CORE module into a two-stage text detector of Mask R-CNN and devise our text detector CORE-Text. Extensive experiments on four benchmarks demonstrate the superiority of CORE-Text. Code is available: \\url{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/jylins/CORE-Text}. </br></br>

<a href='http://arxiv.org/pdf/2111.07492.pdf'>2111.07492</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.9860баллов, №236</br>
<b>Finding Optimal Tangent Points for Reducing Distortions of Hard-label\n  Attacks</b></br>
Authors: , Ma, Chen, Guo, Xiangyu, Chen, Li, Yong, Jun-Hai, Wang, Yisen</br>
  One major problem in black-box <font color="#be00be">adversarial att</font>acks is the high query complexity in the hard-label attack setting, where only the top-1 predicted label is available. In this paper, we propose a novel geometric-based approach called Tangent Attack (TA), which identifies an optimal tangent point of a virtual hemisphere located on the decision boundary to reduce the distortion of the attack. Assuming the decision boundary is locally flat, we <font color="#be00be">theor</font>etically prove that the minimum $\\ell_2$ distortion can be obtained by reaching the decision boundary along the tangent line passing through such tangent point in each iteration. To improve the robustness of our method, we further propose a generalized method which replaces the hemisphere with a semi-ellipsoid to adapt to curved decision boundaries. Our approach is free of hyperparameters and pre-training. Extensive experiments conducted on the ImageNet and CIFAR-10 datasets demonstrate that our approach can consume only a small number of queries to achieve the low-magnitude distortion. The implementation <font color="#00be00">source code</font> is released online at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/machanic/TangentAttack. </br></br>

<a href='http://arxiv.org/pdf/2112.07194.pdf'>2112.07194</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.9826баллов, №237</br>
<b>MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue\n  Evaluation</b></br>
Authors: , Zhang, Chen, D\'Haro, Luis Fernando, Friedrichs, Thomas, Li, Haizhou</br>
  Chatbots are designed to carry out human-like conversations across different domains, such as general chit-chat, knowledge exchange, and persona-grounded conversations. To measure the quality of such conversational agents, a dialogue evaluator is expected to conduct assessment across domains as well. However, most of the <font color="#00be00">state-of-the-art</font> automatic dialogue evaluation metrics (ADMs) are not designed for multi-domain evaluation. We are motivated to design a general and robust framework, MDD-Eval, to address the problem. Specifically, we first train a teacher evaluator with human-annotated data to acquire a rating skill to tell good dialogue responses from bad ones in a particular domain and then, adopt a self-training strategy to train a new evaluator with teacher-annotated multi-domain data, that helps the new evaluator to generalize across multiple domains. MDD-Eval is extensively assessed on six dialogue evaluation benchmarks. Empirical results show that the MDD-Eval framework achieves a strong performance with an absolute improvement of 7% over the state-of-the-art ADMs in terms of mean Spearman correlation scores across all the evaluation benchmarks. </br></br>

<a href='http://arxiv.org/pdf/2112.07948.pdf'>2112.07948</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.9825баллов, №238</br>
<b>Transcoded Video Restoration by Temporal Spatial Auxiliary Network</b></br>
Authors: , Xu, Li, He, Gang, Zhou, Jinjia, Lei, Jie, Xie, Weiying, Li, Yunsong, Tai, Yu-Wing</br>
  In most video platforms, such as Youtube, and TikTok, the played videos usually have undergone multiple video encodings such as hardware encoding by recording devices, software encoding by video editing apps, and single/multiple video transcoding by video application servers. Previous works in compressed video restoration typically assume the compression artifacts are caused by one-time encoding. Thus, the derived solution usually does not work very well in practice. In this paper, we propose a new method, temporal spatial auxiliary network (TSAN), for transcoded video restoration. Our method considers the unique traits between video encoding and transcoding, and we consider the initial shallow encoded videos as the intermediate labels to assist the network to conduct self-supervised attention training. In addition, we employ adjacent multi-frame information and propose the temporal deformable alignment and pyramidal spatial fusion for transcoded video restoration. The experimental results demonstrate that the performance of the proposed method is superior to that of the previous techniques. The code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/icecherylXuli/TSAN. </br></br>

<a href='http://arxiv.org/pdf/2112.08709.pdf'>2112.08709</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.9803баллов, №239</br>
<b>DOCmT5: Document-Level Pretraining of Multilingual Language Models</b></br>
Authors: , Lee, Chia-Hsuan, Siddhant, Aditya, Ratnakar, Viresh, Johnson, Melvin</br>
  In this paper, we introduce DOCmT5, a multilingual sequence-to-sequence language model pre-trained with large scale parallel documents. While previous approaches have focused on leveraging sentence-level parallel data, we try to build a general-purpose pre-trained model that can understand and generate long documents. We propose a simple and effective pre-training objective - Document Reordering Machine Translation (DrMT), in which the input documents that are shuffled and masked need to be translated. DrMT brings consistent improvements over strong baselines on a variety of document-level generation tasks, including over 12 BLEU points for seen-language-pair document-level MT, over 7 BLEU points for unseen-language-pair document-level MT and over 3 ROUGE-1 points for seen-language-pair cross-lingual <font color="#be00be">summarization</font>. We achieve <font color="#00be00">state-of-the-art</font> (SOTA) on WMT20 De-En and IWSLT15 Zh-En document translation tasks. We also conduct extensive analysis on various factors for document pre-training, including (1) the effects of pre-training data quality and (2) The effects of combining mono-lingual and cross-lingual pre-training. We plan to make our model checkpoints <font color="#00be00">publicly available</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.06074.pdf'>2112.06074</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.9663баллов, №240</br>
<b>Early Stopping for Deep Image Prior</b></br>
Authors: , Wang, Hengkang, Li, Taihui, Zhuang, Zhong, Chen, Tiancong, Liang, Hengyue, Sun, Ju</br>
  Deep image prior (DIP) and its variants have showed remarkable potential for solving inverse problems in computer vision, without any extra training data. Practical DIP models are often substantially overparameterized. During the fitting process, these models learn mostly the desired visual content first, and then pick up the potential modeling and observational noise, i.e., overfitting. Thus, the practicality of DIP often depends critically on good early stopping (ES) that captures the transition period. In this regard, the majority of DIP works for vision tasks only demonstrates the potential of the models -- reporting the peak performance against the ground truth, but provides no clue about how to operationally obtain near-peak performance without access to the groundtruth. In this paper, we set to break this practicality barrier of DIP, and propose an efficient ES strategy, which consistently detects near-peak performance across several vision tasks and DIP variants. Based on a simple measure of dispersion of consecutive DIP reconstructions, our ES method not only outpaces the existing ones -- which only work in very narrow domains, but also remains effective when combined with a number of methods that try to mitigate the overfitting. The code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/sun-umn/Early_Stopping_for_DIP. </br></br>

<a href='http://arxiv.org/pdf/2112.08913.pdf'>2112.08913</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.9661баллов, №241</br>
<b>Contrastive Spatio-Temporal Pretext Learning for Self-supervised Video\n  Representation</b></br>
Authors: , Zhang, Yujia, Po, Lai-Man, Xu, Xuyuan, Liu, Mengyang, Wang, Yexin, Ou, Weifeng, Zhao, Yuzhi, Yu, Wing-Yin</br>
  Spatio-temporal representation learning is critical for video self-supervised representation. Recent approaches mainly use contrastive learning and pretext tasks. However, these approaches learn representation by discriminating sampled instances via feature similarity in the latent space while ignoring the intermediate state of the learned representations, which limits the overall performance. In this work, taking into account the degree of similarity of sampled instances as the intermediate state, we propose a novel pretext task - spatio-temporal overlap rate (STOR) prediction. It stems from the observation that humans are capable of discriminating the overlap rates of videos in space and time. This task encourages the model to discriminate the STOR of two generated samples to learn the representations. Moreover, we employ a joint optimization combining pretext tasks with contrastive learning to further enhance the spatio-temporal representation learning. We also study the mutual influence of each component in the proposed scheme. Extensive experiments demonstrate that our proposed STOR task can favor both contrastive learning and pretext tasks. The joint optimization scheme can significantly improve the spatio-temporal representation in video understanding. The code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/Katou2/CSTP. </br></br>

<a href='http://arxiv.org/pdf/2112.02807.pdf'>2112.02807</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.9630баллов, №242</br>
<b>MDPFuzzer: Finding Crash-Triggering State Sequences in Models Solving\n  the Markov Decision Process</b></br>
Authors: , Pang, Qi, Yuan, Yuanyuan, Wang, Shuai</br>
  The Markov decision process (MDP) provides a mathematical framework for modeling sequential decision-making problems, many of which are crucial to security and safety, such as autonomous driving and robot control. The rapid development of artificial intelligence research has created efficient methods for solving MDPs, such as deep neural networks (DNNs), <font color="#00be00">reinforcement learning</font> (RL), and imitation learning (IL). However, these popular models for solving MDPs are neither thoroughly tested nor rigorously reliable.   We present MDPFuzzer, the first blackbox fuzz testing framework for models solving MDPs. MDPFuzzer forms testing oracles by checking whether the target model enters abnormal and dangerous states. During fuzzing, MDPFuzzer decides which mutated state to retain by measuring if it can reduce cumulative rewards or form a new state sequence. We design efficient techniques to quantify the &quot;freshness&quot; of a state sequence using <font color="#be00be">Gaussi</font>an mixture models (GMMs) and dynamic expectation-maximization (DynEM). We also prioritize states with high potential of revealing crashes by estimating the local sensitivity of target models over states.   MDPFuzzer is evaluated on five <font color="#00be00">state-of-the-art</font> models for solving MDPs, including supervised DNN, RL, IL, and multi-agent RL. Our evaluation includes scenarios of autonomous driving, aircraft collision avoidance, and two games that are often used to benchmark RL. During a 12-hour run, we find over 80 crash-triggering state sequences on each model. We show inspiring findings that crash-triggering states, though look normal, induce distinct neuron activation patterns compared with normal states. We further develop an abnormal behavior detector to harden all the evaluated models and repair them with the findings of MDPFuzzer to significantly enhance their robustness without sacrificing accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.07583.pdf'>2112.07583</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.9606баллов, №243</br>
<b>Reinforcing Semantic-Symmetry for Document <font color="#be00be">Summarization</font></b></br>
Authors: , Song, Mingyang, Jing, Liping</br>
  Document <font color="#be00be">summarization</font> condenses a long document into a short version with salient information and accurate semantic descriptions. The main issue is how to make the output summary semantically consistent with the input document. To reach this goal, recently, researchers have focused on supervised end-to-end hybrid approaches, which contain an extractor module and abstractor module. Among them, the extractor identifies the salient sentences from the input document, and the abstractor generates a summary from the salient sentences. This model successfully keeps the consistency between the generated summary and the reference summary via various strategies (e.g., <font color="#00be00">reinforcement learning</font>). There are two semantic gaps when training the hybrid model (one is between document and extracted sentences, and the other is between extracted sentences and summary). However, they are not explicitly considered in the existing methods, which usually results in a semantic bias of summary. To mitigate the above issue, in this paper, a new \\textbf{r}einforcing s\\textbf{e}mantic-\\textbf{sy}mmetry learning \\textbf{m}odel is proposed for document summarization (\\textbf{ReSyM}). ReSyM introduces a semantic-consistency reward in the extractor to bridge the first gap. A semantic dual-reward is designed to bridge the second gap in the abstractor. The whole document summarization process is implemented via reinforcement learning with a hybrid reward mechanism (combining the above two rewards). Moreover, a comprehensive sentence representation learning method is presented to sufficiently capture the information from the original document. A series of experiments have been conducted on two wildly used benchmark datasets CNN/Daily Mail and BigPatent. The results have shown the superiority of ReSyM by comparing it with the <font color="#00be00">state-of-the-art</font> baselines in terms of various evaluation metrics. </br></br>

<a href='http://arxiv.org/pdf/2112.07463.pdf'>2112.07463</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp 0.9526баллов, №244</br>
<b>End-to-end speaker diarization with <font color="#00be00">transformer</font></b></br>
Authors: , Lai, Yongquan, Tang, Xin, Fu, Yuanyuan, Fang, Rui</br>
  Speaker diarization is connected to semantic <font color="#be00be">segmentation</font> in computer vision. Inspired from MaskFormer \\cite{cheng2021per} which treats semantic segmentation as a set-prediction problem, we propose an end-to-end approach to predict a set of targets consisting of binary masks, vocal activities and speaker vectors. Our model, which we coin \\textit{DiFormer}, is mainly based on a speaker encoder and a feature pyramid network (FPN) module to extract multi-scale speaker features which are then fed into a <font color="#00be00">transformer</font> encoder-decoder to predict a set of diarization targets from learned query embedding. To account for temporal characteristics of speech signal, bidirectional LSTMs are inserted into the mask prediction module to improve temporal consistency. Our model handles unknown number of speakers, speech overlaps, as well as vocal activity detection in a unified way. Experiments on multimedia and meeting datasets demonstrate the effectiveness of our approach. </br></br>

<a href='http://arxiv.org/pdf/2112.05172.pdf'>2112.05172</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.9469баллов, №245</br>
<b>Projecting Robot Navigation Paths: Hardware and Software for Projected\n  AR</b></br>
Authors: , Han, Zhao, Parrillo, Jenna, Wilkinson, Alexander, Yanco, Holly A., Williams, Tom</br>
  For<font color="#960096"> mobile </font>robots, mobile manipulators, and autonomous vehicles to safely navigate around populous places such as streets and warehouses, human observers must be able to understand their navigation intent. One way to enable such understanding is by visualizing this intent through projections onto the surrounding environment. But despite the demonstrated effectiveness of such projections, no open codebase with an integrated hardware setup exists. In this work, we detail the empirical evidence for the effectiveness of such directional projections, and share a robot-agnostic implementation of such projections, coded in C++ using the widely-used Robot Operating System (ROS) and rviz. Additionally, we demonstrate a hardware configuration for deploying this software, using a Fetch robot, and briefly summarize a full-scale user study that motivates this configuration. The code, configuration files (roslaunch and rviz files), and documentation are freely available on <font color="#00be00">GitHub</font> at <font color="#006400">http</font>s://github.com/umhan35/arrow_projection. </br></br>

<a href='http://arxiv.org/pdf/2112.05761.pdf'>2112.05761</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.9420баллов, №246</br>
<b>Pre-training and Fine-tuning <font color="#00be00">Transformer</font>s for <font color="#be00be">fMRI</font> Prediction Tasks</b></br>
Authors: , Malkiel, Itzik, Rosenman, Gony, Wolf, Lior, Hendler, Talma</br>
  We present the TFF <font color="#00be00">Transformer</font> framework for the analysis of functional <font color="#be00be">Magnetic Resonance</font> Imaging (<font color="#be00be">fMRI</font>) data. TFF employs a transformer-based architecture and a two-phase training approach. First, self-supervised training is applied to a collection of fMRI scans, where the model is trained for the reconstruction of 3D volume data. Second, the pre-trained model is fine-tuned on specific tasks, utilizing ground truth labels. Our results show <font color="#00be00">state-of-the-art</font> performance on a variety of fMRI tasks, including age and gender prediction, as well as schizophrenia recognition. </br></br>

<a href='http://arxiv.org/pdf/2112.06743.pdf'>2112.06743</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.9407баллов, №247</br>
<b>Attentive Contextual Carryover for Multi-Turn End-to-End Spoken Language\n  Understanding</b></br>
Authors: , Wei, Kai, Tran, Thanh, Chang, Feng-Ju, Sathyendra, Kanthashree Mysore, Muniyappa, Thejaswi, Liu, Jing, Raju, Anirudh, McGowan, Ross, Susanj, Nathan, Rastrow, Ariya, Strimel, Grant P.</br>
  Recent years have seen significant advances in end-to-end (E2E) spoken language understanding (SLU) systems, which directly predict intents and slots from spoken audio. While dialogue history has been exploited to improve conventional text-based natural language understanding systems, current E2E SLU approaches have not yet incorporated such critical contextual signals in multi-turn and task-oriented dialogues. In this work, we propose a contextual E2E SLU model architecture that uses a multi-head attention mechanism over encoded previous utterances and dialogue acts (actions taken by the voice assistant) of a multi-turn dialogue. We detail alternative methods to integrate these contexts into the state-ofthe-art recurrent and <font color="#00be00">transformer</font>-based models. When applied to a large de-identified dataset of utterances collected by a voice assistant, our method reduces average word and semantic error rates by 10.8% and 12.6%, respectively. We also present results on a <font color="#00be00">publicly available</font> dataset and show that our method significantly improves performance over a noncontextual baseline </br></br>

<a href='http://arxiv.org/pdf/2112.07574.pdf'>2112.07574</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.9391баллов, №248</br>
<b>M3E2: Multi-gate Mixture-of-experts for Multi-treatment Effect\n  Estimation</b></br>
Authors: , Aoki, Raquel, Chen, Yizhou, Ester, Martin</br>
  This work proposes the M3E2, a multi-task learning neural network model to estimate the effect of multiple treatments. In contrast to existing methods, M3E2 is robust to multiple treatment effects applied simultaneously to the same unit, continuous and binary treatments, and many covariates. We compared M3E2 with three baselines in three synthetic benchmark datasets: two with multiple treatments and one with one treatment. Our analysis showed that our method has superior performance, making more assertive estimations of the true treatment effects. The code is available at <font color="#00be00">github</font>.com/raquelaoki/M3E2. </br></br>

<a href='http://arxiv.org/pdf/2111.09296.pdf'>2111.09296</a> &nbsp&nbsp (cs:CL, cs:SD) &nbsp&nbsp 0.9347баллов, №249</br>
<b>XLS-R: Self-supervised Cross-lingual Speech Representation Learning at\n  Scale</b></br>
Authors: , Babu, Arun, Wang, Changhan, Tjandra, Andros, Lakhotia, Kushal, Xu, Qiantong, Goyal, Naman, Singh, Kritika, von Platen, Patrick, Saraf, Yatharth, Pino, Juan, Baevski, Alexei, Conneau, Alexis, Auli, Michael</br>
  This paper presents XLS-R, a large-scale model for cross-lingual speech representation learning based on wav2vec 2.0. We train models with up to 2B parameters on nearly half a million hours of <font color="#00be00">publicly available</font> speech audio in 128 languages, an order of magnitude more public data than the largest known prior work. Our evaluation covers a wide range of tasks, domains, data regimes and languages, both high and <font color="#be00be">low-resource</font>. On the CoVoST-2 speech translation benchmark, we improve the previous <font color="#00be00">state of the art</font> by an average of 7.4 BLEU over 21 translation directions into English. For <font color="#be00be">speech recognition</font>, XLS-R improves over the best known prior work on BABEL, MLS, CommonVoice as well as VoxPopuli, lowering error rates by 14-34% relative on average. XLS-R also sets a new state of the art on VoxLingua107 language identification. Moreover, we show that with sufficient model size, cross-lingual pretraining can <font color="#00be00">outperform</font> English-only pretraining when translating English speech into other languages, a setting which favors monolingual pretraining. We hope XLS-R can help to improve speech processing tasks for many more languages of the world. </br></br>

<a href='http://arxiv.org/pdf/2112.07068.pdf'>2112.07068</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp 0.9343баллов, №250</br>
<b>Score-Based Generative Modeling with Critically-Damped Langevin\n  Diffusion</b></br>
Authors: , Dockhorn, Tim, Vahdat, Arash, Kreis, Karsten</br>
  Score-based generative models (SGMs) have demonstrated remarkable synthesis quality. SGMs rely on a diffusion process that gradually perturbs the data towards a tractable distribution, while the generative model learns to denoise. The complexity of this denoising task is, apart from the data distribution itself, uniquely determined by the diffusion process. We argue that current SGMs employ overly simplistic diffusions, leading to unnecessarily complex denoising processes, which limit generative modeling performance. Based on connections to statistical mechanics, we propose a novel critically-damped Langevin diffusion (CLD) and show that CLD-based SGMs achieve superior performance. CLD can be <font color="#be00be">interpret</font>ed as running a joint diffusion in an extended space, where the auxiliary variables can be considered &quot;velocities&quot; that are coupled to the data variables as in Hamiltonian dynamics. We derive a novel score matching objective for CLD and show that the model only needs to learn the score function of the conditional distribution of the velocity given data, an easier task than learning scores of the data directly. We also derive a new sampling scheme for efficient synthesis from CLD-based diffusion models. We find that CLD <font color="#00be00">outperform</font>s previous SGMs in synthesis quality for similar network architectures and sampling compute budgets. We show that our novel sampler for CLD significantly outperforms solvers such as Euler--Maruyama. Our framework provides new insights into score-based denoising diffusion models and can be readily used for high-resolution image synthesis. Project page and code: <font color="#006400">http</font>s://nv-tlabs.<font color="#00be00">github</font>.io/CLD-SGM. </br></br>

<a href='http://arxiv.org/pdf/2112.08682.pdf'>2112.08682</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 0.9343баллов, №251</br>
<b>IsometricMT: Neural Machine Translation for Automatic Dubbing</b></br>
Authors: , Lakew, Surafel M., Virkar, Yogesh, Mathur, Prashant, Federico, Marcello</br>
  Automatic dubbing (AD) is among the use cases where translations should fit a given length template in order to achieve synchronicity between source and target speech. For neural machine translation (MT), generating translations of length close to the source length (e.g. within +-10% in character count), while preserving quality is a challenging task. Controlling NMT output length comes at a cost to translation quality which is usually mitigated with a two step approach of generation of n-best hypotheses and then re-ranking them based on length and quality. This work, introduces a self-learning approach that allows a <font color="#00be00">transformer</font> model to directly learn to generate outputs that closely match the source length, in short isometric MT. In particular, our approach for isometric MT does not require to generate multiple hypotheses nor any auxiliary scoring function. We report results on four language pairs (English - French, Italian, German, Spanish) with a <font color="#00be00">publicly available</font> benchmark based on TED Talk data. Both automatic and manual evaluations show that our self-learning approach to performs on par with more complex isometric MT approaches. </br></br>

<a href='http://arxiv.org/pdf/2111.14592.pdf'>2111.14592</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.9339баллов, №252</br>
<b>GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with\n  Semi-Supervised Learning and Explicit Policy Injection</b></br>
Authors: , He, Wanwei, Dai, Yinpei, Zheng, Yinhe, Wu, Yuchuan, Cao, Zheng, Liu, Dermot, Jiang, Peng, Yang, Min, Huang, Fei, Si, Luo, Sun, Jian, Li, Yongbin</br>
  Pre-trained models have proved to be powerful in enhancing task-oriented dialog systems. However, current pre-training methods mainly focus on enhancing dialog understanding and generation tasks while neglecting the exploitation of dialog policy. In this paper, we propose GALAXY, a novel pre-trained dialog model that explicitly learns dialog policy from limited labeled dialogs and large-scale unlabeled dialog corpora via semi-supervised learning. Specifically, we introduce a dialog act prediction task for policy optimization during pre-training and employ a consistency regularization term to refine the learned representation with the help of unlabeled dialogs. We also implement a gating mechanism to weigh suitable unlabeled dialog samples. Empirical results show that GALAXY substantially improves the performance of task-oriented dialog systems, and achieves new <font color="#00be00">state-of-the-art</font> results on benchmark datasets: In-Car, MultiWOZ2.0 and MultiWOZ2.1, improving their end-to-end combined scores by 2.5, 5.3 and 5.5 points, respectively. We also show that GALAXY has a stronger <font color="#00be00">few-shot</font> ability than existing models under various <font color="#be00be">low-resource</font> settings. </br></br>

<a href='http://arxiv.org/pdf/2111.14831.pdf'>2111.14831</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.9336баллов, №253</br>
<b>Multi-domain Integrative Swin <font color="#00be00">Transformer</font> network for Sparse-View\n  Tomographic Reconstruction</b></br>
Authors: , Pan, Jiayi, Wu, Weiwen, Gao, Zhifan, Zhang, Heye</br>
  The deep learning-based tomographic image reconstruction methods have been attracting much attention among these years. The sparse-view data reconstruction is one of typical underdetermined inverse problems, how to reconstruct high-quality CT images from dozens of projections is still a challenge in practice. To address this challenge, in this article we proposed a Multi-domain Integrative Swin <font color="#00be00">Transformer</font> network (MIST-net). First, the proposed MIST-net incorporated lavish domain features from data, residual-data, image, and residual-image using flexible network architectures. Here, the residual-data and residual-image domains network components can be considered as data consistency module to eliminate interpolation errors in both residual data and image domains, and then further retain image details. Second, to detect image features and further protect image edge, the trainable edge enhancement filter was incorporated into sub-network to improve encode-decode ability. Third, with classical Swin Transformer, we further designed a high-quality reconstruction transformer (i.e., Recformer) to improve reconstruction performance. Recformer inherited the power of Swin transformer to capture global and local features of reconstructed image. The experiments on numerical datasets with 48 views demonstrated our proposed MIST-net provided higher reconstructed image quality with small feature recovery and edge protection than other competitors including advanced unrolled networks. The trained network was transferred to real cardiac CT dataset to further validate the advantages as well as good robustness of our MIST-net in <font color="#be00be">clinic</font>al applications. </br></br>

<a href='http://arxiv.org/pdf/2112.08583.pdf'>2112.08583</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.9297баллов, №254</br>
<b>Does Pre-training Induce Systematic Inference? How Masked Language\n  Models Acquire Commonsense Knowledge</b></br>
Authors: , Porada, Ian, Sordoni, Alessandro, Cheung, Jackie Chi Kit</br>
  <font color="#00be00">Transformer</font> models pre-trained with a masked-language-modeling objective (e.g., BERT) encode commonsense knowledge as evidenced by behavioral probes; however, the extent to which this knowledge is acquired by systematic inference over the semantics of the pre-training corpora is an open question. To answer this question, we selectively inject verbalized knowledge into the minibatches of a<font color="#00be00"> BERT </font>model during pre-training and evaluate how well the model generalizes to supported inferences. We find generalization does not improve over the course of pre-training, suggesting that commonsense knowledge is acquired from surface-level, co-occurrence patterns rather than induced, systematic reasoning. </br></br>

<a href='http://arxiv.org/pdf/2112.06997.pdf'>2112.06997</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.9281баллов, №255</br>
<b>ELF: Exact-Lipschitz Based Universal Density Approximator Flow</b></br>
Authors: , Gopal, Achintya</br>
  Normalizing flows have grown more popular over the last few years; however, they continue to be computationally expensive, making them difficult to be accepted into the broader machine learning community. In this paper, we introduce a simple one-dimensional one-layer network that has closed form Lipschitz constants; using this, we introduce a new Exact-Lipschitz Flow (ELF) that combines the ease of sampling from residual flows with the strong performance of autoregressive flows. Further, we show that ELF is provably a universal density approximator, more computationally and parameter efficient compared to a multitude of other flows, and achieves <font color="#00be00">state-of-the-art</font> performance on multiple large-scale datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.05218.pdf'>2112.05218</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.9279баллов, №256</br>
<b>Learning Generalizable Behavior via Visual Rewrite Rules</b></br>
Authors: , Xie, Yiheng, Li, Mingxuan, Yu, Shangqun, Littman, Michael</br>
  Though deep <font color="#00be00">reinforcement learning</font> agents have achieved unprecedented success in recent years, their learned policies can be brittle, failing to generalize to even slight modifications of their environments or unfamiliar situations. The black-box nature of the neural network learning dynamics makes it impossible to audit trained deep agents and recover from such failures. In this paper, we propose a novel representation and learning approach to capture environment dynamics without using neural networks. It originates from the observation that, in games designed for people, the effect of an action can often be perceived in the form of local changes in consecutive visual observations. Our algorithm is designed to extract such vision-based changes and condense them into a set of action-dependent descriptive rules, which we call \'\'visual rewrite rules\'\' (VRRs). We also present preliminary results from a VRR agent that can explore, expand its rule set, and solve a game via planning with its learned VRR world model. In several classical games, our non-deep agent demonstrates superior performance, extreme <font color="#00be00">sample efficien</font>cy, and robust generalization ability compared with several mainstream deep agents. </br></br>

<a href='http://arxiv.org/pdf/2112.01873.pdf'>2112.01873</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.9192баллов, №257</br>
<b>Image-to-image Translation as a Unique Source of Knowledge</b></br>
Authors: , Mousist, Alejandro D.</br>
  Image-to-image (I2I) translation is an established way of translating data from one domain to another but the usability of the translated images in the target domain when working with such dissimilar domains as the SAR/optical satellite imagery ones and how much of the origin domain is translated to the target domain is still not clear enough. This article address this by performing translations of labelled datasets from the optical domain to the SAR domain with different I2I algorithms from the <font color="#00be00">state-of-the-art</font>, learning from transferred features in the destination domain and evaluating later how much from the original dataset was transferred. Added to this, stacking is proposed as a way of combining the knowledge learned from the different I2I translations and evaluated against single models. </br></br>

<a href='http://arxiv.org/pdf/2112.05341.pdf'>2112.05341</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.9166баллов, №258</br>
<b>Hyperdimensional Feature Fusion for Out-Of-Distribution Detection</b></br>
Authors: , Wilson, Samuel, S&#xfc;nderhauf, Niko, Dayoub, Feras</br>
  We introduce powerful ideas from Hyperdimensional Computing into the challenging field of Out-of-Distribution (OOD) detection. In contrast to most existing work that performs OOD detection based on only a single layer of a neural network, we use similarity-preserving semi-orthogonal projection matrices to project the feature maps from multiple layers into a common vector space. By repeatedly applying the bundling operation $\\oplus$, we create expressive class-specific descriptor vectors for all in-distribution classes. At test time, a simple and efficient cosine similarity calculation between descriptor vectors consistently identifies OOD samples with better performance than the current <font color="#00be00">state-of-the-art</font>. We show that the hyperdimensional fusion of multiple network layers is critical to achieve best general performance. </br></br>

<a href='http://arxiv.org/pdf/2112.07668.pdf'>2112.07668</a> &nbsp&nbsp (cs:CV, cs:CL) &nbsp&nbsp 0.9152баллов, №259</br>
<b>Dual-Key Multimodal Backdoors for Visual Question Answering</b></br>
Authors: , Walmer, Matthew, Sikka, Karan, Sur, Indranil, Shrivastava, Abhinav, Jha, Susmit</br>
  The success of deep learning has enabled advances in multimodal tasks that require non-trivial fusion of multiple input domains. Although multimodal models have shown potential in many problems, their increased complexity makes them more vulnerable to attacks. A Backdoor (or Trojan) attack is a class of security vulnerability wherein an attacker embeds a malicious secret behavior into a network (e.g. targeted misclassification) that is activated when an attacker-specified trigger is added to an input. In this work, we show that multimodal networks are vulnerable to a novel type of attack that we refer to as Dual-Key Multimodal Backdoors. This attack exploits the complex fusion mechanisms used by <font color="#00be00">state-of-the-art</font> networks to embed backdoors that are both effective and stealthy. Instead of using a single trigger, the proposed attack embeds a trigger in each of the input modalities and activates the malicious behavior only when both the triggers are present. We present an extensive study of multimodal backdoors on the Visual Question Answering (VQA) task with multiple architectures and visual feature backbones. A major challenge in embedding backdoors in VQA models is that most models use visual features extracted from a fixed pretrained object detector. This is challenging for the attacker as the detector can distort or ignore the visual trigger entirely, which leads to models where backdoors are over-reliant on the language trigger. We tackle this problem by proposing a visual trigger optimization strategy designed for pretrained object detectors. Through this method, we create Dual-Key Backdoors with over a 98% attack success rate while only poisoning 1% of the training data. Finally, we release TrojVQA, a large collection of clean and trojan VQA models to enable research in defending against multimodal backdoors. </br></br>

<a href='http://arxiv.org/pdf/2112.05598.pdf'>2112.05598</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.9146баллов, №260</br>
<b>PERF: Performant, Explicit Radiance Fields</b></br>
Authors: , Rasmuson, Sverker, Sintorn, Erik, Assarsson, Ulf</br>
  We present a novel way of approaching image-based 3D reconstruction based on radiance fields. The problem of volumetric reconstruction is formulated as a non-linear least-squares problem and solved explicitly without the use of neural networks. This enables the use of solvers with a higher rate of convergence than what is typically used for neural networks, and fewer iterations are required until convergence. The volume is represented using a grid of voxels, with the scene surrounded by a hierarchy of environment maps. This makes it possible to get clean reconstructions of 360{\\deg} scenes where the foreground and background is separated. A number of synthetic and real scenes from well known benchmark-suites are successfully reconstructed with quality on par with <font color="#00be00">state-of-the-art</font> methods, but at significantly reduced reconstruction times. </br></br>

<a href='http://arxiv.org/pdf/2112.08417.pdf'>2112.08417</a> &nbsp&nbsp (cs:AI, cs:ML, stat:ML) &nbsp&nbsp 0.9097баллов, №261</br>
<b>Characterization of causal ancestral graphs for time series with latent\n  confounders</b></br>
Authors: , Gerhardus, Andreas</br>
  Generalizing directed maximal ancestral graphs, we introduce a class of graphical models for representing time lag specific causal relationships and independencies among finitely many regularly sampled and regularly subsampled time steps of multivariate time series with unobserved variables. We completely characterize these graphs and show that they entail constraints beyond those that have previously been considered in the literature. This allows for stronger causal inferences without having imposed additional assumptions. In generalization of directed partial ancestral graphs we further introduce a graphical representation of Markov equivalence classes of the novel type of graphs and show that these are more informative than what current <font color="#00be00">state-of-the-art</font> causal discovery algorithms learn. We also analyze the additional information gained by increasing the number of observed time steps. </br></br>

<a href='http://arxiv.org/pdf/2112.06586.pdf'>2112.06586</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.9082баллов, №262</br>
<b>Active learning with MaskAL reduces annotation effort for training Mask\n  R-CNN</b></br>
Authors: , Blok, Pieter M., Kootstra, Gert, Elghor, Hakim Elchaoui, Diallo, Boubacar, van Evert, Frits K., van Henten, Eldert J.</br>
  The generalisation performance of a convolutional neural network (CNN) is influenced by the quantity, quality, and variety of the training images. Training images must be annotated, and this is time consuming and expensive. The goal of our work was to reduce the number of annotated images needed to train a CNN while maintaining its performance. We hypothesised that the performance of a CNN can be improved faster by ensuring that the set of training images contains a large fraction of hard-to-classify images. The objective of our study was to test this hypothesis with an active learning method that can automatically select the hard-to-classify images. We developed an active learning method for Mask Region-based CNN (Mask R-CNN) and named this method MaskAL. MaskAL involved the iterative training of Mask R-CNN, after which the trained model was used to select a set of unlabelled images about which the model was uncertain. The selected images were then annotated and used to retrain Mask R-CNN, and this was repeated for a number of sampling iterations. In our study, Mask R-CNN was trained on 2500 broccoli images that were selected through 12 sampling iterations by either MaskAL or a random sampling method from a training set of 14,000 broccoli images. For all sampling iterations, MaskAL performed significantly better than the random sampling. Furthermore, MaskAL had the same performance after sampling 900 images as the random sampling had after 2300 images. Compared to a Mask R-CNN model that was trained on the entire training set (14,000 images), MaskAL achieved 93.9% of its performance with 17.9% of its training data. The random sampling achieved 81.9% of its performance with 16.4% of its training data. We conclude that by using MaskAL, the annotation effort can be reduced for training Mask R-CNN on a broccoli dataset. Our software is available on <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/pieterblok/maskal. </br></br>

<a href='http://arxiv.org/pdf/2112.07383.pdf'>2112.07383</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.9039баллов, №263</br>
<b>Improving Human-Object Interaction Detection via Phrase Learning and\n  Label Composition</b></br>
Authors: , Li, Zhimin, Zou, Cheng, Zhao, Yu, Li, Boxun, Zhong, Sheng</br>
  Human-Object Interaction (HOI) detection is a fundamental task in high-level human-centric scene understanding. We propose PhraseHOI, containing a HOI branch and a novel phrase branch, to leverage language prior and improve relation expression. Specifically, the phrase branch is supervised by semantic embeddings, whose ground truths are automatically converted from the original HOI annotations without extra human efforts. Meanwhile, a novel label composition method is proposed to deal with the long-tailed problem in HOI, which composites novel phrase labels by semantic neighbors. Further, to optimize the phrase branch, a loss composed of a distilling loss and a balanced triplet loss is proposed. Extensive experiments are conducted to prove the effectiveness of the proposed PhraseHOI, which achieves significant improvement over the baseline and surpasses previous <font color="#00be00">state-of-the-art</font> methods on Full and NonRare on the challenging HICO-DET benchmark. </br></br>

<a href='http://arxiv.org/pdf/2112.08986.pdf'>2112.08986</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.9016баллов, №264</br>
<b>A Heterogeneous Graph Learning Model for Cyber-Attack Detection</b></br>
Authors: , Lv, Mingqi, Dong, Chengyu, Chen, Tieming, Zhu, Tiantian, Song, Qijie, Fan, Yuan</br>
  A cyber-attack is a malicious attempt by experienced hackers to breach the target information system. Usually, the cyber-attacks are characterized as hybrid TTPs (Tactics, Techniques, and Procedures) and long-term adversarial behaviors, making the traditional intrusion detection methods ineffective. Most existing cyber-attack detection systems are implemented based on manually designed rules by referring to domain knowledge (e.g., threat models, threat intelligences). However, this process is lack of intelligence and generalization ability. Aiming at this limitation, this paper proposes an intelligent cyber-attack detection method based on provenance data. To effective and efficient detect cyber-attacks from a huge number of system events in the provenance data, we firstly model the provenance data by a heterogeneous graph to capture the rich context information of each system entities (e.g., process, file, socket, etc.), and learns a semantic vector representation for each system entity. Then, we perform online cyber-attack detection by sampling a small and compact local graph from the heterogeneous graph, and classifying the key system entities as malicious or benign. We conducted a series of experiments on two provenance datasets with real cyber-attacks. The experiment results show that the proposed method <font color="#00be00">outperform</font>s other learning based detection models, and has <font color="#960096">competitive</font> performance against <font color="#00be00">state-of-the-art</font> rule based cyber-attack detection systems. </br></br>

<a href='http://arxiv.org/pdf/2112.07544.pdf'>2112.07544</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 0.8989баллов, №265</br>
<b>Modeling Strong and Human-Like Gameplay with KL-Regularized Search</b></br>
Authors: , Jacob, Athul Paul, Wu, David J., Farina, Gabriele, Lerer, Adam, Bakhtin, Anton, Andreas, Jacob, Brown, Noam</br>
  We consider the task of building strong but human-like policies in multi-agent decision-making problems, given examples of human behavior. Imitation learning is effective at predicting human actions but may not match the strength of expert humans, while self-play learning and search techniques (e.g. <font color="#00be00">AlphaZero</font>) lead to strong performance but may produce policies that are difficult for humans to understand and coordinate with. We show in chess and Go that regularizing search policies based on the KL divergence from an imitation-learned policy by applying Monte Carlo tree search produces policies that have higher human prediction accuracy and are stronger than the imitation policy. We then introduce a novel regret minimization algorithm that is regularized based on the KL divergence from an imitation-learned policy, and show that applying this algorithm to no-press Diplomacy yields a policy that maintains the same human prediction accuracy as imitation learning while being substantially stronger. </br></br>

<a href='http://arxiv.org/pdf/2112.06671.pdf'>2112.06671</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.8988баллов, №266</br>
<b>Accelerating Deep Learning Classification with Error-controlled\n  Approximate-key Caching</b></br>
Authors: , Finamore, Alessandro, Roberts, James, Gallo, Massimo, Rossi, Dario</br>
  While Deep Learning (DL) technologies are a promising tool to solve networking problems that map to classification tasks, their computational complexity is still too high with respect to real-time traffic measurements requirements. To reduce the DL inference cost, we propose a novel caching paradigm, that we named approximate-key caching, which returns approximate results for lookups of selected input based on cached DL inference results. While approximate cache hits alleviate DL inference workload and increase the system throughput, they however introduce an approximation error. As such, we couple approximate-key caching with an error-correction principled algorithm, that we named auto-refresh. We analytically model our caching system performance for classic LRU and ideal caches, we perform a trace-driven evaluation of the expected performance, and we compare the benefits of our proposed approach with the <font color="#00be00">state-of-the-art</font> similarity caching -- testifying the practical interest of our proposal. </br></br>

<a href='http://arxiv.org/pdf/2112.05692.pdf'>2112.05692</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.8961баллов, №267</br>
<b>VUT: Versatile UI <font color="#00be00">Transformer</font> for Multi-Modal Multi-Task User Interface\n  Modeling</b></br>
Authors: , Li, Yang, Li, Gang, Zhou, Xin, Dehghani, Mostafa, Gritsenko, Alexey</br>
  User interface modeling is inherently multimodal, which involves several distinct types of data: images, structures and language. The tasks are also diverse, including <font color="#be00be">object detection</font>, language generation and grounding. In this paper, we present VUT, a Versatile UI <font color="#00be00">Transformer</font> that takes multimodal input and simultaneously accomplishes 5 distinct tasks with the same model. Our model consists of a multimodal Transformer encoder that jointly encodes UI images and structures, and performs UI object detection when the UI structures are absent in the input. Our model also consists of an auto-regressive Transformer model that encodes the language input and decodes output, for both question-answering and command grounding with respect to the UI. Our experiments show that for most of the tasks, when trained jointly for multi-tasks, VUT substantially reduces the number of models and footprints needed for performing multiple tasks, while achieving accuracy exceeding or on par with baseline models trained for each individual task. </br></br>

<a href='http://arxiv.org/pdf/2111.10291.pdf'>2111.10291</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV) &nbsp&nbsp 0.8921баллов, №268</br>
<b>Meta Adversarial Perturbations</b></br>
Authors: , Yuan, Chia-Hung, Chen, Pin-Yu, Yu, Chia-Mu</br>
  A plethora of attack methods have been proposed to generate adversarial examples, among which the iterative methods have been demonstrated the ability to find a strong attack. However, the computation of an adversarial perturbation for a new data point requires solving a time-consuming optimization problem from scratch. To generate a stronger attack, it normally requires updating a data point with more iterations. In this paper, we show the existence of a meta adversarial perturbation (MAP), a better initialization that causes natural images to be misclassified with high probability after being updated through only a one-step gradient ascent update, and propose an algorithm for computing such perturbations. We conduct extensive experiments, and the empirical results demonstrate that <font color="#00be00">state-of-the-art</font> deep neural networks are vulnerable to meta perturbations. We further show that these perturbations are not only image-agnostic, but also model-agnostic, as a single perturbation generalizes well across unseen data points and different neural network architectures. </br></br>

<a href='http://arxiv.org/pdf/2112.07368.pdf'>2112.07368</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV) &nbsp&nbsp 0.8914баллов, №269</br>
<b>Simple and Robust Loss Design for Multi-Label Learning with Missing\n  Labels</b></br>
Authors: , Zhang, Youcai, Cheng, Yuhao, Huang, Xinyu, Wen, Fei, Feng, Rui, Li, Yaqian, Guo, Yandong</br>
  Multi-label learning in the presence of missing labels (MLML) is a challenging problem. Existing methods mainly focus on the design of network structures or training schemes, which increase the complexity of implementation. This work seeks to fulfill the potential of loss function in MLML without increasing the procedure and complexity. Toward this end, we propose two simple yet effective methods via robust loss design based on an observation that a model can identify missing labels during training with a high precision. The first is a novel robust loss for negatives, namely the Hill loss, which re-weights negatives in the shape of a hill to alleviate the effect of false negatives. The second is a self-paced loss correction (SPLC) method, which uses a loss derived from the maximum likelihood criterion under an approximate distribution of missing labels. Comprehensive experiments on a vast range of multi-label image classification datasets demonstrate that our methods can remarkably boost the performance of MLML and achieve new <font color="#00be00">state-of-the-art</font> loss functions in MLML. </br></br>

<a href='http://arxiv.org/pdf/2112.08619.pdf'>2112.08619</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.8882баллов, №270</br>
<b>Call for Customized Conversation: Customized Conversation Grounding\n  Persona and Knowledge</b></br>
Authors: , Jang, Yoonna, Lim, Jungwoo, Hur, Yuna, Oh, Dongsuk, Son, Suhyune, Lee, Yeonsoo, Shin, Donghoon, Kim, Seungryong, Lim, Heuiseok</br>
  Humans usually have conversations by making use of prior knowledge about a topic and background information of the people whom they are talking to. However, existing conversational agents and datasets do not consider such comprehensive information, and thus they have a limitation in generating the utterances where the knowledge and persona are fused properly. To address this issue, we introduce a call For Customized conversation (FoCus) dataset where the customized answers are built with the user\'s persona and Wikipedia knowledge. To evaluate the abilities to make informative and customized utterances of pre-trained language models, we utilize BART and<font color="#00be00"> GPT</font>-2 as well as <font color="#00be00">transformer</font>-based models. We assess their generation abilities with automatic scores and conduct human evaluations for qualitative results. We examine whether the model reflects adequate persona and knowledge with our proposed two sub-tasks, persona grounding (PG) and knowledge grounding (KG). Moreover, we show that the utterances of our data are constructed with the proper knowledge and persona through grounding quality assessment. </br></br>

<a href='http://arxiv.org/pdf/2112.06417.pdf'>2112.06417</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8859баллов, №271</br>
<b>LC-FDNet: Learned Lossless Image Compression with Frequency\n  Decomposition Network</b></br>
Authors: , Rhee, Hochang, Jang, Yeong Il, Kim, Seyun, Cho, Nam Ik</br>
  Recent learning-based lossless image compression methods encode an image in the unit of subimages and achieve comparable performances to conventional non-learning algorithms. However, these methods do not consider the performance drop in the high-frequency region, giving equal consideration to the low and high-frequency areas. In this paper, we propose a new lossless image compression method that proceeds the encoding in a coarse-to-fine manner to separate and process low and high-frequency regions differently. We initially compress the low-frequency components and then use them as additional input for encoding the remaining high-frequency region. The low-frequency components act as a strong prior in this case, which leads to improved estimation in the high-frequency area. In addition, we design the frequency decomposition process to be adaptive to color channel, spatial location, and image characteristics. As a result, our method derives an image-specific optimal ratio of low/high-frequency components. Experiments show that the proposed method achieves <font color="#00be00">state-of-the-art</font> performance for benchmark high-resolution datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.08273.pdf'>2112.08273</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.8820баллов, №272</br>
<b>Programming Knowledge Tracing: A Comprehensive Dataset and A New Model</b></br>
Authors: , Zhu, Renyu, Zhang, Dongxiang, Han, Chengcheng, Gao, Ming, Lu, Xuesong, Qian, Weining, Zhou, Aoying</br>
  In this paper, we study knowledge tracing in the domain of programming education and make two important contributions. First, we harvest and publish so far the most comprehensive dataset, namely BePKT, which covers various online behaviors in an OJ system, including programming text problems, knowledge annotations, user-submitted code and system-logged events. Second, we propose a new model PDKT to exploit the enriched context for accurate student behavior prediction. More specifically, we construct a bipartite graph for programming problem embedding, and design an improved pre-training model PLCodeBERT for code embedding, as well as a double-sequence RNN model with exponential decay attention for effective feature fusion. Experimental results on the new dataset BePKT show that our proposed model establishes <font color="#00be00">state-of-the-art</font> performance in programming knowledge tracing. In addition, we verify that our code embedding strategy based on PLCodeBERT is complementary to existing knowledge tracing models to further enhance their accuracy. As a side product, PLCodeBERT also results in better performance in other programming-related tasks such as code clone detection. </br></br>

<a href='http://arxiv.org/pdf/2112.07270.pdf'>2112.07270</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8814баллов, №273</br>
<b>Bilateral Cross-Modality Graph Matching Attention for Feature Fusion in\n  Visual Question Answering</b></br>
Authors: , Cao, JianJian, Qin, Xiameng, Zhao, Sanyuan, Shen, Jianbing</br>
  Answering semantically-complicated questions according to an image is challenging in Visual Question Answering (VQA) task. Although the image can be well represented by deep learning, the question is always simply embedded and cannot well indicate its meaning. Besides, the visual and textual features have a gap for different modalities, it is difficult to align and utilize the cross-modality information. In this paper, we focus on these two problems and propose a Graph Matching Attention (GMA) network. Firstly, it not only builds graph for the image, but also constructs graph for the question in terms of both syntactic and embedding information. Next, we explore the intra-modality relationships by a dual-stage graph encoder and then present a bilateral cross-modality graph matching attention to infer the relationships between the image and the question. The updated cross-modality features are then sent into the answer prediction module for final answer prediction. Experiments demonstrate that our network achieves <font color="#00be00">state-of-the-art</font> performance on the GQA dataset and the VQA 2.0 dataset. The ablation studies verify the effectiveness of each modules in our GMA network. </br></br>

<a href='http://arxiv.org/pdf/2112.05794.pdf'>2112.05794</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8764баллов, №274</br>
<b>A Label Correction Algorithm Using Prior Information for Automatic and\n  Accurate Geospatial Object Recognition</b></br>
Authors: , Duan, Weiwei, Chiang, Yao-Yi, Leyk, Stefan, Uhl, Johannes H., Knoblock, Craig A.</br>
  Thousands of scanned historical topographic maps contain valuable information covering long periods of time, such as how the hydrography of a region has changed over time. Efficiently unlocking the information in these maps requires training a geospatial objects recognition system, which needs a large amount of annotated data. Overlapping geo-referenced external vector data with topographic maps according to their coordinates can annotate the desired objects\' locations in the maps automatically. However, directly overlapping the two datasets causes misaligned and false annotations because the publication years and coordinate projection systems of topographic maps are different from the external vector data. We propose a label correction algorithm, which leverages the color information of maps and the prior shape information of the external vector data to reduce misaligned and false annotations. The experiments show that the precision of annotations from the proposed algorithm is 10% higher than the annotations from a <font color="#00be00">state-of-the-art</font> algorithm. Consequently, recognition results using the proposed algorithm\'s annotations achieve 9% higher correctness than using the annotations from the state-of-the-art algorithm. </br></br>

<a href='http://arxiv.org/pdf/2112.07928.pdf'>2112.07928</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8730баллов, №275</br>
<b>Imagine by Reasoning: A Reasoning-Based Implicit Semantic Data\n  Augmentation for Long-Tailed Classification</b></br>
Authors: , Chen, Xiaohua, Zhou, Yucan, Wu, Dayan, Zhang, Wanqian, Zhou, Yu, Li, Bo, Wang, Weiping</br>
  <font color="#009600">Real-world</font> data often follows a long-tailed distribution, which makes the performance of existing classification algorithms degrade heavily. A key issue is that samples in tail categories fail to depict their intra-class diversity. Humans can imagine a sample in new poses, scenes, and view angles with their prior knowledge even if it is the first time to see this category. Inspired by this, we propose a novel reasoning-based implicit semantic data augmentation method to borrow transformation directions from other classes. Since the covariance matrix of each category represents the feature transformation directions, we can sample new directions from similar categories to generate definitely different instances. Specifically, the long-tailed distributed data is first adopted to train a backbone and a classifier. Then, a covariance matrix for each category is estimated, and a <font color="#960096">knowledge graph</font> is constructed to store the relations of any two categories. Finally, tail samples are adaptively enhanced via propagating information from all the similar categories in the knowledge graph. Experimental results on CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018 have demonstrated the effectiveness of our proposed method compared with the <font color="#00be00">state-of-the-art</font> methods. </br></br>

<a href='http://arxiv.org/pdf/2112.08652.pdf'>2112.08652</a> &nbsp&nbsp (cs:ML, cs:CL) &nbsp&nbsp 0.8703баллов, №276</br>
<b>Extreme <font color="#00be00">Zero-Shot</font> Learning for Extreme Text Classification</b></br>
Authors: , Xiong, Yuanhao, Chang, Wei-Cheng, Hsieh, Cho-Jui, Yu, Hsiang-Fu, Dhillon, Inderjit</br>
  The eXtreme Multi-label text Classification (XMC) problem concerns finding most relevant labels for an input text instance from a large label set. However, the XMC setup faces two challenges: (1) it is not generalizable to predict unseen labels in dynamic environments, and (2) it requires a large amount of supervised (instance, label) pairs, which can be difficult to obtain for emerging domains. Recently, the generalized <font color="#00be00">zero-shot</font> XMC (GZ-XMC) setup has been studied and ZestXML is proposed accordingly to handle the unseen labels, which still requires a large number of annotated (instance, label) pairs. In this paper, we consider a more practical scenario called Extreme Zero-Shot XMC (EZ-XMC), in which no supervision is needed and merely raw text of instances and labels are accessible. <font color="#00be00">Few-Shot</font> XMC (FS-XMC), an extension to EZ-XMC with limited supervision is also investigated. To learn the semantic embeddings of instances and labels with raw text, we propose to pre-train <font color="#00be00">Transformer</font>-based encoders with self-supervised contrastive losses. Specifically, we develop a pre-training method MACLR, which thoroughly leverages the raw text with techniques including Multi-scale Adaptive <font color="#be00be">Clustering</font>, Label Regularization, and self-training with pseudo positive pairs. Experimental results on four public EZ-XMC datasets demonstrate that MACLR achieves superior performance compared to all other leading baseline methods, in particular with approximately 5-10% improvement in precision and recall on average. Moreover, we also show that our pre-trained encoder can be further improved on FS-XMC when there are a limited number of ground-truth positive pairs in training. By fine-tuning the encoder on such a few-shot subset, MACLR still <font color="#00be00">outperform</font>s other extreme classifiers significantly. </br></br>

<a href='http://arxiv.org/pdf/2112.06701.pdf'>2112.06701</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8671баллов, №277</br>
<b>Anchor Retouching via Model Interaction for Robust <font color="#be00be">Object Detection</font> in\n  Aerial Images</b></br>
Authors: , Liang, Dong, Geng, Qixiang, Wei, Zongqi, Vorontsov, Dmitry A., Kim, Ekaterina L., Wei, Mingqiang, Zhou, Huiyu</br>
  <font color="#be00be">Object detection</font> has made tremendous strides in computer vision. Small object detection with appearance degradation is a prominent challenge, especially for aerial observations. To collect sufficient positive/negative samples for heuristic training, most object detectors preset region anchors in order to calculate Intersection-over-Union (IoU) against the ground-truthed data. In this case, small objects are frequently abandoned or mislabeled. In this paper, we present an effective Dynamic Enhancement Anchor (DEA) network to construct a novel training sample generator. Different from the other <font color="#00be00">state-of-the-art</font> techniques, the proposed network leverages a sample discriminator to realize interactive sample screening between an anchor-based unit and an anchor-free unit to generate eligible samples. Besides, multi-task joint training with a conservative anchor-based inference scheme enhances the performance of the proposed model while reducing computational complexity. The proposed scheme supports both oriented and horizontal object detection tasks. Extensive experiments on two challenging aerial benchmarks (i.e., DOTA and HRSC2016) indicate that our method achieves state-of-the-art performance in accuracy with moderate inference speed and computational overhead for training. On DOTA, our DEA-Net which integrated with the baseline of RoI-<font color="#00be00">Transformer</font> surpasses the advanced method by 0.40% mean-Average-Precision (mAP) for oriented object detection with a weaker backbone network (ResNet-101 vs ResNet-152) and 3.08% mean-Average-Precision (mAP) for horizontal object detection with the same backbone. Besides, our DEA-Net which integrated with the baseline of ReDet achieves the state-of-the-art performance by 80.37%. On HRSC2016, it surpasses the previous best model by 1.1% using only 3 horizontal anchors. </br></br>

<a href='http://arxiv.org/pdf/2112.06116.pdf'>2112.06116</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.8651баллов, №278</br>
<b>Stereoscopic Universal Perturbations across Different Architectures and\n  Datasets</b></br>
Authors: , Berger, Zachary, Agrawal, Parth, Liu, Tian Yu, Soatto, Stefano, Wong, Alex</br>
  We study the effect of adversarial perturbations of images on deep stereo matching networks for the disparity estimation task. We present a method to craft a single set of perturbations that, when added to any stereo image pair in a dataset, can fool a stereo network to significantly alter the perceived scene geometry. Our perturbation images are &quot;universal&quot; in that they not only corrupt estimates of the network on the dataset they are optimized for, but also generalize to stereo networks with different architectures across different datasets. We evaluate our approach on multiple public benchmark datasets and show that our perturbations can increase D1-error (akin to fooling rate) of <font color="#00be00">state-of-the-art</font> stereo networks from 1% to as much as 87%. We investigate the effect of perturbations on the estimated scene geometry and identify object classes that are most vulnerable. Our analysis on the activations of registered points between left and right images led us to find that certain architectural components, i.e. deformable convolution and explicit matching, can increase robustness against adversaries. We demonstrate that by simply designing networks with such components, one can reduce the effect of adversaries by up to 60.5%, which rivals the robustness of networks fine-tuned with costly adversarial data augmentation. </br></br>

<a href='http://arxiv.org/pdf/2112.05303.pdf'>2112.05303</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8607баллов, №279</br>
<b>Surrogate-based cross-correlation for particle image velocimetry</b></br>
Authors: , Lee, Yong, Gu, Fuqiang, Gong, Zeyu</br>
  This paper presents a novel surrogate-based cross-correlation (SBCC) framework to improve the correlation performance between two image signals. The basic idea behind the SBCC is that an optimized surrogate filter/image, supplanting one original image, will produce a more robust and more accurate correlation signal. The cross-correlation estimation of the SBCC is formularized with an objective function composed of surrogate loss and correlation consistency loss. The closed-form solution provides an efficient estimation. To our surprise, the SBCC framework could provide an alternative view to explain a set of generalized cross-correlation (GCC) methods and comprehend the meaning of parameters. With the help of our SBCC framework, we further propose four new specific cross-correlation methods, and provide some suggestions for improving existing GCC methods. A noticeable fact is that the SBCC could enhance the correlation robustness by incorporating other negative context images. Considering the sub-pixel accuracy and robustness requirement of particle image velocimetry (PIV), the contribution of each term in the objective function is investigated with particles\' images. Compared with the <font color="#00be00">state-of-the-art</font> baseline methods, the SBCC methods exhibit improved performance (accuracy and robustness) on the synthetic dataset and several challenging real experimental PIV cases. </br></br>

<a href='http://arxiv.org/pdf/2112.03266.pdf'>2112.03266</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.8537баллов, №280</br>
<b>Contrastive Cycle Adversarial Autoencoders for Single-cell Multi-omics\n  Alignment and Integration</b></br>
Authors: , Wang, Xuesong, Hu, Zhihang, Yu, Tingyang, Wang, Ruijie, Wei, Yumeng, Shu, Juan, Ma, Jianzhu, Li, Yu</br>
  Muilti-modality data are ubiquitous in biology, especially that we have entered the multi-omics era, when we can measure the same biological object (cell) from different aspects (omics) to provide a more comprehensive insight into the cellular system. When dealing with such multi-omics data, the first step is to determine the correspondence among different modalities. In other words, we should match data from different spaces corresponding to the same object. This problem is particularly challenging in the single-cell multi-omics scenario because such data are very sparse with extremely high dimensions. Secondly, matched single-cell multi-omics data are rare and hard to collect. Furthermore, due to the limitations of the experimental environment, the data are usually highly noisy. To promote the single-cell multi-omics research, we overcome the above challenges, proposing a novel framework to align and integrate single-cell RNA-seq data and single-cell ATAC-seq data. Our approach can efficiently map the above data with high sparsity and noise from different spaces to a low-dimensional manifold in a unified space, making the downstream alignment and integration straightforward. Compared with the other <font color="#00be00">state-of-the-art</font> methods, our method performs better in both simulated and real single-cell data. The proposed method is helpful for the single-cell multi-omics research. The improvement for integration on the simulated data is significant. </br></br>

<a href='http://arxiv.org/pdf/2112.08558.pdf'>2112.08558</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.8490баллов, №281</br>
<b>CONQRR: Conversational Query Rewriting for <font color="#be00be">Retrieval</font> with Reinforcement\n  Learning</b></br>
Authors: , Wu, Zeqiu, Luan, Yi, Rashkin, Hannah, Reitter, David, Tomar, Gaurav Singh</br>
  For open-domain conversational question answering (CQA), it is important to retrieve the most relevant passages to answer a question, but this is challenging compared with standard passage <font color="#be00be">retrieval</font> because it requires understanding the full dialogue context rather than a single query. Moreover, it can be expensive to re-train well-established retrievers such as search engines that are originally developed for non-conversational queries. To facilitate their use, we develop a query rewriting model CONQRR that rewrites a conversational question in context into a standalone question. It is trained with a novel reward function to directly optimize towards retrieval and can be adapted to any fixed blackbox retriever using <font color="#00be00">reinforcement learning</font>. We show that CONQRR achieves <font color="#00be00">state-of-the-art</font> results on a recent open-domain CQA dataset, a combination of conversations from three different sources. We also conduct extensive experiments to show the effectiveness of CONQRR for any given fixed retriever. </br></br>

<a href='http://arxiv.org/pdf/2112.08782.pdf'>2112.08782</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.8485баллов, №282</br>
<b>Improved YOLOv5 network for real-time multi-scale traffic sign detection</b></br>
Authors: , Wang, Junfan, Chen, Yi, Gao, Mingyu, Dong, Zhekang</br>
  Traffic sign detection is a challenging task for the unmanned driving system, especially for the detection of multi-scale targets and the real-time problem of detection. In the traffic sign detection process, the scale of the targets changes greatly, which will have a certain impact on the detection accuracy. Feature pyramid is widely used to solve this problem but it might break the feature consistency across different scales of traffic signs. Moreover, in practical application, it is difficult for common methods to improve the detection accuracy of multi-scale traffic signs while ensuring real-time detection. In this paper, we propose an improved feature pyramid model, named AF-FPN, which utilizes the adaptive attention module (AAM) and feature enhancement module (FEM) to reduce the information loss in the process of feature map generation and enhance the representation ability of the feature pyramid. We replaced the original feature pyramid network in YOLOv5 with AF-FPN, which improves the detection performance for multi-scale targets of the YOLOv5 network under the premise of ensuring real-time detection. Furthermore, a new automatic learning data augmentation method is proposed to enrich the dataset and improve the robustness of the model to make it more suitable for practical scenarios. Extensive experimental results on the Tsinghua-Tencent 100K (TT100K) dataset demonstrate the effectiveness and superiority of the proposed method when compared with several <font color="#00be00">state-of-the-art</font> methods. </br></br>

<a href='http://arxiv.org/pdf/2112.08991.pdf'>2112.08991</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.8470баллов, №283</br>
<b>ADBCMM : Acronym Disambiguation by Building Counterfactuals and\n  Multilingual Mixing</b></br>
Authors: , Weng, Yixuan, Xia, Fei, Li, Bin, Huang, Xiusheng, He, Shizhu, Liu, Kang, Zhao, Jun</br>
  Scientific documents often contain a large number of acronyms. Disambiguation of these acronyms will help researchers better understand the meaning of vocabulary in the documents. In the past, thanks to large amounts of data from English literature, acronym task was mainly applied in English literature. However, for other <font color="#be00be">low-resource</font> languages, this task is difficult to obtain good performance and receives less attention due to the lack of large amount of annotation data. To address the above issue, this paper proposes an new method for acronym disambiguation, named as ADBCMM, which can significantly improve the performance of low-resource languages by building counterfactuals and multilingual mixing. Specifically, by balancing data bias in low-resource langauge, ADBCMM will able to improve the test performance outside the data set. In SDU@AAAI-22 - Shared Task 2: Acronym Disambiguation, the proposed method won first place in French and Spanish. You can repeat our results here <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/WENGSYX/ADBCMM. </br></br>

<a href='http://arxiv.org/pdf/2112.06910.pdf'>2112.06910</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8460баллов, №284</br>
<b>DenseGAP: Graph-Structured Dense Correspondence Learning with Anchor\n  Points</b></br>
Authors: , Kuang, Zhengfei, Li, Jiaman, He, Mingming, Wang, Tong, Zhao, Yajie</br>
  Establishing dense correspondence between two images is a fundamental computer vision problem, which is typically tackled by matching local feature descriptors. However, without global awareness, such local features are often insufficient for disambiguating similar regions. And computing the pairwise feature correlation across images is both computation-expensive and memory-intensive. To make the local features aware of the global context and improve their matching accuracy, we introduce DenseGAP, a new solution for efficient Dense correspondence learning with a Graph-structured neural network conditioned on Anchor Points. Specifically, we first propose a graph structure that utilizes anchor points to provide sparse but reliable prior on inter- and intra-image context and propagates them to all image points via directed edges. We also design a graph-structured network to broadcast multi-level contexts via light-weighted message-passing layers and generate high-resolution feature maps at low memory cost. Finally, based on the predicted feature maps, we introduce a coarse-to-fine framework for accurate correspondence prediction using cycle consistency. Our feature descriptors capture both local and global information, thus enabling a continuous feature field for querying arbitrary points at high resolution. Through comprehensive ablative experiments and evaluations on large-scale indoor and outdoor datasets, we demonstrate that our method advances the <font color="#00be00">state-of-the-art</font> of correspondence learning on most benchmarks. </br></br>

<a href='http://arxiv.org/pdf/2112.05746.pdf'>2112.05746</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.8431баллов, №285</br>
<b>On Causally Disentangled Representations</b></br>
Authors: , Reddy, Abbavaram Gowtham, L, Benin Godfrey, Balasubramanian, Vineeth N</br>
  Representation learners that disentangle factors of variation have already proven to be important in addressing various <font color="#009600">real world</font> concerns such as fairness and <font color="#be00be">interpret</font>ability. Initially consisting of unsupervised models with independence assumptions, more recently, weak supervision and correlated features have been explored, but without a causal view of the generative process. In contrast, we work under the regime of a causal generative process where generative factors are either independent or can be potentially confounded by a set of observed or unobserved confounders. We present an analysis of disentangled representations through the notion of disentangled causal process. We motivate the need for new metrics and datasets to study causal disentanglement and propose two evaluation metrics and a dataset. We show that our metrics capture the desiderata of disentangled causal process. Finally, we perform an empirical study on <font color="#00be00">state of the art</font> disentangled representation learners using our metrics and dataset to evaluate them from causal perspective. </br></br>

<a href='http://arxiv.org/pdf/2112.04731.pdf'>2112.04731</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.8424баллов, №286</br>
<b>Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class\n  Incremental Learning</b></br>
Authors: , Shi, Yujun, Zhou, Kuangqi, Liang, Jian, Jiang, Zihang, Feng, Jiashi, Torr, Philip, Bai, Song, Tan, Vincent Y. F.</br>
  Class Incremental Learning (CIL) aims at learning a multi-class classifier in a phase-by-phase manner, in which only data of a subset of the classes are provided at each phase. Previous works mainly focus on mitigating forgetting in phases after the initial one. However, we find that improving CIL at its initial phase is also a promising direction. Specifically, we experimentally show that directly encouraging CIL Learner at the initial phase to output similar representations as the model jointly trained on all classes can greatly boost the CIL performance. Motivated by this, we study the difference between a na\\&quot;ively-trained initial-phase model and the oracle model. Specifically, since one major difference between these two models is the number of training classes, we investigate how such difference affects the model representations. We find that, with fewer training classes, the data representations of each class lie in a long and narrow region; with more training classes, the representations of each class scatter more uniformly. Inspired by this observation, we propose Class-wise Decorrelation (CwD) that effectively regularizes representations of each class to scatter more uniformly, thus mimicking the model jointly trained with all classes (i.e., the oracle model). Our CwD is simple to implement and easy to plug into existing methods. Extensive experiments on various benchmark datasets show that CwD consistently and significantly improves the performance of existing <font color="#00be00">state-of-the-art</font> methods by around 1\\% to 3\\%. Code will be released. </br></br>

<a href='http://arxiv.org/pdf/2112.07263.pdf'>2112.07263</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.8389баллов, №287</br>
<b>Quantifying Multimodality in World Models</b></br>
Authors: , Sedlmeier, Andreas, K&#xf6;lle, Michael, M&#xfc;ller, Robert, Baudrexel, Leo, Linnhoff-Popien, Claudia</br>
  Model-based Deep <font color="#00be00">Reinforcement Learning</font> (RL) assumes the availability of a model of an environment\'s underlying transition dynamics. This model can be used to predict future effects of an agent\'s possible actions. When no such model is available, it is possible to learn an approximation of the real environment, e.g. by using generative neural networks, sometimes also called World Models. As most <font color="#009600">real-world</font> environments are stochastic in nature and the transition dynamics are oftentimes multimodal, it is important to use a modelling technique that is able to reflect this multimodal uncertainty. In order to safely deploy such learning systems in the <font color="#009600">real world</font>, especially in an industrial context, it is paramount to consider these uncertainties. In this work, we analyze existing and propose new metrics for the detection and quantification of multimodal uncertainty in RL based World Models. The correct modelling &amp; detection of uncertain future states lays the foundation for handling critical situations in a safe way, which is a prerequisite for deploying RL systems in real-world settings. </br></br>

<a href='http://arxiv.org/pdf/2112.05290.pdf'>2112.05290</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8365баллов, №288</br>
<b>Image-to-Image Translation-based Data Augmentation for Robust EV\n  Charging Inlet Detection</b></br>
Authors: , Bang, Yeonjun, Lee, Yeejin, Kang, Byeongkeun</br>
  This work addresses the task of electric vehicle (EV) charging inlet detection for autonomous EV charging robots. Recently, automated EV charging systems have received huge attention to improve users\' experience and to efficiently utilize charging infrastructures and parking lots. However, most related works have focused on system design, robot control, planning, and manipulation. Towards robust EV charging inlet detection, we propose a new dataset (EVCI dataset) and a novel data augmentation method that is based on image-to-image translation where typical image-to-image translation methods synthesize a new image in a different domain given an image. To the best of our knowledge, the EVCI dataset is the first EV charging inlet dataset. For the data augmentation method, we focus on being able to control synthesized images\' captured environments (e.g., time, lighting) in an intuitive way. To achieve this, we first propose the environment guide vector that humans can intuitively <font color="#be00be">interpret</font>. We then propose a novel image-to-image translation network that translates a given image towards the environment described by the vector. Accordingly, it aims to synthesize a new image that has the same content as the given image while looking like captured in the provided environment by the environment guide vector. Lastly, we train a detection method using the augmented dataset. Through experiments on the EVCI dataset, we demonstrate that the proposed method <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> methods. We also show that the proposed method is able to control synthesized images using an image and environment guide vectors. </br></br>

<a href='http://arxiv.org/pdf/2112.06978.pdf'>2112.06978</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.8320баллов, №289</br>
<b>Exploring Latent Dimensions of Crowd-sourced Creativity</b></br>
Authors: , Kocasari, Umut, Bag, Alperen, Atici, Efehan, Yanardag, Pinar</br>
  Recently, the discovery of <font color="#be00be">interpret</font>able directions in the latent spaces of pre-trained GANs has become a popular topic. While existing works mostly consider directions for semantic image manipulations, we focus on an abstract property: creativity. Can we manipulate an image to be more or less creative? We build our work on the largest AI-based creativity platform, Artbreeder, where users can generate images using pre-trained GAN models. We explore the latent dimensions of images generated on this platform and present a novel framework for manipulating images to make them more creative. Our code and dataset are available at <font color="#006400">http</font>://<font color="#00be00">github</font>.com/catlab-team/latentcreative. </br></br>

<a href='http://arxiv.org/pdf/2112.07957.pdf'>2112.07957</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8295баллов, №290</br>
<b>FEAR: Fast, Efficient, Accurate and Robust Visual <font color="#be00be">Tracker</font></b></br>
Authors: , Borsuk, Vasyl, Vei, Roman, Kupyn, Orest, Martyniuk, Tetiana, Krashenyi, Igor, Matas, Ji&#x159;i</br>
  We present FEAR, a novel, fast, efficient, accurate, and robust Siamese visual <font color="#be00be">tracker</font>. We introduce an architecture block for object model adaption, called dual-template representation, and a pixel-wise fusion block to achieve extra flexibility and efficiency of the model. The dual-template module incorporates temporal information with only a single learnable parameter, while the pixel-wise fusion block encodes more discriminative features with fewer parameters compared to standard correlation modules. By plugging-in sophisticated backbones with the novel modules, FEAR-M and FEAR-L trackers surpass most Siamesetrackers on several academic benchmarks in both accuracy and efficiencies. Employed with the <font color="#be00be">lightweight</font> backbone, the optimized version FEAR-XS offers more than 10 times faster <font color="#be00be">tracking</font> than current Siamese trackers while maintaining near <font color="#00be00">state-of-the-art</font> results. FEAR-XS tracker is 2.4x smaller and 4.3x faster than LightTrack [62] with superior accuracy. In addition, we expand the definition of the model efficiency by introducing a benchmark on energy consumption and execution speed. <font color="#00be00">Source code</font>, pre-trained models, and evaluation protocol will be made available upon request </br></br>

<a href='http://arxiv.org/pdf/2111.09794.pdf'>2111.09794</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.8249баллов, №291</br>
<b>A Survey of Generalisation in Deep <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Kirk, Robert, Zhang, Amy, Grefenstette, Edward, Rockt&#xe4;schel, Tim</br>
  The study of generalisation in deep <font color="#00be00">Reinforcement Learning</font> (RL) aims to produce RL algorithms whose policies generalise well to novel unseen situations at deployment time, avoiding overfitting to their training environments. Tackling this is vital if we are to deploy reinforcement learning algorithms in <font color="#009600">real world</font> scenarios, where the environment will be diverse, dynamic and unpredictable. This survey is an overview of this nascent field. We provide a unifying formalism and terminology for discussing different generalisation problems, building upon previous works. We go on to categorise existing benchmarks for generalisation, as well as current methods for tackling the generalisation problem. Finally, we provide a critical discussion of the current state of the field, including <font color="#be00be">recommendat</font>ions for future work. Among other conclusions, we argue that taking a purely procedural content generation approach to benchmark design is not conducive to progress in generalisation, we suggest fast online adaptation and tackling RL-specific problems as some areas for future work on methods for generalisation, and we recommend building benchmarks in underexplored problem settings such as offline RL generalisation and reward-function variation. </br></br>

<a href='http://arxiv.org/pdf/2112.04493.pdf'>2112.04493</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.8227баллов, №292</br>
<b>Binary Change Guided Hyperspectral Multiclass Change Detection</b></br>
Authors: , Hu, Meiqi, Wu, Chen, Du, Bo, Zhang, Liangpei</br>
  Characterized by tremendous spectral information, hyperspectral image is able to detect subtle changes and discriminate various change classes for change detection. The recent research works dominated by hyperspectral binary change detection, however, cannot provide fine change classes information. And most methods incorporating spectral unmixing for hyperspectral multiclass change detection (HMCD), yet suffer from the neglection of temporal correlation and error accumulation. In this study, we proposed an unsupervised Binary Change Guided hyperspectral multiclass change detection Network (BCG-Net) for HMCD, which aims at boosting the multiclass change detection result and unmixing result with the mature binary change detection approaches. In BCG-Net, a novel partial-siamese united-unmixing module is designed for multi-temporal spectral unmixing, and a groundbreaking temporal correlation constraint directed by the pseudo-labels of binary change detection result is developed to guide the unmixing process from the perspective of change detection, encouraging the abundance of the unchanged pixels more coherent and that of the changed pixels more accurate. Moreover, an innovative binary change detection rule is put forward to deal with the problem that traditional rule is susceptible to numerical values. The iterative optimization of the spectral unmixing process and the change detection process is proposed to eliminate the accumulated errors and bias from unmixing result to change detection result. The experimental results demonstrate that our proposed BCG-Net could achieve comparative or even outstanding performance of multiclass change detection among the <font color="#00be00">state-of-the-art</font> approaches and gain better spectral unmixing results at the same time. </br></br>

<a href='http://arxiv.org/pdf/2112.07662.pdf'>2112.07662</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.8210баллов, №293</br>
<b>Out-of-Distribution Detection without Class Labels</b></br>
Authors: , Cohen, Niv, Abutbul, Ron, Hoshen, Yedid</br>
  <font color="#be00be">Anomal</font>y detection methods identify samples that deviate from the normal behavior of the dataset. It is typically tackled either for training sets containing normal data from multiple labeled classes or a single unlabeled class. Current methods struggle when faced with training data consisting of multiple classes but no labels. In this work, we first discover that classifiers learned by self-supervised image <font color="#be00be">clustering</font> methods provide a strong baseline for anomaly detection on unlabeled multi-class datasets. Perhaps <font color="#00be00">surprisin</font>gly, we find that initializing clustering methods with pre-trained features does not improve over their self-supervised counterparts. This is due to the phenomenon of catastrophic forgetting. Instead, we suggest a two stage approach. We first cluster images using self-supervised methods and obtain a cluster label for every image. We use the cluster labels as &quot;pseudo supervision&quot; for out-of-distribution (OOD) methods. Specifically, we finetune pretrained features on the task of classifying images by their cluster labels. We provide extensive analyses of our method and demonstrate the necessity of our two-stage approach. We evaluate it against the <font color="#00be00">state-of-the-art</font> self-supervised and pretrained methods and demonstrate superior performance. </br></br>

<a href='http://arxiv.org/pdf/2112.08594.pdf'>2112.08594</a> &nbsp&nbsp (cs:CV, cs:CL) &nbsp&nbsp 0.8208баллов, №294</br>
<b>Twitter-COMMs: Detecting <font color="#be00be">Climate</font>, COVID, and Military Multimodal\n  Misinformation</b></br>
Authors: , Biamby, Giscard, Luo, Grace, Darrell, Trevor, Rohrbach, Anna</br>
  Detecting out-of-context media, such as &quot;miscaptioned&quot; images on Twitter, often requires detecting inconsistencies between the two modalities. This paper describes our approach to the Image-Text Inconsistency Detection challenge of the DARPA Semantic Forensics (SemaFor) Program. First, we collect Twitter-COMMs, a large-scale multimodal dataset with 884k tweets relevant to the topics of <font color="#be00be">Climate</font> Change, COVID-19, and Military Vehicles. We train our approach, based on the <font color="#00be00">state-of-the-art</font> CLIP model, leveraging automatically generated random and hard negatives. Our method is then tested on a hidden human-generated evaluation set. We achieve the best result on the program leaderboard, with 11% detection improvement in a high precision regime over a <font color="#00be00">zero-shot</font> CLIP baseline. </br></br>

<a href='http://arxiv.org/pdf/2112.06419.pdf'>2112.06419</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.8204баллов, №295</br>
<b>Stacked Generative Machine Learning Models for Fast Approximations of\n  Steady-State Navier-Stokes Equations</b></br>
Authors: , Wang, Shen, Nikfar, Mehdi, Agar, Joshua C., Liu, Yaling</br>
  Computational fluid dynamics (CFD) simulations are broadly applied in engineering and physics. A standard description of fluid dynamics requires solving the Navier-Stokes (N-S) equations in different flow regimes. However, applications of CFD simulations are computationally-limited by the availability, speed, and parallelism of high-performance computing. To improve computational efficiency, machine learning techniques have been used to create accelerated data-driven approximations for CFD. A majority of such approaches rely on large labeled CFD datasets that are expensive to obtain at the scale necessary to build robust data-driven models. We develop a weakly-supervised approach to solve the steady-state N-S equations under various boundary conditions, using a multi-channel input with boundary and geometric conditions. We achieve <font color="#00be00">state-of-the-art</font> results without any labeled simulation data, but using a custom data-driven and physics-informed loss function by using and small-scale solutions to prime the model to solve the N-S equations. To improve the resolution and predictability, we train stacked models of increasing complexity generating the numerical solutions for N-S equations. Without expensive computations, our model achieves high predictability with a variety of obstacles and boundary conditions. Given its high flexibility, the model can generate a solution on a 64 x 64 domain within 5 ms on a regular desktop computer which is 1000 times faster than a regular CFD solver. Translation of interactive CFD simulation on local consumer computing hardware enables new applications in real-time predictions on the internet of things devices where data transfer is prohibitive and can increase the scale, speed, and computational cost of boundary-value fluid problems. </br></br>

<a href='http://arxiv.org/pdf/2112.05910.pdf'>2112.05910</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 0.8156баллов, №296</br>
<b>An Empirical Study on Relation Extraction in the Bio<font color="#640064">medic</font>al Domain</b></br>
Authors: , Li, Yongkang</br>
  Relation extraction is a fundamental problem in natural language processing. Most existing models are defined for relation extraction in the general domain. However, their performance on specific domains (e.g., bio<font color="#640064">medic</font>ine) is yet unclear. To fill this gap, this paper carries out an empirical study on relation extraction in biomedical research articles. Specifically, we consider both sentence-level and document-level relation extraction, and run a few <font color="#00be00">state-of-the-art</font> methods on several benchmark datasets. Our results show that (1) current document-level relation extraction methods have strong generalization ability; (2) existing methods require a large amount of labeled data for model fine-tuning in biomedicine. Our observations may inspire people in this field to develop more effective models for biomedical relation extraction. </br></br>

<a href='http://arxiv.org/pdf/2112.08091.pdf'>2112.08091</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.8155баллов, №297</br>
<b>Ensuring DNN Solution Feasibility for Optimization Problems with Convex\n  Constraints and Its Application to DC Optimal Power Flow Problems</b></br>
Authors: , Zhao, Tianyu, Pan, Xiang, Chen, Minghua, Low, Steven H.</br>
  Ensuring solution feasibility is a key challenge in developing Deep Neural Network (DNN) schemes for solving constrained optimization problems, due to inherent DNN prediction errors. In this paper, we propose a &quot;preventive learning\'&quot; framework to systematically guarantee DNN solution feasibility for problems with convex constraints and general objective functions. We first apply a predict-and-reconstruct design to not only guarantee equality constraints but also exploit them to reduce the number of variables to be predicted by DNN. Then, as a key methodological contribution, we systematically calibrate inequality constraints used in DNN training, thereby anticipating prediction errors and ensuring the resulting solutions remain feasible. We characterize the calibration magnitudes and the DNN size sufficient for ensuring universal feasibility. We propose a new Adversary-Sample Aware training algorithm to improve DNN\'s optimality performance without sacrificing feasibility guarantee. Overall, the framework provides two DNNs. The first one from characterizing the sufficient DNN size can guarantee universal feasibility while the other from the proposed training algorithm further improves optimality and maintains DNN\'s universal feasibility simultaneously. We apply the preventive learning framework to develop DeepOPF+ for solving the essential DC optimal power flow problem in grid operation. It improves over existing DNN-based schemes in ensuring feasibility and attaining consistent desirable speedup performance in both light-load and heavy-load regimes. Simulation results over IEEE Case-30/118/300 test cases show that DeepOPF+ generates $100\\%$ feasible solutions with $&lt;$0.5% optimality loss and up to two orders of magnitude computational speedup, as compared to a <font color="#00be00">state-of-the-art</font> iterative solver. </br></br>

<a href='http://arxiv.org/pdf/2112.07516.pdf'>2112.07516</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.8147баллов, №298</br>
<b>Transferrable Contrastive Learning for Visual Domain Adaptation</b></br>
Authors: , Chen, Yang, Pan, Yingwei, Wang, Yu, Yao, Ting, Tian, Xinmei, Mei, Tao</br>
  Self-supervised learning (SSL) has recently become the favorite among feature learning methodologies. It is therefore appealing for domain adaptation approaches to consider incorporating SSL. The intuition is to enforce instance-level feature consistency such that the predictor becomes somehow invariant across domains. However, most existing SSL methods in the regime of domain adaptation usually are treated as standalone auxiliary components, leaving the signatures of domain adaptation unattended. Actually, the optimal region where the domain gap vanishes and the instance level constraint that SSL peruses may not coincide at all. From this point, we present a particular paradigm of self-supervised learning tailored for domain adaptation, i.e., Transferrable Contrastive Learning (TCL), which links the SSL and the desired cross-domain transferability congruently. We find contrastive learning intrinsically a suitable candidate for domain adaptation, as its instance invariance assumption can be conveniently promoted to cross-domain class-level invariance favored by domain adaptation tasks. Based on particular memory bank constructions and pseudo label strategies, TCL then penalizes cross-domain intra-class domain discrepancy between source and target through a clean and novel contrastive loss. The free lunch is, thanks to the incorporation of contrastive learning, TCL relies on a moving-averaged key encoder that naturally achieves a temporally ensembled version of pseudo labels for target data, which avoids pseudo label error propagation at no extra cost. TCL therefore efficiently reduces cross-domain gaps. Through extensive experiments on benchmarks (Office-Home, VisDA-2017, Digits-five, PACS and DomainNet) for both single-source and multi-source domain adaptation tasks, TCL has demonstrated <font color="#00be00">state-of-the-art</font> performances. </br></br>

<a href='http://arxiv.org/pdf/2112.08916.pdf'>2112.08916</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.8081баллов, №299</br>
<b>GOSH: Task Scheduling Using Deep Surrogate Models in Fog Computing\n  Environments</b></br>
Authors: , Tuli, Shreshth, Casale, Giuliano, Jennings, Nicholas R.</br>
  Recently, intelligent scheduling approaches using surrogate models have been proposed to efficiently allocate volatile tasks in heterogeneous fog environments. Advances like deterministic surrogate models, deep neural networks (DNN) and gradient-based optimization allow low energy consumption and response times to be reached. However, deterministic surrogate models, which estimate objective values for optimization, do not consider the uncertainties in the distribution of the Quality of Service (QoS) objective function that can lead to high Service Level Agreement (SLA) violation rates. Moreover, the brittle nature of DNN training and prevent such models from reaching minimal energy or response times. To overcome these difficulties, we present a novel scheduler: GOSH i.e. Gradient Based Optimization using Second Order derivatives and Heteroscedastic Deep Surrogate Models. GOSH uses a second-order gradient based optimization approach to obtain better QoS and reduce the number of iterations to converge to a scheduling decision, subsequently lowering the scheduling time. Instead of a vanilla DNN, GOSH uses a Natural Parameter Network to approximate objective scores. Further, a Lower Confidence Bound optimization approach allows GOSH to find an optimal trade-off between greedy minimization of the mean latency and uncertainty reduction by employing error-based exploration. Thus, GOSH and its co-simulation based extension GOSH*, can adapt quickly and reach better objective scores than baseline methods. We show that GOSH* reaches better objective scores than GOSH, but it is suitable only for high resource availability settings, whereas GOSH is apt for limited resource settings. Real system experiments for both GOSH and GOSH* show significant improvements against the <font color="#00be00">state-of-the-art</font> in terms of energy consumption, response time and SLA violations by up to 18, 27 and 82 percent, respectively. </br></br>

<a href='http://arxiv.org/pdf/2112.07515.pdf'>2112.07515</a> &nbsp&nbsp (cs:CV, cs:AI, cs:CL) &nbsp&nbsp 0.7994баллов, №300</br>
<b>CoCo-BERT: Improving Video-Language Pre-training with Contrastive\n  Cross-modal Matching and Denoising</b></br>
Authors: , Luo, Jianjie, Li, Yehao, Pan, Yingwei, Yao, Ting, Chao, Hongyang, Mei, Tao</br>
  BERT-type structure has led to the revolution of vision-language pre-training and the achievement of <font color="#00be00">state-of-the-art</font> results on numerous vision-language downstream tasks. Existing solutions dominantly capitalize on the multi-modal inputs with mask tokens to trigger mask-based proxy pre-training tasks (e.g., masked language modeling and masked object/frame prediction). In this work, we argue that such masked inputs would inevitably introduce noise for cross-modal matching proxy task, and thus leave the inherent vision-language association under-explored. As an alternative, we derive a particular form of cross-modal proxy objective for video-language pre-training, i.e., Contrastive Cross-modal matching and denoising (CoCo). By viewing the masked frame/word sequences as the noisy augmentation of primary unmasked ones, CoCo strengthens video-language association by simultaneously pursuing inter-modal matching and intra-modal denoising between masked and unmasked inputs in a contrastive manner. Our CoCo proxy objective can be further integrated into any BERT-type encoder-decoder structure for video-language pre-training, named as Contrastive Cross-modal<font color="#00be00"> BERT </font>(CoCo-BERT). We pre-train CoCo-BERT on TV dataset and a newly collected large-scale GIF video dataset (ACTION). Through extensive experiments over a wide range of downstream tasks (e.g., cross-modal <font color="#be00be">retrieval</font>, video question answering, and video captioning), we demonstrate the superiority of CoCo-BERT as a pre-trained structure. </br></br>

<a href='http://arxiv.org/pdf/2112.07434.pdf'>2112.07434</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 0.7971баллов, №301</br>
<b>Exploring the Limits of Natural Language Inference Based Setup for\n  <font color="#00be00">Few-Shot</font> Intent Detection</b></br>
Authors: , Malik, Vijit, Kumar, Ayush, Veppa, Jithendra</br>
  One of the core components of goal-oriented dialog systems is the task of Intent Detection. <font color="#00be00">Few-shot</font> Learning upon Intent Detection is challenging due to the scarcity of available annotated utterances. Although recent works making use of metric-based and optimization-based methods have been proposed, the task is still challenging in large label spaces and much smaller number of shots. Generalized Few-shot learning is more difficult due to the presence of both novel and seen classes during the testing phase. In this work, we propose a simple and effective method based on Natural Language Inference that not only tackles the problem of few shot intent detection, but also proves useful in <font color="#00be00">zero-shot</font> and generalized few shot learning problems. Our extensive experiments on a number of Natural Language Understanding (NLU) and Spoken Language Understanding (SLU) datasets show the effectiveness of our approach. In addition, we highlight the settings in which our NLI based method <font color="#00be00">outperform</font>s the baselines by huge margins. </br></br>

<a href='http://arxiv.org/pdf/2112.04744.pdf'>2112.04744</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.7922баллов, №302</br>
<b>Superpixel-Based Building Damage Detection from Post-earthquake Very\n  High Resolution Imagery Using Deep Neural Networks</b></br>
Authors: , Wang, Jun, Li, Zhoujing, Qiao, Yixuan, Qin, Qiming, Gao, Peng, Xie, Guotong</br>
  Building damage detection after natural disasters like earthquakes is crucial for initiating effective emergency response actions. Remotely sensed very high spatial resolution (VHR) imagery can provide vital information due to their ability to map the affected buildings with high geometric precision. Many approaches have been developed to detect damaged buildings due to earthquakes. However, little attention has been paid to exploiting rich features represented in VHR images using Deep Neural Networks (DNN). This paper presents a novel super-pixel based approach combining DNN and a modified <font color="#be00be">segmentation</font> method, to detect damaged buildings from VHR imagery. Firstly, a modified Fast Scanning and Adaptive Merging method is extended to create initial over-segmentation. Secondly, the segments are merged based on the Region Adjacent Graph (RAG), considered an improved semantic similarity criterion composed of Local Binary Patterns (LBP) texture, spectral, and shape features. Thirdly, a pre-trained DNN using Stacked Denoising Auto-Encoders called SDAE-DNN is presented, to exploit the rich semantic features for building damage detection. Deep-layer feature abstraction of SDAE-DNN could boost detection accuracy through learning more intrinsic and discriminative features, which <font color="#00be00">outperform</font>ed other methods using <font color="#00be00">state-of-the-art</font> alternative classifiers. We demonstrate the feasibility and effectiveness of our method using a subset of WorldView-2 imagery, in the complex urban areas of Bhaktapur, Nepal, which was affected by the Nepal Earthquake of April 25, 2015. </br></br>

<a href='http://arxiv.org/pdf/2112.06447.pdf'>2112.06447</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.7901баллов, №303</br>
<b>SVIP: Sequence VerIfication for Procedures in Videos</b></br>
Authors: , Qian, Yicheng, Luo, Weixin, Lian, Dongze, Tang, Xu, Zhao, Peilin, Gao, Shenghua</br>
  In this paper, we propose a novel sequence verification task that aims to distinguish positive video pairs performing the same action sequence from negative ones with step-level transformations but still conducting the same task. Such a challenging task resides in an open-set setting without prior action detection or <font color="#be00be">segmentation</font> that requires event-level or even frame-level annotations. To that end, we carefully reorganize two <font color="#00be00">publicly available</font> action-related datasets with step-procedure-task structure. To fully investigate the effectiveness of any method, we collect a scripted video dataset enumerating all kinds of step-level transformations in chemical experiments. Besides, a novel evaluation metric Weighted Distance Ratio is introduced to ensure equivalence for different step-level transformations during evaluation. In the end, a simple but effective baseline based on the <font color="#00be00">transformer</font> with a novel sequence alignment loss is introduced to better characterize long-term dependency between steps, which <font color="#00be00">outperform</font>s other action recognition methods. Codes and data will be released. </br></br>

<a href='http://arxiv.org/pdf/2112.05346.pdf'>2112.05346</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.7844баллов, №304</br>
<b>Findings on Conversation Disentanglement</b></br>
Authors: , Zhu, Rongxin, Lau, Jey Han, Qi, Jianzhong</br>
  Conversation disentanglement, the task to identify separate threads in conversations, is an important pre-processing step in multi-party conversational NLP applications such as conversational question answering and conversation <font color="#be00be">summarization</font>. Framing it as a utterance-to-utterance classification problem -- i.e. given an utterance of interest (UOI), find which past utterance it replies to -- we explore a number of <font color="#00be00">transformer</font>-based models and found that<font color="#00be00"> BERT </font>in combination with handcrafted features remains a strong baseline. We then build a multi-task learning model that jointly learns utterance-to-utterance and utterance-to-thread classification. Observing that the ground truth label (past utterance) is in the top candidates when our model makes an error, we experiment with using bipartite graphs as a post-processing step to learn how to best match a set of UOIs to past utterances. Experiments on the Ubuntu IRC dataset show that this approach has the potential to <font color="#00be00">outperform</font> the conventional greedy approach of simply selecting the highest probability candidate for each UOI independently, indicating a promising future research direction. </br></br>

<a href='http://arxiv.org/pdf/2112.07406.pdf'>2112.07406</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.7805баллов, №305</br>
<b>Branching Time Active Inference with <font color="#be00be">Bayes</font>ian Filtering</b></br>
Authors: , Champion, Th&#xe9;ophile, Grze&#x15b;, Marek, Bowman, Howard</br>
  Branching Time Active Inference (Champion et al., 2021b,a) is a framework proposing to look at planning as a form of <font color="#be00be">Bayes</font>ian model expansion. Its root can be found in Active Inference (Friston et al., 2016; Da Costa et al., 2020; Champion et al., 2021c), a neuroscientific framework widely used for <font color="#00be00">brain</font> modelling, as well as in Monte Carlo Tree Search (Browne et al., 2012), a method broadly applied in the <font color="#00be00">Reinforcement Learning</font> literature. Up to now, the inference of the latent variables was carried out by taking advantage of the flexibility offered by Variational Message Passing (Winn and Bishop, 2005), an iterative process that can be understood as sending messages along the edges of a factor graph (Forney, 2001). In this paper, we harness the efficiency of an alternative method for inference called Bayesian Filtering (Fox et al., 2003), which does not require the iteration of the update equations until convergence of the Variational Free Energy. Instead, this scheme alternates between two phases: integration of evidence and prediction of future states. Both of those phases can be performed efficiently and this provides a seventy times speed up over the <font color="#00be00">state-of-the-art</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.06999.pdf'>2112.06999</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.7787баллов, №306</br>
<b>Designing weighted and multiplex networks for deep learning user\n  geolocation in Twitter</b></br>
Authors: , Funes, Federico M., Alvarez-Hamelin, Jos&#xe9; Ignacio, Beir&#xf3;, Mariano G.</br>
  Predicting the geographical location of users of social media like Twitter has found several applications in health <font color="#be00be">surveillance</font>, emergency monitoring, content personalization, and social studies in general. In this work we contribute to the research in this area by designing and evaluating new methods based on the literature of weighted multigraphs combined with <font color="#00be00">state-of-the-art</font> deep learning techniques. The explored methods depart from a similar underlying structure (that of an extended mention and/or follower network) but use different information processing strategies, e.g., information diffusion through transductive and inductive algorithms -- RGCNs and GraphSAGE, respectively -- and node embeddings with Node2vec+. These graphs are then combined with attention mechanisms to incorporate the users\' text view into the models. We assess the performance of each of these methods and compare them to baseline models in the <font color="#00be00">publicly available</font> Twitter-US dataset; we also make a new dataset available based on a large Twitter capture in Latin America. Finally, our work discusses the limitations and validity of the comparisons among methods in the context of different label definitions and metrics. </br></br>

<a href='http://arxiv.org/pdf/2111.14192.pdf'>2111.14192</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.7741баллов, №307</br>
<b><font color="#00be00">Zero-Shot</font> Cross-Lingual Transfer in Legal Domain Using <font color="#00be00">Transformer</font>\n  Models</b></br>
Authors: , Shaheen, Zein, Wohlgenannt, Gerhard, Mouromtsev, Dmitry</br>
  <font color="#00be00">Zero-shot</font> cross-lingual transfer is an important feature in modern NLP models and architectures to support <font color="#be00be">low-resource</font> languages. In this work, We study zero-shot cross-lingual transfer from English to French and German under Multi-Label Text Classification, where we train a classifier using English training set, and we test using French and German test sets. We extend EURLEX57K dataset, the English dataset for topic classification of legal documents, with French and German official translation. We investigate the effect of using some training techniques, namely Gradual Unfreezing and Language Model finetuning, on the quality of zero-shot cross-lingual transfer. We find that Language model finetuning of multi-lingual pre-trained model (M-DistilBERT, M-BERT) leads to 32.0-34.94%, 76.15-87.54% relative improvement on French and German test sets correspondingly. Also, Gradual unfreezing of pre-trained model\'s layers during training results in relative improvement of 38-45% for French and 58-70% for German. Compared to training a model in Joint Training scheme using English, French and German training sets, zero-shot BERT-based classification model reaches 86% of the performance achieved by jointly-trained BERT-based classification model. </br></br>

<a href='http://arxiv.org/pdf/2112.06242.pdf'>2112.06242</a> &nbsp&nbsp (cs:CV, cs:ML, cs:RO) &nbsp&nbsp 0.7615баллов, №308</br>
<b>Image Reconstruction from Events. Why learn it?</b></br>
Authors: , Zhang, Zelin, Yezzi, Anthony, Gallego, Guillermo</br>
  Traditional cameras measure image intensity. Event cameras, by contrast, measure per-pixel temporal intensity changes asynchronously. Recovering intensity from events is a popular research topic since the reconstructed images inherit the high dynamic range (HDR) and high-speed properties of events; hence they can be used in many robotic vision applications and to generate slow-motion HDR videos. However, <font color="#00be00">state-of-the-art</font> methods tackle this problem by training an event-to-image recurrent neural network (RNN), which lacks explainability and is difficult to tune. In this work we show, for the first time, how tackling the joint problem of motion and intensity estimation leads us to model event-based image reconstruction as a linear inverse problem that can be solved without training an image reconstruction RNN. Instead, classical and learning-based image priors can be used to solve the problem and remove artifacts from the reconstructed images. The experiments show that the proposed approach generates images with visual quality on par with state-of-the-art methods despite only using data from a short time interval (i.e., without recurrent connections). Our method can also be used to improve the quality of images reconstructed by approaches that first estimate the image Laplacian; here our method can be <font color="#be00be">interpret</font>ed as Poisson reconstruction guided by image priors. </br></br>

<a href='http://arxiv.org/pdf/2112.05846.pdf'>2112.05846</a> &nbsp&nbsp (cs:CV, cs:RO) &nbsp&nbsp 0.7583баллов, №309</br>
<b>Semantic Interaction in Augmented Reality Environments for Microsoft\n  HoloLens</b></br>
Authors: , Sch&#xfc;ett, Peer, Schwarz, Max, Behnke, Sven</br>
  Augmented Reality is a promising technique for human-machine interaction. Especially in robotics, which always considers systems in their environment, it is highly beneficial to display visualizations and receive user input directly in exactly that environment. We explore this idea using the Microsoft HoloLens, with which we capture indoor environments and display interaction cues with known object classes. The 3D mesh recorded by the HoloLens is annotated on-line, as the user moves, with semantic classes using a projective approach, which allows us to use a <font color="#00be00">state-of-the-art</font> 2D semantic <font color="#be00be">segmentation</font> method. The results are fused onto the mesh; prominent object segments are identified and displayed in 3D to the user. Finally, the user can trigger actions by gesturing at the object. We both present qualitative results and analyze the accuracy and performance of our method in detail on an indoor dataset. </br></br>

<a href='http://arxiv.org/pdf/2112.06251.pdf'>2112.06251</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.7557баллов, №310</br>
<b>Learning with Subset Stacking</b></br>
Authors: , Birbil, S. Ilker, Yildirim, Sinan, Gokalp, Kaya, Akyuz, Hakan</br>
  We propose a new algorithm that learns from a set of input-output pairs. Our algorithm is designed for populations where the relation between the input variables and the output variable exhibits a heterogeneous behavior across the predictor space. The algorithm starts with generating subsets that are concentrated around random points in the input space. This is followed by training a local predictor for each subset. Those predictors are then combined in a novel way to yield an overall predictor. We call this algorithm &quot;LEarning with Subset Stacking&quot; or LESS, due to its resemblance to method of stacking regressors. We compare the testing performance of LESS with the <font color="#00be00">state-of-the-art</font> methods on several datasets. Our comparison shows that LESS is a <font color="#960096">competitive</font> supervised learning method. Moreover, we observe that LESS is also efficient in terms of computation time and it allows a straightforward parallel implementation. </br></br>

<a href='http://arxiv.org/pdf/2112.06104.pdf'>2112.06104</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.7523баллов, №311</br>
<b>Synthetic Map Generation to Provide Unlimited Training Data for\n  Historical Map Text Detection</b></br>
Authors: , Li, Zekun, Guan, Runyu, Yu, Qianmu, Chiang, Yao-Yi, Knoblock, Craig A.</br>
  Many historical map sheets are <font color="#00be00">publicly available</font> for studies that require long-term historical geographic data. The cartographic design of these maps includes a combination of map symbols and text labels. Automatically reading text labels from map images could greatly speed up the map <font color="#be00be">interpret</font>ation and helps generate rich metadata describing the map content. Many text detection algorithms have been proposed to locate text regions in map images automatically, but most of the algorithms are trained on out-ofdomain datasets (e.g., scenic images). Training data determines the quality of machine learning models, and manually annotating text regions in map images is labor-extensive and time-consuming. On the other hand, existing geographic data sources, such as Open- StreetMap (OSM), contain machine-readable map layers, which allow us to separate out the text layer and obtain text label annotations easily. However, the cartographic <font color="#be00be">style</font>s between OSM map tiles and historical maps are significantly different. This paper proposes a method to automatically generate an unlimited amount of annotated historical map images for training text detection models. We use a style transfer model to convert contemporary map images into historical style and place text labels upon them. We show that the <font color="#00be00">state-of-the-art</font> text detection models (e.g., PSENet) can benefit from the synthetic historical maps and achieve significant improvement for historical map text detection. </br></br>

<a href='http://arxiv.org/pdf/2112.05343.pdf'>2112.05343</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.7512баллов, №312</br>
<b>Blockwise Sequential Model Learning for Partially Observable\n  <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Park, Giseung, Choi, Sungho, Sung, Youngchul</br>
  This paper proposes a new sequential model learning architecture to solve partially observable Markov decision problems. Rather than compressing sequential information at every timestep as in conventional recurrent neural network-based methods, the proposed architecture generates a latent variable in each data block with a length of multiple timesteps and passes the most relevant information to the next block for policy optimization. The proposed blockwise sequential model is implemented based on self-attention, making the model capable of detailed sequential learning in partial observable settings. The proposed model builds an additional learning network to efficiently implement gradient estimation by using self-normalized importance sampling, which does not require the complex blockwise input data reconstruction in the model learning. Numerical results show that the proposed method significantly <font color="#00be00">outperform</font>s previous methods in various partially observable environments. </br></br>

<a href='http://arxiv.org/pdf/2112.02157.pdf'>2112.02157</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.7498баллов, №313</br>
<b>A Web of Confocal Parabolas in a Grid of Hexagons</b></br>
Authors: , Moses, Peter, Reznik, Dan</br>
  If one erects regular hexagons upon the sides of a triangle $T$, several <font color="#00be00">surprisin</font>g properties emerge, including: (i) the triangles which flank said hexagons have an isodynamic point common with $T$, (ii) the construction can be extended iteratively, forming an infinite grid of regular hexagons and flank triangles, (iii) a web of confocal parabolas with only three distinct foci interweaves the vertices of hexagons in the grid. Finally, (iv) said foci are the vertices of an equilateral triangle. </br></br>

<a href='http://arxiv.org/pdf/2112.06185.pdf'>2112.06185</a> &nbsp&nbsp (cs:RO, cs:AI) &nbsp&nbsp 0.7464баллов, №314</br>
<b>Multi-Agent Vulnerability Discovery for Autonomous Driving with Hazard\n  Arbitration Reward</b></br>
Authors: , Liu, Weilin, Mu, Ye, Yu, Chao, Ning, Xuefei, Cao, Zhong, Wu, Yi, Liang, Shuang, Yang, Huazhong, Wang, Yu</br>
  Discovering hazardous scenarios is crucial in testing and further improving driving policies. However, conducting efficient driving policy testing faces two key challenges. On the one hand, the probability of naturally encountering hazardous scenarios is low when testing a well-trained autonomous driving strategy. Thus, discovering these scenarios by purely <font color="#009600">real-world</font> road testing is extremely costly. On the other hand, a proper determination of accident responsibility is necessary for this task. Collecting scenarios with wrong-attributed responsibilities will lead to an overly conservative autonomous driving strategy. To be more specific, we aim to discover hazardous scenarios that are autonomous-vehicle responsible (AV-responsible), i.e., the vulnerabilities of the under-test driving policy.   To this end, this work proposes a Safety Test framework by finding Av-Responsible Scenarios (STARS) based on multi-agent <font color="#00be00">reinforcement learning</font>. STARS guides other traffic participants to produce Av-Responsible Scenarios and make the under-test driving policy misbehave via introducing Hazard Arbitration Reward (HAR). HAR enables our framework to discover diverse, complex, and AV-responsible hazardous scenarios. Experimental results against four different driving policies in three environments demonstrate that STARS can effectively discover AV-responsible hazardous scenarios. These scenarios indeed correspond to the vulnerabilities of the under-test driving policies, thus are meaningful for their further improvements. </br></br>

<a href='http://arxiv.org/pdf/2112.07878.pdf'>2112.07878</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.7396баллов, №315</br>
<b>Gaze Estimation with Eye Region <font color="#be00be">Segmentation</font> and Self-Supervised\n  Multistream Learning</b></br>
Authors: , Mahmud, Zunayed, Hungler, Paul, Etemad, Ali</br>
  We present a novel multistream network that learns robust eye representations for gaze estimation. We first create a synthetic dataset containing eye region masks detailing the visible eyeball and iris using a simulator. We then perform eye region <font color="#be00be">segmentation</font> with a U-Net type model which we later use to generate eye region masks for <font color="#009600">real-world</font> eye images. Next, we pretrain an eye image encoder in the real domain with self-supervised contrastive learning to learn generalized eye representations. Finally, this pretrained eye encoder, along with two additional encoders for visible eyeball region and iris, are used in parallel in our multistream framework to extract salient features for gaze estimation from real-world images. We demonstrate the performance of our method on the EYEDIAP dataset in two different evaluation settings and achieve <font color="#00be00">state-of-the-art</font> results, <font color="#00be00">outperform</font>ing all the existing benchmarks on this dataset. We also conduct additional experiments to validate the robustness of our self-supervised network with respect to different amounts of labeled data used for training. </br></br>

<a href='http://arxiv.org/pdf/2112.07380.pdf'>2112.07380</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.7372баллов, №316</br>
<b>TRACER: Extreme Attention Guided Salient Object Tracing Network</b></br>
Authors: , Lee, Min Seok, Shin, WooSeok, Han, Sung Won</br>
  Existing studies on salient <font color="#be00be">object detection</font> (SOD) focus on extracting distinct objects with edge information and aggregating multi-level features to improve SOD performance. To achieve satisfactory performance, the methods employ refined edge information and low multi-level discrepancy. However, both performance gain and computational efficiency cannot be attained, which has motivated us to study the inefficiencies in existing encoder-decoder structures to avoid this trade-off. We propose TRACER, which detects salient objects with explicit edges by incorporating attention guided tracing modules. We employ a masked edge attention module at the end of the first encoder using a fast Fourier transform to propagate the refined edge information to the downstream feature extraction. In the multi-level aggregation phase, the union attention module identifies the complementary channel and important spatial information. To improve the decoder performance and computational efficiency, we minimize the decoder block usage with object attention module. This module extracts undetected objects and edge information from refined channels and spatial representations. Subsequently, we propose an adaptive pixel intensity loss function to deal with the relatively important pixels unlike conventional loss functions which treat all pixels equally. A comparison with 13 existing methods reveals that TRACER achieves <font color="#00be00">state-of-the-art</font> performance on five benchmark datasets. In particular, TRACER-Efficient3 (TE3) <font color="#00be00">outperform</font>s LDF, an existing method while requiring 1.8x fewer learning parameters and less time; TE3 is 5x faster. </br></br>

<a href='http://arxiv.org/pdf/2112.05996.pdf'>2112.05996</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.7298баллов, №317</br>
<b>Formalising the Foundations of Discrete <font color="#00be00">Reinforcement Learning</font> in\n  Isabelle/HOL</b></br>
Authors: , Chevallier, Mark, Fleuriot, Jacques</br>
  We present a formalisation of finite Markov decision processes with rewards in the Isabelle <font color="#be00be">theor</font>em prover. We focus on the foundations required for dynamic programming and the use of <font color="#00be00">reinforcement learning</font> agents over such processes. In particular, we derive the Bellman equation from first principles (in both scalar and vector form), derive a vector calculation that produces the expected value of any policy p, and go on to prove the existence of a universally optimal policy where there is a discounting factor less than one. Lastly, we prove that the value iteration and the policy iteration algorithms work in finite time, producing an epsilon-optimal and a fully optimal policy respectively. </br></br>

<a href='http://arxiv.org/pdf/2112.07041.pdf'>2112.07041</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.7294баллов, №318</br>
<b>Survey of Generative Methods for Social Media Analysis</b></br>
Authors: , Matwin, Stan, Milios, Aristides, Pra&#x142;at, Pawe&#x142;, Soares, Amilcar, Th&#xe9;berge, Fran&#xe7;ois</br>
  This survey draws a broad-stroke, panoramic picture of the <font color="#00be00">State of the Art</font> (SoTA) of the research in generative methods for the analysis of social media data. It fills a void, as the existing survey articles are either much narrower in their scope or are dated. We included two important aspects that currently gain importance in mining and modeling social media: dynamics and networks. Social dynamics are important for understanding the spreading of influence or <font color="#be00be">diseas</font>es, formation of friendships, the productivity of teams, etc. Networks, on the other hand, may capture various complex relationships providing additional insight and identifying important patterns that would otherwise go unnoticed. </br></br>

<a href='http://arxiv.org/pdf/2111.08872.pdf'>2111.08872</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.7274баллов, №319</br>
<b>TorchGeo: deep learning with geospatial data</b></br>
Authors: , Stewart, Adam J., Robinson, Caleb, Corley, Isaac A., Ortiz, Anthony, Ferres, Juan M. Lavista, Banerjee, Arindam</br>
  Remotely sensed geospatial data are critical for applications including precision agriculture, urban planning, disaster monitoring and response, and <font color="#be00be">climate</font> change research, among others. Deep learning methods are particularly promising for modeling many remote sensing tasks given the success of deep neural networks in similar computer vision tasks and the sheer volume of remotely sensed imagery available. However, the variance in data collection methods and handling of geospatial metadata make the application of deep learning methodology to remotely sensed data nontrivial. For example, satellite imagery often includes additional spectral bands beyond red, green, and blue and must be joined to other geospatial data sources that can have differing coordinate systems, bounds, and resolutions. To help realize the potential of deep learning for remote sensing applications, we introduce TorchGeo, a Python library for integrating geospatial data into the PyTorch deep learning ecosystem. TorchGeo provides data loaders for a variety of benchmark datasets, composable datasets for generic geospatial data sources, samplers for geospatial data, and transforms that work with multispectral imagery. TorchGeo is also the first library to provide pre-trained models for multispectral satellite imagery (e.g. models that use all bands from the Sentinel 2 satellites), allowing for advances in transfer learning on downstream remote sensing tasks with limited labeled data. We use TorchGeo to create reproducible benchmark results on existing datasets and benchmark our proposed method for preprocessing geospatial imagery on-the-fly. TorchGeo is open-source and available on <font color="#00be00">GitHub</font>: <font color="#006400">http</font>s://github.com/microsoft/torchgeo. </br></br>

<a href='http://arxiv.org/pdf/2112.06953.pdf'>2112.06953</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp 0.7229баллов, №320</br>
<b>Controlled Cue Generation for Play Scripts</b></br>
Authors: , Dirik, Alara, Donmez, Hilal, Yanardag, Pinar</br>
  In this paper, we use a large-scale play scripts dataset to propose the novel task of theatrical cue generation from dialogues. Using over one million lines of dialogue and cues, we approach the problem of cue generation as a controlled text generation task, and show how cues can be used to enhance the impact of dialogue using a language model conditioned on a dialogue/cue discriminator. In addition, we explore the use of topic keywords and <font color="#be00be">emotion</font>s for controlled text generation. Extensive quantitative and qualitative experiments show that language models can be successfully used to generate plausible and attribute-controlled texts in highly specialised domains such as play scripts. Supporting materials can be found at: <font color="#006400">http</font>s://catlab-team.<font color="#00be00">github</font>.io/cuegen. </br></br>

<a href='http://arxiv.org/pdf/2112.06530.pdf'>2112.06530</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.7222баллов, №321</br>
<b>Centroid-UNet: Detecting Centroids in Aerial Images</b></br>
Authors: , Deshapriya, N. Lakmal, Tran, Dan, Reddy, Sriram, Gunasekara, Kavinda</br>
  In many applications of aerial/satellite image analysis (remote sensing), the generation of exact shapes of objects is a cumbersome task. In most remote sensing applications such as counting objects requires only location estimation of objects. Hence, locating object centroids in aerial/satellite images is an easy solution for tasks where the object\'s exact shape is not necessary. Thus, this study focuses on assessing the feasibility of using deep neural networks for locating object centroids in satellite images. Name of our model is Centroid-UNet. The Centroid-UNet model is based on classic U-Net semantic <font color="#be00be">segmentation</font> architecture. We modified and adapted the U-Net semantic segmentation architecture into a centroid detection model preserving the simplicity of the original model. Furthermore, we have tested and evaluated our model with two case studies involving aerial/satellite images. Those two case studies are building centroid detection case study and coconut tree centroid detection case study. Our evaluation results have reached comparably good accuracy compared to other methods, and also offer simplicity. The code and models developed under this study are also available in the Centroid-UNet <font color="#00be00">GitHub</font> repository: <font color="#006400">http</font>s://github.com/gicait/centroid-unet </br></br>

<a href='http://arxiv.org/pdf/2112.06390.pdf'>2112.06390</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.7162баллов, №322</br>
<b>PartGlot: Learning Shape Part <font color="#be00be">Segmentation</font> from Language Reference Games</b></br>
Authors: , Koo, Juil, Huang, Ian, Achlioptas, Panos, Guibas, Leonidas, Sung, Minhyuk</br>
  We introduce PartGlot, a neural framework and associated architectures for learning semantic part <font color="#be00be">segmentation</font> of 3D shape geometry, based solely on part referential language. We exploit the fact that linguistic descriptions of a shape can provide priors on the shape\'s parts -- as natural language has evolved to reflect human perception of the compositional structure of objects, essential to their recognition and use. For training, we use the paired geometry / language data collected in the ShapeGlot work for their reference game, where a speaker creates an utterance to differentiate a target shape from two distractors and the listener has to find the target based on this utterance. Our network is designed to solve this target discrimination problem, carefully incorporating a <font color="#00be00">Transformer</font>-based attention module so that the output attention can precisely highlight the semantic part or parts described in the language. Furthermore, the network operates without any direct supervision on the 3D geometry itself. <font color="#00be00">Surprisin</font>gly, we further demonstrate that the learned part information is generalizable to shape classes unseen during training. Our approach opens the possibility of learning 3D shape parts from language alone, without the need for large-scale part geometry annotations, thus facilitating annotation acquisition. </br></br>

<a href='http://arxiv.org/pdf/2112.04421.pdf'>2112.04421</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.7148баллов, №323</br>
<b>SoK: Vehicle Orientation Representations for Deep Rotation Estimation</b></br>
Authors: , Tu, Huahong, Peng, Siyuan, Leung, Vladimir, Gao, Richard</br>
  In recent years, there is an influx of deep learning models for 3D vehicle <font color="#be00be">object detection</font>. However, little attention was paid to orientation prediction. Existing research work proposed various vehicle orientation representation methods for deep learning, however a holistic, systematic review has not been conducted. Through our experiments, we categorize and compare the accuracy performance of various existing orientation representations using the KITTI 3D object detection dataset, and propose a new form of orientation representation: Tricosine. Among these, the 2D Cartesian-based representation, or Single Bin, achieves the highest accuracy, with additional channeled inputs (positional encoding and depth map) not boosting prediction performance. Our code is published on <font color="#00be00">GitHub</font>: <font color="#006400">http</font>s://github.com/umd-fire-coml/KITTI-orientation-learning </br></br>

<a href='http://arxiv.org/pdf/2112.08526.pdf'>2112.08526</a> &nbsp&nbsp (cs:ML, cs:RO) &nbsp&nbsp 0.7118баллов, №324</br>
<b>Invariance Through Inference</b></br>
Authors: , Yoneda, Takuma, Yang, Ge, Walter, Matthew R., Stadie, Bradly</br>
  We introduce a general approach, called Invariance through Inference, for improving the test-time performance of an agent in deployment environments with unknown perceptual variations. Instead of producing invariant visual features through interpolation, invariance through inference turns adaptation at deployment-time into an unsupervised learning problem. This is achieved in practice by deploying a straightforward algorithm that tries to match the distribution of latent features to the agent\'s prior experience, without relying on paired data. Although simple, we show that this idea leads to <font color="#00be00">surprisin</font>g improvements on a variety of adaptation scenarios without access to deployment-time rewards, including changes in camera poses and lighting conditions. Results are presented on challenging distractor control suite, a robotics environment with image-based observations. </br></br>

<a href='http://arxiv.org/pdf/2112.07719.pdf'>2112.07719</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.7111баллов, №325</br>
<b>Identifying Class Specific Filters with L1 Norm Frequency Histograms in\n  Deep CNNs</b></br>
Authors: , Badola, Akshay, Roy, Cherian, Padmanabhan, Vineet, Lal, Rajendra</br>
  <font color="#be00be">Interpret</font>ability of Deep Neural Networks has become a major area of exploration. Although these networks have achieved <font color="#00be00">state of the art</font> accuracy in many tasks, it is extremely difficult to interpret and explain their decisions. In this work we analyze the final and penultimate layers of Deep Convolutional Networks and provide an efficient method for identifying subsets of features that contribute most towards the network\'s decision for a class. We demonstrate that the number of such features per class is much lower in comparison to the dimension of the final layer and therefore the decision surface of Deep CNNs lies on a low dimensional manifold and is proportional to the network depth. Our methods allow to decompose the final layer into separate subspaces which is far more interpretable and has a lower computational cost as compared to the final layer of the full network. </br></br>

<a href='http://arxiv.org/pdf/2112.06476.pdf'>2112.06476</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.7040баллов, №326</br>
<b>gACSON software for automated <font color="#be00be">segmentation</font> and morphology analyses of\n  myelinated axons in 3D electron microscopy</b></br>
Authors: , Behanova, Andrea, Abdollahzadeh, Ali, Belevich, Ilya, Jokitalo, Eija, Sierra, Alejandra, Tohka, Jussi</br>
  Background and Objective: Advances in electron microscopy (EM) now allow three-dimensional (3D) imaging of hundreds of micrometers of tissue with nanometer-scale resolution, providing new opportunities to study the ultrastructure of the <font color="#00be00">brain</font>. In this work, we introduce a freely available gACSON software for visualization, <font color="#be00be">segmentation</font>, assessment, and morphology analysis of myelinated axons in 3D-EM volumes of brain tissue samples. Methods: The gACSON software is equipped with a graphical user interface (GUI). It automatically segments the intra-axonal space of myelinated axons and their corresponding myelin sheaths and allows manual segmentation, proofreading, and interactive correction of the segmented components. gACSON analyzes the morphology of myelinated axons, such as axonal diameter, axonal eccentricity, myelin thickness, or g-ratio. Results: We illustrate the use of gACSON by segmenting and analyzing myelinated axons in six 3D-EM volumes of rat somatosensory cortex after sham surgery or traumatic brain injury (TBI). Our results suggest that the equivalent diameter of myelinated axons in somatisensory cortex was decreased in TBI animals five months after the injury. Conclusions: Our results indicate that gACSON is a valuable tool for visualization, segmentation, assessment, and morphology analysis of myelinated axons in 3D-EM volumes. gACSON is freely available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/AndreaBehan/g-ACSON under the MIT license. </br></br>

<a href='http://arxiv.org/pdf/2112.05727.pdf'>2112.05727</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.7031баллов, №327</br>
<b>Neural Belief Propagation for Scene Graph Generation</b></br>
Authors: , Liu, Daqi, Bober, Miroslaw, Kittler, Josef</br>
  Scene graph generation aims to <font color="#be00be">interpret</font> an input image by explicitly modelling the potential objects and their relationships, which is predominantly solved by the message passing neural network models in previous methods. Currently, such approximation models generally assume the output variables are totally independent and thus ignore the informative structural higher-order interactions. This could lead to the inconsistent interpretations for an input image. In this paper, we propose a novel neural belief propagation method to generate the resulting scene graph. It employs a structural Bethe approximation rather than the mean field approximation to infer the associated marginals. To find a better bias-variance trade-off, the proposed model not only incorporates pairwise interactions but also higher order interactions into the associated scoring function. It achieves the <font color="#00be00">state-of-the-art</font> performance on various popular scene graph generation benchmarks. </br></br>

<a href='http://arxiv.org/pdf/2112.05621.pdf'>2112.05621</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.7011баллов, №328</br>
<b>Reward-Based Environment States for Robot Manipulation Policy Learning</b></br>
Authors: , Mouliets, C&#xe9;d&#xe9;rick, Ferran&#xe9;, Isabelle, Cuay&#xe1;huitl, Heriberto</br>
  Training robot manipulation policies is a challenging and open problem in robotics and artificial intelligence. In this paper we propose a novel and compact state representation based on the rewards predicted from an image-based task success classifier. Our experiments, using the Pepper robot in simulation with two deep <font color="#00be00">reinforcement learning</font> algorithms on a grab-and-lift task, reveal that our proposed state representation can achieve up to 97% task success using our best policies. </br></br>

<a href='http://arxiv.org/pdf/2112.07066.pdf'>2112.07066</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.7001баллов, №329</br>
<b>Continual Learning In Environments With Polynomial Mixing Times</b></br>
Authors: , Riemer, Matthew, Raparthy, Sharath Chandra, Cases, Ignacio, Subbaraj, Gopeshh, Touzel, Maximilian Puelma, Rish, Irina</br>
  The mixing time of the Markov chain induced by a policy limits performance in <font color="#009600">real-world</font> continual learning scenarios. Yet, the effect of mixing times on learning in continual <font color="#00be00">reinforcement learning</font> (RL) remains underexplored. In this paper, we characterize problems that are of long-term interest to the development of continual RL, which we call scalable MDPs, through the lens of mixing times. In particular, we establish that scalable MDPs have mixing times that scale polynomially with the size of the problem. We go on to demonstrate that polynomial mixing times present significant difficulties for existing approaches and propose a family of model-based algorithms that speed up learning by directly optimizing for the average reward through a novel bootstrapping procedure. Finally, we perform empirical regret analysis of our proposed approaches, demonstrating clear improvements over baselines and also how scalable MDPs can be used for analysis of RL algorithms as mixing times scale. </br></br>

<a href='http://arxiv.org/pdf/2111.15611.pdf'>2111.15611</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 0.6935баллов, №330</br>
<b>The Power of Communication in a Distributed Multi-Agent System</b></br>
Authors: , Siedler, Philipp Dominic</br>
  Single-Agent (SA) <font color="#00be00">Reinforcement Learning</font> systems have shown outstanding re-sults on non-stationary problems. However, Multi-Agent Reinforcement Learning(MARL) can surpass SA systems generally and when scaling. Furthermore, MAsystems can be super-powered by collaboration, which can happen through ob-serving others, or a communication system used to share information betweencollaborators. Here, we developed a distributed MA learning mechanism withthe ability to communicate based on decentralised partially observable Markovdecision processes (Dec-POMDPs) and Graph Neural Networks (GNNs). Minimis-ing the time and energy consumed by training Machine Learning models whileimproving performance can be achieved by collaborative MA mechanisms. Wedemonstrate this in a <font color="#009600">real-world</font> scenario, an offshore wind farm, including a set ofdistributed wind turbines, where the objective is to maximise collective efficiency.Compared to a SA system, MA collaboration has shown significantly reducedtraining time and higher cumulative rewards in unseen and scaled scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.07945.pdf'>2112.07945</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.6908баллов, №331</br>
<b>Efficient Geometry-aware 3D Generative Adversarial Networks</b></br>
Authors: , Chan, Eric R., Lin, Connor Z., Chan, Matthew A., Nagano, Koki, Pan, Boxiao, De Mello, Shalini, Gallo, Orazio, Guibas, Leonidas, Tremblay, Jonathan, Khamis, Sameh, Karras, Tero, Wetzstein, Gordon</br>
  Unsupervised generation of high-quality multi-view-consistent images and 3D shapes using only collections of single-view 2D photographs has been a long-standing challenge. Existing 3D GANs are either compute-intensive or make approximations that are not 3D-consistent; the former limits quality and resolution of the generated images and the latter adversely affects multi-view consistency and shape quality. In this work, we improve the computational efficiency and image quality of 3D GANs without overly relying on these approximations. For this purpose, we introduce an expressive hybrid explicit-implicit network architecture that, together with other design choices, synthesizes not only high-resolution multi-view-consistent images in real time but also produces high-quality 3D geometry. By decoupling feature generation and neural rendering, our framework is able to leverage <font color="#00be00">state-of-the-art</font> 2D CNN generators, such as <font color="#be00be">Style</font>GAN2, and inherit their efficiency and expressiveness. We demonstrate state-of-the-art 3D-aware synthesis with FFHQ and AFHQ Cats, among other experiments. </br></br>

<a href='http://arxiv.org/pdf/2112.06443.pdf'>2112.06443</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp 0.6900баллов, №332</br>
<b>Detecting Audio Adversarial Examples with Logit Noising</b></br>
Authors: , Park, Namgyu, Ji, Sangwoo, Kim, Jong</br>
  Automatic <font color="#be00be">speech recognition</font> (ASR) systems are vulnerable to audio adversarial examples that attempt to deceive ASR systems by adding perturbations to benign speech signals. Although an adversarial example and the original benign wave are indistinguishable to humans, the former is transcribed as a malicious target sentence by ASR systems. Several methods have been proposed to generate audio adversarial examples and feed them directly into the ASR system (over-line). Furthermore, many researchers have demonstrated the feasibility of robust physical audio adversarial examples(over-air). To defend against the attacks, several studies have been proposed. However, deploying them in a <font color="#009600">real-world</font> situation is difficult because of accuracy drop or time overhead. In this paper, we propose a novel method to detect audio adversarial examples by adding noise to the logits before feeding them into the decoder of the ASR. We show that carefully selected noise can significantly impact the transcription results of the audio adversarial examples, whereas it has minimal impact on the transcription results of benign audio waves. Based on this characteristic, we detect audio adversarial examples by comparing the transcription altered by logit noising with its original transcription. The proposed method can be easily applied to ASR systems without any structural changes or additional training. The experimental results show that the proposed method is robust to over-line audio adversarial examples as well as over-air audio adversarial examples compared with <font color="#00be00">state-of-the-art</font> detection methods. </br></br>

<a href='http://arxiv.org/pdf/2112.07328.pdf'>2112.07328</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.6899баллов, №333</br>
<b>Biased Gradient Estimate with Drastic Variance Reduction for Meta\n  <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Tang, Yunhao</br>
  Despite the empirical success of meta <font color="#00be00">reinforcement learning</font> (meta-RL), there are still a number poorly-understood discrepancies between <font color="#be00be">theor</font>y and practice. Critically, biased gradient estimates are almost always implemented in practice, whereas prior theory on meta-RL only establishes convergence under unbiased gradient estimates. In this work, we investigate such a discrepancy. In particular, (1) We show that unbiased gradient estimates have variance $\\Theta(N)$ which linearly depends on the sample size $N$ of the inner loop updates; (2) We propose linearized score function (LSF) gradient estimates, which have bias $\\mathcal{O}(1/\\sqrt{N})$ and variance $\\mathcal{O}(1/N)$; (3) We show that most empirical prior work in fact implements variants of the LSF gradient estimates. This implies that practical algorithms &quot;accidentally&quot; introduce bias to achieve better performance; (4) We establish theoretical guarantees for the LSF gradient estimates in meta-RL regarding its convergence to stationary points, showing better dependency on $N$ than prior work when $N$ is large. </br></br>

<a href='http://arxiv.org/pdf/2112.07222.pdf'>2112.07222</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.6865баллов, №334</br>
<b>Meta-CPR: Generalize to Unseen Large Number of Agents with Communication\n  Pattern Recognition Module</b></br>
Authors: , Tseng, Wei-Cheng, Wei, Wei, Juan, Da-Chen, Sun, Min</br>
  Designing an effective communication mechanism among agents in <font color="#00be00">reinforcement learning</font> has been a challenging task, especially for <font color="#009600">real-world</font> applications. The number of agents can grow or an environment sometimes needs to interact with a changing number of agents in real-world scenarios. To this end, a multi-agent framework needs to handle various scenarios of agents, in terms of both scales and dynamics, for being practical to real-world applications. We formulate the multi-agent environment with a different number of agents as a multi-tasking problem and propose a meta reinforcement learning (meta-RL) framework to tackle this problem. The proposed framework employs a meta-learned Communication Pattern Recognition (CPR) module to identify communication behavior and extract information that facilitates the training process. Experimental results are poised to demonstrate that the proposed framework (a) generalizes to an unseen larger number of agents and (b) allows the number of agents to change between episodes. The ablation study is also provided to reason the proposed CPR design and show such design is effective. </br></br>

<a href='http://arxiv.org/pdf/2112.04148.pdf'>2112.04148</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.6849баллов, №335</br>
<b>Neural Points: <font color="#be00be">Point Cloud</font> Representation with Neural Fields</b></br>
Authors: , Feng, Wanquan, Li, Jin, Cai, Hongrui, Luo, Xiaonan, Zhang, Juyong</br>
  In this paper, we propose \\emph{Neural Points}, a novel <font color="#be00be">point cloud</font> representation. Unlike traditional point cloud representation where each point only represents a position or a local plane in the 3D space, each point in Neural Points represents a local continuous geometric shape via neural fields. Therefore, Neural Points can express much more complex details and thus have a stronger representation ability. Neural Points is trained with high-resolution surface containing rich geometric details, such that the trained model has enough expression ability for various shapes. Specifically, we extract deep local features on the points and construct neural fields through the local isomorphism between the 2D parametric domain and the 3D local patch. In the final, local neural fields are integrated together to form the global surface. Experimental results show that Neural Points has powerful representation ability and demonstrate excellent robustness and generalization ability. With Neural Points, we can resample point cloud with arbitrary resolutions, and it <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> point cloud upsampling methods by a large margin. </br></br>

<a href='http://arxiv.org/pdf/2112.06150.pdf'>2112.06150</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.6815баллов, №336</br>
<b>Deep Translation Prior: Test-time Training for Photorealistic <font color="#be00be">Style</font>\n  Transfer</b></br>
Authors: , Kim, Sunwoo, Kim, Soohyun, Kim, Seungryong</br>
  Recent techniques to solve photorealistic <font color="#be00be">style</font> transfer within deep convolutional neural networks (CNNs) generally require intensive training from large-scale datasets, thus having limited applicability and poor generalization ability to unseen images or styles. To overcome this, we propose a novel framework, dubbed Deep Translation Prior (DTP), to accomplish photorealistic style transfer through test-time training on given input image pair with untrained networks, which learns an image pair-specific translation prior and thus yields better performance and generalization. Tailored for such test-time training for style transfer, we present novel network architectures, with two sub-modules of correspondence and generation modules, and loss functions consisting of contrastive content, style, and cycle consistency losses. Our framework does not require offline training phase for style transfer, which has been one of the main challenges in existing methods, but the networks are to be solely learned during test-time. Experimental results prove that our framework has a better generalization ability to unseen image pairs and even <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> methods. </br></br>

<a href='http://arxiv.org/pdf/2111.07658.pdf'>2111.07658</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.6781баллов, №337</br>
<b>Calculating Question Similarity is Enough: A New Method for KBQA Tasks</b></br>
Authors: , Zhao, Hanyu, Yuan, Sha, Leng, Jiahong, Pan, Xiang, Wang, Guoqiang</br>
  Knowledge Base Question Answering (KBQA) aims to answer natural language questions with the help of an external knowledge base. The core idea is to find the link between the internal knowledge behind questions and known triples of the knowledge base. The KBQA task pipeline contains several steps, including entity recognition, entity linking, answering selection, etc. This kind of pipeline method means that errors in any procedure will inevitably propagate to the final prediction. To address this challenge, this paper proposes a Corpus Generation - Retrieve Method (CGRM) with Pre-training Language Model (PLM) for the KBQA task. The major novelty lies in the design of the new method, wherein our approach, the knowledge enhanced T5 (kT5) model aims to generate natural language QA pairs based on <font color="#960096">Knowledge Graph</font> triples and directly solve the QA by only retrieving the synthetic dataset. The new method can extract more information about the entities from PLM to improve accuracy and simplify the processes. We test our method on NLPCC-ICCPOL 2016 KBQA dataset, and the results show that our method improves the performance of KBQA and the out straight-forward method is <font color="#960096">competitive</font> with the <font color="#00be00">state-of-the-art</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.05787.pdf'>2112.05787</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.6745баллов, №338</br>
<b>Representation Learning for Conversational Data using Discourse Mutual\n  Information Maximization</b></br>
Authors: , Santra, Bishal, Roychowdhury, Sumegh, Mandal, Aishik, Gurram, Vasu, Naik, Atharva, Gupta, Manish, Goyal, Pawan</br>
  Although many pretrained models exist for text or images, there have been relatively fewer attempts to train representations specifically for dialog understanding. Prior works usually relied on finetuned representations based on generic text representation models like<font color="#00be00"> BERT </font>or<font color="#00be00"> GPT</font>-2. But, existing pretraining objectives do not take the structural information of text into consideration. Although generative dialog models can learn structural features too, we argue that the structure-unaware word-by-word generation is not suitable for effective conversation modeling. We empirically demonstrate that such representations do not perform consistently across various dialog understanding tasks. Hence, we propose a structure-aware Mutual Information based loss-function DMI (Discourse Mutual Information) for training dialog-representation models, that additionally captures the inherent uncertainty in response prediction. Extensive evaluation on nine diverse dialog modeling tasks shows that our proposed DMI-based models <font color="#00be00">outperform</font> strong baselines by significant margins, even with small-scale pretraining. Our models show the most promising performance on the dialog evaluation task DailyDialog++, in both random and adversarial negative scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.05277.pdf'>2112.05277</a> &nbsp&nbsp (cs:CV, cs:CL) &nbsp&nbsp 0.6723баллов, №339</br>
<b>Skeletal Graph Self-Attention: Embedding a Skeleton Inductive Bias into\n  Sign Language Production</b></br>
Authors: , Saunders, Ben, Camgoz, Necati Cihan, Bowden, Richard</br>
  Recent approaches to Sign Language Production (SLP) have adopted spoken language Neural Machine Translation (NMT) architectures, applied without sign-specific modifications. In addition, these works represent sign language as a sequence of skeleton pose vectors, projected to an abstract representation with no inherent skeletal structure. In this paper, we represent sign language sequences as a skeletal graph structure, with joints as nodes and both spatial and temporal connections as edges. To operate on this graphical structure, we propose Skeletal Graph Self-Attention (SGSA), a novel graphical attention layer that embeds a skeleton inductive bias into the SLP model. Retaining the skeletal feature representation throughout, we directly apply a spatio-temporal adjacency matrix into the self-attention formulation. This provides structure and context to each skeletal joint that is not possible when using a non-graphical abstract representation, enabling fluid and expressive sign language production. We evaluate our Skeletal Graph Self-Attention architecture on the challenging RWTH-PHOENIX-<font color="#be00be">Weather</font>-2014T(PHOENIX14T) dataset, achieving <font color="#00be00">state-of-the-art</font> back translation performance with an 8% and 7% improvement over competing methods for the dev and test sets. </br></br>

<a href='http://arxiv.org/pdf/2112.08761.pdf'>2112.08761</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.6711баллов, №340</br>
<b>DISTREAL: Distributed Resource-Aware Learning in Heterogeneous Systems</b></br>
Authors: , Rapp, Martin, Khalili, Ramin, Pfeiffer, Kilian, Henkel, J&#xf6;rg</br>
  We study the problem of distributed training of neural networks (NNs) on devices with heterogeneous, limited, and time-varying availability of computational resources. We present an adaptive, resource-aware, on-device learning mechanism, DISTREAL, which is able to fully and efficiently utilize the available resources on devices in a distributed manner, increasing the convergence speed. This is achieved with a dropout mechanism that dynamically adjusts the computational complexity of training an NN by randomly dropping filters of convolutional layers of the model. Our main contribution is the introduction of a design space exploration (DSE) technique, which finds Pareto-optimal per-layer dropout vectors with respect to resource requirements and convergence speed of the training. Applying this technique, each device is able to dynamically select the dropout vector that fits its available resource without requiring any assistance from the server. We implement our solution in a <font color="#be00be">federated</font> learning (FL) system, where the availability of computational resources varies both between devices and over time, and show through extensive evaluation that we are able to significantly increase the convergence speed over the <font color="#00be00">state of the art</font> without compromising on the final accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.05808.pdf'>2112.05808</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.6675баллов, №341</br>
<b>Benchmarking human visual search computational models in natural scenes:\n  models comparison and reference datasets</b></br>
Authors: , Travi, F., Ruarte, G., Bujia, G., Kamienkowski, J. E.</br>
  Visual search is an essential part of almost any everyday human goal-directed interaction with the environment. Nowadays, several algorithms are able to predict gaze positions during simple observation, but few models attempt to simulate human behavior during visual search in natural scenes. Furthermore, these models vary widely in their design and exhibit differences in the datasets and metrics with which they were evaluated. Thus, there is a need for a reference point, on which each model can be tested and from where potential improvements can be derived. In the present work, we select <font color="#00be00">publicly available</font> <font color="#00be00">state-of-the-art</font> visual search models in natural scenes and evaluate them on different datasets, employing the same metrics to estimate their efficiency and similarity with human subjects. In particular, we propose an improvement to the Ideal <font color="#be00be">Bayes</font>ian Searcher through a combination with a neural network-based visual search model, enabling it to generalize to other datasets. The present work sheds light on the limitations of current models and how potential improvements can be accomplished by combining approaches. Moreover, it moves forward on providing a solution for the urgent need for benchmarking data and metrics to support the development of more general human visual search computational models. </br></br>

<a href='http://arxiv.org/pdf/2112.07752.pdf'>2112.07752</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 0.6641баллов, №342</br>
<b>Representation and Invariance in <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Alexander, Samuel, Pedersen, Arthur Paul</br>
  If we changed the rules, would the wise trade places with the fools? Different groups formalize <font color="#00be00">reinforcement learning</font> (RL) in different ways. If an agent in one RL formalization is to run within another RL formalization\'s environment, the agent must first be converted, or mapped. A criterion of adequacy for any such mapping is that it preserves relative intelligence. This paper investigates the formulation and properties of this criterion of adequacy. However, prior to the problem of formulation is, we argue, the problem of comparative intelligence. We compare intelligence using ultrafilters, motivated by viewing agents as candidates in intelligence elections where voters are environments. These comparators are counterintuitive, but we prove an impossibility <font color="#be00be">theor</font>em about RL intelligence measurement, suggesting such counterintuitions are unavoidable. Given a mapping between RL frameworks, we establish sufficient conditions to ensure that, for any ultrafilter-based intelligence comparator in the destination framework, there exists an ultrafilter-based intelligence comparator in the source framework such that the mapping preserves relative intelligence. We consider three concrete mappings between various RL frameworks and show that they satisfy these sufficient conditions and therefore preserve suitably-measured relative intelligence. </br></br>

<a href='http://arxiv.org/pdf/2112.04796.pdf'>2112.04796</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 0.6580баллов, №343</br>
<b>Detecting Potentially Harmful and Protective Suicide-related Content on\n  Twitter: A Machine Learning Approach</b></br>
Authors: , Metzler, Hannah, Baginski, Hubert, Niederkrotenthaler, Thomas, Garcia, David</br>
  Research shows that exposure to suicide-related news media content is associated with suicide rates, with some content characteristics likely having harmful and others potentially protective effects. Although good evidence exists for a few selected characteristics, systematic large scale investigations are missing in general, and in particular for social media data. We apply machine learning methods to automatically label large quantities of Twitter data. We developed a novel annotation scheme that classifies suicide-related tweets into different message types and problem- vs. solution-focused perspectives. We then trained a benchmark of machine learning models including a majority classifier, an approach based on word frequency (TF-IDF with a linear <font color="#be00be">SVM</font>) and two <font color="#00be00">state-of-the-art</font> deep learning models (BERT, XLNet). The two deep learning models achieved the best performance in two classification tasks: First, we classified six main content categories, including personal stories about either suicidal ideation and attempts or coping, calls for action intending to spread either problem awareness or prevention-related information, reportings of suicide cases, and other suicide-related and off-topic tweets. The deep learning models reach accuracy scores above 73% on average across the six categories, and F1-scores in between 69% and 85% for all but the suicidal ideation and attempts category (55%). Second, in separating postings referring to actual suicide from off-topic tweets, they correctly labelled around 88% of tweets, with<font color="#00be00"> BERT </font>achieving F1-scores of 93% and 74% for the two categories. These classification performances are comparable to the state-of-the-art on similar tasks. By making data labeling more efficient, this work enables future large-scale investigations on harmful and protective effects of various kinds of social media content on suicide rates and on help-seeking behavior. </br></br>

<a href='http://arxiv.org/pdf/2112.08777.pdf'>2112.08777</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.6574баллов, №344</br>
<b>Utilizing Evidence Spans via Sequence-Level Contrastive Learning for\n  Long-Context Question Answering</b></br>
Authors: , Caciularu, Avi, Dagan, Ido, Goldberger, Jacob, Cohan, Arman</br>
  Long-range <font color="#00be00">transformer</font> models have achieved encouraging results on long-context question answering (QA) tasks. Such tasks often require reasoning over a long document, and they benefit from identifying a set of evidence spans (e.g., sentences) that provide supporting evidence for addressing the question. In this work, we propose a novel method for equipping long-range transformers with an additional sequence-level objective for better identification of supporting evidence spans. We achieve this by proposing an additional contrastive supervision signal in finetuning, where the model is encouraged to explicitly discriminate supporting evidence sentences from negative ones by maximizing the question-evidence similarity. The proposed additional loss exhibits consistent improvements on three different strong long-context transformer models, across two challenging question answering benchmarks - HotpotQA and QAsper. </br></br>

<a href='http://arxiv.org/pdf/2112.07870.pdf'>2112.07870</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.6509баллов, №345</br>
<b>Cross-Domain Generalization and Knowledge Transfer in <font color="#00be00">Transformer</font>s\n  Trained on Legal Data</b></br>
Authors: , Savelka, Jaromir, Westermann, Hannes, Benyekhlef, Karim</br>
  We analyze the ability of pre-trained language models to transfer knowledge among datasets annotated with different type systems and to generalize beyond the domain and dataset they were trained on. We create a meta task, over multiple datasets focused on the prediction of rhetorical roles. Prediction of the rhetorical role a sentence plays in a case decision is an important and often studied task in AI &amp; Law. Typically, it requires the annotation of a large number of sentences to train a model, which can be time-consuming and expensive. Further, the application of the models is restrained to the same dataset it was trained on. We fine-tune language models and evaluate their performance across datasets, to investigate the models\' ability to generalize across domains. Our results suggest that the approach could be helpful in overcoming the cold-start problem in active or interactvie learning, and shows the ability of the models to generalize across datasets and domains. </br></br>

<a href='http://arxiv.org/pdf/2112.09055.pdf'>2112.09055</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.6487баллов, №346</br>
<b><font color="#00be00">Hierarchical</font> <font color="#be00be">Clustering</font>: $O(1)$-Approximation for Well-Clustered Graphs</b></br>
Authors: , Manghiuc, Bogdan-Adrian, Sun, He</br>
  <font color="#00be00">Hierarchical</font> <font color="#be00be">clustering</font> studies a recursive partition of a data set into clusters of successively smaller size, and is a fundamental problem in data analysis. In this work we study the cost function for hierarchical clustering introduced by Dasgupta, and present two polynomial-time approximation algorithms: Our first result is an $O(1)$-approximation algorithm for graphs of high conductance. Our simple construction bypasses complicated recursive routines of finding sparse cuts known in the literature. Our second and main result is an $O(1)$-approximation algorithm for a wide family of graphs that exhibit a well-defined structure of clusters. This result generalises the previous <font color="#00be00">state-of-the-art</font>, which holds only for graphs generated from stochastic models. The significance of our work is demonstrated by the empirical analysis on both synthetic and <font color="#009600">real-world</font> data sets, on which our presented algorithm <font color="#00be00">outperform</font>s the previously proposed algorithm for graphs with a well-defined cluster structure. </br></br>

<a href='http://arxiv.org/pdf/2112.03615.pdf'>2112.03615</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.6438баллов, №347</br>
<b>Saliency Diversified Deep Ensemble for Robustness to Adversaries</b></br>
Authors: , Bogun, Alex, Kostadinov, Dimche, Borth, Damian</br>
  Deep learning models have shown incredible performance on numerous image recognition, classification, and reconstruction tasks. Although very appealing and valuable due to their predictive capabilities, one common threat remains challenging to resolve. A specifically trained attacker can introduce malicious input perturbations to fool the network, thus causing potentially harmful mispredictions. Moreover, these attacks can succeed when the adversary has full access to the target model (white-box) and even when such access is limited (black-box setting). The ensemble of models can protect against such attacks but might be brittle under shared vulnerabilities in its members (attack transferability). To that end, this work proposes a novel diversity-promoting learning approach for the deep ensembles. The idea is to promote saliency map diversity (SMD) on ensemble members to prevent the attacker from targeting all ensemble members at once by introducing an additional term in our learning objective. During training, this helps us minimize the alignment between model saliencies to reduce shared member vulnerabilities and, thus, increase ensemble robustness to adversaries. We empirically show a reduced transferability between ensemble members and improved performance compared to the <font color="#00be00">state-of-the-art</font> ensemble defense against medium and high strength white-box attacks. In addition, we demonstrate that our approach combined with existing methods <font color="#00be00">outperform</font>s state-of-the-art ensemble algorithms for defense under white-box and <font color="#be00be">black-box attack</font>s. </br></br>

<a href='http://arxiv.org/pdf/2112.07528.pdf'>2112.07528</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.6359баллов, №348</br>
<b>n-CPS: Generalising Cross Pseudo Supervision to n networks for\n  Semi-Supervised Semantic <font color="#be00be">Segmentation</font></b></br>
Authors: , Filipiak, Dominik, Tempczyk, Piotr, Cygan, Marek</br>
  We present n-CPS - a generalisation of the recent <font color="#00be00">state-of-the-art</font> cross pseudo supervision (CPS) approach for the task of semi-supervised semantic <font color="#be00be">segmentation</font>. In n-CPS, there are n simultaneously trained subnetworks that learn from each other through one-hot encoding perturbation and consistency regularisation. We also show that ensembling techniques applied to subnetworks outputs can significantly improve the performance. To the best of our knowledge, n-CPS paired with CutMix <font color="#00be00">outperform</font>s CPS and sets the new state-of-the-art for Pascal VOC 2012 with (1/16, 1/8, 1/4, and 1/2 supervised regimes) and Cityscapes (1/16 supervised). </br></br>

<a href='http://arxiv.org/pdf/2112.03254.pdf'>2112.03254</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp 0.6328баллов, №349</br>
<b>Human Parity on CommonsenseQA: Augmenting Self-Attention with External\n  Attention</b></br>
Authors: , Xu, Yichong, Zhu, Chenguang, Wang, Shuohang, Sun, Siqi, Cheng, Hao, Liu, Xiaodong, Gao, Jianfeng, He, Pengcheng, Zeng, Michael, Huang, Xuedong</br>
  Most of today\'s AI systems focus on using self-attention mechanisms and <font color="#00be00">transformer</font> architectures on large amounts of diverse data to achieve impressive performance gains. In this paper, we propose to augment the transformer architecture with an external attention mechanism to bring external knowledge and context to bear. By integrating external information into the prediction process, we hope to reduce the need for ever-larger models and increase the democratization of AI systems. We find that the proposed external attention mechanism can significantly improve the performance of existing AI systems, allowing practitioners to easily customize foundation AI models to many diverse downstream applications. In particular, we focus on the task of Commonsense Reasoning, demonstrating that the proposed external attention mechanism can augment existing transformer models and significantly improve the model\'s reasoning capabilities. The proposed system, Knowledgeable External Attention for commonsense Reasoning (KEAR), reaches human parity on the open CommonsenseQA research benchmark with an accuracy of 89.4\\% in comparison to the human accuracy of 88.9\\%. </br></br>

<a href='http://arxiv.org/pdf/2112.07642.pdf'>2112.07642</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.6313баллов, №350</br>
<b>EgoBody: Human Body Shape, Motion and Social Interactions from\n  Head-Mounted Devices</b></br>
Authors: , Zhang, Siwei, Ma, Qianli, Zhang, Yan, Qian, Zhiyin, Pollefeys, Marc, Bogo, Federica, Tang, Siyu</br>
  Understanding social interactions from first-person views is crucial for many applications, ranging from assistive robotics to AR/VR. A first step for reasoning about interactions is to understand human pose and shape. However, research in this area is currently hindered by the lack of data. Existing datasets are limited in terms of either size, annotations, ground-truth capture modalities or the diversity of interactions. We address this shortcoming by proposing EgoBody, a novel large-scale dataset for social interactions in complex 3D scenes. We employ Microsoft HoloLens2 headsets to record rich egocentric data streams (including RGB, depth, eye gaze, head and hand <font color="#be00be">tracking</font>). To obtain accurate 3D ground-truth, we calibrate the headset with a multi-Kinect rig and fit expressive SMPL-X body meshes to multi-view RGB-D frames, reconstructing 3D human poses and shapes relative to the scene. We collect 68 sequences, spanning diverse sociological interaction categories, and propose the first benchmark for 3D full-body pose and shape estimation from egocentric views. Our dataset and code will be available for research at <font color="#006400">http</font>s://sanweiliti.<font color="#00be00">github</font>.io/egobody/egobody.html. </br></br>

<a href='http://arxiv.org/pdf/2112.08786.pdf'>2112.08786</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.6298баллов, №351</br>
<b>Efficient <font color="#00be00">Hierarchical</font> Domain Adaptation for Pretrained Language Models</b></br>
Authors: , Chronopoulou, Alexandra, Peters, Matthew E., Dodge, Jesse</br>
  Generative language models are trained on diverse, general domain corpora. However, this limits their applicability to narrower domains, and prior work has shown that continued in-domain training can provide further gains. In this paper, we introduce a method to scale domain adaptation to many diverse domains using a computationally efficient adapter approach. Our method is based on the observation that textual domains are partially overlapping, and we represent domains as a <font color="#00be00">hierarchical</font> tree structure where each node in the tree is associated with a set of adapter weights. When combined with a frozen pretrained language model, this approach enables parameter sharing among related domains, while avoiding negative interference between unrelated ones. It is efficient and computational cost scales as O(log(D)) for D domains. Experimental results with<font color="#00be00"> GPT</font>-2 and a large fraction of the 100 most represented websites in C4 show across-the-board improvements in-domain. We additionally provide an inference time algorithm for a held-out domain and show that averaging over multiple paths through the tree enables further gains in generalization, while adding only a marginal cost to inference. </br></br>

<a href='http://arxiv.org/pdf/2112.08616.pdf'>2112.08616</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 0.6273баллов, №352</br>
<b>Masked Measurement Prediction: Learning to Jointly Predict Quantities\n  and Units from Textual Context</b></br>
Authors: , Spokoyny, Daniel, Lee, Ivan, Jin, Zhao, Berg-Kirkpatrick, Taylor</br>
  Physical measurements constitute a large portion of numbers in academic papers, engineering reports, and web tables. Current benchmarks fall short of properly evaluating numeracy of pretrained language models on measurements, hindering research on developing new methods and applying them to numerical tasks. To that end, we introduce a novel task, Masked Measurement Prediction (MMP), where a model learns to reconstruct a number together with its associated unit given masked text. MMP is useful for both training new numerically informed models as well as evaluating numeracy of existing systems. In order to address this task, we introduce a new Generative Masked Measurement (GeMM) model that jointly learns to predict numbers along with their units. We perform fine-grained analyses comparing our model with various ablations and baselines. We use linear probing of traditional pretrained <font color="#00be00">transformer</font> models (RoBERTa) to show that they significantly underperform jointly trained number-unit models, highlighting the difficulty of this new task and the benefits of our proposed pretraining approach. We hope this framework accelerates the progress towards building more robust numerical reasoning systems in the future. </br></br>

<a href='http://arxiv.org/pdf/2112.07820.pdf'>2112.07820</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.6248баллов, №353</br>
<b>Value <font color="#be00be">Retrieval</font> with Arbitrary Queries for Form-like Documents</b></br>
Authors: , Gao, Mingfei, Xue, Le, Ramaiah, Chetan, Xing, Chen, Xu, Ran, Xiong, Caiming</br>
  We propose value <font color="#be00be">retrieval</font> with arbitrary queries for form-like documents to reduce human effort of processing forms. Unlike previous methods that only address a fixed set of field items, our method predicts target value for an arbitrary query based on the understanding of layout and semantics of a form. To further boost model performance, we propose a simple document language modeling (simpleDLM) strategy to improve document understanding on large-scale model pre-training. Experimental results show that our method <font color="#00be00">outperform</font>s our baselines significantly and the simpleDLM further improves our performance on value retrieval by around 17\\% F1 score compared with the <font color="#00be00">state-of-the-art</font> pre-training method. Code will be made <font color="#00be00">publicly available</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.06926.pdf'>2112.06926</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.6246баллов, №354</br>
<b>Addressing Bias in Active Learning with Depth Uncertainty Networks... or\n  Not</b></br>
Authors: , Murray, Chelsea, Allingham, James U., Antor&#xe1;n, Javier, Hern&#xe1;ndez-Lobato, Jos&#xe9; Miguel</br>
  Farquhar et al. [2021] show that correcting for active learning bias with underparameterised models leads to improved downstream performance. For overparameterised models such as NNs, however, correction leads either to decreased or unchanged performance. They suggest that this is due to an &quot;overfitting bias&quot; which offsets the active learning bias. We show that depth uncertainty networks operate in a low overfitting regime, much like underparameterised models. They should therefore see an increase in performance with bias correction. <font color="#00be00">Surprisin</font>gly, they do not. We propose that this negative result, as well as the results Farquhar et al. [2021], can be explained via the lens of the bias-variance decomposition of generalisation error. </br></br>

<a href='http://arxiv.org/pdf/2112.08635.pdf'>2112.08635</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.6214баллов, №355</br>
<b>Road-aware Monocular Structure from Motion and Homography Estimation</b></br>
Authors: , Sui, Wei, Chen, Teng, Zhang, Jiaxin, Lu, Jiao, Zhang, Qian</br>
  Structure from motion (SFM) and ground plane homography estimation are critical to autonomous driving and other robotics applications. Recently, much progress has been made in using deep neural networks for SFM and homography estimation respectively. However, directly applying existing methods for ground plane homography estimation may fail because the road is often a small part of the scene. Besides, the performances of deep SFM approaches are still inferior to traditional methods. In this paper, we propose a method that learns to solve both problems in an end-to-end manner, improving performance on both. The proposed networks consist of a Depth-CNN, a Pose-CNN and a Ground-CNN. The Depth-CNN and Pose-CNN estimate dense depth map and ego-motion respectively, solving SFM, while the Pose-CNN and Ground-CNN followed by a homography layer solve the ground plane estimation problem. By enforcing coherency between SFM and homography estimation results, the whole network can be trained end to end using photometric loss and homography loss without any groundtruth except the road <font color="#be00be">segmentation</font> provided by an off-the-shelf segmenter. Comprehensive experiments are conducted on KITTI benchmark to demonstrate promising results compared with various <font color="#00be00">state-of-the-art</font> approaches. </br></br>

<a href='http://arxiv.org/pdf/2112.06538.pdf'>2112.06538</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.6159баллов, №356</br>
<b>Hybrid Graph Neural Networks for <font color="#00be00">Few-Shot</font> Learning</b></br>
Authors: , Yu, Tianyuan, He, Sen, Song, Yi-Zhe, Xiang, Tao</br>
  Graph neural networks (GNNs) have been used to tackle the <font color="#00be00">few-shot</font> learning (FSL) problem and shown great potentials under the transductive setting. However under the inductive setting, existing GNN based methods are less <font color="#960096">competitive</font>. This is because they use an instance GNN as a label propagation/classification module, which is jointly meta-learned with a feature embedding network. This design is problematic because the classifier needs to adapt quickly to new tasks while the embedding does not. To overcome this problem, in this paper we propose a novel hybrid GNN (HGNN) model consisting of two GNNs, an instance GNN and a prototype GNN. Instead of label propagation, they act as feature embedding adaptation modules for quick adaptation of the meta-learned feature embedding to new tasks. Importantly they are designed to deal with a fundamental yet often neglected challenge in FSL, that is, with only a handful of shots per class, any few-shot classifier would be sensitive to badly sampled shots which are either <font color="#be00be">outlier</font>s or can cause inter-class distribution overlapping. %Our two GNNs are designed to address these two types of poorly sampled few-shots respectively and their complementarity is exploited in the hybrid GNN model. Extensive experiments show that our HGNN obtains new <font color="#00be00">state-of-the-art</font> on three FSL benchmarks. </br></br>

<a href='http://arxiv.org/pdf/2112.08470.pdf'>2112.08470</a> &nbsp&nbsp (cs:CL, cs:CV) &nbsp&nbsp 0.6151баллов, №357</br>
<b>Insta-VAX: A Multimodal Benchmark for Anti-Vaccine and Misinformation\n  Posts Detection on Social Media</b></br>
Authors: , Zhou, Mingyang, Chakraborti, Mahasweta, Qian, Sijia, Yu, Zhou, Zhang, Jingwen</br>
  Sharing of anti-vaccine posts on social media, including misinformation posts, has been shown to create confusion and reduce the publics confidence in vaccines, leading to vaccine hesitancy and resistance. Recent years have witnessed the fast rise of such anti-vaccine posts in a variety of linguistic and visual forms in online networks, posing a great challenge for effective content moderation and <font color="#be00be">tracking</font>. Extending previous work on leveraging textual information to understand vaccine information, this paper presents Insta-VAX, a new multi-modal dataset consisting of a sample of 64,957 Instagram posts related to human vaccines. We applied a crowdsourced annotation procedure verified by two trained expert judges to this dataset. We then bench-marked several <font color="#00be00">state-of-the-art</font> NLP and computer vision classifiers to detect whether the posts show anti-vaccine attitude and whether they contain misinformation. Extensive experiments and analyses demonstrate the multimodal models can classify the posts more accurately than the uni-modal models, but still need improvement especially on visual context understanding and external knowledge cooperation. The dataset and classifiers contribute to monitoring and tracking of vaccine discussions for social scientific and public health efforts in combating the problem of vaccine misinformation. </br></br>

<a href='http://arxiv.org/pdf/2112.06620.pdf'>2112.06620</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.6127баллов, №358</br>
<b>A Review: Challenges and Opportunities for Artificial Intelligence and\n  Robotics in the Offshore Wind Sector</b></br>
Authors: , Mitchell, Daniel, Blanche, Jamie, Harper, Sam, Lim, Theodore, Gupta, Ranjeetkumar, Zaki, Osama, Tang, Wenshuo, Robu, Valentin, Watson, Simon, Flynn, David</br>
  A global trend in increasing wind turbine size and distances from shore is emerging within the rapidly growing offshore wind farm <font color="#be00be">market</font>. In the UK, the offshore wind sector produced its highest amount of electricity in the UK in 2019, a 19.6% increase on the year before. Currently, the UK is set to increase production further, targeting a 74.7% increase of installed turbine capacity as reflected in recent Crown Estate leasing rounds. With such tremendous growth, the sector is now looking to Robotics and Artificial Intelligence (RAI) in order to tackle lifecycle service barriers as to support sustainable and profitable offshore wind energy production. Today, RAI applications are predominately being used to support short term objectives in operation and maintenance. However, moving forward, RAI has the potential to play a critical role throughout the full lifecycle of offshore wind infrastructure, from surveying, planning, design, logistics, operational support, training and decommissioning. This paper presents one of the first systematic reviews of RAI for the offshore renewable energy sector. The <font color="#00be00">state-of-the-art</font> in RAI is analyzed with respect to offshore energy requirements, from both industry and academia, in terms of current and future requirements. Our review also includes a detailed evaluation of investment, regulation and skills development required to support the adoption of RAI. The key trends identified through a detailed analysis of patent and academic publication databases provide insights to barriers such as certification of autonomous platforms for safety compliance and reliability, the need for digital architectures for scalability in autonomous fleets, adaptive mission planning for resilient resident operations and optimization of human machine interaction for trusted partnerships between people and autonomous assistants. </br></br>

<a href='http://arxiv.org/pdf/2112.08459.pdf'>2112.08459</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.6120баллов, №359</br>
<b>Rethinking <font color="#be00be">Nearest Neighbo</font>rs for Visual Classification</b></br>
Authors: , Jia, Menglin, Chen, Bor-Chun, Wu, Zuxuan, Cardie, Claire, Belongie, Serge, Lim, Ser-Nam</br>
  Neural network classifiers have become the de-facto choice for current &quot;pre-train then fine-tune&quot; paradigms of visual classification. In this paper, we investigate $k$-Nearest-Neighbor (k-NN) classifiers, a classical model-free learning method from the pre-deep learning era, as an augmentation to modern neural network based approaches. As a lazy learning method, k-NN simply aggregates the distance between the test image and top-k neighbors in a training set. We adopt k-NN with pre-trained visual representations produced by either supervised or self-supervised methods in two steps: (1) Leverage k-NN predicted probabilities as indications for easy \\vs~hard examples during training. (2) Linearly interpolate the k-NN predicted distribution with that of the augmented classifier. Via extensive experiments on a wide range of classification tasks, our study reveals the generality and flexibility of k-NN integration with additional insights: (1) k-NN achieves <font color="#960096">competitive</font> results, sometimes even <font color="#00be00">outperform</font>ing a standard linear classifier. (2) Incorporating k-NN is especially beneficial for tasks where parametric classifiers perform poorly and / or in low-data regimes. We hope these discoveries will encourage people to rethink the role of pre-deep learning, classical methods in computer vision. Our code is available at: <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/KMnP/nn-revisit. </br></br>

<a href='http://arxiv.org/pdf/2112.05147.pdf'>2112.05147</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.6089баллов, №360</br>
<b>Learning Deep Context-Sensitive Decomposition for Low-Light Image\n  Enhancement</b></br>
Authors: , Ma, Long, Liu, Risheng, Zhang, Jiaao, Fan, Xin, Luo, Zhongxuan</br>
  Enhancing the quality of low-light images plays a very important role in many image processing and multimedia applications. In recent years, a variety of deep learning techniques have been developed to address this challenging task. A typical framework is to simultaneously estimate the illumination and reflectance, but they disregard the scene-level contextual information encapsulated in feature spaces, causing many unfavorable outcomes, e.g., details loss, color unsaturation, artifacts, and so on. To address these issues, we develop a new context-sensitive decomposition network architecture to exploit the scene-level contextual dependencies on spatial scales. More concretely, we build a two-stream estimation mechanism including reflectance and illumination estimation network. We design a novel context-sensitive decomposition connection to bridge the two-stream mechanism by incorporating the physical principle. The spatially-varying illumination guidance is further constructed for achieving the edge-aware smoothness property of the illumination component. According to different training patterns, we construct CSDNet (paired supervision) and CSDGAN (unpaired supervision) to fully evaluate our designed architecture. We test our method on seven testing benchmarks to conduct plenty of analytical and evaluated experiments. Thanks to our designed context-sensitive decomposition connection, we successfully realized excellent enhanced results, which fully indicates our superiority against existing <font color="#00be00">state-of-the-art</font> approaches. Finally, considering the practical needs for high-efficiency, we develop a <font color="#be00be">lightweight</font> CSDNet (named LiteCSDNet) by reducing the number of channels. Further, by sharing an encoder for these two components, we obtain a more lightweight version (SLiteCSDNet for short). SLiteCSDNet just contains 0.0301M parameters but achieves the almost same performance as CSDNet. </br></br>

<a href='http://arxiv.org/pdf/2012.12111.pdf'>2012.12111</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.6066баллов, №361</br>
<b>MOCCA: Multi-Layer One-Class ClassificAtion for <font color="#be00be">Anomal</font>y Detection</b></br>
Authors: , Massoli, Fabio Valerio, Falchi, Fabrizio, Kantarci, Alperen, Akti, &#x15e;eymanur, Ekenel, Hazim Kemal, Amato, Giuseppe</br>
  <font color="#be00be">Anomal</font>ies are ubiquitous in all scientific fields and can express an unexpected event due to incomplete knowledge about the data distribution or an unknown process that suddenly comes into play and distorts observations. Due to such events\' rarity, to train deep learning models on the Anomaly Detection (AD) task, scientists only rely on &quot;normal&quot; data, i.e., non-anomalous samples. Thus, letting the neural network infer the distribution beneath the input data. In such a context, we propose a novel framework, named Multi-layer One-Class ClassificAtion (MOCCA),to train and test deep learning models on the AD task. Specifically, we applied it to autoencoders. A key novelty in our work stems from the explicit optimization of intermediate representations for the AD task. Indeed, differently from commonly used approaches that consider a neural network as a single computational block, i.e., using the output of the last layer only, MOCCA explicitly leverages the multi-layer structure of deep architectures. Each layer\'s feature space is optimized for AD during training, while in the test phase, the deep representations extracted from the trained layers are combined to detect anomalies. With MOCCA, we split the training process into two steps. First, the autoencoder is trained on the reconstruction task only. Then, we only retain the encoder tasked with minimizing the L_2 distance between the output representation and a reference point, the anomaly-free training data centroid, at each considered layer. Subsequently, we combine the deep features extracted at the various trained layers of the encoder model to detect anomalies at inference time. To assess the performance of the models trained with MOCCA, we conduct extensive experiments on <font color="#00be00">publicly available</font> datasets. We show that our proposed method reaches comparable or superior performance to <font color="#00be00">state-of-the-art</font> approaches available in the literature. </br></br>

<a href='http://arxiv.org/pdf/2112.06193.pdf'>2112.06193</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.6064баллов, №362</br>
<b>Multimodal-based Scene-Aware Framework for Aquatic Animal <font color="#be00be">Segmentation</font></b></br>
Authors: , Le, Minh-Quan, Le, Trung-Nghia, Nguyen, Tam V., Echizen, Isao, Tran, Minh-Triet</br>
  Recent years have witnessed great advances in object <font color="#be00be">segmentation</font> research. In addition to generic objects, aquatic animals have attracted research attention. Deep learning-based methods are widely used for aquatic animal segmentation and have achieved promising performance. However, there is a lack of challenging datasets for benchmarking. Therefore, we have created a new dataset dubbed &quot;Aquatic Animal Species.&quot; Furthermore, we devised a novel multimodal-based scene-aware segmentation framework that leverages the advantages of multiple view segmentation models to segment images of aquatic animals effectively. To improve training performance, we developed a guided mixup augmentation method. Extensive experiments comparing the performance of the proposed framework with <font color="#00be00">state-of-the-art</font> instance segmentation methods demonstrated that our method is effective and that it significantly <font color="#00be00">outperform</font>s existing methods. </br></br>

<a href='http://arxiv.org/pdf/2112.06733.pdf'>2112.06733</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.6011баллов, №363</br>
<b>Context vs Target Word: Quantifying Biases in Lexical Semantic Datasets</b></br>
Authors: , Liu, Qianchu, McCarthy, Diana, Korhonen, Anna</br>
  <font color="#00be00">State-of-the-art</font> contextualized models such as<font color="#00be00"> BERT </font>use tasks such as WiC and WSD to evaluate their word-in-context representations. This inherently assumes that performance in these tasks reflect how well a model represents the coupled word and context semantics. This study investigates this assumption by presenting the first quantitative analysis (using probing baselines) on the context-word interaction being tested in major contextual lexical semantic tasks. Specifically, based on the probing baseline performance, we propose measures to calculate the degree of context or word biases in a dataset, and plot existing datasets on a continuum. The analysis shows most existing datasets fall into the extreme ends of the continuum (i.e. they are either heavily context-biased or target-word-biased) while only AM$^2$iCo and Sense <font color="#be00be">Retrieval</font> challenge a model to represent both the context and target words. Our case study on WiC reveals that human subjects do not share models\' strong context biases in the dataset (humans found semantic judgments much more difficult when the target word is missing) and models are learning spurious correlations from context alone. This study demonstrates that models are usually not being tested for word-in-context representations as such in these tasks and results are therefore open to mis<font color="#be00be">interpret</font>ation. We recommend our framework as sanity check for context and target word biases of future task design and application in lexical semantics. </br></br>

<a href='http://arxiv.org/pdf/2112.07891.pdf'>2112.07891</a> &nbsp&nbsp (cs:SD, cs:AI, cs:ML) &nbsp&nbsp 0.6006баллов, №364</br>
<b><font color="#00be00">Zero-shot</font> Audio Source Separation through Query-based Learning from\n  Weakly-labeled Data</b></br>
Authors: , Chen, Ke, Du, Xingjian, Zhu, Bilei, Ma, Zejun, Berg-kirkpatrick, Taylor, Dubnov, Shlomo</br>
  Deep learning techniques for separating audio into different sound sources<font color="#be00be"> face </font>several challenges. Standard architectures require training separate models for different types of audio sources. Although some universal separators employ a single model to target multiple sources, they have difficulty generalizing to unseen sources. In this paper, we propose a three-component pipeline to train a universal audio source separator from a large, but weakly-labeled dataset: AudioSet. First, we propose a <font color="#00be00">transformer</font>-based sound event detection system for processing weakly-labeled training data. Second, we devise a query-based audio separation model that leverages this data for model training. Third, we design a latent embedding processor to encode queries that specify audio targets for separation, allowing for <font color="#00be00">zero-shot</font> generalization. Our approach uses a single model for source separation of multiple sound types, and relies solely on weakly-labeled data for training. In addition, the proposed audio separator can be used in a zero-shot setting, learning to separate types of audio sources that were never seen in training. To evaluate the separation performance, we test our model on MUSDB18, while training on the disjoint AudioSet. We further verify the zero-shot performance by conducting another experiment on audio source types that are held-out from training. The model achieves comparable Source-to-Distortion Ratio (SDR) performance to current supervised models in both cases. </br></br>

<a href='http://arxiv.org/pdf/2112.07337.pdf'>2112.07337</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.5999баллов, №365</br>
<b>Multi-Instance Training for Question Answering Across Table and Linked\n  Text</b></br>
Authors: , Kumar, Vishwajeet, Chemmengath, Saneem, Gupta, Yash, Sen, Jaydeep, Bharadwaj, Samarth, Chakrabarti, Soumen</br>
  Answering natural language questions using information from tables (TableQA) is of considerable recent interest. In many applications, tables occur not in isolation, but embedded in, or linked to unstructured text. Often, a question is best answered by matching its parts to either table cell contents or unstructured text spans, and extracting answers from either source. This leads to a new space of TextTableQA problems that was introduced by the HybridQA dataset. Existing adaptations of table representation to <font color="#00be00">transformer</font>-based reading comprehension (RC) architectures fail to tackle the diverse modalities of the two representations through a single system. Training such systems is further challenged by the need for distant supervision. To reduce cognitive burden, training instances usually include just the question and answer, the latter matching multiple table rows and text passages. This leads to a noisy multi-instance training regime involving not only rows of the table, but also spans of linked text. We respond to these challenges by proposing MITQA, a new TextTableQA system that explicitly models the different but closely-related probability spaces of table row selection and text span selection. Our experiments indicate the superiority of our approach compared to recent baselines. The proposed method is currently at the top of the HybridQA leaderboard with a held out test set, achieving 21 % absolute improvement on both EM and F1 scores over previous published results. </br></br>

<a href='http://arxiv.org/pdf/2112.06189.pdf'>2112.06189</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 0.5994баллов, №366</br>
<b>MPLR: a novel model for multi-target learning of logical rules for\n  <font color="#960096">knowledge graph</font> reasoning</b></br>
Authors: , Wei, Yuliang, Li, Haotian, Xin, Guodong, Wang, Yao, Wang, Bailing</br>
  Large-scale <font color="#960096">knowledge graph</font>s (KGs) provide structured representations of human knowledge. However, as it is impossible to contain all knowledge, KGs are usually incomplete. Reasoning based on existing facts paves a way to discover missing facts. In this paper, we study the problem of learning logic rules for reasoning on knowledge graphs for completing missing factual triplets. Learning logic rules equips a model with strong <font color="#be00be">interpret</font>ability as well as the ability to generalize to similar tasks. We propose a model called MPLR that improves the existing models to fully use training data and multi-target scenarios are considered. In addition, considering the deficiency in evaluating the performance of models and the quality of mined rules, we further propose two novel indicators to help with the problem. Experimental results empirically demonstrate that our MPLR model <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> methods on five benchmark datasets. The results also prove the effectiveness of the indicators. </br></br>

<a href='http://arxiv.org/pdf/2112.06482.pdf'>2112.06482</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.5923баллов, №367</br>
<b>ITA: Image-Text Alignments for Multi-Modal <font color="#be00be">Named Entity</font> Recognition</b></br>
Authors: , Wang, Xinyu, Gui, Min, Jiang, Yong, Jia, Zixia, Bach, Nguyen, Wang, Tao, Huang, Zhongqiang, Huang, Fei, Tu, Kewei</br>
  Recently, Multi-modal <font color="#be00be">Named Entity</font> Recognition (MNER) has attracted a lot of attention. Most of the work utilizes image information through region-level visual representations obtained from a pretrained object detector and relies on an attention mechanism to model the interactions between image and text representations. However, it is difficult to model such interactions as image and text representations are trained separately on the data of their respective modality and are not aligned in the same space. As text representations take the most important role in MNER, in this paper, we propose {\\bf I}mage-{\\bf t}ext {\\bf A}lignments (ITA) to align image features into the textual space, so that the attention mechanism in <font color="#00be00">transformer</font>-based pretrained textual embeddings can be better utilized. ITA first locally and globally aligns regional object tags and image-level captions as visual contexts, concatenates them with the input texts as a new cross-modal input, and then feeds it into a pretrained textual embedding model. This makes it easier for the attention module of a pretrained textual embedding model to model the interaction between the two modalities since they are both represented in the textual space. ITA further aligns the output distributions predicted from the cross-modal input and textual input views so that the MNER model can be more practical and robust to noises from images. In our experiments, we show that ITA models can achieve <font color="#00be00">state-of-the-art</font> accuracy on multi-modal Named Entity Recognition datasets, even without image information. </br></br>

<a href='http://arxiv.org/pdf/2112.07042.pdf'>2112.07042</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.5900баллов, №368</br>
<b>How to Learn when Data Gradually Reacts to Your Model</b></br>
Authors: , Izzo, Zachary, Zou, James, Ying, Lexing</br>
  A recent line of work has focused on training machine learning (ML) models in the performative setting, i.e. when the data distribution reacts to the deployed model. The goal in this setting is to learn a model which both induces a favorable data distribution and performs well on the induced distribution, thereby minimizing the test loss. Previous work on finding an optimal model assumes that the data distribution immediately adapts to the deployed model. In practice, however, this may not be the case, as the population may take time to adapt to the model. In many applications, the data distribution depends on both the currently deployed ML model and on the &quot;state&quot; that the population was in before the model was deployed. In this work, we propose a new algorithm, Stateful Performative Gradient Descent (Stateful PerfGD), for minimizing the performative loss even in the presence of these effects. We provide <font color="#be00be">theor</font>etical guarantees for the convergence of Stateful PerfGD. Our experiments confirm that Stateful PerfGD substantially <font color="#00be00">outperform</font>s previous <font color="#00be00">state-of-the-art</font> methods. </br></br>

<a href='http://arxiv.org/pdf/2111.00788.pdf'>2111.00788</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.5881баллов, №369</br>
<b><font color="#00be00">Hierarchical</font> Adaptable and Transferable Networks (HATN) for Driving\n  Behavior Prediction</b></br>
Authors: , Wang, Letian, Hu, Yeping, Sun, Liting, Zhan, Wei, Tomizuka, Masayoshi, Liu, Changliu</br>
  When autonomous vehicles still struggle to solve challenging situations during on-road driving, humans have long mastered the essence of driving with efficient transferable and adaptable driving capability. By mimicking humans\' cognition model and semantic understanding during driving, we present HATN, a <font color="#00be00">hierarchical</font> framework to generate high-quality driving behaviors in multi-agent dense-traffic environments. Our method hierarchically consists of a high-level intention identification and low-level action generation policy. With the semantic sub-task definition and generic state representation, the hierarchical framework is transferable across different driving scenarios. Besides, our model is also able to capture variations of driving behaviors among individuals and scenarios by an online adaptation module. We demonstrate our algorithms in the task of trajectory prediction for real traffic data at intersections and roundabouts, where we conducted extensive studies of the proposed method and demonstrated how our method <font color="#00be00">outperform</font>ed other methods in terms of prediction accuracy and transferability. </br></br>

<a href='http://arxiv.org/pdf/2112.07471.pdf'>2112.07471</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.5859баллов, №370</br>
<b>I M Avatar: Implicit Morphable Head Avatars from Videos</b></br>
Authors: , Zheng, Yufeng, Abrevaya, Victoria Fern&#xe1;ndez, Chen, Xu, B&#xfc;hler, Marcel C., Black, Michael J., Hilliges, Otmar</br>
  Traditional morphable<font color="#be00be"> face </font>models provide fine-grained control over expression but cannot easily capture geometric and appearance details. Neural volumetric representations approach photo-realism but are hard to animate and do not generalize well to unseen expressions. To tackle this problem, we propose IMavatar (Implicit Morphable avatar), a novel method for learning implicit head avatars from monocular videos. Inspired by the fine-grained control mechanisms afforded by conventional 3DMMs, we represent the expression- and pose-related deformations via learned blendshapes and skinning fields. These attributes are pose-independent and can be used to morph the canonical geometry and texture fields given novel expression and pose parameters. We employ ray tracing and iterative root-finding to locate the canonical surface intersection for each pixel. A key contribution is our novel analytical gradient formulation that enables end-to-end training of IMavatars from videos. We show quantitatively and qualitatively that our method improves geometry and covers a more complete expression space compared to <font color="#00be00">state-of-the-art</font> methods. </br></br>

<a href='http://arxiv.org/pdf/2112.06582.pdf'>2112.06582</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.5826баллов, №371</br>
<b>Geometric Path Enumeration for Equivalence Verification of Neural\n  Networks</b></br>
Authors: , Teuber, Samuel, B&#xfc;ning, Marko Kleine, Kern, Philipp, Sinz, Carsten</br>
  As neural networks (NNs) are increasingly introduced into safety-critical domains, there is a growing need to formally verify NNs before deployment. In this work we focus on the formal verification problem of NN equivalence which aims to prove that two NNs (e.g. an original and a compressed version) show equivalent behavior. Two approaches have been proposed for this problem: Mixed integer linear programming and interval propagation. While the first approach lacks scalability, the latter is only suitable for structurally similar NNs with small weight changes.   The contribution of our paper has four parts. First, we show a <font color="#be00be">theor</font>etical result by proving that the epsilon-equivalence problem is coNP-complete. Secondly, we extend Tran et al.\'s single NN geometric path enumeration algorithm to a setting with multiple NNs. In a third step, we implement the extended algorithm for equivalence verification and evaluate optimizations necessary for its practical use. Finally, we perform a comparative evaluation showing use-cases where our approach <font color="#00be00">outperform</font>s the previous <font color="#00be00">state of the art</font>, both, for equivalence verification as well as for counter-example finding. </br></br>

<a href='http://arxiv.org/pdf/2112.05533.pdf'>2112.05533</a> &nbsp&nbsp (cs:CV, cs:RO) &nbsp&nbsp 0.5807баллов, №372</br>
<b>Error <font color="#be00be">Diagnos</font>is of Deep Monocular Depth Estimation Models</b></br>
Authors: , Chawla, Jagpreet, Thakurdesai, Nikhil, Godase, Anuj, Reza, Md, Crandall, David, Jung, Soon-Heung</br>
  Estimating depth from a monocular image is an ill-posed problem: when the camera projects a 3D scene onto a 2D plane, depth information is inherently and permanently lost. Nevertheless, recent work has shown impressive results in estimating 3D structure from 2D images using deep learning. In this paper, we put on an introspective hat and analyze <font color="#00be00">state-of-the-art</font> monocular depth estimation models in indoor scenes to understand these models\' limitations and error patterns. To address errors in depth estimation, we introduce a novel Depth Error Detection Network (DEDN) that spatially identifies erroneous depth predictions in the monocular depth estimation models. By experimenting with multiple state-of-the-art monocular indoor depth estimation models on multiple datasets, we show that our proposed depth error detection network can identify a significant number of errors in the predicted depth maps. Our module is flexible and can be readily plugged into any monocular depth prediction network to help <font color="#be00be">diagnos</font>e its results. Additionally, we propose a simple yet effective Depth Error Correction Network (DECN) that iteratively corrects errors based on our initial error diagnosis. </br></br>

<a href='http://arxiv.org/pdf/2112.07221.pdf'>2112.07221</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.5789баллов, №373</br>
<b>HET: Scaling out Huge Embedding Model Training via Cache-enabled\n  Distributed Framework</b></br>
Authors: , Miao, Xupeng, Zhang, Hailin, Shi, Yining, Nie, Xiaonan, Yang, Zhi, Tao, Yangyu, Cui, Bin</br>
  Embedding models have been an effective learning paradigm for high-dimensional data. However, one open issue of embedding models is that their representations (latent factors) often result in large parameter space. We observe that existing distributed training frameworks<font color="#be00be"> face </font>a scalability issue of embedding models since updating and retrieving the shared embedding parameters from servers usually dominates the training cycle. In this paper, we propose HET, a new system framework that significantly improves the scalability of huge embedding model training. We embrace skewed popularity distributions of embeddings as a performance opportunity and leverage it to address the communication bottleneck with an embedding cache. To ensure consistency across the caches, we incorporate a new consistency model into HET design, which provides fine-grained consistency guarantees on a per-embedding basis. Compared to previous work that only allows staleness for read operations, HET also utilizes staleness for write operations. Evaluations on six representative tasks show that HET achieves up to 88% embedding communication reductions and up to 20.68x performance speedup over the <font color="#00be00">state-of-the-art</font> baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.06909.pdf'>2112.06909</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.5753баллов, №374</br>
<b>Hallucinating Pose-Compatible Scenes</b></br>
Authors: , Brooks, Tim, Efros, Alexei A.</br>
  What does human pose tell us about a scene? We propose a task to answer this question: given human pose as input, hallucinate a compatible scene. Subtle cues captured by human pose -- action semantics, environment affordances, object interactions -- provide <font color="#00be00">surprisin</font>g insight into which scenes are compatible. We present a large-scale generative adversarial network for pose-conditioned scene generation. We significantly scale the size and complexity of training data, curating a massive meta-dataset containing over 19 million frames of humans in everyday environments. We double the capacity of our model with respect to <font color="#be00be">Style</font>GAN2 to handle such complex data, and design a pose conditioning mechanism that drives our model to learn the nuanced relationship between pose and scene. We leverage our trained model for various applications: hallucinating pose-compatible scene(s) with or without humans, visualizing incompatible scenes and poses, placing a person from one generated image into another scene, and animating pose. Our model produces diverse samples and <font color="#00be00">outperform</font>s pose-conditioned StyleGAN2 and Pix2Pix baselines in terms of accurate human placement (percent of correct keypoints) and image quality (Frechet inception distance). </br></br>

<a href='http://arxiv.org/pdf/2112.05848.pdf'>2112.05848</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.5736баллов, №375</br>
<b>Deep Q-Network with Proximal Iteration</b></br>
Authors: , Asadi, Kavosh, Fakoor, Rasool, Gottesman, Omer, Littman, Michael L., Smola, Alexander J.</br>
  We employ Proximal Iteration for value-function optimization in <font color="#00be00">reinforcement learning</font>. Proximal Iteration is a computationally efficient technique that enables us to bias the optimization procedure towards more desirable solutions. As a concrete application of Proximal Iteration in deep reinforcement learning, we endow the objective function of the Deep Q-Network (DQN) agent with a proximal term to ensure that the online-network component of DQN remains in the vicinity of the target network. The resultant agent, which we call DQN with Proximal Iteration, or DQNPro, exhibits significant improvements over the original DQN on the Atari benchmark. Our results accentuate the power of employing sound optimization techniques for deep reinforcement learning. </br></br>

<a href='http://arxiv.org/pdf/2112.06204.pdf'>2112.06204</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.5732баллов, №376</br>
<b><font color="#00be00">Few-Shot</font> Out-of-Domain Transfer Learning of Natural Language\n  Explanations</b></br>
Authors: , Yordanov, Yordan, Kocijan, Vid, Lukasiewicz, Thomas, Camburu, Oana-Maria</br>
  Recently, there has been an increasing interest in models that generate natural language explanations (NLEs) for their decisions. However, training a model to provide NLEs requires the acquisition of task-specific NLEs, which is time- and resource-consuming. A potential solution is the out-of-domain transfer of NLEs from a domain with a large number of NLEs to a domain with scarce NLEs but potentially a large number of labels, via <font color="#00be00">few-shot</font> transfer learning. In this work, we introduce three vanilla approaches for few-shot transfer learning of NLEs for the case of few NLEs but abundant labels, along with an adaptation of an existing vanilla fine-tuning approach. We transfer explainability from the natural language inference domain, where a large dataset of human-written NLEs exists (e-SNLI), to the domains of (1) hard cases of pronoun resolution, where we introduce a small dataset of NLEs on top of the WinoGrande dataset (small-e-WinoGrande), and (2) commonsense validation (ComVE). Our results demonstrate that the transfer of NLEs <font color="#00be00">outperform</font>s the single-task methods, and establish the best strategies out of the four identified training regimes. We also investigate the scalability of the best methods, both in terms of training data and model size. </br></br>

<a href='http://arxiv.org/pdf/2112.08025.pdf'>2112.08025</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.5718баллов, №377</br>
<b>TLogic: Temporal Logical Rules for Explainable Link Forecasting on\n  Temporal <font color="#960096">Knowledge Graph</font>s</b></br>
Authors: , Liu, Yushan, Ma, Yunpu, Hildebrandt, Marcel, Joblin, Mitchell, Tresp, Volker</br>
  Conventional static <font color="#960096">knowledge graph</font>s model entities in relational data as nodes, connected by edges of specific relation types. However, information and knowledge evolve continuously, and temporal dynamics emerge, which are expected to influence future situations. In temporal knowledge graphs, time information is integrated into the graph by equipping each edge with a timestamp or a time range. Embedding-based methods have been introduced for link prediction on temporal knowledge graphs, but they mostly lack explainability and comprehensible reasoning chains. Particularly, they are usually not designed to deal with link forecasting -- event prediction involving future timestamps. We address the task of link forecasting on temporal knowledge graphs and introduce TLogic, an explainable framework that is based on temporal logical rules extracted via temporal random walks. We compare TLogic with <font color="#00be00">state-of-the-art</font> baselines on three benchmark datasets and show better overall performance while our method also provides explanations that preserve time consistency. Furthermore, in contrast to most state-of-the-art embedding-based methods, TLogic works well in the inductive setting where already learned rules are transferred to related datasets with a common vocabulary. </br></br>

<a href='http://arxiv.org/pdf/2112.07768.pdf'>2112.07768</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.5718баллов, №378</br>
<b>Efficient Dynamic Graph Representation Learning at Scale</b></br>
Authors: , Chen, Xinshi, Zhu, Yan, Xu, Haowen, Liu, Mengyang, Xiong, Liang, Zhang, Muhan, Song, Le</br>
  Dynamic graphs with ordered sequences of events between nodes are prevalent in <font color="#009600">real-world</font> industrial applications such as <font color="#be00be">e-commerce</font> and social platforms. However, representation learning for dynamic graphs has posed great computational challenges due to the time and structure dependency and irregular nature of the data, preventing such models from being deployed to real-world applications. To tackle this challenge, we propose an efficient algorithm, Efficient Dynamic Graph lEarning (EDGE), which selectively expresses certain temporal dependency via training loss to improve the parallelism in computations. We show that EDGE can scale to dynamic graphs with millions of nodes and hundreds of millions of temporal events and achieve new <font color="#00be00">state-of-the-art</font> (SOTA) performance. </br></br>

<a href='http://arxiv.org/pdf/2112.06628.pdf'>2112.06628</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 0.5681баллов, №379</br>
<b>Quantum Stream Learning</b></br>
Authors: , Ding, Yongcheng, Chen, Xi, Magdalena-Benedicto, Rafael, Mart&#xed;n-Guerrero, Jos&#xe9; D.</br>
  The exotic nature of quantum mechanics makes machine learning (ML) be different in the quantum realm compared to classical applications. ML can be used for knowledge discovery using information continuously extracted from a quantum system in a broad range of tasks. The model receives streaming quantum information for learning and decision-making, resulting in instant feedback on the quantum system. As a stream learning approach, we present a deep <font color="#00be00">reinforcement learning</font> on streaming data from a continuously measured qubit at the presence of detuning, dephasing, and relaxation. We also investigate how the agent adapts to another quantum noise pattern by transfer learning. Stream learning provides a better understanding of closed-loop quantum control, which may pave the way for advanced quantum technologies. </br></br>

<a href='http://arxiv.org/pdf/2112.08321.pdf'>2112.08321</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.5674баллов, №380</br>
<b>CheckDST: Measuring <font color="#009600">Real-World</font> Generalization of Dialogue State <font color="#be00be">Tracking</font>\n  Performance</b></br>
Authors: , Cho, Hyundong, Sankar, Chinnadhurai, Lin, Christopher, Sadagopan, Kaushik Ram, Shayandeh, Shahin, Celikyilmaz, Asli, May, Jonathan, Beirami, Ahmad</br>
  Recent neural models that extend the pretrain-then-finetune paradigm continue to achieve new <font color="#00be00">state-of-the-art</font> results on joint goal accuracy (JGA) for dialogue state <font color="#be00be">tracking</font> (DST) benchmarks. However, we call into question their robustness as they show sharp drops in JGA for conversations containing utterances or dialog flows with realistic perturbations. Inspired by CheckList (Ribeiro et al., 2020), we design a collection of metrics called CheckDST that facilitate comparisons of DST models on comprehensive dimensions of robustness by testing well-known weaknesses with augmented test sets. We evaluate recent DST models with CheckDST and argue that models should be assessed more holistically rather than pursuing state-of-the-art on JGA since a higher JGA does not guarantee better overall robustness. We find that span-based classification models are resilient to unseen named entities but not robust to language variety, whereas those based on autoregressive language models generalize better to language variety but tend to memorize named entities and often hallucinate. Due to their respective weaknesses, neither approach is yet suitable for <font color="#009600">real-world</font> deployment. We believe CheckDST is a useful guide for future research to develop task-oriented dialogue models that embody the strengths of various methods. </br></br>

<a href='http://arxiv.org/pdf/2112.06725.pdf'>2112.06725</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp 0.5674баллов, №381</br>
<b>Computational bioacoustics with deep learning: a review and roadmap</b></br>
Authors: , Stowell, Dan</br>
  Animal vocalisations and natural soundscapes are fascinating objects of study, and contain valuable evidence about animal behaviours, populations and ecosystems. They are studied in bioacoustics and ecoacoustics, with signal processing and analysis an important component. Computational bioacoustics has accelerated in recent decades due to the growth of affordable digital sound recording devices, and to huge progress in informatics such as big data, signal processing and machine learning. Methods are inherited from the wider field of deep learning, including speech and image processing. However, the tasks, demands and data characteristics are often different from those addressed in speech or<font color="#be00be"> music </font>analysis. There remain unsolved problems, and tasks for which evidence is surely present in many acoustic signals, but not yet realised. In this paper I perform a review of the <font color="#00be00">state of the art</font> in deep learning for computational bioacoustics, aiming to clarify key concepts and identify and analyse knowledge gaps. Based on this, I offer a subjective but principled roadmap for computational bioacoustics with deep learning: topics that the community should aim to address, in order to make the most of future developments in AI and informatics, and to use audio data in answering zoological and ecological questions. </br></br>

<a href='http://arxiv.org/pdf/2112.05593.pdf'>2112.05593</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.5668баллов, №382</br>
<b>A Review of Indoor Millimeter Wave Device-based Localization and\n  Device-free Sensing Technologies</b></br>
Authors: , Shastri, Anish, Valecha, Neharika, Bashirov, Enver, Tataria, Harsh, Lentmaier, Michael, Tufvesson, Fredrik, Rossi, Michele, Casari, Paolo</br>
  The commercial availability of low-cost millimeter wave (mmWave) communication and radar devices is starting to improve the penetration of such technologies in consumer <font color="#be00be">market</font>s, paving the way for large-scale and dense deployments in fifth-generation (5G)-and-beyond as well as 6G networks. At the same time, pervasive mmWave access will enable device localization and device-free sensing with unprecedented accuracy, especially with respect to sub-6 GHz commercial-grade devices. This paper surveys the <font color="#00be00">state of the art</font> in device-based localization and device-free sensing using mmWave communication and radar devices, with a focus on indoor deployments. We first overview key concepts about mmWave signal propagation and system design. Then, we provide a detailed account of approaches and algorithms for localization and sensing enabled by mmWaves. We consider several dimensions in our analysis, including the main objectives, techniques, and performance of each work, whether each research reached some degree of implementation, and which hardware platforms were used for this purpose. We conclude by discussing that better algorithms for consumer-grade devices, data fusion methods for dense deployments, as well as an educated application of machine learning methods are promising, relevant and timely research directions. </br></br>

<a href='http://arxiv.org/pdf/2112.07269.pdf'>2112.07269</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.5605баллов, №383</br>
<b>MCDS: AI Augmented Workflow Scheduling in<font color="#960096"> Mobile </font>Edge Cloud Computing\n  Systems</b></br>
Authors: , Tuli, Shreshth, Casale, Giuliano, Jennings, Nicholas R.</br>
  Workflow scheduling is a long-studied problem in parallel and distributed computing (PDC), aiming to efficiently utilize compute resources to meet user\'s service requirements. Recently proposed scheduling methods leverage the low response times of edge computing platforms to optimize application Quality of Service (QoS). However, scheduling workflow applications in<font color="#960096"> mobile </font>edge-cloud systems is challenging due to computational heterogeneity, changing latencies of mobile devices and the volatile nature of workload resource requirements. To overcome these difficulties, it is essential, but at the same time challenging, to develop a long-sighted optimization scheme that efficiently models the QoS objectives. In this work, we propose MCDS: Monte Carlo Learning using Deep Surrogate Models to efficiently schedule workflow applications in mobile edge-cloud computing systems. MCDS is an Artificial Intelligence (AI) based scheduling approach that uses a tree-based search strategy and a deep neural network-based surrogate model to estimate the long-term QoS impact of immediate actions for robust optimization of scheduling decisions. Experiments on physical and simulated edge-cloud testbeds show that MCDS can improve over the <font color="#00be00">state-of-the-art</font> methods in terms of energy consumption, response time, SLA violations and cost by at least 6.13, 4.56, 45.09 and 30.71 percent respectively. </br></br>

<a href='http://arxiv.org/pdf/2112.06240.pdf'>2112.06240</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.5599баллов, №384</br>
<b>Improving Logical-Level Natural Language Generation with\n  Topic-Conditioned Data Augmentation and Logical Form Generation</b></br>
Authors: , Liu, Ao, Luo, Congjian, Okazaki, Naoaki</br>
  Logical Natural Language Generation, i.e., generating textual descriptions that can be logically entailed by a structured table, has been a challenge due to the low fidelity of the generation. \\citet{chen2020logic2text} have addressed this problem by annotating interim logical programs to control the generation contents and semantics, and presented the task of table-aware logical form to text (Logic2text) generation. However, although table instances are abundant in the <font color="#009600">real world</font>, logical forms paired with textual descriptions require costly human annotation work, which limits the performance of neural models. To mitigate this, we propose topic-conditioned data augmentation (TopicDA), which utilizes<font color="#00be00"> GPT</font>-2 to generate unpaired logical forms and textual descriptions directly from tables. We further introduce logical form generation (LG), a dual task of Logic2text that requires generating a valid logical form based on a text description of a table. We also propose a semi-supervised learning approach to jointly train a Logic2text and an LG model with both labeled and augmented data. The two models benefit from each other by providing extra supervision signals through back-translation. Experimental results on the Logic2text dataset and the LG task demonstrate that our approach can effectively utilize the augmented data and <font color="#00be00">outperform</font> supervised baselines by a substantial margin. </br></br>

<a href='http://arxiv.org/pdf/2112.07819.pdf'>2112.07819</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.5456баллов, №385</br>
<b>Weed Recognition using Deep Learning Techniques on Class-imbalanced\n  Imagery</b></br>
Authors: , Hasan, A S M Mahmudul, Sohel, Ferdous, Diepeveen, Dean, Laga, Hamid, Jones, Michael G. K.</br>
  Most weed species can adversely impact agricultural productivity by competing for nutrients required by high-value crops. Manual weeding is not practical for large cropping areas. Many studies have been undertaken to develop automatic weed management systems for agricultural crops. In this process, one of the major tasks is to recognise the weeds from images. However, weed recognition is a challenging task. It is because weed and crop plants can be similar in colour, texture and shape which can be exacerbated further by the imaging conditions, geographic or <font color="#be00be">weather</font> conditions when the images are recorded. Advanced machine learning techniques can be used to recognise weeds from imagery. In this paper, we have investigated five <font color="#00be00">state-of-the-art</font> deep neural networks, namely VGG16, ResNet-50, Inception-V3, Inception-ResNet-v2 and MobileNetV2, and evaluated their performance for weed recognition. We have used several experimental settings and multiple dataset combinations. In particular, we constructed a large weed-crop dataset by combining several smaller datasets, mitigating class imbalance by data augmentation, and using this dataset in benchmarking the deep neural networks. We investigated the use of transfer learning techniques by preserving the pre-trained weights for extracting the features and fine-tuning them using the images of crop and weed datasets. We found that VGG16 performed better than others on small-scale datasets, while ResNet-50 performed better than other deep networks on the large combined dataset. </br></br>

<a href='http://arxiv.org/pdf/2112.07403.pdf'>2112.07403</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.5444баллов, №386</br>
<b>Stochastic Actor-Executor-Critic for Image-to-Image Translation</b></br>
Authors: , Luo, Ziwei, Hu, Jing, Wang, Xin, Lyu, Siwei, Kong, Bin, Yin, Youbing, Song, Qi, Wu, Xi</br>
  Training a model-free deep <font color="#00be00">reinforcement learning</font> model to solve image-to-image translation is difficult since it involves high-dimensional continuous state and action spaces. In this paper, we draw inspiration from the recent success of the maximum entropy reinforcement learning framework designed for challenging continuous control problems to develop stochastic policies over high dimensional continuous spaces including image representation, generation, and control simultaneously. Central to this method is the Stochastic Actor-Executor-Critic (SAEC) which is an off-policy actor-critic model with an additional executor to generate realistic images. Specifically, the actor focuses on the high-level representation and control policy by a stochastic latent action, as well as explicitly directs the executor to generate low-level actions to manipulate the state. Experiments on several image-to-image translation tasks have demonstrated the effectiveness and robustness of the proposed SAEC when facing high-dimensional continuous space problems. </br></br>

<a href='http://arxiv.org/pdf/2111.15296.pdf'>2111.15296</a> &nbsp&nbsp (cs:NE) &nbsp&nbsp 0.5415баллов, №387</br>
<b><font color="#00be00">Brain</font>ScaleS Large Scale Spike Communication using Extoll</b></br>
Authors: , Thommes, Tobias, Buwen, Niels, Gr&#xfc;bl, Andreas, M&#xfc;ller, Eric, Br&#xfc;ning, Ulrich, Schemmel, Johannes</br>
  The <font color="#00be00">Brain</font>ScaleS Neuromorphic Computing System is currently connected to a compute cluster via Gigabit-Ethernet network technology. This is convenient for the currently used experiment mode, where neuronal networks cover at most one wafer module. When modelling networks of larger size, as for example a full sized cortical microcircuit model, one has to think about connecting neurons across wafer modules to larger networks. This can be done, using the Extoll networking technology, which provides high bandwidth and low latencies, as well as a low overhead packet protocol format. </br></br>

<a href='http://arxiv.org/pdf/2112.05893.pdf'>2112.05893</a> &nbsp&nbsp (cs:SD, cs:ML) &nbsp&nbsp 0.5370баллов, №388</br>
<b>Hybrid Neural Networks for On-device Directional Hearing</b></br>
Authors: , Wang, Anran, Kim, Maruchi, Zhang, Hao, Gollakota, Shyamnath</br>
  On-device directional hearing requires audio source separation from a given direction while achieving stringent human-imperceptible latency requirements. While neural nets can achieve significantly better performance than traditional beamformers, all existing models fall short of supporting low-latency causal inference on computationally-constrained wearables. We present DeepBeam, a hybrid model that combines traditional beamformers with a custom <font color="#be00be">lightweight</font> neural net. The former reduces the computational burden of the latter and also improves its generalizability, while the latter is designed to further reduce the memory and computational overhead to enable real-time and low-latency operations. Our evaluation shows comparable performance to <font color="#00be00">state-of-the-art</font> causal inference models on synthetic data while achieving a 5x reduction of model size, 4x reduction of computation per second, 5x reduction in processing time and generalizing better to real hardware data. Further, our real-time hybrid model runs in 8 ms on<font color="#960096"> mobile </font>CPUs designed for low-power wearable devices and achieves an end-to-end latency of 17.5 ms. </br></br>

<a href='http://arxiv.org/pdf/2112.07610.pdf'>2112.07610</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.5351баллов, №389</br>
<b>Improving Compositional Generalization with Latent Structure and Data\n  Augmentation</b></br>
Authors: , Qiu, Linlu, Shaw, Peter, Pasupat, Panupong, Nowak, Pawe&#x142; Krzysztof, Linzen, Tal, Sha, Fei, Toutanova, Kristina</br>
  Generic unstructured neural networks have been shown to struggle on out-of-distribution compositional generalization. Compositional data augmentation via example recombination has transferred some prior knowledge about compositionality to such black-box neural models for several semantic <font color="#be00be">parsing</font> tasks, but this often required task-specific engineering or provided limited gains.   We present a more powerful data recombination method using a model called Compositional Structure Learner (CSL). CSL is a generative model with a quasi-synchronous context-free grammar backbone, which we induce from the training data. We sample recombined examples from CSL and add them to the fine-tuning data of a pre-trained sequence-to-sequence model (T5). This procedure effectively transfers most of CSL\'s compositional bias to T5 for <font color="#be00be">diagnos</font>tic tasks, and results in a model even stronger than a T5-CSL ensemble on two <font color="#009600">real world</font> compositional generalization tasks. This results in new <font color="#00be00">state-of-the-art</font> performance for these challenging semantic parsing tasks requiring generalization to both natural language variation and novel compositions of elements. </br></br>

<a href='http://arxiv.org/pdf/2112.06598.pdf'>2112.06598</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.5344баллов, №390</br>
<b>WECHSEL: Effective initialization of subword embeddings for\n  cross-lingual transfer of monolingual language models</b></br>
Authors: , Minixhofer, Benjamin, Paischer, Fabian, Rekabsaz, Navid</br>
  Recently, large pretrained language models (LMs) have gained popularity. Training these models requires ever more computational resources and most of the existing models are trained on English text only. It is exceedingly expensive to train these models in other languages. To alleviate this problem, we introduce a method -- called WECHSEL -- to transfer English models to new languages. We exchange the tokenizer of the English model with a tokenizer in the target language and initialize token embeddings such that they are close to semantically similar English tokens by utilizing multilingual static word embeddings covering English and the target language. We use WECHSEL to transfer<font color="#00be00"> GPT</font>-2 and RoBERTa models to 4 other languages (French, German, <font color="#be00be">Chinese</font> and Swahili). WECHSEL improves over a previously proposed method for cross-lingual parameter transfer and <font color="#00be00">outperform</font>s models of comparable size trained from scratch in the target language with up to 64x less training effort. Our method makes training large language models for new languages more accessible and less damaging to the environment. We make our code and models <font color="#00be00">publicly available</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.07917.pdf'>2112.07917</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.5327баллов, №391</br>
<b>SPTS: Single-Point Text Spotting</b></br>
Authors: , Peng, Dezhi, Wang, Xinyu, Liu, Yuliang, Zhang, Jiaxin, Huang, Mingxin, Lai, Songxuan, Zhu, Shenggao, Li, Jing, Lin, Dahua, Shen, Chunhua, Jin, Lianwen</br>
  Almost all scene text spotting (detection and recognition) methods rely on costly box annotation (e.g., text-line box, word-level box, and character-level box). For the first time, we demonstrate that training scene text spotting models can be achieved with an extremely low-cost annotation of a single-point for each instance. We propose an end-to-end scene text spotting method that tackles scene text spotting as a sequence prediction task, like language modeling. Given an image as input, we formulate the desired detection and recognition results as a sequence of discrete tokens and use an auto-regressive <font color="#00be00">transformer</font> to predict the sequence. We achieve promising results on several horizontal, multi-oriented, and arbitrarily shaped scene text benchmarks. Most significantly, we show that the performance is not very sensitive to the positions of the point annotation, meaning that it can be much easier to be annotated and automatically generated than the bounding box that requires precise positions. We believe that such a pioneer attempt indicates a significant opportunity for scene text spotting applications of a much larger scale than previously possible. </br></br>

<a href='http://arxiv.org/pdf/2112.05596.pdf'>2112.05596</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.5320баллов, №392</br>
<b>Automated tabulation of <font color="#be00be">clinic</font>al trial results: A joint entity and\n  relation extraction approach with <font color="#00be00">transformer</font>-based language representations</b></br>
Authors: , Whitton, Jetsun, Hunter, Anthony</br>
  Evidence-based <font color="#640064">medic</font>ine, the practice in which healthcare professionals refer to the best available evidence when making decisions, forms the foundation of modern healthcare. However, it relies on labour-intensive systematic reviews, where domain specialists must aggregate and extract information from thousands of publications, primarily of randomised controlled trial (RCT) results, into evidence tables. This paper investigates automating evidence table generation by decomposing the problem across two language processing tasks: \\textit{<font color="#be00be">named entity</font> recognition}, which identifies key entities within text, such as <font color="#00be00">drug</font> names, and \\textit{relation extraction}, which maps their relationships for separating them into ordered tuples. We focus on the automatic tabulation of sentences from published RCT abstracts that report the results of the study outcomes. Two deep neural net models were developed as part of a joint extraction pipeline, using the principles of transfer learning and <font color="#00be00">transformer</font>-based language representations. To train and test these models, a new gold-standard corpus was developed, comprising almost 600 result sentences from six <font color="#be00be">diseas</font>e areas. This approach demonstrated significant advantages, with our system performing well across multiple natural language processing tasks and disease areas, as well as in generalising to disease domains unseen during training. Furthermore, we show these results were achievable through training our models on as few as 200 example sentences. The final system is a proof of concept that the generation of evidence tables can be semi-automated, representing a step towards fully automating systematic reviews. </br></br>

<a href='http://arxiv.org/pdf/2112.06121.pdf'>2112.06121</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.5309баллов, №393</br>
<b>Magnifying Networks for Images with Billions of Pixels</b></br>
Authors: , Dimitriou, Neofytos, Arandjelovic, Ognjen</br>
  The shift towards end-to-end deep learning has brought unprecedented advances in many areas of computer vision. However, there are cases where the input images are excessively large, deeming end-to-end approaches impossible. In this paper, we introduce a new network, the Magnifying Network (MagNet), which can be trained end-to-end independently of the input image size. MagNets combine convolutional neural networks with differentiable spatial <font color="#00be00">transformer</font>s, in a new way, to navigate and successfully learn from images with billions of pixels. Drawing inspiration from the magnifying nature of an ordinary brightfield microscope, a MagNet processes a downsampled version of an image, and without supervision learns how to identify areas that may carry value to the task at hand, upsamples them, and recursively repeats this process on each of the extracted patches. Our results on the <font color="#00be00">publicly available</font> Camelyon16 and Camelyon17 datasets first corroborate to the effectiveness of MagNets and the proposed optimization framework and second, demonstrate the advantage of Magnets\' built-in transparency, an attribute of utmost importance for critical processes such as <font color="#640064">medic</font>al <font color="#be00be">diagnos</font>is. </br></br>

<a href='http://arxiv.org/pdf/2112.06244.pdf'>2112.06244</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.5288баллов, №394</br>
<b>SHGNN: Structure-Aware Heterogeneous Graph Neural Network</b></br>
Authors: , Xu, Wentao, Xia, Yingce, Liu, Weiqing, Bian, Jiang, Yin, Jian, Liu, Tie-Yan</br>
  Many <font color="#009600">real-world</font> graphs (networks) are heterogeneous with different types of nodes and edges. Heterogeneous graph embedding, aiming at learning the low-dimensional node representations of a heterogeneous graph, is vital for various downstream applications. Many meta-path based embedding methods have been proposed to learn the semantic information of heterogeneous graphs in recent years. However, most of the existing techniques overlook the graph structure information when learning the heterogeneous graph embeddings. This paper proposes a novel Structure-Aware Heterogeneous Graph Neural Network (SHGNN) to address the above limitations. In detail, we first utilize a feature propagation module to capture the local structure information of intermediate nodes in the meta-path. Next, we use a tree-attention aggregator to incorporate the graph structure information into the aggregation module on the meta-path. Finally, we leverage a meta-path aggregator to fuse the information aggregated from different meta-paths. We conducted experiments on node classification and <font color="#be00be">clustering</font> tasks and achieved <font color="#00be00">state-of-the-art</font> results on the benchmark datasets, which shows the effectiveness of our proposed method. </br></br>

<a href='http://arxiv.org/pdf/2112.07569.pdf'>2112.07569</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.5230баллов, №395</br>
<b>Cooperation for Scalable Supervision of Autonomy in Mixed Traffic</b></br>
Authors: , Hickert, Cameron, Li, Sirui, Wu, Cathy</br>
  Improvements in autonomy offer the potential for positive outcomes in a number of domains, yet guaranteeing their safe deployment is difficult. This work investigates how humans can intelligently supervise agents to achieve some level of safety even when performance guarantees are elusive. The motivating research question is: In safety-critical settings, can we avoid the need to have one human supervise one machine at all times? The paper formalizes this \'scaling supervision\' problem, and investigates its application to the safety-critical context of autonomous vehicles (AVs) merging into traffic. It proposes a conservative, reachability-based method to reduce the burden on the AVs\' human supervisors, which allows for the establishment of high-confidence upper bounds on the supervision requirements in this setting. Order statistics and traffic simulations with deep <font color="#00be00">reinforcement learning</font> show analytically and numerically that teaming of AVs enables supervision time sublinear in AV adoption. A key takeaway is that, despite present imperfections of AVs, supervision becomes more tractable as AVs are deployed en masse. While this work focuses on AVs, the scalable supervision framework is relevant to a broader array of autonomous control challenges. </br></br>

<a href='http://arxiv.org/pdf/2112.08743.pdf'>2112.08743</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.5215баллов, №396</br>
<b>Radio-Assisted Human Detection</b></br>
Authors: , Qiu, Chengrun, Zhang, Dongheng, Hu, Yang, Li, Houqiang, Sun, Qibin, Chen, Yan</br>
  In this paper, we propose a radio-assisted human detection framework by incorporating radio information into the <font color="#00be00">state-of-the-art</font> detection methods, including anchor-based onestage detectors and two-stage detectors. We extract the radio localization and identifer information from the radio signals to assist the human detection, due to which the problem of false positives and false negatives can be greatly alleviated. For both detectors, we use the confidence score revision based on the radio localization to improve the detection performance. For two-stage detection methods, we propose to utilize the region proposals generated from radio localization rather than relying on region proposal network (RPN). Moreover, with the radio identifier information, a non-max suppression method with the radio localization constraint has also been proposed to further suppress the false detections and reduce miss detections. Experiments on the simulative Microsoft COCO dataset and Caltech <font color="#be00be">pedestrian</font> datasets show that the mean average precision (mAP) and the miss rate of the state-of-the-art detection methods can be improved with the aid of radio information. Finally, we conduct experiments in <font color="#009600">real-world</font> scenarios to demonstrate the feasibility of our proposed method in practice. </br></br>

<a href='http://arxiv.org/pdf/2112.05908.pdf'>2112.05908</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.5146баллов, №397</br>
<b><font color="#be00be">Federated</font> <font color="#00be00">Reinforcement Learning</font> at the Edge</b></br>
Authors: , Gatsis, Konstantinos</br>
  Modern cyber-physical architectures use data collected from systems at different physical locations to learn appropriate behaviors and adapt to uncertain environments. However, an important challenge arises as communication exchanges at the edge of networked systems are costly due to limited resources. This paper considers a setup where multiple agents need to communicate efficiently in order to jointly solve a <font color="#00be00">reinforcement learning</font> problem over time-series data collected in a distributed manner. This is posed as learning an approximate value function over a communication network. An algorithm for achieving communication efficiency is proposed, supported with <font color="#be00be">theor</font>etical guarantees, practical implementations, and numerical evaluations. The approach is based on the idea of communicating only when sufficiently informative data is collected. </br></br>

<a href='http://arxiv.org/pdf/2112.07805.pdf'>2112.07805</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.5130баллов, №398</br>
<b>Network Graph Based Neural <font color="#00be00">Architecture Search</font></b></br>
Authors: , Huang, Zhenhan, Jiang, Chunheng, Chen, Pin-Yu, Gao, Jianxi</br>
  Neural <font color="#00be00">architecture search</font> enables automation of architecture design. Despite its success, it is computationally costly and does not provide an insight on how to design a desirable architecture. Here we propose a new way of searching neural network where we search neural architecture by rewiring the corresponding graph and predict the architecture performance by graph properties. Because we do not perform machine learning over the entire graph space and use predicted architecture performance to search architecture, the searching process is remarkably efficient. We find graph based search can give a reasonably good prediction of desirable architecture. In addition, we find graph properties that are effective to predict architecture performance. Our work proposes a new way of searching neural architecture and provides insights on neural architecture design. </br></br>

<a href='http://arxiv.org/pdf/2112.05381.pdf'>2112.05381</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.5125баллов, №399</br>
<b>UNIST: Unpaired Neural Implicit Shape Translation Network</b></br>
Authors: , Chen, Qimin, Merz, Johannes, Sanghi, Aditya, Shayani, Hooman, Mahdavi-Amiri, Ali, Zhang, Hao</br>
  We introduce UNIST, the first deep neural implicit model for general-purpose, unpaired shape-to-shape translation, in both 2D and 3D domains. Our model is built on autoencoding implicit fields, rather than <font color="#be00be">point cloud</font>s which represents the <font color="#00be00">state of the art</font>. Furthermore, our translation network is trained to perform the task over a latent grid representation which combines the merits of both latent-space processing and position awareness, to not only enable drastic shape transforms but also well preserve spatial features and fine local details for natural shape translations. With the same network architecture and only dictated by the input domain pairs, our model can learn both <font color="#be00be">style</font>-preserving content alteration and content-preserving style transfer. We demonstrate the generality and quality of the translation results, and compare them to well-known baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.07859.pdf'>2112.07859</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.5114баллов, №400</br>
<b>Finite-Sample Analysis of Decentralized Q-Learning for Stochastic Games</b></br>
Authors: , Gao, Zuguang, Ma, Qianqian, Ba&#x15f;ar, Tamer, Birge, John R.</br>
  Learning in stochastic games is arguably the most standard and fundamental setting in multi-agent <font color="#00be00">reinforcement learning</font> (MARL). In this paper, we consider decentralized MARL in stochastic games in the non-asymptotic regime. In particular, we establish the finite-sample complexity of fully decentralized Q-learning algorithms in a significant class of general-sum stochastic games (SGs) - weakly acyclic SGs, which includes the common cooperative MARL setting with an identical reward to all agents (a Markov team problem) as a special case. We focus on the practical while challenging setting of fully decentralized MARL, where neither the rewards nor the actions of other agents can be observed by each agent. In fact, each agent is completely oblivious to the presence of other decision makers. Both the tabular and the linear function approximation cases have been considered. In the tabular setting, we analyze the sample complexity for the decentralized Q-learning algorithm to converge to a Markov perfect equilibrium (Nash equilibrium). With linear function approximation, the results are for convergence to a linear approximated equilibrium - a new notion of equilibrium that we propose - which describes that each agent\'s policy is a best reply (to other agents) within a linear space. Numerical experiments are also provided for both settings to demonstrate the results. </br></br>

<a href='http://arxiv.org/pdf/2112.06454.pdf'>2112.06454</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.5071баллов, №401</br>
<b>Split GCN: Effective Interactive Annotation for <font color="#be00be">Segmentation</font> of\n  Disconnected Instance</b></br>
Authors: , Kim, Namgil, Kang, Barom, Cho, Yeonok</br>
  Annotating object boundaries by humans demands high costs. Recently, polygon-based annotation methods with human interaction have shown successful performance. However, given the connected vertex topology, these methods exhibit difficulty predicting the disconnected components in an object. This paper introduces Split-GCN, a novel architecture based on the polygon approach and self-attention mechanism. By offering the direction information, Split-GCN enables the polygon vertices to move more precisely to the object boundary. Our model successfully predicts disconnected components of an object by transforming the initial topology using the context exchange about the dependencies of vertices. Split-GCN demonstrates <font color="#960096">competitive</font> performance with the <font color="#00be00">state-of-the-art</font> models on Cityscapes and even higher performance with the baseline models. On four cross-domain datasets, we confirm our model\'s generalization ability. </br></br>

<a href='http://arxiv.org/pdf/2112.05181.pdf'>2112.05181</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.5008баллов, №402</br>
<b>Contextualized Spatio-Temporal Contrastive Learning with\n  Self-Supervision</b></br>
Authors: , Yuan, Liangzhe, Qian, Rui, Cui, Yin, Gong, Boqing, Schroff, Florian, Yang, Ming-Hsuan, Adam, Hartwig, Liu, Ting</br>
  A modern self-supervised learning algorithm typically enforces persistency of the representations of an instance across views. While being very effective on learning holistic image and video representations, such an approach becomes sub-optimal for learning spatio-temporally fine-grained features in videos, where scenes and instances evolve through space and time. In this paper, we present the Contextualized Spatio-Temporal Contrastive Learning (ConST-CL) framework to effectively learn spatio-temporally fine-grained representations using self-supervision. We first design a region-based self-supervised pretext task which requires the model to learn to transform instance representations from one view to another guided by context features. Further, we introduce a simple network design that effectively reconciles the simultaneous learning process of both holistic and local representations. We evaluate our learned representations on a variety of downstream tasks and ConST-CL achieves <font color="#00be00">state-of-the-art</font> results on four datasets. For spatio-temporal action localization, ConST-CL achieves 39.4% mAP with ground-truth boxes and 30.5% mAP with detected boxes on the AVA-Kinetics validation set. For object <font color="#be00be">tracking</font>, ConST-CL achieves 78.1% precision and 55.2% success scores on OTB2015. Furthermore, ConST-CL achieves 94.8% and 71.9% top-1 fine-tuning accuracy on video action recognition datasets, UCF101 and HMDB51 respectively. We plan to release our code and models to the public. </br></br>

<a href='http://arxiv.org/pdf/2112.05807.pdf'>2112.05807</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CL) &nbsp&nbsp 0.4978баллов, №403</br>
<b>Computer-Assisted Creation of Boolean Search Rules for Text\n  Classification in the Legal Domain</b></br>
Authors: , Westermann, Hannes, Savelka, Jaromir, Walker, Vern R., Ashley, Kevin D., Benyekhlef, Karim</br>
  In this paper, we present a method of building strong, explainable classifiers in the form of Boolean search rules. We developed an interactive environment called CASE (Computer Assisted Semantic Exploration) which exploits word co-occurrence to guide human annotators in selection of relevant search terms. The system seamlessly facilitates iterative evaluation and improvement of the classification rules. The process enables the human annotators to leverage the benefits of statistical information while incorporating their expert intuition into the creation of such rules. We evaluate classifiers created with our CASE system on 4 datasets, and compare the results to machine learning methods, including SKOPE rules, <font color="#be00be">Random forest</font>, Support Vector Machine, and fastText classifiers. The results drive the discussion on trade-offs between superior compactness, simplicity, and intuitiveness of the Boolean search rules versus the better performance of <font color="#00be00">state-of-the-art</font> machine learning models for text classification. </br></br>

<a href='http://arxiv.org/pdf/2112.06677.pdf'>2112.06677</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.4954баллов, №404</br>
<b>Firefly: Supporting Drone Localization With Visible Light Communication</b></br>
Authors: , Hern&#xe1;ndez, Ricardo Ampudia, Xu, Talia, Huang, Yanqiu, Zamalloa, Marco A. Z&#xfa;&#xf1;iga</br>
  Drones are not fully trusted yet. Their reliance on radios and cameras for navigation raises safety and <font color="#be00be">privacy</font> concerns. These systems can fail, causing accidents, or be misused for unauthorized recordings. Considering recent regulations allowing commercial drones to operate only at night, we propose a radically new approach where drones obtain navigation information from artificial lighting. In our system, standard light bulbs modulate their intensity to send beacons and drones decode this information with a simple photodiode. This optical information is combined with the inertial and altitude sensors in the drones to provide localization without the need for radios, GPS or cameras. Our framework is the first to provide 3D drone localization with light and we evaluate it with a testbed consisting of four light beacons and a mini-drone. We show that, our approach allows to locate the drone within a few decimeters of the actual position and compared to <font color="#00be00">state-of-the-art</font> positioning methods, reduces the localization error by 42%. </br></br>

<a href='http://arxiv.org/pdf/2112.05213.pdf'>2112.05213</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.4917баллов, №405</br>
<b>Progressive Seed Generation Auto-encoder for Unsupervised <font color="#be00be">Point Cloud</font>\n  Learning</b></br>
Authors: , Yang, Juyoung, Ahn, Pyunghwan, Kim, Doyeon, Lee, Haeil, Kim, Junmo</br>
  With the development of 3D scanning technologies, 3D vision tasks have become a popular research area. Owing to the large amount of data acquired by sensors, unsupervised learning is essential for understanding and utilizing <font color="#be00be">point cloud</font>s without an expensive annotation process. In this paper, we propose a novel framework and an effective auto-encoder architecture named &quot;PSG-Net&quot; for reconstruction-based learning of point clouds. Unlike existing studies that used fixed or random 2D points, our framework generates input-dependent point-wise features for the latent point set. PSG-Net uses the encoded input to produce point-wise features through the seed generation module and extracts richer features in multiple stages with gradually increasing resolution by applying the seed feature propagation module progressively. We prove the effectiveness of PSG-Net experimentally; PSG-Net shows <font color="#00be00">state-of-the-art</font> performances in point cloud reconstruction and unsupervised classification, and achieves comparable performance to counterpart methods in supervised completion. </br></br>

<a href='http://arxiv.org/pdf/2112.08764.pdf'>2112.08764</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.4904баллов, №406</br>
<b>Graph Convolutional Networks with Dual Message Passing for Subgraph\n  Isomorphism Counting and Matching</b></br>
Authors: , Liu, Xin, Song, Yangqiu</br>
  Graph neural networks (GNNs) and message passing neural networks (MPNNs) have been proven to be expressive for subgraph structures in many applications. Some applications in heterogeneous graphs require explicit edge modeling, such as subgraph isomorphism counting and matching. However, existing message passing mechanisms are not designed well in <font color="#be00be">theor</font>y. In this paper, we start from a particular edge-to-vertex transform and exploit the isomorphism property in the edge-to-vertex dual graphs. We prove that searching isomorphisms on the original graph is equivalent to searching on its dual graph. Based on this observation, we propose dual message passing neural networks (DMPNNs) to enhance the substructure representation learning in an asynchronous way for subgraph isomorphism counting and matching as well as unsupervised node classification. Extensive experiments demonstrate the robust performance of DMPNNs by combining both node and edge representation learning in synthetic and real heterogeneous graphs. Code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/HKUST-KnowComp/DualMessagePassing. </br></br>

<a href='http://arxiv.org/pdf/2112.07839.pdf'>2112.07839</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.4857баллов, №407</br>
<b>LoSAC: An Efficient Local Stochastic Average Control Method for\n  <font color="#be00be">Federated</font> Optimization</b></br>
Authors: , Chen, Huiming, Wang, Huandong, Yao, Quanming, Li, Yong, Jin, Depeng, Yang, Qiang</br>
  <font color="#be00be">Federated</font> optimization (FedOpt), which targets at collaboratively training a learning model across a large number of distributed clients, is vital for federated learning. The primary concerns in FedOpt can be attributed to the model divergence and communication efficiency, which significantly affect the performance. In this paper, we propose a new method, i.e., LoSAC, to learn from heterogeneous distributed data more efficiently. Its key algorithmic insight is to locally update the estimate for the global full gradient after {each} regular local model update. Thus, LoSAC can keep clients\' information refreshed in a more compact way. In particular, we have studied the convergence result for LoSAC. Besides, the bonus of LoSAC is the ability to defend the information leakage from the recent technique Deep Leakage Gradients (DLG). Finally, experiments have verified the superiority of LoSAC comparing with <font color="#00be00">state-of-the-art</font> FedOpt algorithms. Specifically, LoSAC significantly improves communication efficiency by more than $100\\%$ on average, mitigates the model divergence problem and equips with the defense ability against DLG. </br></br>

<a href='http://arxiv.org/pdf/2112.05498.pdf'>2112.05498</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.4803баллов, №408</br>
<b>Sparse Depth Completion with Semantic Mesh Deformation Optimization</b></br>
Authors: , Zhou, Bing, Aiskovich, Matias, Guven, Sinem</br>
  Sparse depth measurements are widely available in many applications such as augmented reality, visual inertial <font color="#be00be">odometry</font> and robots equipped with low cost depth sensors. Although such sparse depth samples work well for certain applications like motion <font color="#be00be">tracking</font>, a complete depth map is usually preferred for broader applications, such as 3D object recognition, 3D reconstruction and autonomous driving. Despite the recent advancements in depth prediction from single RGB images with deeper neural networks, the existing approaches do not yield reliable results for practical use. In this work, we propose a neural network with post-optimization, which takes an RGB image and sparse depth samples as input and predicts the complete depth map. We make three major contributions to advance the <font color="#00be00">state-of-the-art</font>: an improved backbone network architecture named EDNet, a semantic edge-weighted loss function and a semantic mesh deformation optimization method. Our evaluation results <font color="#00be00">outperform</font> the existing work consistently on both indoor and outdoor datasets, and it significantly reduces the mean average error by up to 19.5% under the same settings of 200 sparse samples on NYU-Depth-V2 dataset. </br></br>

<a href='http://arxiv.org/pdf/2112.08369.pdf'>2112.08369</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.4768баллов, №409</br>
<b>Feature-Attending Recurrent Modules for Generalization in Reinforcement\n  Learning</b></br>
Authors: , Carvalho, Wilka, Lampinen, Andrew, Nikiforou, Kyriacos, Hill, Felix, Shanahan, Murray</br>
  Deep <font color="#00be00">reinforcement learning</font> (Deep RL) has recently seen significant progress in developing algorithms for generalization. However, most algorithms target a single type of generalization setting. In this work, we study generalization across three disparate task structures: (a) tasks composed of spatial and temporal compositions of regularly occurring object motions; (b) tasks composed of active perception of and navigation towards regularly occurring 3D objects; and (c) tasks composed of remembering goal-information over sequences of regularly occurring object-configurations. These diverse task structures all share an underlying idea of compositionality: task completion always involves combining recurring segments of task-oriented perception and behavior. We hypothesize that an agent can generalize within a task structure if it can discover representations that capture these recurring task-segments. For our tasks, this corresponds to representations for recognizing individual object motions, for navigation towards 3D objects, and for navigating through object-configurations. Taking inspiration from cognitive science, we term representations for recurring segments of an agent\'s experience, &quot;perceptual schemas&quot;. We propose Feature Attending Recurrent Modules (FARM), which learns a state representation where perceptual schemas are distributed across multiple, relatively small recurrent modules. We compare FARM to recurrent architectures that leverage spatial attention, which reduces observation features to a weighted average over spatial positions. Our experiments indicate that our feature-attention mechanism better enables FARM to generalize across the diverse object-centric domains we study. </br></br>

<a href='http://arxiv.org/pdf/2112.06456.pdf'>2112.06456</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.4632баллов, №410</br>
<b>Real Time Action Recognition from Video Footage</b></br>
Authors: , Apon, Tasnim Sakib, Chowdhury, Mushfiqul Islam, Reza, MD Zubair, Datta, Arpita, Hasan, Syeda Tanjina, Alam, MD. Golam Rabiul</br>
  Crime rate is increasing proportionally with the increasing rate of the population. The most prominent approach was to introduce Closed-Circuit Television (CCTV) camera-based <font color="#be00be">surveillance</font> to tackle the issue. Video surveillance cameras have added a new dimension to detect crime. Several research works on autonomous security camera surveillance are currently ongoing, where the fundamental goal is to discover violent activity from video feeds. From the technical viewpoint, this is a challenging problem because analyzing a set of frames, i.e., videos in temporal dimension to detect violence might need careful machine learning model training to reduce false results. This research focuses on this problem by integrating <font color="#00be00">state-of-the-art</font> Deep Learning methods to ensure a robust pipeline for autonomous surveillance for detecting violent activities, e.g., kicking, punching, and slapping. Initially, we designed a dataset of this specific interest, which contains 600 videos (200 for each action). Later, we have utilized existing pre-trained model architectures to extract features, and later used deep learning network for classification. Also, We have classified our models\' accuracy, and confusion matrix on different pre-trained architectures like VGG16, InceptionV3, ResNet50, Xception and MobileNet V2 among which VGG16 and MobileNet V2 performed better. </br></br>

<a href='http://arxiv.org/pdf/2112.05399.pdf'>2112.05399</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 0.4586баллов, №411</br>
<b>A Generative Car-following Model Conditioned On Driving <font color="#be00be">Style</font>s</b></br>
Authors: , Zhang, Yifan, Chen, Xinhong, Wang, Jianping, Zheng, Zuduo, Wu, Kui</br>
  Car-following (CF) modeling, an essential component in simulating human CF behaviors, has attracted increasing research interest in the past decades. This paper pushes the <font color="#00be00">state of the art</font> by proposing a novel generative hybrid CF model, which achieves high accuracy in characterizing dynamic human CF behaviors and is able to generate realistic human CF behaviors for any given observed or even unobserved driving <font color="#be00be">style</font>. Specifically, the ability of accurately capturing human CF behaviors is ensured by designing and calibrating an Intelligent Driver Model (IDM) with time-varying parameters. The reason behind is that such time-varying parameters can express both the inter-driver heterogeneity, i.e., diverse driving styles of different drivers, and the intra-driver heterogeneity, i.e., changing driving styles of the same driver. The ability of generating realistic human CF behaviors of any given observed driving style is achieved by applying a neural process (NP) based model. The ability of inferring CF behaviors of unobserved driving styles is supported by exploring the relationship between the calibrated time-varying IDM parameters and an intermediate variable of NP. To demonstrate the effectiveness of our proposed models, we conduct extensive experiments and comparisons, including CF model parameter calibration, CF behavior prediction, and trajectory simulation for different driving styles. </br></br>

<a href='http://arxiv.org/pdf/2112.05554.pdf'>2112.05554</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.4444баллов, №412</br>
<b>Using Machine Learning to Find New Density Functionals</b></br>
Authors: , Kalita, Bhupalee, Burke, Kieron</br>
  Machine learning has now become an integral part of research and innovation. The field of machine learning density functional <font color="#be00be">theor</font>y has continuously expanded over the years while making several noticeable advances. We briefly discuss the status of this field and point out some current and future challenges. We also talk about how <font color="#00be00">state-of-the-art</font> science and technology tools can help overcome these challenges. This draft is a part of the &quot;Roadmap on Machine Learning in Electronic Structure&quot; to be published in Electronic Structure (EST). </br></br>

<a href='http://arxiv.org/pdf/2112.07804.pdf'>2112.07804</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.4325баллов, №413</br>
<b>Tackling the Generative Learning Trilemma with Denoising Diffusion GANs</b></br>
Authors: , Xiao, Zhisheng, Kreis, Karsten, Vahdat, Arash</br>
  A wide variety of deep generative models has been developed in the past decade. Yet, these models often struggle with simultaneously addressing three key requirements including: high sample quality, mode coverage, and fast sampling. We call the challenge imposed by these requirements the generative learning trilemma, as the existing models often trade some of them for others. Particularly, denoising diffusion models have shown impressive sample quality and diversity, but their expensive sampling does not yet allow them to be applied in many <font color="#009600">real-world</font> applications. In this paper, we argue that slow sampling in these models is fundamentally attributed to the <font color="#be00be">Gaussi</font>an assumption in the denoising step which is justified only for small step sizes. To enable denoising with large steps, and hence, to reduce the total number of denoising steps, we propose to model the denoising distribution using a complex multimodal distribution. We introduce denoising diffusion generative adversarial networks (denoising diffusion GANs) that model each denoising step using a multimodal conditional GAN. Through extensive evaluations, we show that denoising diffusion GANs obtain sample quality and diversity <font color="#960096">competitive</font> with original diffusion models while being 2000$\\times$ faster on the CIFAR-10 dataset. Compared to traditional GANs, our model exhibits better mode coverage and sample diversity. To the best of our knowledge, denoising diffusion GAN is the first model that reduces sampling cost in diffusion models to an extent that allows them to be applied to real-world applications inexpensively. Project page and code: <font color="#006400">http</font>s://nvlabs.<font color="#00be00">github</font>.io/denoising-diffusion-gan </br></br>

<a href='http://arxiv.org/pdf/2112.02834.pdf'>2112.02834</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.4267баллов, №414</br>
<b>A Generalized <font color="#00be00">Zero-Shot</font> Quantization of Deep Convolutional Neural\n  Networks via Learned Weights Statistics</b></br>
Authors: , Sharma, Prasen Kumar, Abraham, Arun, Rajendiran, Vikram Nelvoy</br>
  Quantizing the floating-point weights and activations of deep convolutional neural networks to fixed-point representation yields reduced memory footprints and inference time. Recently, efforts have been afoot towards <font color="#00be00">zero-shot</font> quantization that does not require original unlabelled training samples of a given task. These best-published works heavily rely on the learned batch normalization (BN) parameters to infer the range of the activations for quantization. In particular, these methods are built upon either empirical estimation framework or the data distillation approach, for computing the range of the activations. However, the performance of such schemes severely degrades when presented with a network that does not accommodate BN layers. In this line of thought, we propose a generalized zero-shot quantization (GZSQ) framework that neither requires original data nor relies on BN layer statistics. We have utilized the data distillation approach and leveraged only the pre-trained weights of the model to estimate enriched data for range calibration of the activations. To the best of our knowledge, this is the first work that utilizes the distribution of the pretrained weights to assist the process of zero-shot quantization. The proposed scheme has significantly <font color="#00be00">outperform</font>ed the existing zero-shot works, e.g., an improvement of ~ 33% in classification accuracy for MobileNetV2 and several other models that are w &amp; w/o BN layers, for a variety of tasks. We have also demonstrated the efficacy of the proposed work across multiple open-source quantization frameworks. Importantly, our work is the first attempt towards the post-training zero-shot quantization of futuristic unnormalized deep neural networks. </br></br>

<a href='http://arxiv.org/pdf/2112.05814.pdf'>2112.05814</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.4241баллов, №415</br>
<b>Deep ViT Features as Dense Visual Descriptors</b></br>
Authors: , Amir, Shir, Gandelsman, Yossi, Bagon, Shai, Dekel, Tali</br>
  We leverage deep features extracted from a pre-trained Vision <font color="#00be00">Transformer</font> (ViT) as dense visual descriptors. We demonstrate that such features, when extracted from a self-supervised ViT model (DINO-ViT), exhibit several striking properties: (i) the features encode powerful high level information at high spatial resolution -- i.e., capture semantic object parts at fine spatial granularity, and (ii) the encoded semantic information is shared across related, yet different object categories (i.e. super-categories). These properties allow us to design powerful dense ViT descriptors that facilitate a variety of applications, including co-<font color="#be00be">segmentation</font>, part co-segmentation and correspondences -- all achieved by applying <font color="#be00be">lightweight</font> methodologies to deep ViT features (e.g., binning / <font color="#be00be">clustering</font>). We take these applications further to the realm of inter-class tasks -- demonstrating how objects from related categories can be commonly segmented into semantic parts, under significant pose and appearance changes. Our methods, extensively evaluated qualitatively and quantitatively, achieve <font color="#00be00">state-of-the-art</font> part co-segmentation results, and <font color="#960096">competitive</font> results with recent supervised methods trained specifically for co-segmentation and correspondences. </br></br>

<a href='http://arxiv.org/pdf/2112.08122.pdf'>2112.08122</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.4237баллов, №416</br>
<b>Self-Supervised Monocular Depth and Ego-Motion Estimation in Endoscopy:\n  Appearance Flow to the Rescue</b></br>
Authors: , Shao, Shuwei, Pei, Zhongcai, Chen, Weihai, Zhu, Wentao, Wu, Xingming, Sun, Dianmin, Zhang, Baochang</br>
  Recently, self-supervised learning technology has been applied to calculate depth and ego-motion from monocular videos, achieving remarkable performance in autonomous driving scenarios. One widely adopted assumption of depth and ego-motion self-supervised learning is that the image brightness remains constant within nearby frames. Unfortunately, the endoscopic scene does not meet this assumption because there are severe brightness fluctuations induced by illumination variations, non-Lambertian reflections and interreflections during data collection, and these brightness fluctuations inevitably deteriorate the depth and ego-motion estimation accuracy. In this work, we introduce a novel concept referred to as appearance flow to address the brightness inconsistency problem. The appearance flow takes into consideration any variations in the brightness pattern and enables us to develop a generalized dynamic image constraint. Furthermore, we build a unified self-supervised framework to estimate monocular depth and ego-motion simultaneously in endoscopic scenes, which comprises a structure module, a motion module, an appearance module and a correspondence module, to accurately reconstruct the appearance and calibrate the image brightness. Extensive experiments are conducted on the SCARED dataset and EndoSLAM dataset, and the proposed unified framework exceeds other self-supervised approaches by a large margin. To validate our framework\'s generalization ability on different <font color="#be00be">patient</font>s and cameras, we train our model on SCARED but test it on the SERV-CT and Hamlyn datasets without any fine-tuning, and the superior results reveal its strong generalization ability. Code will be available at: \\url{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/ShuweiShao/AF-SfMLearner}. </br></br>

<a href='http://arxiv.org/pdf/2112.08534.pdf'>2112.08534</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.4105баллов, №417</br>
<b>Trading with the Momentum <font color="#00be00">Transformer</font>: An Intelligent and <font color="#be00be">Interpret</font>able\n  Architecture</b></br>
Authors: , Wood, Kieran, Giegerich, Sven, Roberts, Stephen, Zohren, Stefan</br>
  Deep learning architectures, specifically Deep Momentum Networks (DMNs) [1904.04912], have been found to be an effective approach to momentum and mean-reversion trading. However, some of the key challenges in recent years involve learning long-term dependencies, degradation of performance when considering returns net of transaction costs and adapting to new <font color="#be00be">market</font> regimes, notably during the SARS-CoV-2 crisis. Attention mechanisms, or <font color="#00be00">Transformer</font>-based architectures, are a solution to such challenges because they allow the network to focus on significant time steps in the past and longer-term patterns. We introduce the Momentum Transformer, an attention-based architecture which <font color="#00be00">outperform</font>s the benchmarks, and is inherently <font color="#be00be">interpret</font>able, providing us with greater insights into our deep learning trading strategy. Our model is an extension to the LSTM-based DMN, which directly outputs position sizing by optimising the network on a risk-adjusted performance metric, such as Sharpe ratio. We find an attention-LSTM hybrid Decoder-Only Temporal Fusion Transformer (TFT) <font color="#be00be">style</font> architecture is the best performing model. In terms of interpretability, we observe remarkable structure in the attention patterns, with significant peaks of importance at momentum turning points. The time series is thus segmented into regimes and the model tends to focus on previous time-steps in alike regimes. We find changepoint detection (CPD) [2105.13727], another technique for responding to regime change, can complement multi-headed attention, especially when we run CPD at multiple timescales. Through the addition of an interpretable variable selection network, we observe how CPD helps our model to move away from trading predominantly on daily returns data. We note that the model can intelligently switch between, and blend, classical strategies - basing its decision on patterns in the data. </br></br>

<a href='http://arxiv.org/pdf/2112.05301.pdf'>2112.05301</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.4032баллов, №418</br>
<b>Self-Ensemling for 3D <font color="#be00be">Point Cloud</font> Domain Adaption</b></br>
Authors: , Li, Qing, Peng, Xiaojiang, Hao, Qi</br>
  Recently 3D <font color="#be00be">point cloud</font> learning has been a hot topic in computer vision and autonomous driving. Due to the fact that it is difficult to manually annotate a qualitative large-scale 3D point cloud dataset, unsupervised domain adaptation (UDA) is popular in 3D point cloud learning which aims to transfer the learned knowledge from the labeled source domain to the unlabeled target domain. However, the generalization and reconstruction errors caused by domain shift with simply-learned model are inevitable which substantially hinder the model\'s capability from learning good representations. To address these issues, we propose an end-to-end self-ensembling network (SEN) for 3D point cloud domain adaption tasks. Generally, our SEN resorts to the advantages of Mean Teacher and semi-supervised learning, and introduces a soft classification loss and a consistency loss, aiming to achieve consistent generalization and accurate reconstruction. In SEN, a student network is kept in a collaborative manner with supervised learning and self-supervised learning, and a teacher network conducts temporal consistency to learn useful representations and ensure the quality of point clouds reconstruction. Extensive experiments on several 3D point cloud UDA benchmarks show that our SEN <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> methods on both classification and <font color="#be00be">segmentation</font> tasks. Moreover, further analysis demonstrates that our SEN also achieves better reconstruction results. </br></br>

<a href='http://arxiv.org/pdf/2112.09061.pdf'>2112.09061</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.4017баллов, №419</br>
<b>Solving Inverse Problems with NerfGANs</b></br>
Authors: , Daras, Giannis, Chu, Wen-Sheng, Kumar, Abhishek, Lagun, Dmitry, Dimakis, Alexandros G.</br>
  We introduce a novel framework for solving inverse problems using NeRF-<font color="#be00be">style</font> generative models. We are interested in the problem of 3-D scene reconstruction given a single 2-D image and known camera parameters. We show that naively optimizing the latent space leads to artifacts and poor novel view rendering. We attribute this problem to volume obstructions that are clear in the 3-D geometry and become visible in the renderings of novel views. We propose a novel radiance field regularization method to obtain better 3-D surfaces and improved novel views given single view observations. Our method naturally extends to general inverse problems including <font color="#be00be">inpainting</font> where one observes only partially a single view. We experimentally evaluate our method, achieving visual improvements and performance boosts over the baselines in a wide range of tasks. Our method achieves $30-40\\%$ MSE reduction and $15-25\\%$ reduction in LPIPS loss compared to the previous <font color="#00be00">state of the art</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.07522.pdf'>2112.07522</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.4002баллов, №420</br>
<b>LMTurk: <font color="#00be00">Few-Shot</font> Learners as Crowdsourcing Workers</b></br>
Authors: , Zhao, Mengjie, Mi, Fei, Wang, Yasheng, Li, Minglei, Jiang, Xin, Liu, Qun, Sch&#xfc;tze, Hinrich</br>
  Vast efforts have been devoted to creating high-performance <font color="#00be00">few-shot</font> learners, i.e., models that perform well with little training data. Training large-scale pretrained language models (PLMs) has incurred significant cost, but utilizing PLM-based few-shot learners is still challenging due to their enormous size. This work focuses on a crucial question: How to make effective use of these few-shot learners? We propose LMTurk, a novel approach that treats few-shot learners as crowdsourcing workers. The rationale is that crowdsourcing workers are in fact few-shot learners: They are shown a few illustrative examples to learn about a task and then start annotating. LMTurk employs few-shot learners built upon PLMs as workers. We show that the resulting annotations can be utilized to train models that solve the task well and are small enough to be deployable in practical scenarios. Altogether, LMTurk is an important step towards making effective use of current PLM-based few-shot learners. </br></br>

<a href='http://arxiv.org/pdf/2112.05662.pdf'>2112.05662</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3969баллов, №421</br>
<b>Match Your Words! A Study of Lexical Matching in Neural Information\n  <font color="#be00be">Retrieval</font></b></br>
Authors: , Formal, Thibault, Piwowarski, Benjamin, Clinchant, St&#xe9;phane</br>
  Neural Information <font color="#be00be">Retrieval</font> models hold the promise to replace lexical matching models, e.g. BM25, in modern search engines. While their capabilities have fully shone on in-domain datasets like MS MARCO, they have recently been challenged on out-of-domain <font color="#00be00">zero-shot</font> settings (BEIR benchmark), questioning their actual generalization capabilities compared to bag-of-words approaches. Particularly, we wonder if these shortcomings could (partly) be the consequence of the inability of neural IR models to perform lexical matching off-the-shelf. In this work, we propose a measure of discrepancy between the lexical matching performed by any (neural) model and an \'ideal\' one. Based on this, we study the behavior of different <font color="#00be00">state-of-the-art</font> neural IR models, focusing on whether they are able to perform lexical matching when it\'s actually useful, i.e. for important terms. Overall, we show that neural IR models fail to properly generalize term importance on out-of-domain collections or terms almost unseen during training </br></br>

<a href='http://arxiv.org/pdf/2112.08001.pdf'>2112.08001</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.3957баллов, №422</br>
<b>Autoencoder-based background reconstruction and foreground <font color="#be00be">segmentation</font>\n  with background noise estimation</b></br>
Authors: , Sauvalle, Bruno, de La Fortelle, Arnaud</br>
  Even after decades of research, dynamic scene background reconstruction and foreground object <font color="#be00be">segmentation</font> are still considered as open problems due various challenges such as illumination changes, camera movements, or background noise caused by air turbulence or moving trees. We propose in this paper to model the background of a video sequence as a low dimensional manifold using an autoencoder and to compare the reconstructed background provided by this autoencoder with the original image to compute the foreground/background segmentation masks. The main novelty of the proposed model is that the autoencoder is also trained to predict the background noise, which allows to compute for each frame a pixel-dependent threshold to perform the background/foreground segmentation. Although the proposed model does not use any temporal or motion information, it exceeds the <font color="#00be00">state of the art</font> for unsupervised background subtraction on the CDnet 2014 and LASIESTA datasets, with a significant improvement on videos where the camera is moving. </br></br>

<a href='http://arxiv.org/pdf/2112.06180.pdf'>2112.06180</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.3937баллов, №423</br>
<b>360-DFPE: Leveraging Monocular 360-Layouts for Direct Floor Plan\n  Estimation</b></br>
Authors: , Solarte, Bolivar, Liu, Yueh-Cheng, Wu, Chin-Hsuan, Tsai, Yi-Hsuan, Sun, Min</br>
  We present 360-DFPE, a sequential floor plan estimation method that directly takes 360-images as input without relying on active sensors or 3D information. Our approach leverages a loosely coupled integration between a monocular visual SLAM solution and a monocular 360-room layout approach, which estimate camera poses and layout geometries, respectively. Since our task is to sequentially capture the floor plan using monocular images, the entire scene structure, room instances, and room shapes are unknown. To tackle these challenges, we first handle the scale difference between visual <font color="#be00be">odometry</font> and layout geometry via formulating an entropy minimization process, which enables us to directly align 360-layouts without knowing the entire scene in advance. Second, to sequentially identify individual rooms, we propose a novel room identification algorithm that tracks every room along the camera exploration using geometry information. Lastly, to estimate the final shape of the room, we propose a shortest path algorithm with an iterative coarse-to-fine strategy, which improves prior formulations with higher accuracy and faster run-time. Moreover, we collect a new floor plan dataset with challenging large-scale scenes, providing both <font color="#be00be">point cloud</font>s and sequential 360-image information. Experimental results show that our monocular solution achieves favorable performance against the current <font color="#00be00">state-of-the-art</font> algorithms that rely on active sensors and require the entire scene reconstruction data in advance. Our code and dataset will be released soon. </br></br>

<a href='http://arxiv.org/pdf/2112.09131.pdf'>2112.09131</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.3930баллов, №424</br>
<b>HODOR: High-level Object Descriptors for Object Re-<font color="#be00be">segmentation</font> in Video\n  Learned from Static Images</b></br>
Authors: , Athar, Ali, Luiten, Jonathon, Hermans, Alexander, Ramanan, Deva, Leibe, Bastian</br>
  Existing <font color="#00be00">state-of-the-art</font> methods for Video Object <font color="#be00be">Segmentation</font> (VOS) learn low-level pixel-to-pixel correspondences between frames to propagate object masks across video. This requires a large amount of densely annotated video data, which is costly to annotate, and largely redundant since frames within a video are highly correlated. In light of this, we propose HODOR: a novel method that tackles VOS by effectively leveraging annotated static images for understanding object appearance and scene context. We encode object instances and scene information from an image frame into robust high-level descriptors which can then be used to re-segment those objects in different frames. As a result, HODOR achieves state-of-the-art performance on the DAVIS and YouTube-VOS benchmarks compared to existing methods trained without video annotations. Without any architectural modification, HODOR can also learn from video context around single annotated video frames by utilizing cyclic consistency, whereas other methods rely on dense, temporally consistent annotations. </br></br>

<a href='http://arxiv.org/pdf/2112.05585.pdf'>2112.05585</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.3926баллов, №425</br>
<b>Discrete neural representations for explainable <font color="#be00be">anomal</font>y detection</b></br>
Authors: , Szymanowicz, Stanislaw, Charles, James, Cipolla, Roberto</br>
  The aim of this work is to detect and automatically generate high-level explanations of <font color="#be00be">anomal</font>ous events in video. Understanding the cause of an anomalous event is crucial as the required response is dependant on its nature and severity. Recent works typically use object or action classifier to detect and provide labels for anomalous events. However, this constrains detection systems to a finite set of known classes and prevents generalisation to unknown objects or behaviours. Here we show how to robustly detect anomalies without the use of object or action classifiers yet still recover the high level reason behind the event. We make the following contributions: (1) a method using saliency maps to decouple the explanation of anomalous events from object and action classifiers, (2) show how to improve the quality of saliency maps using a novel neural architecture for learning discrete representations of video by predicting future frames and (3) beat the <font color="#00be00">state-of-the-art</font> anomaly explanation methods by 60\\% on a subset of the public benchmark X-MAN dataset. </br></br>

<a href='http://arxiv.org/pdf/2112.05783.pdf'>2112.05783</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3902баллов, №426</br>
<b>The <font color="#00be00">Hierarchical</font> Organization of Syntax</b></br>
Authors: , Ravandi, Babak, Concu, Valentina</br>
  Hierarchies are the backbones of complex systems and their analysis allows for a deeper understanding of their structure and how they evolve. We consider languages to be also complex adaptive systems. Hence, we analyzed the <font color="#00be00">hierarchical</font> organization of historical syntactic networks from German that were created from a corpus of texts from the 11th to 17th centuries. We tracked the emergence of syntactic structures in these networks and mapped them to specific communicative needs. We named these emerging structures communicative hierarchies. We hypothesise that the communicative needs of speakers are the organizational force of syntax. We propose that the emergence of these multiple communicative hierarchies is what shapes syntax, and that these hierarchies are the prerequisite to the Zipf\'s law. The emergence of communicative hierarchies indicates that the objective of language evolution is not only to increase the efficiency of transferring information. Language is also evolving to increase our capacity to communicate more sophisticated abstractions as we advance as a species. </br></br>

<a href='http://arxiv.org/pdf/2112.08936.pdf'>2112.08936</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.3813баллов, №427</br>
<b>Autonomous Driving in Adverse <font color="#be00be">Weather</font> Conditions: A Survey</b></br>
Authors: , Zhang, Yuxiao, Carballo, Alexander, Yang, Hanting, Takeda, Kazuya</br>
  Automated Driving Systems (ADS) open up a new domain for the automotive industry and offer new possibilities for future transportation with higher efficiency and comfortable experiences. However, autonomous driving under adverse <font color="#be00be">weather</font> conditions has been the problem that keeps autonomous vehicles (AVs) from going to level 4 or higher autonomy for a long time. This paper assesses the influences and challenges that weather brings to ADS sensors in an analytic and statistical way, and surveys the solutions against inclement weather conditions. <font color="#00be00">State-of-the-art</font> techniques on perception enhancement with regard to each kind of weather are thoroughly reported. External auxiliary solutions like V2X technology, weather conditions coverage in currently available datasets, simulators, and experimental facilities with weather chambers are distinctly sorted out. By pointing out all kinds of major weather problems the autonomous driving field is currently facing, and reviewing both hardware and computer science solutions in recent years, this survey contributes a holistic overview on the obstacles and directions of ADS development in terms of adverse weather driving conditions. </br></br>

<a href='http://arxiv.org/pdf/2112.05396.pdf'>2112.05396</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.3811баллов, №428</br>
<b>Towards Full-to-Empty Room Generation with Structure-Aware Feature\n  Encoding and Soft Semantic Region-Adaptive Normalization</b></br>
Authors: , Gkitsas, Vasileios, Zioulis, Nikolaos, Sterzentsenko, Vladimiros, Doumanoglou, Alexandros, Zarpalas, Dimitrios</br>
  The task of transforming a furnished room image into a background-only is extremely challenging since it requires making large changes regarding the scene context while still preserving the overall layout and <font color="#be00be">style</font>. In order to acquire photo-realistic and structural consistent background, existing deep learning methods either employ image <font color="#be00be">inpainting</font> approaches or incorporate the learning of the scene layout as an individual task and leverage it later in a not fully differentiable semantic region-adaptive normalization module. To tackle these drawbacks, we treat scene layout generation as a feature linear transformation problem and propose a simple yet effective adjusted fully differentiable soft semantic region-adaptive normalization module (softSEAN) block. We showcase the applicability in diminished reality and depth estimation tasks, where our approach besides the advantages of mitigating training complexity and non-differentiability issues, surpasses the compared methods both quantitatively and qualitatively. Our softSEAN block can be used as a drop-in module for existing discriminative and generative models. Implementation is available on vcl3d.<font color="#00be00">github</font>.io/PanoDR/. </br></br>

<a href='http://arxiv.org/pdf/2112.08200.pdf'>2112.08200</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.3792баллов, №429</br>
<b>Taming Overconfident Prediction on Unlabeled Data from Hindsight</b></br>
Authors: , Li, Jing, Pan, Yuangang, Tsang, Ivor W.</br>
  Minimizing prediction uncertainty on unlabeled data is a key factor to achieve good performance in semi-supervised learning (SSL). The prediction uncertainty is typically expressed as the \\emph{entropy} computed by the transformed probabilities in output space. Most existing works distill low-entropy prediction by either accepting the determining class (with the largest probability) as the true label or suppressing subtle predictions (with the smaller probabilities). Unarguably, these distillation strategies are usually heuristic and less informative for model training. From this discernment, this paper proposes a dual mechanism, named ADaptive Sharpening (\\ADS), which first applies a soft-threshold to adaptively mask out determinate and negligible predictions, and then seamlessly sharpens the informed predictions, distilling certain predictions with the informed ones only. More importantly, we <font color="#be00be">theor</font>etically analyze the traits of \\ADS by comparing with various distillation strategies. Numerous experiments verify that \\ADS significantly improves the <font color="#00be00">state-of-the-art</font> SSL methods by making it a plug-in. Our proposed \\ADS forges a cornerstone for future distillation-based SSL research. </br></br>

<a href='http://arxiv.org/pdf/2112.07577.pdf'>2112.07577</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3759баллов, №430</br>
<b>GPL: Generative Pseudo Labeling for Unsupervised Domain Adaptation of\n  Dense <font color="#be00be">Retrieval</font></b></br>
Authors: , Wang, Kexin, Thakur, Nandan, Reimers, Nils, Gurevych, Iryna</br>
  Dense <font color="#be00be">retrieval</font> approaches can overcome the lexical gap and lead to significantly improved search results. However, they require large amounts of training data which is not available for most domains. As shown in previous work (Thakur et al., 2021b), the performance of dense retrievers severely degrades under a domain shift. This limits the usage of dense retrieval approaches to only a few domains with large training datasets.   In this paper, we propose the novel unsupervised domain adaptation method Generative Pseudo Labeling (GPL), which combines a query generator with pseudo labeling from a cross-encoder. On six representative domain-specialized datasets, we find the proposed GPL can <font color="#00be00">outperform</font> an out-of-the-box <font color="#00be00">state-of-the-art</font> dense retrieval approach by up to 8.9 points nDCG@10. GPL requires less (unlabeled) data from the target domain and is more robust in its training than previous methods.   We further investigate the role of six recent pre-training methods in the scenario of domain adaptation for retrieval tasks, where only three could yield improved results. The best approach, TSDAE (Wang et al., 2021) can be combined with GPL, yielding another average improvement of 1.0 points nDCG@10 across the six tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.08808.pdf'>2112.08808</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3755баллов, №431</br>
<b>Simple Questions Generate <font color="#be00be">Named Entity</font> Recognition Datasets</b></br>
Authors: , Kim, Hyunjae, Yoo, Jaehyo, Yoon, Seunghyun, Lee, Jinhyuk, Kang, Jaewoo</br>
  <font color="#be00be">Named entity</font> recognition (NER) is a task of extracting named entities of specific types from text. Current<font color="#be00be"> NER </font>models often rely on human-annotated datasets requiring the vast engagement of professional knowledge on the target domain and entities. This work introduces an ask-to-generate approach, which automatically generates NER datasets by asking simple natural language questions that reflect the needs for entity types (e.g., Which <font color="#be00be">diseas</font>e?) to an open-domain question answering system. Without using any in-domain resources (i.e., training sentences, labels, or in-domain dictionaries), our models solely trained on our generated datasets largely <font color="#00be00">outperform</font> previous weakly supervised models on six NER benchmarks across four different domains. <font color="#00be00">Surprisin</font>gly, on NCBI-disease, our model achieves 75.5 F1 score and even outperforms the previous best weakly supervised model by 4.1 F1 score, which utilizes a rich in-domain dictionary provided by domain experts. Formulating the needs of NER with natural language also allows us to build NER models for fine-grained entity types such as Award, where our model even outperforms fully supervised models. On three <font color="#00be00">few-shot</font> NER benchmarks, our model achieves new <font color="#00be00">state-of-the-art</font> performance. </br></br>

<a href='http://arxiv.org/pdf/2112.08542.pdf'>2112.08542</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3734баллов, №432</br>
<b>QAFactEval: Improved QA-Based Factual Consistency Evaluation for\n  <font color="#be00be">Summarization</font></b></br>
Authors: , Fabbri, Alexander R., Wu, Chien-Sheng, Liu, Wenhao, Xiong, Caiming</br>
  Factual consistency is an essential quality of text <font color="#be00be">summarization</font> models in practical settings. Existing work in evaluating this dimension can be broadly categorized into two lines of research, entailment-based metrics and question answering (QA)-based metrics. However, differing experimental setups presented in recent work lead to contrasting conclusions as to which paradigm performs best. In this work, we conduct an extensive comparison of entailment and QA-based metrics, demonstrating that carefully choosing the components of a QA-based metric is critical to performance. Building on those insights, we propose an optimized metric, which we call QAFactEval, that leads to a 15% average improvement over previous QA-based metrics on the SummaC factual consistency benchmark. Our solution improves upon the best-performing entailment-based metric and achieves <font color="#00be00">state-of-the-art</font> performance on this benchmark. Furthermore, we find that QA-based and entailment-based metrics offer complementary signals and combine the two into a single, learned metric for further performance boost. Through qualitative and quantitative analyses, we point to question generation and answerability classification as two critical components for future work in QA-based metrics. </br></br>

<a href='http://arxiv.org/pdf/2112.07868.pdf'>2112.07868</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.3730баллов, №433</br>
<b><font color="#00be00">Few-shot</font> Instruction Prompts for Pretrained Language Models to Detect\n  Social Biases</b></br>
Authors: , Prabhumoye, Shrimai, Kocielnik, Rafal, Shoeybi, Mohammad, Anandkumar, Anima, Catanzaro, Bryan</br>
  Detecting social bias in text is challenging due to nuance, subjectivity, and difficulty in obtaining good quality labeled datasets at scale, especially given the evolving nature of social biases and society. To address these challenges, we propose a <font color="#00be00">few-shot</font> instruction-based method for prompting pre-trained language models (LMs). We select a few label-balanced exemplars from a small support repository that are closest to the query to be labeled in the embedding space. We then provide the LM with instruction that consists of this subset of labeled exemplars, the query text to be classified, a definition of bias, and prompt it to make a decision. We demonstrate that large LMs used in a few-shot context can detect different types of fine-grained biases with similar and sometimes superior accuracy to fine-tuned models. We observe that the largest 530B parameter model is significantly more effective in detecting social bias compared to smaller models (achieving at least 20% improvement in AUC metric compared to other models). It also maintains a high AUC (dropping less than 5%) in a few-shot setting with a labeled repository reduced to as few as 100 samples. Large pretrained language models thus make it easier and quicker to build new bias detectors. </br></br>

<a href='http://arxiv.org/pdf/2112.08266.pdf'>2112.08266</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3723баллов, №434</br>
<b>KGR^4: <font color="#be00be">Retrieval</font>, Retrospect, Refine and Rethink for Commonsense\n  Generation</b></br>
Authors: , Liu, Xin, Liu, Dayiheng, Yang, Baosong, Zhang, Haibo, Ding, Junwei, Yao, Wenqing, Luo, Weihua, Zhang, Haiying, Su, Jinsong</br>
  Generative commonsense reasoning requires machines to generate sentences describing an everyday scenario given several concepts, which has attracted much attention recently. However, existing models cannot perform as well as humans, since sentences they produce are often implausible and grammatically incorrect. In this paper, inspired by the process of humans creating sentences, we propose a novel Knowledge-enhanced Commonsense Generation framework, termed KGR^4, consisting of four stages: <font color="#be00be">Retrieval</font>, Retrospect, Refine, Rethink. Under this framework, we first perform retrieval to search for relevant sentences from external corpus as the prototypes. Then, we train the generator that either edits or copies these prototypes to generate candidate sentences, of which potential errors will be fixed by an autoencoder-based refiner. Finally, we select the output sentence from candidate sentences produced by generators with different hyper-parameters. Experimental results and in-depth analysis on the CommonGen benchmark strongly demonstrate the effectiveness of our framework. Particularly, KGR^4 obtains 33.56 SPICE points in the official leaderboard, <font color="#00be00">outperform</font>ing the previously-reported best result by 2.49 SPICE points and achieving <font color="#00be00">state-of-the-art</font> performance. </br></br>

<a href='http://arxiv.org/pdf/2112.06068.pdf'>2112.06068</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp 0.3716баллов, №435</br>
<b>Perceptual Loss with Recognition Model for Single-Channel Enhancement\n  and Robust ASR</b></br>
Authors: , Plantinga, Peter, Bagchi, Deblin, Fosler-Lussier, Eric</br>
  Single-channel <font color="#be00be">speech enhancement</font> approaches do not always improve automatic recognition rates in the presence of noise, because they can introduce distortions unhelpful for recognition. Following a trend towards end-to-end training of sequential neural network models, several research groups have addressed this problem with joint training of front-end enhancement module with back-end recognition module. While this approach ensures enhancement outputs are helpful for recognition, the enhancement model can overfit to the training data, weakening the recognition model in the presence of unseen noise. To address this, we used a pre-trained acoustic model to generate a perceptual loss that makes speech enhancement more aware of the phonetic properties of the signal. This approach keeps some benefits of joint training, while alleviating the overfitting problem. Experiments on Voicebank + DEMAND dataset for enhancement show that this approach achieves a new <font color="#00be00">state of the art</font> for some objective enhancement scores. In combination with distortion-independent training, our approach gets a WER of 2.80\\% on the test set, which is more than 20\\% relative better recognition performance than joint training, and 14\\% relative better than distortion-independent mask training. </br></br>

<a href='http://arxiv.org/pdf/2112.08177.pdf'>2112.08177</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.3697баллов, №436</br>
<b>Multi-View Depth Estimation by Fusing Single-View Depth Probability with\n  Multi-View Geometry</b></br>
Authors: , Bae, Gwangbin, Budvytis, Ignas, Cipolla, Roberto</br>
  Multi-view depth estimation methods typically require the computation of a multi-view cost-volume, which leads to huge memory consumption and slow inference. Furthermore, multi-view matching can fail for texture-less surfaces, reflective surfaces and moving objects. For such failure modes, single-view depth estimation methods are often more reliable. To this end, we propose MaGNet, a novel framework for fusing single-view depth probability with multi-view geometry, to improve the accuracy, robustness and efficiency of multi-view depth estimation. For each frame, MaGNet estimates a single-view depth probability distribution, parameterized as a pixel-wise <font color="#be00be">Gaussi</font>an. The distribution estimated for the reference frame is then used to sample per-pixel depth candidates. Such probabilistic sampling enables the network to achieve higher accuracy while evaluating fewer depth candidates. We also propose depth consistency weighting for the multi-view matching score, to ensure that the multi-view depth is consistent with the single-view predictions. The proposed method achieves <font color="#00be00">state-of-the-art</font> performance on ScanNet, 7-Scenes and KITTI. Qualitative evaluation demonstrates that our method is more robust against challenging artifacts such as texture-less/reflective surfaces and moving objects. </br></br>

<a href='http://arxiv.org/pdf/2112.03530.pdf'>2112.03530</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.3621баллов, №437</br>
<b>A Conditional Point Diffusion-Refinement Paradigm for 3D <font color="#be00be">Point Cloud</font>\n  Completion</b></br>
Authors: , Lyu, Zhaoyang, Kong, Zhifeng, Xu, Xudong, Pan, Liang, Lin, Dahua</br>
  3D <font color="#be00be">point cloud</font> is an important 3D representation for capturing <font color="#009600">real world</font> 3D objects. However, real-scanned 3D point clouds are often incomplete, and it is important to recover complete point clouds for downstream applications. Most existing point cloud completion methods use Chamfer Distance (CD) loss for training. The CD loss estimates correspondences between two point clouds by searching <font color="#be00be">nearest neighbo</font>rs, which does not capture the overall point density distribution on the generated shape, and therefore likely leads to non-uniform point cloud generation. To tackle this problem, we propose a novel Point Diffusion-Refinement (PDR) paradigm for point cloud completion. PDR consists of a Conditional Generation Network (CGNet) and a ReFinement Network (RFNet). The CGNet uses a conditional generative model called the denoising diffusion probabilistic model (DDPM) to generate a coarse completion conditioned on the partial observation. DDPM establishes a one-to-one pointwise mapping between the generated point cloud and the uniform ground truth, and then optimizes the mean squared error loss to realize uniform generation. The RFNet refines the coarse output of the CGNet and further improves quality of the completed point cloud. Furthermore, we develop a novel dual-path architecture for both networks. The architecture can (1) effectively and efficiently extract multi-level features from partially observed point clouds to guide completion, and (2) accurately manipulate spatial locations of 3D points to obtain smooth surfaces and sharp details. Extensive experimental results on various benchmark datasets show that our PDR paradigm <font color="#00be00">outperform</font>s previous <font color="#00be00">state-of-the-art</font> methods for point cloud completion. Remarkably, with the help of the RFNet, we can accelerate the iterative generation process of the DDPM by up to 50 times without much performance drop. </br></br>

<a href='http://arxiv.org/pdf/2112.06489.pdf'>2112.06489</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.3620баллов, №438</br>
<b>Multi-Modal Mutual Information Maximization: A Novel Approach for\n  Unsupervised Deep Cross-Modal Hashing</b></br>
Authors: , Hoang, Tuan, Do, Thanh-Toan, Nguyen, Tam V., Cheung, Ngai-Man</br>
  In this paper, we adopt the maximizing mutual information (MI) approach to tackle the problem of unsupervised learning of binary hash codes for efficient cross-modal <font color="#be00be">retrieval</font>. We proposed a novel method, dubbed Cross-Modal Info-Max Hashing (CMIMH). First, to learn informative representations that can preserve both intra- and inter-modal similarities, we leverage the recent advances in estimating variational lower-bound of MI to maximize the MI between the binary representations and input features and between binary representations of different modalities. By jointly maximizing these MIs under the assumption that the binary representations are modelled by multivariate Bernoulli distributions, we can learn binary representations, which can preserve both intra- and inter-modal similarities, effectively in a mini-batch manner with gradient descent. Furthermore, we find out that trying to minimize the modality gap by learning similar binary representations for the same instance from different modalities could result in less informative representations. Hence, balancing between reducing the modality gap and losing modality-<font color="#be00be">private</font> information is important for the cross-modal retrieval tasks. Quantitative evaluations on standard benchmark datasets demonstrate that the proposed method consistently <font color="#00be00">outperform</font>s other <font color="#00be00">state-of-the-art</font> cross-modal retrieval methods. </br></br>

<a href='http://arxiv.org/pdf/2112.05359.pdf'>2112.05359</a> &nbsp&nbsp (cs:ML, cs:CL, stat:ML) &nbsp&nbsp 0.3570баллов, №439</br>
<b>Sketching as a Tool for Understanding and Accelerating Self-attention\n  for Long Sequences</b></br>
Authors: , Chen, Yifan, Zeng, Qi, Hakkani-Tur, Dilek, Jin, Di, Ji, Heng, Yang, Yun</br>
  <font color="#00be00">Transformer</font>-based models are not efficient in processing long sequences due to the quadratic space and time complexity of the self-attention modules. To address this limitation, Linformer and Informer are proposed to reduce the quadratic complexity to linear (modulo logarithmic factors) via low-dimensional projection and row selection respectively. These two models are intrinsically connected, and to understand their connection, we introduce a <font color="#be00be">theor</font>etical framework of matrix sketching. Based on the theoretical analysis, we propose Skeinformer to accelerate self-attention and further improve the accuracy of matrix approximation to self-attention with three carefully designed components: column sampling, adaptive row normalization and pilot sampling reutilization. Experiments on the Long Range Arena (LRA) benchmark demonstrate that our methods <font color="#00be00">outperform</font> alternatives with a consistently smaller time/space footprint. </br></br>

<a href='http://arxiv.org/pdf/2112.08176.pdf'>2112.08176</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.3564баллов, №440</br>
<b>AMSER: Adaptive Multi-modal Sensing for Energy Efficient and Resilient\n  eHealth Systems</b></br>
Authors: , Naeini, Emad Kasaeyan, Shahhosseini, Sina, Kanduri, Anil, Liljeberg, Pasi, Rahmani, Amir M., Dutt, Nikil</br>
  eHealth systems deliver critical digital healthcare and wellness services for users by continuously monitoring physiological and contextual data. eHealth applications use multi-modal machine learning <font color="#be00be">kernel</font>s to analyze data from different sensor modalities and automate decision-making. Noisy inputs and motion artifacts during sensory data acquisition affect the i) prediction accuracy and resilience of eHealth services and ii) energy efficiency in processing garbage data. Monitoring raw sensory inputs to identify and drop data and features from noisy modalities can improve prediction accuracy and energy efficiency. We propose a closed-loop monitoring and control framework for multi-modal eHealth applications, AMSER, that can mitigate garbage-in garbage-out by i) monitoring input modalities, ii) analyzing raw input to selectively drop noisy data and features, and iii) choosing appropriate machine learning models that fit the configured data and feature vector - to improve prediction accuracy and energy efficiency. We evaluate our AMSER approach using multi-modal eHealth applications of pain assessment and stress monitoring over different levels and types of noisy components incurred via different sensor modalities. Our approach achieves up to 22\\% improvement in prediction accuracy and 5.6$\\times$ energy consumption reduction in the sensing phase against the <font color="#00be00">state-of-the-art</font> multi-modal monitoring application. </br></br>

<a href='http://arxiv.org/pdf/2112.04913.pdf'>2112.04913</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.3550баллов, №441</br>
<b>Identification of Twitter Bots Based on an Explainable Machine Learning\n  Framework: The US 2020 Elections Case Study</b></br>
Authors: , Shevtsov, Alexander, Tzagkarakis, Christos, Antonakaki, Despoina, Ioannidis, Sotiris</br>
  Twitter is one of the most popular social networks attracting millions of users, while a considerable proportion of online discourse is captured. It provides a simple usage framework with short messages and an efficient application programming interface (API) enabling the research community to study and analyze several aspects of this social network. However, the Twitter usage simplicity can lead to malicious handling by various bots. The malicious handling phenomenon expands in online discourse, especially during the electoral periods, where except the legitimate bots used for dissemination and communication purposes, the goal is to manipulate the public opinion and the electorate towards a certain direction, specific ideology, or political party. This paper focuses on the design of a novel system for identifying Twitter bots based on labeled Twitter data. To this end, a supervised machine learning (ML) framework is adopted using an Extreme Gradient Boosting (XGBoost) algorithm, where the hyper-parameters are tuned via cross-validation. Our study also deploys Shapley Additive Explanations (SHAP) for explaining the ML model predictions by calculating feature importance, using the game <font color="#be00be">theor</font>etic-based Shapley values. Experimental evaluation on distinct Twitter datasets demonstrate the superiority of our approach, in terms of bot detection accuracy, when compared against a recent <font color="#00be00">state-of-the-art</font> Twitter bot detection method. </br></br>

<a href='http://arxiv.org/pdf/2112.08949.pdf'>2112.08949</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.3520баллов, №442</br>
<b>Slot-VPS: Object-centric Representation Learning for Video Panoptic\n  <font color="#be00be">Segmentation</font></b></br>
Authors: , Zhou, Yi, Zhang, Hui, Lee, Hana, Sun, Shuyang, Li, Pingjun, Zhu, Yangguang, Yoo, ByungIn, Qi, Xiaojuan, Han, Jae-Joon</br>
  Video Panoptic <font color="#be00be">Segmentation</font> (VPS) aims at assigning a class label to each pixel, uniquely segmenting and identifying all object instances consistently across all frames. Classic solutions usually decompose the VPS task into several sub-tasks and utilize multiple surrogates (e.g. boxes and masks, centres and offsets) to represent objects. However, this divide-and-conquer strategy requires complex post-processing in both spatial and temporal domains and is vulnerable to failures from surrogate tasks. In this paper, inspired by object-centric learning which learns compact and robust object representations, we present Slot-VPS, the first end-to-end framework for this task. We encode all panoptic entities in a video, including both foreground instances and background semantics, with a unified representation called panoptic slots. The coherent spatio-temporal object\'s information is retrieved and encoded into the panoptic slots by the proposed Video Panoptic Retriever, enabling it to localize, segment, differentiate, and associate objects in a unified manner. Finally, the output panoptic slots can be directly converted into the class, mask, and object ID of panoptic objects in the video. We conduct extensive ablation studies and demonstrate the effectiveness of our approach on two benchmark datasets, Cityscapes-VPS (\\textit{val} and test sets) and VIPER (\\textit{val} set), achieving new <font color="#00be00">state-of-the-art</font> performance of 63.7, 63.3 and 56.2 VPQ, respectively. </br></br>

<a href='http://arxiv.org/pdf/2112.08718.pdf'>2112.08718</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 0.3471баллов, №443</br>
<b>Domain Prompts: Towards memory and compute efficient domain adaptation\n  of ASR systems</b></br>
Authors: , Dingliwal, Saket, Shenoy, Ashish, Bodapati, Sravan, Gandhe, Ankur, Gadde, Ravi Teja, Kirchhoff, Katrin</br>
  Automatic <font color="#be00be">Speech Recognition</font> (ASR) systems have found their use in numerous industrial applications in very diverse domains. Since domain-specific systems perform better than their generic counterparts on in-domain evaluation, the need for memory and compute-efficient domain adaptation is obvious. Particularly, adapting parameter-heavy <font color="#00be00">transformer</font>-based language models used for rescoring ASR hypothesis is challenging. In this work, we introduce domain-prompts, a methodology that trains a small number of domain token embedding parameters to prime a transformer-based LM to a particular domain. With just a handful of extra parameters per domain, we achieve 7-14% WER improvement over the baseline of using an unadapted LM. Despite being parameter-efficient, these improvements are comparable to those of fully-fine-tuned models with hundreds of millions of parameters. With ablations on prompt-sizes, dataset sizes, initializations and domains, we provide evidence for the benefits of using domain-prompts in ASR systems. </br></br>

<a href='http://arxiv.org/pdf/2112.08553.pdf'>2112.08553</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.3471баллов, №444</br>
<b>UMAD: Universal Model Adaptation under Domain and Category Shift</b></br>
Authors: , Liang, Jian, Hu, Dapeng, Feng, Jiashi, He, Ran</br>
  Learning to reject unknown samples (not present in the source classes) in the target domain is fairly important for unsupervised domain adaptation (UDA). There exist two typical UDA scenarios, i.e., open-set, and open-partial-set, and the latter assumes that not all source classes appear in the target domain. However, most prior methods are designed for one UDA scenario and always perform badly on the other UDA scenario. Moreover, they also require the labeled source data during adaptation, limiting their usability in data <font color="#be00be">privacy</font>-sensitive applications. To address these issues, this paper proposes a Universal Model ADaptation (UMAD) framework which handles both UDA scenarios without access to the source data nor prior knowledge about the category shift between domains. Specifically, we aim to learn a source model with an elegantly designed two-head classifier and provide it to the target domain. During adaptation, we develop an informative consistency score to help distinguish unknown samples from known samples. To achieve bilateral adaptation in the target domain, we further maximize localized mutual information to align known samples with the source classifier and employ an entropic loss to push unknown samples far away from the source classification boundary, respectively. Experiments on open-set and open-partial-set UDA scenarios demonstrate that UMAD, as a unified approach without access to source data, exhibits comparable, if not superior, performance to <font color="#00be00">state-of-the-art</font> data-dependent methods. </br></br>

<a href='http://arxiv.org/pdf/2112.05351.pdf'>2112.05351</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.3456баллов, №445</br>
<b>Exploring Pixel-level Self-supervision for Weakly Supervised Semantic\n  <font color="#be00be">Segmentation</font></b></br>
Authors: , Yoon, Sung-Hoon, Kweon, Hyeokjun, Jeong, Jaeseok, Kim, Hyeonseong, Kim, Shinjeong, Yoon, Kuk-Jin</br>
  Existing studies in weakly supervised semantic <font color="#be00be">segmentation</font> (WSSS) have utilized class activation maps (CAMs) to localize the class objects. However, since a classification loss is insufficient for providing precise object regions, CAMs tend to be biased towards discriminative patterns (i.e., sparseness) and do not provide precise object boundary information (i.e., impreciseness). To resolve these limitations, we propose a novel framework (composed of MainNet and SupportNet.) that derives pixel-level self-supervision from given image-level supervision. In our framework, with the help of the proposed Regional Contrastive Module (RCM) and Multi-scale Attentive Module (MAM), MainNet is trained by self-supervision from the SupportNet. The RCM extracts two forms of self-supervision from SupportNet: (1) class region masks generated from the CAMs and (2) class-wise prototypes obtained from the features according to the class region masks. Then, every pixel-wise feature of the MainNet is trained by the prototype in a contrastive manner, sharpening the resulting CAMs. The MAM utilizes CAMs inferred at multiple scales from the SupportNet as self-supervision to guide the MainNet. Based on the dissimilarity between the multi-scale CAMs from MainNet and SupportNet, CAMs from the MainNet are trained to expand to the less-discriminative regions. The proposed method shows <font color="#00be00">state-of-the-art</font> WSSS performance both on the train and validation sets on the PASCAL VOC 2012 dataset. For reproducibility, code will be available publicly soon. </br></br>

<a href='http://arxiv.org/pdf/2112.08996.pdf'>2112.08996</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.3451баллов, №446</br>
<b>Activation Modulation and Recalibration Scheme for Weakly Supervised\n  Semantic <font color="#be00be">Segmentation</font></b></br>
Authors: , Qin, Jie, Wu, Jie, Xiao, Xuefeng, Li, Lujun, Wang, Xingang</br>
  Image-level weakly supervised semantic <font color="#be00be">segmentation</font> (WSSS) is a fundamental yet challenging computer vision task facilitating scene understanding and automatic driving. Most existing methods resort to classification-based Class Activation Maps (CAMs) to play as the initial pseudo labels, which tend to focus on the discriminative image regions and lack customized characteristics for the segmentation task. To alleviate this issue, we propose a novel activation modulation and recalibration (AMR) scheme, which leverages a spotlight branch and a compensation branch to obtain weighted CAMs that can provide recalibration supervision and task-specific concepts. Specifically, an attention modulation module (AMM) is employed to rearrange the distribution of feature importance from the channel-spatial sequential perspective, which helps to explicitly model channel-wise interdependencies and spatial encodings to adaptively modulate segmentation-oriented activation responses. Furthermore, we introduce a cross pseudo supervision for dual branches, which can be regarded as a semantic similar regularization to mutually refine two branches. Extensive experiments show that AMR establishes a new <font color="#00be00">state-of-the-art</font> performance on the PASCAL VOC 2012 dataset, surpassing not only current methods trained with the image-level of supervision but also some methods relying on stronger supervision, such as saliency label. Experiments also reveal that our scheme is plug-and-play and can be incorporated with other approaches to boost their performance. </br></br>

<a href='http://arxiv.org/pdf/2112.07708.pdf'>2112.07708</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3399баллов, №447</br>
<b>Learning to Retrieve Passages without Supervision</b></br>
Authors: , Ram, Ori, Shachaf, Gal, Levy, Omer, Berant, Jonathan, Globerson, Amir</br>
  Dense retrievers for open-domain question answering (ODQA) have been shown to achieve impressive performance by training on large datasets of question-passage pairs. We investigate whether dense retrievers can be learned in a self-supervised fashion, and applied effectively without any annotations. We observe that existing pretrained models for <font color="#be00be">retrieval</font> struggle in this scenario, and propose a new pretraining scheme designed for retrieval: recurring span retrieval. We use recurring spans across passages in a document to create pseudo examples for contrastive learning. The resulting model -- Spider -- performs <font color="#00be00">surprisin</font>gly well without any examples on a wide range of ODQA datasets, and is <font color="#960096">competitive</font> with BM25, a strong sparse baseline. In addition, Spider often <font color="#00be00">outperform</font>s strong baselines like DPR trained on Natural Questions, when evaluated on questions from other datasets. Our hybrid retriever, which combines Spider with BM25, improves over its components across all datasets, and is often competitive with in-domain DPR models, which are trained on tens of thousands of examples. </br></br>

<a href='http://arxiv.org/pdf/2112.06061.pdf'>2112.06061</a> &nbsp&nbsp (cs:RO, cs:ML) &nbsp&nbsp 0.3383баллов, №448</br>
<b>OstrichRL: A Musculoskeletal Ostrich Simulation to Study Bio-mechanical\n  Locomotion</b></br>
Authors: , La Barbera, Vittorio, Pardo, Fabio, Tassa, Yuval, Daley, Monica, Richards, Christopher, Kormushev, Petar, Hutchinson, John</br>
  Muscle-actuated control is a research topic of interest spanning different fields, in particular biomechanics, robotics and graphics. This type of control is particularly challenging because models are often overactuated, and dynamics are delayed and non-linear. It is however a very well tested and tuned actuation model that has undergone millions of years of evolution and that involves interesting properties exploiting passive forces of muscle-tendon units and efficient energy storage and release. To facilitate research on muscle-actuated simulation, we release a 3D musculoskeletal simulation of an ostrich based on the <font color="#006400">MuJoCo</font> simulator. Ostriches are one of the fastest bipeds on earth and are therefore an excellent model for studying muscle-actuated bipedal locomotion. The model is based on CT scans and dissections used to gather actual muscle data such as insertion sites, lengths and pennation angles. Along with this model, we also provide a set of <font color="#00be00">reinforcement learning</font> tasks, including reference motion <font color="#be00be">tracking</font> and a reaching task with the neck. The reference motion data are based on motion capture clips of various behaviors which we pre-processed and adapted to our model. This paper describes how the model was built and iteratively improved using the tasks. We evaluate the accuracy of the muscle actuation patterns by comparing them to experimentally collected electromyographic data from locomoting birds. We believe that this work can be a useful bridge between the biomechanics, reinforcement learning, graphics and robotics communities, by providing a fast and easy to use simulation. </br></br>

<a href='http://arxiv.org/pdf/2112.08615.pdf'>2112.08615</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3352баллов, №449</br>
<b>Commonsense Knowledge-Augmented Pretrained Language Models for Causal\n  Reasoning Classification</b></br>
Authors: , Hosseini, Pedram, Broniatowski, David A., Diab, Mona</br>
  Commonsense knowledge can be leveraged for identifying causal relations in text. In this work, we verbalize triples in ATOMIC2020, a wide coverage commonsense reasoning <font color="#960096">knowledge graph</font>, to natural language text and continually pretrain a<font color="#00be00"> BERT </font>pretrained language model. We evaluate the resulting model on answering commonsense reasoning questions. Our results show that a continually pretrained language model augmented with commonsense reasoning knowledge <font color="#00be00">outperform</font>s our baseline on two commonsense causal reasoning benchmarks, COPA and BCOPA-CE, without additional improvement on the base model or using quality-enhanced data for fine-tuning. </br></br>

<a href='http://arxiv.org/pdf/2112.06161.pdf'>2112.06161</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.3348баллов, №450</br>
<b>Semi-supervised Domain Adaptive Structure Learning</b></br>
Authors: , Qin, Can, Wang, Lichen, Ma, Qianqian, Yin, Yu, Wang, Huan, Fu, Yun</br>
  Semi-supervised domain adaptation (SSDA) is quite a challenging problem requiring methods to overcome both 1) overfitting towards poorly annotated data and 2) distribution shift across domains. Unfortunately, a simple combination of domain adaptation (DA) and semi-supervised learning (SSL) methods often fail to address such two objects because of training data bias towards labeled samples. In this paper, we introduce an adaptive structure learning method to regularize the cooperation of SSL and DA. Inspired by the multi-views learning, our proposed framework is composed of a shared feature encoder network and two classifier networks, trained for contradictory purposes. Among them, one of the classifiers is applied to group target features to improve intra-class density, enlarging the gap of categorical clusters for robust representation learning. Meanwhile, the other classifier, serviced as a regularizer, attempts to scatter the source features to enhance the smoothness of the decision boundary. The iterations of target <font color="#be00be">clustering</font> and source expansion make the target features being well-enclosed inside the dilated boundary of the corresponding source points. For the joint address of cross-domain features alignment and partially labeled data learning, we apply the maximum mean discrepancy (MMD) distance minimization and self-training (ST) to project the contradictory structures into a shared view to make the reliable final decision. The experimental results over the standard SSDA benchmarks, including DomainNet and Office-home, demonstrate both the accuracy and robustness of our method over the <font color="#00be00">state-of-the-art</font> approaches. </br></br>

<a href='http://arxiv.org/pdf/2112.05362.pdf'>2112.05362</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.3339баллов, №451</br>
<b>Where is Memory Information Stored in the <font color="#00be00">Brain</font>?</b></br>
Authors: , Tee, James, Taylor, Desmond P.</br>
  Within the scientific research community, memory information in the <font color="#00be00">brain</font> is commonly believed to be stored in the synapse - a hypothesis famously attributed to psychologist Donald Hebb. However, there is a growing minority who postulate that memory is stored inside the neuron at the molecular (RNA or DNA) level - an alternative postulation known as the cell-intrinsic hypothesis, coined by psychologist Randy Gallistel. In this paper, we review a selection of key experimental evidence from both sides of the argument. We begin with Eric Kandel\'s studies on sea slugs, which provided the first evidence in support of the synaptic hypothesis. Next, we touch on experiments in mice by John O\'Keefe (declarative memory and the hippocampus) and Joseph LeDoux (procedural fear memory and the amygdala). Then, we introduce the synapse as the basic building block of today\'s artificial intelligence neural networks. After that, we describe David Glanzman\'s study on dissociating memory storage and synaptic change in sea slugs, and Susumu Tonegawa\'s experiment on reactivating retrograde amnesia in mice using laser. From there, we highlight Germund Hesslow\'s experiment on conditioned pauses in ferrets, and Beatrice Gelber\'s experiment on conditioning in single-celled organisms without synapses (Paramecium aurelia). This is followed by a description of David Glanzman\'s experiment on transplanting memory between sea slugs using RNA. Finally, we provide an overview of Brian Dias and Kerry Ressler\'s experiment on DNA transfer of fear in mice from parents to offspring. We conclude with some potential implications for the wider field of psychology. </br></br>

<a href='http://arxiv.org/pdf/2112.07771.pdf'>2112.07771</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3136баллов, №452</br>
<b>Boosted Dense Retriever</b></br>
Authors: , Lewis, Patrick, O&#x11f;uz, Barlas, Xiong, Wenhan, Petroni, Fabio, Yih, Wen-tau, Riedel, Sebastian</br>
  We propose DrBoost, a dense <font color="#be00be">retrieval</font> ensemble inspired by boosting. DrBoost is trained in stages: each component model is learned sequentially and specialized by focusing only on retrieval mistakes made by the current ensemble. The final representation is the concatenation of the output vectors of all the component models, making it a drop-in replacement for standard dense retrievers at test time. DrBoost enjoys several advantages compared to standard dense retrieval models. It produces representations which are 4x more compact, while delivering comparable retrieval results. It also performs <font color="#00be00">surprisin</font>gly well under approximate search with coarse quantization, reducing latency and bandwidth needs by another 4x. In practice, this can make the difference between serving indices from disk versus from memory, paving the way for much cheaper deployments. </br></br>

<a href='http://arxiv.org/pdf/2112.06437.pdf'>2112.06437</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.3128баллов, №453</br>
<b>Semi-Supervised Contrastive Learning for Remote Sensing: Identifying\n  Ancient Urbanization in the South Central Andes</b></br>
Authors: , Xu, Jiachen, Zimmer-Dauphinee, James, Liu, Quan, Shi, Yuxuan, Wernke, Steven, Huo, Yuankai</br>
  The detection of ancient settlements is a key focus in landscape archaeology. Traditionally, settlements were identified through <font color="#be00be">pedestrian</font> survey, as researchers physically traversed the landscape and recorded settlement locations. Recently the manual identification and labeling of ancient remains in satellite imagery have increased the scale of archaeological data collection, but the process remains tremendously time-consuming and arduous. The development of self-supervised learning (e.g., contrastive learning) offers a scalable learning scheme in locating archaeological sites using unlabeled satellite and historical aerial images. However, archaeology sites are only present in a very small proportion of the whole landscape, while the modern contrastive-supervised learning approach typically yield inferior performance on the highly balanced dataset, such as identifying sparsely localized ancient urbanization on a large area using satellite images. In this work, we propose a framework to solve this long-tail problem. As opposed to the existing contrastive learning approaches that typically treat the labeled and unlabeled data separately, the proposed method reforms the learning paradigm under a semi-supervised setting to fully utilize the precious annotated data (&lt;7% in our setting). Specifically, the highly unbalanced nature of the data is employed as the prior knowledge to form pseudo negative pairs by ranking the similarities between unannotated image patches and annotated anchor images. In this study, we used 95,358 unlabeled images and 5,830 labeled images to solve the problem of detecting ancient buildings from a long-tailed satellite image dataset. From the results, our semi-supervised contrastive learning model achieved a promising testing balanced accuracy of 79.0%, which is 3.8% improvement over <font color="#00be00">state-of-the-art</font> approaches. </br></br>

<a href='http://arxiv.org/pdf/2112.09060.pdf'>2112.09060</a> &nbsp&nbsp (cs:SD, cs:CV, cs:ML) &nbsp&nbsp 0.3056баллов, №454</br>
<b>Towards Robust Real-time Audio-Visual <font color="#be00be">Speech Enhancement</font></b></br>
Authors: , Gogate, Mandar, Dashtipour, Kia, Hussain, Amir</br>
  The human <font color="#00be00">brain</font> contextually exploits heterogeneous sensory information to efficiently perform cognitive tasks including vision and hearing. For example, during the cocktail party situation, the human auditory cortex contextually integrates audio-visual (AV) cues in order to better perceive speech. Recent studies have shown that AV <font color="#be00be">speech enhancement</font> (SE) models can significantly improve speech quality and intelligibility in very low signal to noise ratio (SNR) environments as compared to audio-only SE models. However, despite significant research in the area of AV SE, development of real-time processing models with low latency remains a formidable technical challenge. In this paper, we present a novel framework for low latency speaker-independent AV SE that can generalise on a range of visual and acoustic noises. In particular, a generative adversarial networks (GAN) is proposed to address the practical issue of visual imperfections in AV SE. In addition, we propose a deep neural network based real-time AV SE model that takes into account the cleaned visual speech output from GAN to deliver more robust SE. The proposed framework is evaluated on synthetic and real noisy AV corpora using objective speech quality and intelligibility metrics and subjective listing tests. Comparative simulation results show that our real time AV SE framework <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> SE approaches, including recent DNN based SE models. </br></br>

<a href='http://arxiv.org/pdf/2112.05364.pdf'>2112.05364</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.3052баллов, №455</br>
<b>Human <font color="#be00be">Interpret</font>ation and Exploitation of Self-attention Patterns in\n  <font color="#00be00">Transformer</font>s: A Case Study in Extractive <font color="#be00be">Summarization</font></b></br>
Authors: , Li, Raymond, Xiao, Wen, Wang, Lanjun, Carenini, Giuseppe</br>
  The <font color="#00be00">transformer</font> multi-head self-attention mechanism has been thoroughly investigated recently. On one hand, researchers are interested in understanding why and how transformers work. On the other hand, they propose new attention augmentation methods to make transformers more accurate, efficient and <font color="#be00be">interpret</font>able. In this paper, we synergize these two lines of research in a human-in-the-loop pipeline to first find important task-specific attention patterns. Then those patterns are applied, not only to the original model, but also to smaller models, as a human-guided knowledge distillation process. The benefits of our pipeline are demonstrated in a case study with the extractive <font color="#be00be">summarization</font> task. After finding three meaningful attention patterns in the popular BERTSum model, experiments indicate that when we inject such patterns, both the original and the smaller model show improvements in performance and arguably interpretability. </br></br>

<a href='http://arxiv.org/pdf/2111.04198.pdf'>2111.04198</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.3011баллов, №456</br>
<b>TaCL: Improving<font color="#00be00"> BERT </font>Pre-training with Token-aware Contrastive Learning</b></br>
Authors: , Su, Yixuan, Liu, Fangyu, Meng, Zaiqiao, Lan, Tian, Shu, Lei, Shareghi, Ehsan, Collier, Nigel</br>
  Masked language models (MLMs) such as<font color="#00be00"> BERT </font>and RoBERTa have revolutionized the field of Natural Language Understanding in the past few years. However, existing pre-trained MLMs often output an anisotropic distribution of token representations that occupies a narrow subset of the entire representation space. Such token representations are not ideal, especially for tasks that demand discriminative semantic meanings of distinct tokens. In this work, we propose TaCL (Token-aware Contrastive Learning), a novel continual pre-training approach that encourages BERT to learn an isotropic and discriminative distribution of token representations. TaCL is fully unsupervised and requires no additional data. We extensively test our approach on a wide range of English and <font color="#be00be">Chinese</font> benchmarks. The results show that TaCL brings consistent and notable improvements over the original BERT model. Furthermore, we conduct detailed analysis to reveal the merits and inner-workings of our approach. </br></br>

<a href='http://arxiv.org/pdf/2112.07517.pdf'>2112.07517</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.2872баллов, №457</br>
<b>A <font color="#be00be">Style</font> and Semantic Memory Mechanism for Domain Generalization</b></br>
Authors: , Chen, Yang, Wang, Yu, Pan, Yingwei, Yao, Ting, Tian, Xinmei, Mei, Tao</br>
  Mainstream <font color="#00be00">state-of-the-art</font> domain generalization algorithms tend to prioritize the assumption on semantic invariance across domains. Meanwhile, the inherent intra-domain <font color="#be00be">style</font> invariance is usually underappreciated and put on the shelf. In this paper, we reveal that leveraging intra-domain style invariance is also of pivotal importance in improving the efficiency of domain generalization. We verify that it is critical for the network to be informative on what domain features are invariant and shared among instances, so that the network sharpens its understanding and improves its semantic discriminative ability. Correspondingly, we also propose a novel &quot;jury&quot; mechanism, which is particularly effective in learning useful semantic feature commonalities among domains. Our complete model called STEAM can be <font color="#be00be">interpret</font>ed as a novel probabilistic graphical model, for which the implementation requires convenient constructions of two kinds of memory banks: semantic feature bank and style feature bank. Empirical results show that our proposed framework surpasses the state-of-the-art methods by clear margins. </br></br>

<a href='http://arxiv.org/pdf/2112.07200.pdf'>2112.07200</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.2845баллов, №458</br>
<b>Weakly Supervised High-Fidelity Clothing Model Generation</b></br>
Authors: , Feng, Ruili, Ma, Cheng, Shen, Chengji, Gao, Xin, Liu, Zhenjiang, Li, Xiaobo, Ou, Kairi, Zha, Zhengjun</br>
  The development of online <font color="#be00be">economic</font>s arouses the demand of generating images of models on product clothes, to display new clothes and promote sales. However, the expensive proprietary model images challenge the existing image virtual try-on methods in this scenario, as most of them need to be trained on considerable amounts of model images accompanied with paired clothes images. In this paper, we propose a cheap yet scalable weakly-supervised method called Deep Generative Projection (DGP) to address this specific scenario. Lying in the heart of the proposed method is to imitate the process of human predicting the wearing effect, which is an unsupervised imagination based on life experience rather than computation rules learned from supervisions. Here a pretrained <font color="#be00be">Style</font>GAN is used to capture the practical experience of wearing. Experiments show that projecting the rough alignment of clothing and body onto the StyleGAN space can yield photo-realistic wearing results. Experiments on real scene proprietary model images demonstrate the superiority of DGP over several <font color="#00be00">state-of-the-art</font> supervised methods when generating clothing model images. </br></br>

<a href='http://arxiv.org/pdf/2112.08804.pdf'>2112.08804</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.2836баллов, №459</br>
<b>CrossSum: Beyond English-Centric Cross-Lingual Abstractive Text\n  <font color="#be00be">Summarization</font> for 1500+ Language Pairs</b></br>
Authors: , Hasan, Tahmid, Bhattacharjee, Abhik, Ahmad, Wasi Uddin, Li, Yuan-Fang, Kang, Yong-Bin, Shahriyar, Rifat</br>
  We present CrossSum, a large-scale dataset comprising 1.65 million cross-lingual article-summary samples in 1500+ language-pairs constituting 45 languages. We use the multilingual XL-Sum dataset and align identical articles written in different languages via cross-lingual <font color="#be00be">retrieval</font> using a language-agnostic representation model. We propose a multi-stage data sampling algorithm and fine-tune mT5, a multilingual pretrained model, with explicit cross-lingual supervision with CrossSum and introduce a new metric for evaluating cross-lingual <font color="#be00be">summarization</font>. Results on established and our proposed metrics indicate that models fine-tuned on CrossSum <font color="#00be00">outperform</font>s summarization+translation baselines, even when the source and target language pairs are linguistically distant. To the best of our knowledge, CrossSum is the largest cross-lingual summarization dataset and also the first-ever that does not rely on English as the pivot language. We are releasing the dataset, alignment and training scripts, and the models to spur future research on cross-lingual abstractive summarization. The resources can be found at \\url{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/csebuetnlp/CrossSum}. </br></br>

<a href='http://arxiv.org/pdf/2112.09015.pdf'>2112.09015</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.2741баллов, №460</br>
<b>Multivariate Realized Volatility Forecasting with Graph Neural Network</b></br>
Authors: , Chen, Qinkai, Robert, Christian-Yann</br>
  The existing publications demonstrate that the limit order book data is useful in predicting short-term volatility in stock <font color="#be00be">market</font>s. Since stocks are not independent, changes on one stock can also impact other related stocks. In this paper, we are interested in forecasting short-term realized volatility in a multivariate approach based on limit order book data and relational data. To achieve this goal, we introduce Graph <font color="#00be00">Transformer</font> Network for Volatility Forecasting. The model allows to combine limit order book features and an unlimited number of temporal and cross-sectional relations from different sources. Through experiments based on about 500 stocks from S&amp;P 500 index, we find a better performance for our model than for other benchmarks. </br></br>

<a href='http://arxiv.org/pdf/2112.08213.pdf'>2112.08213</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.2738баллов, №461</br>
<b>Enhancing operations management through smart sensors: measuring and\n  improving well-being, interaction and performance of logistics workers</b></br>
Authors: , Aloini, D., Colladon, A. Fronzetti, Gloor, P., Guerrazzi, E., Stefanini, A.</br>
  Purpose The purpose of the research is to conduct an exploratory investigation of the material handling activities of an Italian logistics hub. Wearable sensors and other smart tools were used for collecting human and environmental features during working activities. These factors were correlated with workers\' performance and well-being.   Design/methodology/approach Human and environmental factors play an important role in operations management activities since they significantly influence employees\' performance, well-being and safety. <font color="#00be00">Surprisin</font>gly, empirical studies about the impact of such aspects on logistics operations are still very limited. Trying to fill this gap, the research empirically explores human and environmental factors affecting the performance of logistics workers exploiting smart tools.   Findings Results suggest that human attitudes, interactions, <font color="#be00be">emotion</font>s and environmental conditions remarkably influence workers\' performance and well-being, however, showing different relationships depending on individual characteristics of each worker.   Practical implications The authors\' research opens up new avenues for profiling employees and adopting an individualized human resource management, providing managers with an operational system capable to potentially check and improve workers\' well-being and performance.   Originality/value The originality of the study comes from the in-depth exploration of human and environmental factors using body-worn sensors during work activities, by recording individual, collaborative and environmental data in real-time. To the best of the authors\' knowledge, the current paper is the first time that such a detailed analysis has been carried out in <font color="#009600">real-world</font> logistics operations. </br></br>

<a href='http://arxiv.org/pdf/2112.08351.pdf'>2112.08351</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.2724баллов, №462</br>
<b>Database Search Results Disambiguation for Task-Oriented Dialog Systems</b></br>
Authors: , Qian, Kun, Beirami, Ahmad, Kottur, Satwik, Shayandeh, Shahin, Crook, Paul, Geramifard, Alborz, Yu, Zhou, Sankar, Chinnadhurai</br>
  As task-oriented dialog systems are becoming increasingly popular in our lives, more realistic tasks have been proposed and explored. However, new practical challenges arise. For instance, current dialog systems cannot effectively handle multiple search results when querying a database, due to the lack of such scenarios in existing public datasets. In this paper, we propose Database Search Result (DSR) Disambiguation, a novel task that focuses on disambiguating database search results, which enhances user experience by allowing them to choose from multiple options instead of just one. To study this task, we augment the popular task-oriented dialog datasets (MultiWOZ and SGD) with turns that resolve ambiguities by (a) synthetically generating turns through a pre-defined grammar, and (b) collecting human paraphrases for a subset. We find that training on our augmented dialog data improves the model\'s ability to deal with ambiguous scenarios, without sacrificing performance on unmodified turns. Furthermore, pre-fine tuning and multi-task learning help our model to improve performance on DSR-disambiguation even in the absence of in-domain data, suggesting that it can be learned as a universal dialog skill. Our data and code will be made <font color="#00be00">publicly available</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.06592.pdf'>2112.06592</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.2619баллов, №463</br>
<b>CR-FIQA:<font color="#be00be"> Face </font>Image Quality Assessment by Learning Sample Relative\n  Classifiability</b></br>
Authors: , Boutros, Fadi, Fang, Meiling, Klemt, Marcel, Fu, Biying, Damer, Naser</br>
  The quality of<font color="#be00be"> face </font>images significantly influences the performance of underlying face recognition algorithms. Face image quality assessment (FIQA) estimates the utility of the captured image in achieving reliable and accurate recognition performance. In this work, we propose a novel learning paradigm that learns internal network observations during the training process. Based on that, our proposed CR-FIQA uses this paradigm to estimate the face image quality of a sample by predicting its relative classifiability. This classifiability is measured based on the allocation of the training sample feature representation in angular space with respect to its class center and the nearest negative class center. We experimentally illustrate the correlation between the face image quality and the sample relative classifiability. As such property is only observable for the training dataset, we propose to learn this property from the training dataset and utilize it to predict the quality measure on unseen samples. This training is performed simultaneously while optimizing the class centers by an angular margin penalty-based softmax loss used for face recognition model training. Through extensive evaluation experiments on eight benchmarks and four face recognition models, we demonstrate the superiority of our proposed CR-FIQA over <font color="#00be00">state-of-the-art</font> (SOTA) FIQA algorithms. </br></br>

<a href='http://arxiv.org/pdf/2112.08345.pdf'>2112.08345</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.2600баллов, №464</br>
<b>Reliable Multi-Object <font color="#be00be">Tracking</font> in the Presence of Unreliable Detections</b></br>
Authors: , Mandel, Travis, Jimenez, Mark, Risley, Emily, Nammoto, Taishi, Williams, Rebekka, Panoff, Max, Ballesteros, Meynard, Suarez, Bobbie</br>
  Recent multi-object <font color="#be00be">tracking</font> (MOT) systems have leveraged highly accurate object detectors; however, training such detectors requires large amounts of labeled data. Although such data is widely available for humans and vehicles, it is significantly more scarce for other animal species. We present Robust Confidence Tracking (RCT), an algorithm designed to maintain robust performance even when detection quality is poor. In contrast to prior methods which discard detection confidence information, RCT takes a fundamentally different approach, relying on the exact detection confidence values to initialize tracks, extend tracks, and filter tracks. In particular, RCT is able to minimize identity switches by efficiently using low-confidence detections (along with a single object <font color="#be00be">tracker</font>) to keep continuous track of objects. To evaluate trackers in the presence of unreliable detections, we present a challenging <font color="#009600">real-world</font> underwater fish tracking dataset, FISHTRAC. In an evaluation on FISHTRAC as well as the UA-DETRAC dataset, we find that RCT <font color="#00be00">outperform</font>s other algorithms when provided with imperfect detections, including <font color="#00be00">state-of-the-art</font> deep single and multi-object trackers as well as more classic approaches. Specifically, RCT has the best average HOTA across methods that successfully return results for all sequences, and has significantly less identity switches than other methods. </br></br>

<a href='http://arxiv.org/pdf/2112.06540.pdf'>2112.06540</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.2561баллов, №465</br>
<b>A Study on Token Pruning for ColBERT</b></br>
Authors: , Lassance, Carlos, Maachou, Maroua, Park, Joohee, Clinchant, St&#xe9;phane</br>
  The ColBERT model has recently been proposed as an effective<font color="#00be00"> BERT </font>based ranker. By adopting a late interaction mechanism, a major advantage of ColBERT is that document representations can be precomputed in advance. However, the big downside of the model is the index size, which scales linearly with the number of tokens in the collection. In this paper, we study various designs for ColBERT models in order to attack this problem. While compression techniques have been explored to reduce the index size, in this paper we study token pruning techniques for ColBERT. We compare simple heuristics, as well as a single layer of attention mechanism to select the tokens to keep at indexing time. Our experiments show that ColBERT indexes can be pruned up to 30\\% on the MS MARCO passage collection without a significant drop in performance. Finally, we experiment on MS MARCO documents, which reveal several challenges for such mechanism. </br></br>

<a href='http://arxiv.org/pdf/2112.07224.pdf'>2112.07224</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.2541баллов, №466</br>
<b>Exploring Category-correlated Feature for <font color="#00be00">Few-shot</font> Image Classification</b></br>
Authors: , Xu, Jing, Pan, Xinglin, Luo, Xu, Pei, Wenjie, Xu, Zenglin</br>
  <font color="#00be00">Few-shot</font> classification aims to adapt classifiers to novel classes with a few training samples. However, the insufficiency of training data may cause a biased estimation of feature distribution in a certain class. To alleviate this problem, we present a simple yet effective feature rectification method by exploring the category correlation between novel and base classes as the prior knowledge. We explicitly capture such correlation by mapping features into a latent vector with dimension matching the number of base classes, treating it as the logarithm probability of the feature over base classes. Based on this latent vector, the rectified feature is directly constructed by a decoder, which we expect maintaining category-related information while removing other stochastic factors, and consequently being closer to its class centroid. Furthermore, by changing the temperature value in softmax, we can re-balance the feature rectification and reconstruction for better performance. Our method is generic, flexible and agnostic to any feature extractor and classifier, readily to be embedded into existing FSL approaches. Experiments verify that our method is capable of rectifying biased features, especially when the feature is far from the class centroid. The proposed approach consistently obtains considerable performance gains on three widely used benchmarks, evaluated with different backbones and classifiers.   The code will be made public. </br></br>

<a href='http://arxiv.org/pdf/2112.08132.pdf'>2112.08132</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV) &nbsp&nbsp 0.2539баллов, №467</br>
<b>Improving Self-supervised Learning with Automated Unsupervised <font color="#be00be">Outlier</font>\n  Arbitration</b></br>
Authors: , Wang, Yu, Lin, Jingyang, Zou, Jingjing, Pan, Yingwei, Yao, Ting, Mei, Tao</br>
  Our work reveals a structured shortcoming of the existing mainstream self-supervised learning methods. Whereas self-supervised learning frameworks usually take the prevailing perfect instance level invariance hypothesis for granted, we carefully investigate the pitfalls behind. Particularly, we argue that the existing augmentation pipeline for generating multiple positive views naturally introduces out-of-distribution (OOD) samples that undermine the learning of the downstream tasks. Generating diverse positive augmentations on the input does not always pay off in benefiting downstream tasks. To overcome this inherent deficiency, we introduce a <font color="#be00be">lightweight</font> latent variable model UOTA, targeting the view sampling issue for self-supervised learning. UOTA adaptively searches for the most important sampling region to produce views, and provides viable choice for <font color="#be00be">outlier</font>-robust self-supervised learning approaches. Our method directly generalizes to many mainstream self-supervised learning approaches, regardless of the loss\'s nature contrastive or not. We empirically show UOTA\'s advantage over the <font color="#00be00">state-of-the-art</font> self-supervised paradigms with evident margin, which well justifies the existence of the OOD sample issue embedded in the existing approaches. Especially, we <font color="#be00be">theor</font>etically prove that the merits of the proposal boil down to guaranteed estimator variance and bias reduction. Code is available: at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/ssl-codelab/uota. </br></br>

<a href='http://arxiv.org/pdf/2112.06752.pdf'>2112.06752</a> &nbsp&nbsp (cs:RO, cs:AI) &nbsp&nbsp 0.2416баллов, №468</br>
<b>Adaptation through prediction: multisensory active inference torque\n  control</b></br>
Authors: , Meo, Cristian, Franzese, Giovanni, Pezzato, Corrado, Spahn, Max, Lanillos, Pablo</br>
  Adaptation to external and internal changes is major for robotic systems in uncertain environments. Here we present a novel multisensory active inference torque controller for industrial arms that shows how prediction can be used to resolve adaptation. Our controller, inspired by the predictive <font color="#00be00">brain</font> hypothesis, improves the capabilities of current active inference approaches by incorporating learning and multimodal integration of low and high-dimensional sensor inputs (e.g., raw images) while simplifying the architecture. We performed a systematic evaluation of our model on a 7DoF Franka Emika Panda robot arm by comparing its behavior with previous active inference baselines and classic controllers, analyzing both qualitatively and quantitatively adaptation capabilities and control accuracy. Results showed improved control accuracy in goal-directed reaching with high noise rejection due to multimodal filtering, and adaptability to dynamical inertial changes, elasticity constraints and human disturbances without the need to relearn the model nor parameter retuning. </br></br>

<a href='http://arxiv.org/pdf/2112.02039.pdf'>2112.02039</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.2391баллов, №469</br>
<b>Bridging the Gap: <font color="#be00be">Point Cloud</font>s for Merging Neurons in Connectomics</b></br>
Authors: , Berman, Jules, Chklovskii, Dmitri B., Wu, Jingpeng</br>
  In the field of Connectomics, a primary problem is that of 3D neuron <font color="#be00be">segmentation</font>. Although deep learning-based methods have achieved remarkable accuracy, errors still exist, especially in regions with image defects. One common type of defect is that of consecutive missing image sections. Here, data is lost along some axis, and the resulting neuron segmentations are split across the gap. To address this problem, we propose a novel method based on <font color="#be00be">point cloud</font> representations of neurons. We formulate the problem as a classification problem and train CurveNet, a <font color="#00be00">state-of-the-art</font> point cloud classification model, to identify which neurons should be merged. We show that our method not only performs strongly but also scales reasonably to gaps well beyond what other methods have attempted to address. Additionally, our point cloud representations are highly efficient in terms of data, maintaining high performance with an amount of data that would be unfeasible for other methods. We believe that this is an indicator of the viability of using point cloud representations for other proofreading tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.06379.pdf'>2112.06379</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.2297баллов, №470</br>
<b>5th Place Solution for VSPW 2021 Challenge</b></br>
Authors: , Zhuang, Jiafan, Zhang, Yixin, Hu, Xinyu, Li, Junjie, Wang, Zilei</br>
  In this article, we introduce the solution we used in the VSPW 2021 Challenge. Our experiments are based on two baseline models, Swin <font color="#00be00">Transformer</font> and MaskFormer. To further boost performance, we adopt stochastic weight averaging technique and design <font color="#00be00">hierarchical</font> ensemble strategy. Without using any external semantic <font color="#be00be">segmentation</font> dataset, our solution ranked the 5th place in the <font color="#be00be">private</font> leaderboard. Besides, we have some interesting attempts to tackle long-tail recognition and overfitting issues, which achieves improvement on val subset. Maybe due to distribution difference, these attempts don\'t work on test subset. We will also introduce these attempts and hope to inspire other researchers. </br></br>

<a href='http://arxiv.org/pdf/2112.07227.pdf'>2112.07227</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.2288баллов, №471</br>
<b>Unsupervised feature selection via self-paced learning and low-redundant\n  regularization</b></br>
Authors: , Li, Weiyi, Chen, Hongmei, Li, Tianrui, Wan, Jihong, Sang, Binbin</br>
  Much more attention has been paid to unsupervised feature selection nowadays due to the emergence of massive unlabeled data. The distribution of samples and the latent effect of training a learning method using samples in more effective order need to be considered so as to improve the robustness of the method. Self-paced learning is an effective method considering the training order of samples. In this study, an unsupervised feature selection is proposed by integrating the framework of self-paced learning and subspace learning. Moreover, the local manifold structure is preserved and the redundancy of features is constrained by two regularization terms. $L_{2,1/2}$-norm is applied to the projection matrix, which aims to retain discriminative features and further alleviate the effect of noise in the data. Then, an iterative method is presented to solve the optimization problem. The convergence of the method is proved <font color="#be00be">theor</font>etically and experimentally. The proposed method is compared with other <font color="#00be00">state of the art</font> algorithms on nine <font color="#009600">real-world</font> datasets. The experimental results show that the proposed method can improve the performance of <font color="#be00be">clustering</font> methods and <font color="#00be00">outperform</font> other compared algorithms. </br></br>

<a href='http://arxiv.org/pdf/2112.08598.pdf'>2112.08598</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.2259баллов, №472</br>
<b>FIgLib &amp; SmokeyNet: Dataset and Deep Learning Model for Real-Time\n  Wildland Fire Smoke Detection</b></br>
Authors: , Dewangan, Anshuman, Pande, Yash, Braun, Hans-Werner, Vernon, Frank, Perez, Ismael, Atlintas, Ilkay, Cottrell, Gary, Nguyen, Mai H.</br>
  The size and frequency of wildland fires in the western United States have dramatically increased in recent years. On high fire-risk days, a small fire ignition can rapidly grow and get out of control. Early detection of fire ignitions from initial smoke can assist the response to such fires before they become difficult to manage. Past deep learning approaches for wildfire smoke detection have suffered from small or unreliable datasets that make it difficult to extrapolate performance to <font color="#009600">real-world</font> scenarios. In this work, we present the Fire Ignition Library (FIgLib), a publicly-available dataset of nearly 25,000 labeled wildfire smoke images as seen from fixed-view cameras deployed in Southern California. We also introduce SmokeyNet, a novel deep learning architecture using spatio-temporal information from camera imagery for real-time wildfire smoke detection. When trained on the FIgLib dataset, SmokeyNet <font color="#00be00">outperform</font>s comparable baselines and rivals human performance. We hope that the availability of the FIgLib dataset and the SmokeyNet architecture will inspire further research into deep learning methods for wildfire smoke detection, leading to automated notification systems that reduce the time to wildfire response. </br></br>

<a href='http://arxiv.org/pdf/2112.06174.pdf'>2112.06174</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.2195баллов, №473</br>
<b>Implicit <font color="#00be00">Transformer</font> Network for Screen Content Image Continuous\n  <font color="#be00be">Super-Resolution</font></b></br>
Authors: , Yang, Jingyu, Shen, Sheng, Yue, Huanjing, Li, Kun</br>
  Nowadays, there is an explosive growth of screen contents due to the wide application of screen sharing, remote cooperation, and online education. To match the limited terminal bandwidth, high-resolution (HR) screen contents may be downsampled and compressed. At the receiver side, the <font color="#be00be">super-resolution</font> (SR) of low-resolution (LR) screen content images (SCIs) is highly demanded by the HR display or by the users to zoom in for detail observation. However, image SR methods mostly designed for natural images do not generalize well for SCIs due to the very different image characteristics as well as the requirement of SCI browsing at arbitrary scales. To this end, we propose a novel Implicit <font color="#00be00">Transformer</font> Super-Resolution Network (ITSRN) for SCISR. For high-quality continuous SR at arbitrary ratios, pixel values at query coordinates are inferred from image features at key coordinates by the proposed implicit transformer and an implicit position encoding scheme is proposed to aggregate similar neighboring pixel values to the query one. We construct benchmark SCI1K and SCI1K-compression datasets with LR and HR SCI pairs. Extensive experiments show that the proposed ITSRN significantly <font color="#00be00">outperform</font>s several <font color="#960096">competitive</font> continuous and discrete SR methods for both compressed and uncompressed SCIs. </br></br>

<a href='http://arxiv.org/pdf/2112.07922.pdf'>2112.07922</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.2125баллов, №474</br>
<b>Ten years of image analysis and machine learning competitions in\n  dementia</b></br>
Authors: , Bron, Esther E., Klein, Stefan, Reinke, Annika, Papma, Janne M., Maier-Hein, Lena, Alexander, Daniel C., Oxtoby, Neil P.</br>
  Machine learning methods exploiting multi-parametric biomarkers, especially based on neuroimaging, have huge potential to improve early <font color="#be00be">diagnos</font>is of dementia and to predict which individuals are at-risk of developing dementia. To benchmark algorithms in the field of machine learning and neuroimaging in dementia and assess their potential for use in <font color="#be00be">clinic</font>al practice and clinical trials, seven grand challenges have been organized in the last decade: MIRIAD, Alzheimer\'s <font color="#be00be">Diseas</font>e Big Data DREAM, CADDementia, Machine Learning Challenge, MCI Neuroimaging, TADPOLE, and the Predictive Analytics Competition. Based on two challenge evaluation frameworks, we analyzed how these grand challenges are complementing each other regarding research questions, datasets, validation approaches, results and impact. The seven grand challenges addressed questions related to screening, diagnosis, prediction and monitoring in (pre-clinical) dementia. There was little overlap in clinical questions, tasks and performance metrics. Whereas this has the advantage of providing insight on a broad range of questions, it also limits the validation of results across challenges. In general, winning algorithms performed rigorous data pre-processing and combined a wide range of input features. Despite high <font color="#00be00">state-of-the-art</font> performances, most of the methods evaluated by the challenges are not clinically used. To increase impact, future challenges could pay more attention to statistical analysis of which factors (i.e., features, models) relate to higher performance, to clinical questions beyond Alzheimer\'s disease, and to using testing data beyond the Alzheimer\'s Disease Neuroimaging Initiative. Given the potential and lessons learned in the past ten years, we are excited by the prospects of grand challenges in machine learning and neuroimaging for the next ten years and beyond. </br></br>

<a href='http://arxiv.org/pdf/2112.06096.pdf'>2112.06096</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp 0.2102баллов, №475</br>
<b>Selecting Parallel In-domain Sentences for Neural Machine Translation\n  Using Monolingual Texts</b></br>
Authors: , Sharami, Javad Pourmostafa Roshan, Shterionov, Dimitar, Spronck, Pieter</br>
  Continuously-growing data volumes lead to larger generic models. Specific use-cases are usually left out, since generic models tend to perform poorly in domain-specific cases. Our work addresses this gap with a method for selecting in-domain data from generic-domain (parallel text) corpora, for the task of machine translation. The proposed method ranks sentences in parallel general-domain data according to their cosine similarity with a monolingual domain-specific data set. We then select the top K sentences with the highest similarity score to train a new machine translation system tuned to the specific in-domain data. Our experimental results show that models trained on this in-domain data <font color="#00be00">outperform</font> models trained on generic or a mixture of generic and domain data. That is, our method selects high-quality domain-specific training instances at low computational cost and data size. </br></br>

<a href='http://arxiv.org/pdf/2112.08544.pdf'>2112.08544</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.2101баллов, №476</br>
<b>NewsClaims: A New Benchmark for Claim Detection from News with\n  Background Knowledge</b></br>
Authors: , Reddy, Revanth Gangi, Chinthakindi, Sai, Wang, Zhenhailong, Fung, Yi R., Conger, Kathryn S., Elsayed, Ahmed S., Palmer, Martha, Ji, Heng</br>
  Claim detection and verification are crucial for news understanding and have emerged as promising technologies for mitigating misinformation in news. However, most existing work focus on analysis of claim sentences while overlooking crucial background attributes, such as the claimer, claim objects, and other knowledge connected to the claim. In this work, we present NewsClaims , a new benchmark for knowledge-aware claim detection in the news domain. We re-define the claim detection problem to include extraction of additional background attributes related to the claim and release 529 claims annotated over 103 news articles. In addition, NewsClaims aims to benchmark claim detection systems in emerging scenarios, comprising unseen topics with little or no training data. Finally, we provide a comprehensive evaluation of various <font color="#00be00">zero-shot</font> and prompt-based baselines for this new benchmark. </br></br>

<a href='http://arxiv.org/pdf/2112.05694.pdf'>2112.05694</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.2041баллов, №477</br>
<b>unrolling palm for sparse semi-blind source separation</b></br>
Authors: , Fahes, Mohammad, Kervazo, Christophe, Bobin, J&#xe9;r&#xf4;me, Tupin, Florence</br>
  Sparse Blind Source Separation (BSS) has become a well established tool for a wide range of applications - for instance, in astrophysics and remote sensing. Classical sparse BSS methods, such as the Proximal Alternating Linearized Minimization (PALM) algorithm, nevertheless often suffer from a difficult hyperparameter choice, which undermines their results. To bypass this pitfall, we propose in this work to build on the thriving field of algorithm unfolding/unrolling. Unrolling PALM enables to leverage the data-driven knowledge stemming from realistic simulations or ground-truth data by learning both PALM hyperparameters and variables. In contrast to most existing unrolled algorithms, which assume a fixed known dictionary during the training and testing phases, this article further emphasizes on the ability to deal with variable mixing matrices (a.k.a. dictionaries). The proposed Learned PALM (LPALM) algorithm thus enables to perform semi-blind source separation, which is key to increase the generalization of the learnt model in <font color="#009600">real-world</font> applications. We illustrate the relevance of LPALM in astrophysical multispectral imaging: the algorithm not only needs up to $10^4-10^5$ times fewer iterations than PALM, but also improves the separation quality, while avoiding the cumbersome hyperparameter and initialization choice of PALM. We further show that LPALM <font color="#00be00">outperform</font>s other unrolled source separation methods in the semi-blind setting. </br></br>

<a href='http://arxiv.org/pdf/2112.09076.pdf'>2112.09076</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 0.2019баллов, №478</br>
<b>SanMove: Next Location <font color="#be00be">Recommendat</font>ion via Self-Attention Network</b></br>
Authors: , Li, Huifeng, Wang, Bin, Zhu, Sulei, Xu, Yanyan</br>
  Currently, next location <font color="#be00be">recommendat</font>ion plays a vital role in location-based social network applications and services. Although many methods have been proposed to solve this problem, three important challenges have not been well addressed so far: (1) most existing methods are based on recurrent network, which is time-consuming to train long sequences due to not allowing for full parallelism; (2) personalized preferences generally are not considered reasonably; (3) existing methods rarely systematically studied how to efficiently utilize various auxiliary information (e.g., user ID and timestamp) in trajectory data and the spatio-temporal relations among non-consecutive locations. To address the above challenges, we propose a novel method named SanMove, a self-attention network based model, to predict the next location via capturing the long- and short-term mobility patterns of users. Specifically, SanMove introduces a long-term preference learning module, and it uses a self-attention module to capture the users long-term mobility pattern which can represent personalized location preferences of users. Meanwhile, SanMove uses a spatial-temporal guided non-invasive self-attention (STNOVA) to exploit auxiliary information to learn short-term preferences. We evaluate SanMove with two <font color="#009600">real-world</font> datasets, and demonstrate SanMove is not only faster than the <font color="#00be00">state-of-the-art</font> RNN-based predict model but also <font color="#00be00">outperform</font>s the baselines for next location prediction. </br></br>

<a href='http://arxiv.org/pdf/2112.08570.pdf'>2112.08570</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.2009баллов, №479</br>
<b>Can Multilinguality benefit Non-autoregressive Machine Translation?</b></br>
Authors: , Agrawal, Sweta, Kreutzer, Julia, Cherry, Colin</br>
  Non-autoregressive (NAR) machine translation has recently achieved significant improvements, and now <font color="#00be00">outperform</font>s autoregressive (AR) models on some benchmarks, providing an efficient alternative to AR inference. However, while AR translation is often implemented using multilingual models that benefit from transfer between languages and from improved serving efficiency, multilingual NAR models remain relatively unexplored. Taking Connectionist Temporal Classification (CTC) as an example NAR model and Imputer as a semi-NAR model, we present a comprehensive empirical study of multilingual NAR. We test its capabilities with respect to positive transfer between related languages and negative transfer under capacity constraints. As NAR models require distilled training sets, we carefully study the impact of bilingual versus multilingual teachers. Finally, we fit a scaling law for multilingual NAR, which quantifies its performance relative to the AR model as model scale increases. </br></br>

<a href='http://arxiv.org/pdf/2112.00971.pdf'>2112.00971</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp 0.1950баллов, №480</br>
<b>Towards Personalization of User Preferences in Partially Observable\n  Smart Home Environments</b></br>
Authors: , Suman, Shashi, Rivest, Francois, Etemad, Ali</br>
  The technologies used in smart homes have recently improved to learn the user preferences from feedback in order to enhance the user convenience and quality of experience. Most smart homes learn a uniform model to represent the thermal preferences of users, which generally fails when the pool of occupants includes people with different sensitivities to temperature, for instance due to age and physiological factors. Thus, a smart home with a single optimal policy may fail to provide comfort when a new user with a different preference is integrated into the home. In this paper, we propose a <font color="#be00be">Bayes</font>ian <font color="#00be00">Reinforcement learning</font> framework that can approximate the current occupant state in a partially observable smart home environment using its thermal preference, and then identify the occupant as a new user or someone is already known to the system. Our proposed framework can be used to identify users based on the temperature and humidity preferences of the occupant when performing different activities to enable personalization and improve comfort. We then compare the proposed framework with a baseline long short-term memory learner that learns the thermal preference of the user from the sequence of actions which it takes. We perform these experiments with up to 5 simulated human models each based on <font color="#00be00">hierarchical</font> reinforcement learning. The results show that our framework can approximate the belief state of the current user just by its temperature and humidity preferences across different activities with a high degree of accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.08186.pdf'>2112.08186</a> &nbsp&nbsp (cs:AI, cs:NE) &nbsp&nbsp 0.1950баллов, №481</br>
<b>Planning with Biological Neurons and Synapses</b></br>
Authors: , d\'Amore, Francesco, Mitropolsky, Daniel, Crescenzi, Pierluigi, Natale, Emanuele, Papadimitriou, Christos H.</br>
  We revisit the planning problem in the blocks world, and we implement a known heuristic for this task. Importantly, our implementation is biologically plausible, in the sense that it is carried out exclusively through the spiking of neurons. Even though much has been accomplished in the blocks world over the past five decades, we believe that this is the first algorithm of its kind. The input is a sequence of symbols encoding an initial set of block stacks as well as a target set, and the output is a sequence of motion commands such as &quot;put the top block in stack 1 on the table&quot;. The program is written in the Assembly Calculus, a recently proposed computational framework meant to model computation in the <font color="#00be00">brain</font> by bridging the gap between neural activity and cognitive function. Its elementary objects are assemblies of neurons (stable sets of neurons whose simultaneous firing signifies that the subject is thinking of an object, concept, word, etc.), its commands include project and merge, and its execution model is based on widely accepted tenets of neuroscience. A program in this framework essentially sets up a dynamical system of neurons and synapses that eventually, with high probability, accomplishes the task. The purpose of this work is to establish empirically that reasonably large programs in the Assembly Calculus can execute correctly and reliably; and that rather realistic -- if idealized -- higher cognitive functions, such as planning in the blocks world, can be implemented successfully by such programs. </br></br>

<a href='http://arxiv.org/pdf/2111.09502.pdf'>2111.09502</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.1949баллов, №482</br>
<b>Docking-based Virtual Screening with Multi-Task Learning</b></br>
Authors: , Liu, Zijing, Ye, Xianbin, Fang, Xiaomin, Wang, Fan, Wu, Hua, Wang, Haifeng</br>
  Machine learning shows great potential in virtual screening for <font color="#00be00">drug</font> discovery. Current efforts on accelerating docking-based virtual screening do not consider using existing data of other previously developed targets. To make use of the knowledge of the other targets and take advantage of the existing data, in this work, we apply multi-task learning to the problem of docking-based virtual screening. With two large docking datasets, the results of extensive experiments show that multi-task learning can achieve better performances on docking score prediction. By learning knowledge across multiple targets, the model trained by multi-task learning shows a better ability to adapt to a new target. Additional empirical study shows that other problems in drug discovery, such as the experimental drug-target affinity prediction, may also benefit from multi-task learning. Our results demonstrate that multi-task learning is a promising machine learning approach for docking-based virtual screening and accelerating the process of drug discovery. </br></br>

<a href='http://arxiv.org/pdf/2112.08633.pdf'>2112.08633</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 0.1948баллов, №483</br>
<b>Learning To Retrieve Prompts for In-Context Learning</b></br>
Authors: , Rubin, Ohad, Herzig, Jonathan, Berant, Jonathan</br>
  In-context learning is a recent paradigm in natural language understanding, where a large pre-trained language model (LM) observes a test instance and a few training examples as its input, and directly decodes the output without any update to its parameters. However, performance has been shown to strongly depend on the selected training examples (termed prompt). In this work, we propose an efficient method for retrieving prompts for in-context learning using annotated data and a LM. Given an input-output pair, we estimate the probability of the output given the input and a candidate training example as the prompt, and label training examples as positive or negative based on this probability. We then train an efficient dense retriever from this data, which is used to retrieve training examples as prompts at test time. We evaluate our approach on three sequence-to-sequence tasks where language utterances are mapped to meaning representations, and find that it substantially <font color="#00be00">outperform</font>s prior work and multiple baselines across the board. </br></br>

<a href='http://arxiv.org/pdf/2112.08645.pdf'>2112.08645</a> &nbsp&nbsp (cs:ML, cs:AI, cs:NE) &nbsp&nbsp 0.1895баллов, №484</br>
<b>Learning <font color="#be00be">Interpret</font>able Models Through Multi-Objective Neural\n  <font color="#00be00">Architecture Search</font></b></br>
Authors: , Carmichael, Zachariah, Moon, Tim, Jacobs, Sam Ade</br>
  Monumental advances in deep learning have led to unprecedented achievements across a multitude of domains. While the performance of deep neural networks is indubitable, the architectural design and <font color="#be00be">interpret</font>ability of such models are nontrivial. Research has been introduced to automate the design of neural network architectures through neural <font color="#00be00">architecture search</font> (NAS). Recent progress has made these methods more pragmatic by exploiting distributed computation and novel optimization algorithms. However, there is little work in optimizing architectures for interpretability. To this end, we propose a multi-objective distributed NAS framework that optimizes for both task performance and introspection. We leverage the non-dominated sorting genetic algorithm (NSGA-II) and explainable AI (XAI) techniques to reward architectures that can be better comprehended by humans. The framework is evaluated on several image classification datasets. We demonstrate that jointly optimizing for introspection ability and task error leads to more disentangled architectures that perform within tolerable error. </br></br>

<a href='http://arxiv.org/pdf/2112.07198.pdf'>2112.07198</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.1869баллов, №485</br>
<b>From Dense to Sparse: Contrastive Pruning for Better Pre-trained\n  Language Model Compression</b></br>
Authors: , Xu, Runxin, Luo, Fuli, Wang, Chengyu, Chang, Baobao, Huang, Jun, Huang, Songfang, Huang, Fei</br>
  Pre-trained Language Models (PLMs) have achieved great success in various Natural Language Processing (NLP) tasks under the pre-training and fine-tuning paradigm. With large quantities of parameters, PLMs are computation-intensive and resource-hungry. Hence, model pruning has been introduced to compress large-scale PLMs. However, most prior approaches only consider task-specific knowledge towards downstream tasks, but ignore the essential task-agnostic knowledge during pruning, which may cause catastrophic forgetting problem and lead to poor generalization ability. To maintain both task-agnostic and task-specific knowledge in our pruned model, we propose ContrAstive Pruning (CAP) under the paradigm of pre-training and fine-tuning. It is designed as a general framework, compatible with both structured and unstructured pruning. Unified in contrastive learning, CAP enables the pruned model to learn from the pre-trained model for task-agnostic knowledge, and fine-tuned model for task-specific knowledge. Besides, to better retain the performance of the pruned model, the snapshots (i.e., the intermediate models at each pruning iteration) also serve as effective supervisions for pruning. Our extensive experiments show that adopting CAP consistently yields significant improvements, especially in extremely high sparsity scenarios. With only 3% model parameters reserved (i.e., 97% sparsity), CAP successfully achieves 99.2% and 96.3% of the original<font color="#00be00"> BERT </font>performance in QQP and MNLI tasks. In addition, our probing experiments demonstrate that the model pruned by CAP tends to achieve better generalization ability. </br></br>

<a href='http://arxiv.org/pdf/2112.06507.pdf'>2112.06507</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.1847баллов, №486</br>
<b>Automated Evidence Collection for <font color="#be00be">Fake News</font> Detection</b></br>
Authors: , Rawat, Mrinal, Kanojia, Diptesh</br>
  <font color="#be00be">Fake news</font>, misinformation, and unverifiable facts on social media platforms propagate disharmony and affect society, especially when dealing with an epidemic like COVID-19. The task of Fake News Detection aims to tackle the effects of such misinformation by classifying news items as fake or real. In this paper, we propose a novel approach that improves over the current automatic fake news detection approaches by automatically gathering evidence for each claim. Our approach extracts supporting evidence from the web articles and then selects appropriate text to be treated as evidence sets. We use a pre-trained summarizer on these evidence sets and then use the extracted summary as supporting evidence to aid the classification task. Our experiments, using both machine learning and deep learning-based methods, help perform an extensive evaluation of our approach. The results show that our approach <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> methods in fake news detection to achieve an F1-score of 99.25 over the dataset provided for the CONSTRAINT-2021 Shared Task. We also release the augmented dataset, our code and models for any further research. </br></br>

<a href='http://arxiv.org/pdf/2112.08787.pdf'>2112.08787</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.1838баллов, №487</br>
<b>ATM: An Uncertainty-aware Active Self-training Framework for\n  Label-efficient Text Classification</b></br>
Authors: , Yu, Yue, Kong, Lingkai, Zhang, Jieyu, Zhang, Rongzhi, Zhang, Chao</br>
  Despite the great success of pre-trained language models (LMs) in many natural language processing (NLP) tasks, they require excessive labeled data for fine-tuning to achieve satisfactory performance. To enhance the label efficiency, researchers have resorted to active learning (AL), while the potential of unlabeled data is ignored by most of prior work. To unleash the power of unlabeled data for better label efficiency and model performance, we develop ATM, a new framework that leverage self-training to exploit unlabeled data and is agnostic to the specific AL algorithm, serving as a plug-in module to improve existing AL methods. Specifically, the unlabeled data with high uncertainty is exposed to oracle for annotations while those with low uncertainty are leveraged for self-training. To alleviate the label noise propagation issue in self-training, we design a simple and effective momentum-based memory bank to dynamically aggregate the model predictions from all rounds. By extensive experiments, we demonstrate that ATM <font color="#00be00">outperform</font>s the strongest active learning and self-training baselines and improve the label efficiency by 51.9% on average. </br></br>

<a href='http://arxiv.org/pdf/2112.07082.pdf'>2112.07082</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.1726баллов, №488</br>
<b>DeepDiffusion: Unsupervised Learning of <font color="#be00be">Retrieval</font>-adapted\n  Representations via Diffusion-based Ranking on Latent Feature Manifold</b></br>
Authors: , Furuya, Takahiko, Ohbuchi, Ryutarou</br>
  Unsupervised learning of feature representations is a challenging yet important problem for analyzing a large collection of multimedia data that do not have semantic labels. Recently proposed neural network-based unsupervised learning approaches have succeeded in obtaining features appropriate for classification of multimedia data. However, unsupervised learning of feature representations adapted to content-based matching, comparison, or <font color="#be00be">retrieval</font> of multimedia data has not been explored well. To obtain such retrieval-adapted features, we introduce the idea of combining diffusion distance on a feature manifold with neural network-based unsupervised feature learning. This idea is realized as a novel algorithm called DeepDiffusion (DD). DD simultaneously optimizes two components, a feature embedding by a deep neural network and a distance metric that leverages diffusion on a latent feature manifold, together. DD relies on its loss function but not encoder architecture. It can thus be applied to diverse multimedia data types with their respective encoder architectures. Experimental evaluation using 3D shapes and 2D images demonstrates versatility as well as high accuracy of the DD algorithm. Code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/takahikof/DeepDiffusion </br></br>

<a href='http://arxiv.org/pdf/2112.08360.pdf'>2112.08360</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.1708баллов, №489</br>
<b>How to Learn and Represent Abstractions: An Investigation using Symbolic\n  Alchemy</b></br>
Authors: , AlKhamissi, Badr, Srinivasan, Akshay, Nelson, Zeb-Kurth, Ritter, Sam</br>
  Alchemy is a new meta-learning environment rich enough to contain interesting abstractions, yet simple enough to make fine-grained analysis tractable. Further, Alchemy provides an optional symbolic interface that enables meta-RL research without a large compute budget. In this work, we take the first steps toward using Symbolic Alchemy to identify design choices that enable deep-RL agents to learn various types of abstraction. Then, using a variety of behavioral and introspective analyses we investigate how our trained agents use and represent abstract task variables, and find intriguing connections to the neuroscience of abstraction. We conclude by discussing the next steps for using meta-RL and Alchemy to better understand the representation of abstract variables in the <font color="#00be00">brain</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.06826.pdf'>2112.06826</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.1708баллов, №490</br>
<b>BScNets: Block Simplicial Complex Neural Networks</b></br>
Authors: , Chen, Yuzhou, Gel, Yulia R., Poor, H. Vincent</br>
  Simplicial neural networks (SNN) have recently emerged as the newest direction in graph learning which expands the idea of convolutional architectures from node space to simplicial complexes on graphs. Instead of pre-dominantly assessing pairwise relations among nodes as in the current practice, simplicial complexes allow us to describe higher-order interactions and multi-node graph structures. By building upon connection between the convolution operation and the new block Hodge-Laplacian, we propose the first SNN for link prediction. Our new Block Simplicial Complex Neural Networks (BScNets) model generalizes the existing graph convolutional network (GCN) frameworks by systematically incorporating salient interactions among multiple higher-order graph structures of different dimensions. We discuss <font color="#be00be">theor</font>etical foundations behind BScNets and illustrate its utility for link prediction on eight <font color="#009600">real-world</font> and synthetic datasets. Our experiments indicate that BScNets <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> models by a significant margin while maintaining low computation costs. Finally, we show utility of BScNets as the new promising alternative for <font color="#be00be">tracking</font> spread of infectious <font color="#be00be">diseas</font>es such as COVID-19 and measuring the effectiveness of the healthcare risk mitigation strategies. </br></br>

<a href='http://arxiv.org/pdf/2112.05419.pdf'>2112.05419</a> &nbsp&nbsp (cs:AI, cs:CL, cs:CV, cs:ML) &nbsp&nbsp 0.1704баллов, №491</br>
<b>Predicting Physical World Destinations for Commands Given to\n  Self-Driving Cars</b></br>
Authors: , Grujicic, Dusan, Deruyttere, Thierry, Moens, Marie-Francine, Blaschko, Matthew</br>
  In recent years, we have seen significant steps taken in the development of self-driving cars. Multiple companies are starting to roll out impressive systems that work in a variety of settings. These systems can sometimes give the impression that full self-driving is just around the corner and that we would soon build cars without even a steering wheel. The increase in the level of autonomy and control given to an AI provides an opportunity for new modes of human-vehicle interaction. However, surveys have shown that giving more control to an AI in self-driving cars is accompanied by a degree of uneasiness by passengers. In an attempt to alleviate this issue, recent works have taken a natural language-oriented approach by allowing the passenger to give commands that refer to specific objects in the visual scene. Nevertheless, this is only half the task as the car should also understand the physical destination of the command, which is what we focus on in this paper. We propose an extension in which we annotate the 3D destination that the car needs to reach after executing the given command and evaluate multiple different baselines on predicting this destination location. Additionally, we introduce a model that <font color="#00be00">outperform</font>s the prior works adapted for this particular setting. </br></br>

<a href='http://arxiv.org/pdf/2112.06858.pdf'>2112.06858</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.1651баллов, №492</br>
<b>Why Are You Weird? Infusing <font color="#be00be">Interpret</font>ability in Isolation Forest for\n  <font color="#be00be">Anomal</font>y Detection</b></br>
Authors: , Kartha, Nirmal Sobha, Gautrais, Cl&#xe9;ment, Vercruyssen, Vincent</br>
  <font color="#be00be">Anomal</font>y detection is concerned with identifying examples in a dataset that do not conform to the expected behaviour. While a vast amount of anomaly detection algorithms exist, little attention has been paid to explaining why these algorithms flag certain examples as anomalies. However, such an explanation could be extremely useful to anyone <font color="#be00be">interpret</font>ing the algorithms\' output. This paper develops a method to explain the anomaly predictions of the <font color="#00be00">state-of-the-art</font> Isolation Forest anomaly detection algorithm. The method outputs an explanation vector that captures how important each attribute of an example is to identifying it as anomalous. A thorough experimental evaluation on both synthetic and <font color="#009600">real-world</font> datasets shows that our method is more accurate and more efficient than most contemporary state-of-the-art explainability methods. </br></br>

<a href='http://arxiv.org/pdf/2112.08656.pdf'>2112.08656</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.1650баллов, №493</br>
<b>DREAM: Uncovering Mental Models behind Language Models</b></br>
Authors: , Gu, Yuling, Mishra, Bhavana Dalvi, Clark, Peter</br>
  To what extent do language models (LMs) build &quot;mental models&quot; of a scene when answering situated questions (e.g., questions about a specific ethical dilemma)? While cognitive science has shown that mental models play a fundamental role in human problem-solving, it is unclear whether the high question-answering performance of existing LMs is backed by similar model building - and if not, whether that can explain their well-known catastrophic failures. We observed that Macaw, an existing T5-based LM, when probed provides somewhat useful but inadequate mental models for situational questions (estimated accuracy=43%, usefulness=21%, consistency=42%). We propose DREAM, a model that takes a situational question as input to produce a mental model elaborating the situation, without any additional task specific training data for mental models. It inherits its social commonsense through distant supervision from existing NLP resources. Our analysis shows that DREAM can produce significantly better mental models (estimated accuracy=67%, usefulness=37%, consistency=71%) compared to Macaw. Finally, mental models generated by DREAM can be used as additional context for situational QA tasks. This additional context improves the answer accuracy of a Macaw <font color="#00be00">zero-shot</font> model by between +1% and +4% (absolute) on three different datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.05575.pdf'>2112.05575</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.1646баллов, №494</br>
<b>Paradigms of Computational Agency</b></br>
Authors: , Srinivasa, Srinath, Deshmukh, Jayati</br>
  Agent-based models have emerged as a promising paradigm for addressing ever increasing complexity of information systems. In its initial days in the 1990s when object-oriented modeling was at its peak, an agent was treated as a special kind of &quot;object&quot; that had a persistent state and its own independent thread of execution. Since then, agent-based models have diversified enormously to even open new conceptual insights about the nature of systems in general. This paper presents a perspective on the disparate ways in which our understanding of agency, as well as computational models of agency have evolved. Advances in hardware like GPUs, that brought neural networks back to life, may also similarly infuse new life into agent-based models, as well as pave the way for advancements in research on Artificial <font color="#00be00">General Intelligence</font> (AGI). </br></br>

<a href='http://arxiv.org/pdf/2112.08933.pdf'>2112.08933</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.1605баллов, №495</br>
<b>Responsive parallelized architecture for deploying deep learning models\n  in production environments</b></br>
Authors: , Verma, Nikhil, Prasad, Krishna</br>
  Recruiters can easily shortlist candidates for jobs via viewing their curriculum vitae document. Unstructured document CV beholds candidates portfolio and named entities listing details. The main aim of this study is to design and propose a web oriented, highly responsive, computational pipeline that systematically predicts CV entities using <font color="#00be00">hierarchical</font>ly refined label attention networks. </br></br>

<a href='http://arxiv.org/pdf/2112.06106.pdf'>2112.06106</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.1596баллов, №496</br>
<b>Controlled-rearing studies of newborn chicks and deep neural networks</b></br>
Authors: , Lee, Donsuk, Gujarathi, Pranav, Wood, Justin N.</br>
  Convolutional neural networks (CNNs) can now achieve <font color="#00be00">human-level</font> performance on challenging object recognition tasks. CNNs are also the leading quantitative models in terms of predicting neural and behavioral responses in visual recognition tasks. However, there is a widely accepted critique of CNN models: unlike newborn animals, which learn rapidly and efficiently, CNNs are thought to be &quot;data hungry,&quot; requiring massive amounts of training data to develop accurate models for object recognition. This critique challenges the promise of using CNNs as models of visual development. Here, we directly examined whether CNNs are more data hungry than newborn animals by performing parallel controlled-rearing experiments on newborn chicks and CNNs. We raised newborn chicks in strictly controlled visual environments, then simulated the training data available in that environment by constructing a virtual animal chamber in a video game engine. We recorded the visual images acquired by an agent moving through the virtual chamber and used those images to train CNNs. When CNNs received similar visual training data as chicks, the CNNs successfully solved the same challenging view-invariant object recognition tasks as the chicks. Thus, the CNNs were not more data hungry than animals: both CNNs and chicks successfully developed robust object models from training data of a single object. </br></br>

<a href='http://arxiv.org/pdf/2112.07934.pdf'>2112.07934</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.1585баллов, №497</br>
<b>Graph Representation Learning via Contrasting Cluster Assignments</b></br>
Authors: , Zhang, Chunyang, Yao, Hongyu, Chen, C. L. Philip, Lin, Yuena</br>
  With the rise of contrastive learning, unsupervised graph representation learning has been booming recently, even surpassing the supervised counterparts in some machine learning tasks. Most of existing contrastive models for graph representation learning either focus on maximizing mutual information between local and global embeddings, or primarily depend on contrasting embeddings at node level. However, they are still not exquisite enough to comprehensively explore the local and global views of network topology. Although the former considers local-global relationship, its coarse global information leads to grudging cooperation between local and global views. The latter pays attention to node-level feature alignment, so that the role of global view appears inconspicuous. To avoid falling into these two extreme cases, we propose a novel unsupervised graph representation model by contrasting cluster assignments, called as GRCCA. It is motivated to make good use of local and global information synthetically through combining <font color="#be00be">clustering</font> algorithms and contrastive learning. This not only facilitates the contrastive effect, but also provides the more high-quality graph information. Meanwhile, GRCCA further excavates cluster-level information, which make it get insight to the elusive association between nodes beyond graph topology. Specifically, we first generate two augmented graphs with distinct graph augmentation strategies, then employ clustering algorithms to obtain their cluster assignments and prototypes respectively. The proposed GRCCA further compels the identical nodes from different augmented graphs to recognize their cluster assignments mutually by minimizing a cross entropy loss. To demonstrate its effectiveness, we compare with the <font color="#00be00">state-of-the-art</font> models in three different downstream tasks. The experimental results show that GRCCA has strong <font color="#960096">competitive</font>ness in most tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.05957.pdf'>2112.05957</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.1583баллов, №498</br>
<b>AvatarMe++:<font color="#be00be"> Facial </font>Shape and BRDF Inference with Photorealistic\n  Rendering-Aware GANs</b></br>
Authors: , Lattas, Alexandros, Moschoglou, Stylianos, Ploumpis, Stylianos, Gecer, Baris, Ghosh, Abhijeet, Zafeiriou, Stefanos</br>
  Over the last years, many<font color="#be00be"> face </font>analysis tasks have accomplished astounding performance, with applications including face generation and 3D face reconstruction from a single &quot;in-the-wild&quot; image. Nevertheless, to the best of our knowledge, there is no method which can produce render-ready high-resolution 3D faces from &quot;in-the-wild&quot; images and this can be attributed to the: (a) scarcity of available data for training, and (b) lack of robust methodologies that can successfully be applied on very high-resolution data. In this work, we introduce the first method that is able to reconstruct photorealistic render-ready 3D<font color="#be00be"> facial </font>geometry and BRDF from a single &quot;in-the-wild&quot; image. We capture a large dataset of facial shape and reflectance, which we have made public. We define a fast facial photorealistic differentiable rendering methodology with accurate facial skin diffuse and specular reflection, self-occlusion and subsurface scattering approximation. With this, we train a network that disentangles the facial diffuse and specular BRDF components from a shape and texture with baked illumination, reconstructed with a <font color="#00be00">state-of-the-art</font> 3DMM fitting method. Our method <font color="#00be00">outperform</font>s the existing arts by a significant margin and reconstructs high-resolution 3D faces from a single low-resolution image, that can be rendered in various applications, and bridge the uncanny valley. </br></br>

<a href='http://arxiv.org/pdf/2112.06343.pdf'>2112.06343</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.1510баллов, №499</br>
<b>Change Detection Meets Visual Question Answering</b></br>
Authors: , Yuan, Zhenghang, Mou, Lichao, Xiong, Zhitong, Zhu, Xiaoxiang</br>
  The Earth\'s surface is continually changing, and identifying changes plays an important role in urban planning and sustainability. Although change detection techniques have been successfully developed for many years, these techniques are still limited to experts and facilitators in related fields. In order to provide every user with flexible access to change information and help them better understand land-cover changes, we introduce a novel task: change detection-based visual question answering (CDVQA) on multi-temporal aerial images. In particular, multi-temporal images can be queried to obtain high level change-based information according to content changes between two input images. We first build a CDVQA dataset including multi-temporal image-question-answer triplets using an automatic question-answer generation method. Then, a baseline CDVQA framework is devised in this work, and it contains four parts: multi-temporal feature encoding, multi-temporal fusion, multi-modal fusion, and answer prediction. In addition, we also introduce a change enhancing module to multi-temporal feature encoding, aiming at incorporating more change-related information. Finally, effects of different backbones and multi-temporal fusion strategies are studied on the performance of CDVQA task. The experimental results provide useful insights for developing better CDVQA models, which are important for future research on this task. We will make our dataset and code <font color="#00be00">publicly available</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.08581.pdf'>2112.08581</a> &nbsp&nbsp (cs:NE, cs:AI) &nbsp&nbsp 0.1467баллов, №500</br>
<b>A First Mathematical Runtime Analysis of the Non-Dominated Sorting\n  Genetic Algorithm II (NSGA-II)</b></br>
Authors: , Zheng, Weijie, Liu, Yufei, Doerr, Benjamin</br>
  The non-dominated sorting genetic algorithm II (NSGA-II) is the most intensively used multi-objective evolutionary algorithm (MOEA) in <font color="#009600">real-world</font> applications. However, in contrast to several simple MOEAs analyzed also via mathematical means, no such study exists for the NSGA-II so far. In this work, we show that mathematical runtime analyses are feasible also for the NSGA-II. As particular results, we prove that with a population size larger than the Pareto front size by a constant factor, the NSGA-II with two classic mutation operators and three different ways to select the parents satisfies the same asymptotic runtime guarantees as the SEMO and GSEMO algorithms on the basic OneMinMax and LOTZ benchmark functions. However, if the population size is only equal to the size of the Pareto front, then the NSGA-II cannot efficiently compute the full Pareto front (for an exponential number of iterations, the population will always miss a constant fraction of the Pareto front). Our experiments confirm the above findings. </br></br>

<a href='http://arxiv.org/pdf/2112.08352.pdf'>2112.08352</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp 0.1412баллов, №501</br>
<b>Textless Speech-to-Speech Translation on Real Data</b></br>
Authors: , Lee, Ann, Gong, Hongyu, Duquenne, Paul-Ambroise, Schwenk, Holger, Chen, Peng-Jen, Wang, Changhan, Popuri, Sravya, Pino, Juan, Gu, Jiatao, Hsu, Wei-Ning</br>
  We present a textless speech-to-speech translation (S2ST) system that can translate speech from one language into another language and can be built without the need of any text data. Different from existing work in the literature, we tackle the challenge in modeling multi-speaker target speech and train the systems with <font color="#009600">real-world</font> S2ST data. The key to our approach is a self-supervised unit-based speech normalization technique, which finetunes a pre-trained speech encoder with paired audios from multiple speakers and a single reference speaker to reduce the variations due to accents, while preserving the lexical content. With only 10 minutes of paired data for speech normalization, we obtain on average 3.2 BLEU gain when training the S2ST model on the \\vp~S2ST dataset, compared to a baseline trained on un-normalized speech target. We also incorporate automatically mined S2ST data and show an additional 2.0 BLEU gain. To our knowledge, we are the first to establish a textless S2ST technique that can be trained with real-world data and works for multiple language pairs. </br></br>

<a href='http://arxiv.org/pdf/2112.07617.pdf'>2112.07617</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.1407баллов, №502</br>
<b>A cross-domain recommender system using deep coupled autoencoders</b></br>
Authors: , Gkillas, Alexandros, Kosmopoulos, Dimitrios</br>
  Long-standing data sparsity and cold-start constitute thorny and perplexing problems for the <font color="#be00be">recommendat</font>ion systems. Cross-domain recommendation as a domain adaptation framework has been utilized to efficiently address these challenging issues, by exploiting information from multiple domains. In this study, an item-level relevance cross-domain recommendation task is explored, where two related domains, that is, the source and the target domain contain common items without sharing sensitive information regarding the users\' behavior, and thus avoiding the leak of user <font color="#be00be">privacy</font>. In light of this scenario, two novel coupled autoencoder-based deep learning methods are proposed for cross-domain recommendation. The first method aims to simultaneously learn a pair of autoencoders in order to reveal the intrinsic representations of the items in the source and target domains, along with a coupled mapping function to model the non-linear relationships between these representations, thus transferring beneficial information from the source to the target domain. The second method is derived based on a new joint regularized optimization problem, which employs two autoencoders to generate in a deep and non-linear manner the user and item-latent factors, while at the same time a data-driven function is learnt to map the item-latent factors across domains. Extensive numerical experiments on two <font color="#00be00">publicly available</font> benchmark datasets are conducted illustrating the superior performance of our proposed methods compared to several <font color="#00be00">state-of-the-art</font> cross-domain recommendation frameworks. </br></br>

<a href='http://arxiv.org/pdf/2112.08910.pdf'>2112.08910</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.1404баллов, №503</br>
<b>Gendered Language in Resumes and its Implications for Algorithmic Bias\n  in Hiring</b></br>
Authors: , Parasurama, Prasanna, Sedoc, Jo&#xe3;o</br>
  Despite growing concerns around <font color="#be00be">gender bias</font> in NLP models used in algorithmic hiring, there is little empirical work studying the extent and nature of gendered language in resumes. Using a corpus of 709k resumes from IT firms, we train a series of models to classify the gender of the applicant, thereby measuring the extent of gendered information encoded in resumes. We also investigate whether it is possible to obfuscate gender from resumes by removing gender identifiers, hobbies, gender sub-space in embedding models, etc. We find that there is a significant amount of gendered information in resumes even after obfuscation. A simple Tf-Idf model can learn to classify gender with AUROC=0.75, and more sophisticated <font color="#00be00">transformer</font>-based models achieve AUROC=0.8. We further find that gender predictive values have low correlation with gender direction of embeddings -- meaning that, what is predictive of gender is much more than what is &quot;gendered&quot; in the masculine/feminine sense. We discuss the algorithmic bias and fairness implications of these findings in the hiring context. </br></br>

<a href='http://arxiv.org/pdf/2112.08094.pdf'>2112.08094</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.1374баллов, №504</br>
<b>Automatic tuning of hyper-parameters of <font color="#00be00">reinforcement learning</font>\n  algorithms using <font color="#be00be">Bayes</font>ian optimization with behavioral cloning</b></br>
Authors: , Barsce, Juan Cruz, Palombarini, Jorge A., Mart&#xed;nez, Ernesto C.</br>
  Optimal setting of several hyper-parameters in machine learning algorithms is key to make the most of available data. To this aim, several methods such as evolutionary strategies, random search, <font color="#be00be">Bayes</font>ian optimization and heuristic rules of thumb have been proposed. In <font color="#00be00">reinforcement learning</font> (RL), the information content of data gathered by the learning agent while interacting with its environment is heavily dependent on the setting of many hyper-parameters. Therefore, the user of an RL algorithm has to rely on search-based optimization methods, such as grid search or the Nelder-Mead simplex algorithm, that are very inefficient for most RL tasks, slows down significantly the learning curve and leaves to the user the burden of purposefully biasing data gathering. In this work, in order to make an RL algorithm more user-independent, a novel approach for autonomous hyper-parameter setting using Bayesian optimization is proposed. Data from past episodes and different hyper-parameter values are used at a meta-learning level by performing behavioral cloning which helps improving the effectiveness in maximizing a reinforcement learning variant of an acquisition function. Also, by tightly integrating Bayesian optimization in a reinforcement learning agent design, the number of state transitions needed to converge to the optimal policy for a given task is reduced. Computational experiments reveal promising results compared to other manual tweaking and optimization-based approaches which highlights the benefits of changing the algorithm hyper-parameters to increase the information content of generated data. </br></br>

<a href='http://arxiv.org/pdf/2112.05404.pdf'>2112.05404</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.1358баллов, №505</br>
<b>The Large Labelled Logo Dataset (L3D): A Multipurpose and Hand-Labelled\n  Continuously Growing Dataset</b></br>
Authors: , Guti&#xe9;rrez-Fandi&#xf1;o, Asier, P&#xe9;rez-Fern&#xe1;ndez, David, Armengol-Estap&#xe9;, Jordi</br>
  In this work, we present the Large Labelled Logo Dataset (L3D), a multipurpose, hand-labelled, continuously growing dataset. It is composed of around 770k of color 256x256 RGB images extracted from the European Union Intellectual Property Office (EUIPO) open registry. Each of them is associated to multiple labels that classify the figurative and textual elements that appear in the images. These annotations have been classified by the EUIPO evaluators using the Vienna classification, a <font color="#00be00">hierarchical</font> classification of figurative marks. We suggest two direct applications of this dataset, namely, logo classification and logo generation. </br></br>

<a href='http://arxiv.org/pdf/2112.03850.pdf'>2112.03850</a> &nbsp&nbsp (cs:RO, cs:AI) &nbsp&nbsp 0.1352баллов, №506</br>
<b>Policy Search for Model Predictive Control with Application to Agile\n  Drone Flight</b></br>
Authors: , Song, Yunlong, Scaramuzza, Davide</br>
  Policy Search and Model Predictive Control~(MPC) are two different paradigms for robot control: policy search has the strength of automatically learning complex policies using experienced data, while MPC can offer optimal control performance using models and trajectory optimization. An open research question is how to leverage and combine the advantages of both approaches. In this work, we provide an answer by using policy search for automatically choosing high-level decision variables for MPC, which leads to a novel policy-search-for-model-predictive-control framework. Specifically, we formulate the MPC as a parameterized controller, where the hard-to-optimize decision variables are represented as high-level policies. Such a formulation allows optimizing policies in a self-supervised fashion. We validate this framework by focusing on a challenging problem in agile drone flight: flying a quadrotor through fast-moving gates. Experiments show that our controller achieves robust and real-time control performance in both simulation and the <font color="#009600">real world</font>. The proposed framework offers a new perspective for merging learning and control. </br></br>

<a href='http://arxiv.org/pdf/2112.05941.pdf'>2112.05941</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.1342баллов, №507</br>
<b>Learning a Sequential Policy of Efficient Actions for Tangled-Prone\n  Parts in Robotic Bin Picking</b></br>
Authors: , Zhang, Xinyi, Domae, Yukiyasu, Wan, Weiwei, Harada, Kensuke</br>
  This paper introduces an autonomous bin picking system for cable harnesses - an extremely challenging object in bin picking task. Currently cable harnesses are unsuitable to be imported to automated production due to their length and elusive structures. Considering the task of robotic bin picking where the harnesses are heavily entangled, it is challenging for a robot to pick harnesses up one by one using conventional bin picking methods. In this paper, we present an efficient approach to overcoming the difficulties when dealing with entangled-prone parts. We develop several motion schemes for the robot to pick up a single harness avoiding any entanglement. Moreover, we proposed a learning-based bin picking policy to select both grasps and designed motion schemes in a reasonable sequence. Our method is unique due to the novelty for sufficiently solving the entanglement problem in picking cluttered cable harnesses. We demonstrate our approach on a set of <font color="#009600">real-world</font> experiments, during which the proposed method is capable to perform the sequential bin picking task with both effectiveness and accuracy under a variety of cluttered scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.05876.pdf'>2112.05876</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.1329баллов, №508</br>
<b>The Past as a Stochastic Process</b></br>
Authors: , Wolpert, David H., Price, Michael H., Crabtree, Stefani A., Kohler, Timothy A., Jost, Jurgen, Evans, James, Stadler, Peter F., Shimao, Hajime, Laubichler, Manfred D.</br>
  Historical processes manifest remarkable diversity. Nevertheless, scholars have long attempted to identify patterns and categorize historical actors and influences with some success. A stochastic process framework provides a structured approach for the analysis of large historical datasets that allows for detection of sometimes <font color="#00be00">surprisin</font>g patterns, identification of relevant causal actors both endogenous and exogenous to the process, and comparison between different historical cases. The combination of data, analytical tools and the organizing <font color="#be00be">theor</font>etical framework of stochastic processes complements traditional narrative approaches in history and archaeology. </br></br>

<a href='http://arxiv.org/pdf/2111.07597.pdf'>2111.07597</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.1311баллов, №509</br>
<b>DFC: Deep Feature Consistency for Robust <font color="#be00be">Point Cloud</font> Registration</b></br>
Authors: , Xu, Zhu, Bai, Zhengyao, Liu, Huijie, Lu, Qianjie, Fan, Shenglan</br>
  How to extract significant <font color="#be00be">point cloud</font> features and estimate the pose between them remains a challenging question, due to the inherent lack of structure and ambiguous order permutation of point clouds. Despite significant improvements in applying deep learning-based methods for most 3D computer vision tasks, such as object classification, object <font color="#be00be">segmentation</font> and point cloud registration, the consistency between features is still not attractive in existing learning-based pipelines. In this paper, we present a novel learning-based alignment network for complex alignment scenes, titled deep feature consistency and consisting of three main modules: a multiscale graph feature merging network for converting the geometric correspondence set into high-dimensional features, a correspondence weighting module for constructing multiple candidate inlier subsets, and a Procrustes approach named deep feature matching for giving a closed-form solution to estimate the relative pose. As the most important step of the deep feature matching module, the feature consistency matrix for each inlier subset is constructed to obtain its principal vectors as the inlier likelihoods of the corresponding subset. We comprehensively validate the robustness and effectiveness of our approach on both the 3DMatch dataset and the KITTI <font color="#be00be">odometry</font> dataset. For large indoor scenes, registration results on the 3DMatch dataset demonstrate that our method <font color="#00be00">outperform</font>s both the <font color="#00be00">state-of-the-art</font> traditional and learning-based methods. For KITTI outdoor scenes, our approach remains quite capable of lowering the transformation errors. We also explore its strong generalization capability over cross-datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.08000.pdf'>2112.08000</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.1298баллов, №510</br>
<b>Learning Submodular Objectives for Team Environmental Monitoring</b></br>
Authors: , Wilde, Nils, Sadeghi, Armin, Smith, Stephen L.</br>
  In this paper, we study the well-known team orienteering problem where a fleet of robots collects rewards by visiting locations. Usually, the rewards are assumed to be known to the robots; however, in applications such as environmental monitoring or scene reconstruction, the rewards are often subjective and specifying them is challenging. We propose a framework to learn the unknown preferences of the user by presenting alternative solutions to them, and the user provides a ranking on the proposed alternative solutions. We consider the two cases for the user: 1) a deterministic user which provides the optimal ranking for the alternative solutions, and 2) a noisy user which provides the optimal ranking according to an unknown probability distribution. For the deterministic user we propose a framework to minimize a bound on the maximum deviation from the optimal solution, namely regret. We adapt the approach to capture the noisy user and minimize the expected regret. Finally, we demonstrate the importance of learning user preferences and the performance of the proposed methods in an extensive set of experimental results using <font color="#009600">real world</font> datasets for environmental monitoring problems. </br></br>

<a href='http://arxiv.org/pdf/2112.06171.pdf'>2112.06171</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.1275баллов, №511</br>
<b>Pixel-wise Deep Image Stitching</b></br>
Authors: , Kweon, Hyeokjun, Kim, Hyeonseong, Kang, Yoonsu, Yoon, Youngho, Jeong, Wooseong, Yoon, Kuk-Jin</br>
  Image stitching aims at stitching the images taken from different viewpoints into an image with a wider field of view. Existing methods warp the target image to the reference image using the estimated warp function, and a homography is one of the most commonly used warping functions. However, when images have large parallax due to non-planar scenes and translational motion of a camera, the homography cannot fully describe the mapping between two images. Existing approaches based on global or local homography estimation are not free from this problem and suffer from undesired artifacts due to parallax. In this paper, instead of relying on the homography-based warp, we propose a novel deep image stitching framework exploiting the pixel-wise warp field to handle the large-parallax problem. The proposed deep image stitching framework consists of two modules: Pixel-wise Warping Module (PWM) and Stitched Image Generating Module (SIGMo). PWM employs an optical flow estimation model to obtain pixel-wise warp of the whole image, and relocates the pixels of the target image with the obtained warp field. SIGMo blends the warped target image and the reference image while eliminating unwanted artifacts such as misalignments, seams, and holes that harm the plausibility of the stitched result. For training and evaluating the proposed framework, we build a large-scale dataset that includes image pairs with corresponding pixel-wise ground truth warp and sample stitched result images. We show that the results of the proposed framework are qualitatively superior to those of the conventional methods, especially when the images have large parallax. The code and the proposed dataset will be <font color="#00be00">publicly available</font> soon. </br></br>

<a href='http://arxiv.org/pdf/2112.06796.pdf'>2112.06796</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp 0.1268баллов, №512</br>
<b>Depth Uncertainty Networks for Active Learning</b></br>
Authors: , Murray, Chelsea, Allingham, James U., Antor&#xe1;n, Javier, Hern&#xe1;ndez-Lobato, Jos&#xe9; Miguel</br>
  In active learning, the size and complexity of the training dataset changes over time. Simple models that are well specified by the amount of data available at the start of active learning might suffer from bias as more points are actively sampled. Flexible models that might be well suited to the full dataset can suffer from overfitting towards the start of active learning. We tackle this problem using Depth Uncertainty Networks (DUNs), a BNN variant in which the depth of the network, and thus its complexity, is inferred. We find that DUNs <font color="#00be00">outperform</font> other BNN variants on several active learning tasks. Importantly, we show that on the tasks in which DUNs perform best they present notably less overfitting than baselines. </br></br>

<a href='http://arxiv.org/pdf/2111.09098.pdf'>2111.09098</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 0.1250баллов, №513</br>
<b>Unifying Heterogenous Electronic Health Records Systems via Text-Based\n  Code Embedding</b></br>
Authors: , Hur, Kyunghoon, Lee, Jiyoung, Oh, Jungwoo, Price, Wesley, Kim, Young-Hak, Choi, Edward</br>
  EHR systems lack a unified code system forrepresenting <font color="#640064">medic</font>al concepts, which acts asa barrier for the deployment of deep learningmodels in large scale to multiple <font color="#be00be">clinic</font>s and hos-pitals. To overcome this problem, we introduceDescription-based Embedding,DescEmb, a code-agnostic representation learning framework forEHR. DescEmb takes advantage of the flexibil-ity of neural language understanding models toembed clinical events using their textual descrip-tions rather than directly mapping each event toa dedicated embedding. DescEmb <font color="#00be00">outperform</font>edtraditional code-based embedding in extensiveexperiments, especially in a <font color="#00be00">zero-shot</font> transfertask (one hospital to another), and was able totrain a single unified model for heterogeneousEHR datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.06474.pdf'>2112.06474</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.1207баллов, №514</br>
<b>Aerial Chasing of a Dynamic Target in Complex Environments</b></br>
Authors: , Jeon, Boseong Felipe, Kim, Changhyeon, Shin, Hojoon, Kim, H. Jin</br>
  Rapidly generating an optimal chasing motion of a drone to follow a dynamic target among obstacles is challenging due to numerical issues rising from multiple conflicting objectives and non-convex constraints. This study proposes to resolve the difficulties with a fast and reliable pipeline that incorporates 1) a target movement forecaster and 2) a chasing planner. They are based on a sample-and-check approach that consists of the generation of high-quality candidate primitives and the feasibility tests with a light computation load. We forecast the movement of the target by selecting an optimal prediction among a set of candidates built from past observations. Based on the prediction, we construct a set of prospective chasing trajectories which reduce the high-order derivatives, while maintaining the desired relative distance from the predicted target movement. Then, the candidate trajectories are tested on safety of the chaser and visibility toward the target without loose approximation of the constraints. The proposed algorithm is thoroughly evaluated in challenging scenarios involving dynamic obstacles. Also, the overall process from the target recognition to the chasing motion planning is implemented fully onboard on a drone, demonstrating <font color="#009600">real-world</font> applicability. </br></br>

<a href='http://arxiv.org/pdf/2112.06200.pdf'>2112.06200</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.1195баллов, №515</br>
<b>Secure Routine: A Routine-Based Algorithm for Drivers Identification</b></br>
Authors: , Micale, Davide, Costantino, Gianpiero, Matteucci, Ilaria, Patan&#xe8;, Giuseppe, Bella, Giampaolo</br>
  The introduction of Information and Communication Technology (ICT) in transportation systems leads to several advantages (efficiency of transport, mobility, traffic management). However, it may bring some drawbacks in terms of increasing security challenges, also related to human behaviour. As an example , in the last decades attempts to characterize drivers\' behaviour have been mostly targeted. This paper presents Secure Routine, a paradigm that uses driver\'s habits to driver identification and, in particular, to distinguish the vehicle\'s owner from other drivers. We evaluate Secure Routine in combination with other three existing research works based on machine learning techniques. Results are measured using well-known metrics and show that Secure Routine <font color="#00be00">outperform</font>s the compared works. </br></br>

<a href='http://arxiv.org/pdf/2112.05563.pdf'>2112.05563</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.1185баллов, №516</br>
<b>$D^*_{+}$: A Generic Platform-Agnostic and Risk-Aware Path Planing\n  Framework with an Expandable Grid</b></br>
Authors: , Karlsson, Samuel, Koval, Anton, Kanellakis, Christoforos, Agha-mohammadi, Ali-akbar, Nikolakopoulos, George</br>
  This article establishes a novel generic and platform-agnostic risk-aware path planning framework that is based on the classical $D^*$ lite planner with a path design focus on safety and efficiency. The planner generates a grid map where the occupied/free/unknown spaces are represented with different traversal costs. As it will presented, in this case, a traversal cost is added to the unknown voxels that are close to an occupied one. The algorithmic implementation is also enhanced with a dynamic grid map that has the novel ability to update and expand during the robotic operation and thus increase the overall safety of the mission and it is suitable for exploration and search and rescue missions. On the generated grid map, the $D^*$ lite is able to plan a safer path that has a minimum traversal cost. The proposed path planning framework is suitable for generating 2D and 3D paths, for ground and aerial robots respectively and thus in the 3D case, the grid is created with one voxel height to plan for a 2D path, which is the main factor that differentiates between 2D and 3D path planning. The efficacy of the proposed novel path planning scheme is extensively evaluated in multiple simulation and <font color="#009600">real-world</font> field experiments on both a quadcopter platform and the Boston Dynamics Spot legged robot. </br></br>

<a href='http://arxiv.org/pdf/2112.07529.pdf'>2112.07529</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.1172баллов, №517</br>
<b>Improving COVID-19 CXR Detection with Synthetic Data Augmentation</b></br>
Authors: , Schaudt, Daniel, Kloth, Christopher, Spaete, Christian, Hinteregger, Andreas, Beer, Meinrad, von Schwerin, Reinhold</br>
  Since the beginning of the COVID-19 pandemic, researchers have developed deep learning models to classify COVID-19 induced pneumonia. As with many <font color="#640064">medic</font>al imaging tasks, the quality and quantity of the available data is often limited. In this work we train a deep learning model on <font color="#00be00">publicly available</font> COVID-19 image data and evaluate the model on local hospital chest X-ray data. The data has been reviewed and labeled by two radiologists to ensure a high quality estimation of the generalization capabilities of the model. Furthermore, we are using a Generative Adversarial Network to generate synthetic X-ray images based on this data. Our results show that using those synthetic images for data augmentation can improve the model\'s performance significantly. This can be a promising approach for many sparse data domains. </br></br>

<a href='http://arxiv.org/pdf/2112.07423.pdf'>2112.07423</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.1156баллов, №518</br>
<b>Multi-Modal Perception Attention Network with Self-Supervised Learning\n  for Audio-Visual Speaker <font color="#be00be">Tracking</font></b></br>
Authors: , Li, Yidi, Liu, Hong, Tang, Hao</br>
  Multi-modal fusion is proven to be an effective method to improve the accuracy and robustness of speaker <font color="#be00be">tracking</font>, especially in complex scenarios. However, how to combine the heterogeneous information and exploit the complementarity of multi-modal signals remains a challenging issue. In this paper, we propose a novel Multi-modal Perception <font color="#be00be">Tracker</font> (MPT) for speaker tracking using both audio and visual modalities. Specifically, a novel acoustic map based on spatial-temporal Global Coherence Field (stGCF) is first constructed for heterogeneous signal fusion, which employs a camera model to map audio cues to the localization space consistent with the visual cues. Then a multi-modal perception attention network is introduced to derive the perception weights that measure the reliability and effectiveness of intermittent audio and video streams disturbed by noise. Moreover, a unique cross-modal self-supervised learning method is presented to model the confidence of audio and visual observations by leveraging the complementarity and consistency between different modalities. Experimental results show that the proposed MPT achieves 98.6% and 78.3% tracking accuracy on the standard and occluded datasets, respectively, which demonstrates its robustness under adverse conditions and <font color="#00be00">outperform</font>s the current <font color="#00be00">state-of-the-art</font> methods. </br></br>

<a href='http://arxiv.org/pdf/2112.08802.pdf'>2112.08802</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.1138баллов, №519</br>
<b>UniREx: A Unified Learning Framework for Language Model Rationale\n  Extraction</b></br>
Authors: , Chan, Aaron, Sanjabi, Maziar, Mathias, Lambert, Tan, Liang, Nie, Shaoliang, Peng, Xiaochang, Ren, Xiang, Firooz, Hamed</br>
  An extractive rationale explains a language model\'s (LM\'s) prediction on a given task instance by highlighting the text inputs that most influenced the output. Ideally, rationale extraction should be faithful (reflects LM\'s behavior), plausible (makes sense to humans), data-efficient, and fast, without sacrificing the LM\'s task performance. Prior rationale extraction works consist of specialized approaches for addressing various subsets of these desiderata -- but never all five. Narrowly focusing on certain desiderata typically comes at the expense of ignored ones, so existing rationale extractors are often impractical in <font color="#009600">real-world</font> applications. To tackle this challenge, we propose UniREx, a unified and highly flexible learning framework for rationale extraction, which allows users to easily account for all five factors. UniREx enables end-to-end customization of the rationale extractor training process, supporting arbitrary: (1) heuristic/learned rationale extractors, (2) combinations of faithfulness and/or plausibility objectives, and (3) amounts of gold rationale supervision. Across three text classification datasets, our best UniREx configurations achieve a superior balance of the five desiderata, when compared to strong baselines. Furthermore, UniREx-trained rationale extractors can even generalize to unseen datasets and tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.06334.pdf'>2112.06334</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.1131баллов, №520</br>
<b>DPICT: Deep Progressive Image Compression Using Trit-Planes</b></br>
Authors: , Lee, Jae-Han, Jeon, Seungmin, Choi, Kwang Pyo, Park, Youngo, Kim, Chang-Su</br>
  We propose the deep progressive image compression using trit-planes (DPICT) algorithm, which is the first learning-based codec supporting fine granular scalability (FGS). First, we transform an image into a latent tensor using an analysis network. Then, we represent the latent tensor in ternary digits (trits) and encode it into a compressed bitstream trit-plane by trit-plane in the decreasing order of significance. Moreover, within each trit-plane, we sort the trits according to their rate-distortion priorities and transmit more important information first. Since the compression network is less optimized for the cases of using fewer trit-planes, we develop a postprocessing network for refining reconstructed images at low rates. Experimental results show that DPICT <font color="#00be00">outperform</font>s conventional progressive codecs significantly, while enabling FGS transmission. </br></br>

<a href='http://arxiv.org/pdf/2112.06452.pdf'>2112.06452</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.1127баллов, №521</br>
<b>Contextual Exploration Using a Linear Approximation Method Based on\n  Satisficing</b></br>
Authors: , Minami, Akane, Kono, Yu, Takahashi, Tatsuji</br>
  Deep <font color="#00be00">reinforcement learning</font> has enabled <font color="#00be00">human-level</font> or even super-human performance in various types of games. However, the amount of exploration required for learning is often quite large. Deep reinforcement learning also has super-human performance in that no human being would be able to achieve such amounts of exploration. To address this problem, we focus on the \\textit{satisficing} policy, which is a qualitatively different approach from that of existing optimization algorithms. Thus, we propose Linear RS (LinRS), which is a type of satisficing algorithm and a linear extension of risk-sensitive satisficing (RS), for application to a wider range of tasks. The generalization of RS provides an algorithm to reduce the volume of exploratory actions by adopting a different approach from existing optimization algorithms. LinRS utilizes linear <font color="#be00be">regression</font> and multiclass classification to linearly approximate both the action value and proportion of action selections required in the RS calculation. The results of our experiments indicate that LinRS reduced the number of explorations and run time compared to those of existing algorithms in contextual <font color="#be00be">bandit</font> problems. These results suggest that a further generalization of satisficing algorithms may be useful for complex environments, including those that are to be handled with deep reinforcement learning. </br></br>

<a href='http://arxiv.org/pdf/2112.08060.pdf'>2112.08060</a> &nbsp&nbsp (cs:ML, cs:CV, stat:ML) &nbsp&nbsp 0.1114баллов, №522</br>
<b>Leveraging Image-based Generative Adversarial Networks for Time Series\n  Generation</b></br>
Authors: , Hellermann, Justin, Lessmann, Stefan</br>
  Generative models synthesize image data with great success regarding sampling quality, diversity and feature disentanglement. Generative models for time series lack these benefits due to a missing representation, which captures temporal dynamics and allows inversion for sampling. The paper proposes the intertemporal return plot (IRP) representation to facilitate the use of image-based generative adversarial networks for time series generation. The representation proves effective in capturing time series characteristics and, compared to alternative representations, benefits from invertibility and scale-invariance. Empirical benchmarks confirm these features and demonstrate that the IRP enables an off-the-shelf Wasserstein GAN with gradient penalty to sample realistic time series, which <font color="#00be00">outperform</font> a specialized RNN-based GAN, while simultaneously reducing model complexity. </br></br>

<a href='http://arxiv.org/pdf/2112.05197.pdf'>2112.05197</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.1061баллов, №523</br>
<b>Self-Supervised Bot Play for Conversational <font color="#be00be">Recommendat</font>ion with\n  Justifications</b></br>
Authors: , Li, Shuyang, Majumder, Bodhisattwa Prasad, McAuley, Julian</br>
  Conversational recommender systems offer the promise of interactive, engaging ways for users to find items they enjoy. We seek to improve conversational <font color="#be00be">recommendat</font>ion via three dimensions: 1) We aim to mimic a common mode of human interaction for recommendation: experts justify their suggestions, a seeker explains why they don\'t like the item, and both parties iterate through the dialog to find a suitable item. 2) We leverage ideas from conversational critiquing to allow users to flexibly interact with natural language justifications by critiquing subjective aspects. 3) We adapt conversational recommendation to a wider range of domains where crowd-sourced ground truth dialogs are not available. We develop a new two-part framework for training conversational recommender systems. First, we train a recommender system to jointly suggest items and justify its reasoning with subjective aspects. We then fine-tune this model to incorporate iterative user feedback via self-supervised bot-play. Experiments on three <font color="#009600">real-world</font> datasets demonstrate that our system can be applied to different recommendation models across diverse domains to achieve superior performance in conversational recommendation compared to <font color="#00be00">state-of-the-art</font> methods. We also evaluate our model on human users, showing that systems trained under our framework provide more useful, helpful, and knowledgeable recommendations in warm- and cold-start settings. </br></br>

<a href='http://arxiv.org/pdf/2112.07134.pdf'>2112.07134</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp 0.1041баллов, №524</br>
<b>Explore Long-Range Context feature for Speaker Verification</b></br>
Authors: , Li, Zhuo</br>
  Capturing long-range dependency and modeling long temporal contexts is proven to benefit speaker verification tasks. In this paper, we propose the combination of the <font color="#00be00">Hierarchical</font>-Split block(HS-block) and the Depthwise Separable Self-Attention(DSSA) module to capture richer multi-range context speaker features from a local and global perspective respectively. Specifically, the HS-block splits the feature map and filters into several groups and stacks them in one block, which enlarges the receptive fields(RFs) locally. The DSSA module improves the multi-head self-attention mechanism by the depthwise-separable strategy and explicit sparse attention strategy to model the pairwise relations globally and captures effective long-range dependencies in each channel. Experiments are conducted on the Voxceleb and SITW. Our best system achieves 1.27% EER on the Voxceleb1 test set and 1.56% on SITW by applying the combination of HS-block and DSSA module. </br></br>

<a href='http://arxiv.org/pdf/2112.05717.pdf'>2112.05717</a> &nbsp&nbsp (cs:CL, cs:ML, stat:ML) &nbsp&nbsp 0.1020баллов, №525</br>
<b>Discourse-Aware Prompt Design for Text Generation</b></br>
Authors: , Ghazvininejad, Marjan, Karpukhin, Vladimir, Celikyilmaz, Asli</br>
  Current efficient fine-tuning methods (e.g., adapters, prefix-tuning, etc.) have optimized conditional text generation via training a small set of extra parameters of the neural language model, while freezing the rest for efficiency. While showing strong performance on some generation tasks, they don\'t generalize across all generation tasks. In this work, we show that prompt based conditional text generation can be improved with simple and efficient methods that simulate modeling the discourse structure of human written text. We introduce two key design choices: First we show that a higher-level discourse structure of human written text can be modelled with \\textit{<font color="#00be00">hierarchical</font> blocking} on prefix parameters that enable spanning different parts of the input and output text and yield more coherent output generations. Second, we propose sparse prefix tuning by introducing \\textit{attention sparsity} on the prefix parameters at different layers of the network and learn sparse transformations on the softmax-function, respectively. We find that sparse attention enables the prefix-tuning to better control of the input contents (salient facts) yielding more efficient tuning of the prefix-parameters. Experiments on a wide-variety of text generation tasks show that structured design of prefix parameters can achieve comparable results to fine-tuning all parameters while <font color="#00be00">outperform</font>ing standard prefix-tuning on all generation tasks even in <font color="#be00be">low-resource</font> settings. </br></br>

<a href='http://arxiv.org/pdf/2112.08929.pdf'>2112.08929</a> &nbsp&nbsp (cs:AI, cs:ML, cs:SD) &nbsp&nbsp 0.0974баллов, №526</br>
<b>Bootstrap Equilibrium and Probabilistic Speaker Representation Learning\n  for Self-supervised Speaker Verification</b></br>
Authors: , Mun, Sung Hwan, Han, Min Hyun, Lee, Dongjune, Kim, Jihwan, Kim, Nam Soo</br>
  In this paper, we propose self-supervised speaker representation learning strategies, which comprise of a bootstrap equilibrium speaker representation learning in the front-end and an uncertainty-aware probabilistic speaker embedding training in the back-end. In the front-end stage, we learn the speaker representations via the bootstrap training scheme with the uniformity regularization term. In the back-end stage, the probabilistic speaker embeddings are estimated by maximizing the mutual likelihood score between the speech samples belonging to the same speaker, which provide not only speaker representations but also data uncertainty. Experimental results show that the proposed bootstrap equilibrium training strategy can effectively help learn the speaker representations and <font color="#00be00">outperform</font>s the conventional methods based on contrastive learning. Also, we demonstrate that the integrated two-stage framework further improves the speaker verification performance on the VoxCeleb1 test set in terms of EER and MinDCF. </br></br>

<a href='http://arxiv.org/pdf/2112.06405.pdf'>2112.06405</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0973баллов, №527</br>
<b>CSI Feedback with Model-Driven Deep Learning of Massive MIMO Systems</b></br>
Authors: , Guo, J., Wang, L., Li, F., Xue, J.</br>
  In order to achieve reliable communication with a high data rate of massive multiple-input multiple-output (MIMO) systems in frequency division duplex (FDD) mode, the estimated channel state information (CSI) at the receiver needs to be fed back to the transmitter. However, the feedback overhead becomes exorbitant with the increasing number of antennas. In this paper, a two stages low rank (TSLR) CSI feedback scheme for millimeter wave (mmWave) massive MIMO systems is proposed to reduce the feedback overhead based on model-driven deep learning. Besides, we design a deep iterative neural network, named FISTA-Net, by unfolding the fast iterative shrinkage thresholding algorithm (FISTA) to achieve more efficient CSI feedback. Moreover, a shrinkage thresholding network (ST-Net) is designed in FISTA-Net based on the attention mechanism, which can choose the threshold adaptively. Simulation results show that the proposed TSLR CSI feedback scheme and FISTA-Net <font color="#00be00">outperform</font> the existing algorithms in various scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.05917.pdf'>2112.05917</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0957баллов, №528</br>
<b>Show and Write: Entity-aware News Generation with Image Information</b></br>
Authors: , Zhang, Zhongping, Gu, Yiwen, Plummer, Bryan A.</br>
  Automatically writing long articles is a complex and challenging language generation task. Prior work has primarily focused on generating these articles using human-written prompt to provide some topical context and some metadata about the article. That said, for many applications, such as generating news stories, these articles are often paired with images and their captions or alt-text, which in turn are based on <font color="#009600">real-world</font> events and may reference many different named entities that are difficult to be correctly recognized and predicted by language models. To address these two problems, this paper introduces an Entity-aware News Generation method with Image iNformation, Engin, to incorporate news image information into language models. Engin produces news articles conditioned on both metadata and information such as captions and named entities extracted from images. We also propose an Entity-aware mechanism to help our model better recognize and predict the entity names in news. We perform experiments on two public large-scale news datasets, GoodNews and VisualNews. Quantitative results show that our approach improves article perplexity by 4-5 points over the base models. Qualitative results demonstrate the text generated by Engin is more consistent with news images. We also perform article quality annotation experiment on the generated articles to validate that our model produces higher-quality articles. Finally, we investigate the effect Engin has on methods that automatically detect machine-generated articles. </br></br>

<a href='http://arxiv.org/pdf/2112.05244.pdf'>2112.05244</a> &nbsp&nbsp (cs:ML, cs:AI, cs:RO, stat:ML) &nbsp&nbsp 0.0952баллов, №529</br>
<b>An Experimental Design Perspective on Model-Based <font color="#00be00">Reinforcement Learning</font></b></br>
Authors: , Mehta, Viraj, Paria, Biswajit, Schneider, Jeff, Ermon, Stefano, Neiswanger, Willie</br>
  In many practical applications of RL, it is expensive to observe state transitions from the environment. For example, in the problem of plasma control for nuclear fusion, computing the next state for a given state-action pair requires querying an expensive transition function which can lead to many hours of computer simulation or dollars of scientific research. Such expensive data collection prohibits application of standard RL algorithms which usually require a large number of observations to learn. In this work, we address the problem of efficiently learning a policy while making a minimal number of state-action queries to the transition function. In particular, we leverage ideas from <font color="#be00be">Bayes</font>ian optimal experimental design to guide the selection of state-action queries for efficient learning. We propose an acquisition function that quantifies how much information a state-action pair would provide about the optimal solution to a Markov decision process. At each iteration, our algorithm maximizes this acquisition function, to choose the most informative state-action pair to be queried, thus yielding a data-efficient RL approach. We experiment with a variety of simulated continuous control problems and show that our approach learns an optimal policy with up to $5$ -- $1,000\\times$ less data than model-based RL baselines and $10^3$ -- $10^5\\times$ less data than model-free RL baselines. We also provide several ablated comparisons which point to substantial improvements arising from the principled method of obtaining data. </br></br>

<a href='http://arxiv.org/pdf/2112.05914.pdf'>2112.05914</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0946баллов, №530</br>
<b>Leaping Through Time with Gradient-based Adaptation for <font color="#be00be">Recommendat</font>ion</b></br>
Authors: , Chairatanakul, Nuttapong, NT, Hoang, Liu, Xin, Murata, Tsuyoshi</br>
  Modern recommender systems are required to adapt to the change in user preferences and item popularity. Such a problem is known as the temporal dynamics problem, and it is one of the main challenges in recommender system modeling. Different from the popular recurrent modeling approach, we propose a new solution named LeapRec to the temporal dynamic problem by using trajectory-based meta-learning to model time dependencies. LeapRec characterizes temporal dynamics by two complement components named global time leap (GTL) and ordered time leap (OTL). By design, GTL learns long-term patterns by finding the shortest learning path across unordered temporal data. Cooperatively, OTL learns short-term patterns by considering the sequential nature of the temporal data. Our experimental results show that LeapRec consistently <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> methods on several datasets and <font color="#be00be">recommendat</font>ion metrics. Furthermore, we provide an empirical study of the interaction between GTL and OTL, showing the effects of long- and short-term modeling. </br></br>

<a href='http://arxiv.org/pdf/2112.05340.pdf'>2112.05340</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp 0.0941баллов, №531</br>
<b>Tradeoffs Between Contrastive and Supervised Learning: An Empirical\n  Study</b></br>
Authors: , Karthik, Ananya, Wu, Mike, Goodman, Noah, Tamkin, Alex</br>
  Contrastive learning has made considerable progress in computer vision, <font color="#00be00">outperform</font>ing supervised pretraining on a range of downstream datasets. However, is contrastive learning the better choice in all situations? We demonstrate two cases where it is not. First, under sufficiently small pretraining budgets, supervised pretraining on ImageNet consistently outperforms a comparable contrastive model on eight diverse image classification datasets. This suggests that the common practice of comparing pretraining approaches at hundreds or thousands of epochs may not produce actionable insights for those with more limited compute budgets. Second, even with larger pretraining budgets we identify tasks where supervised learning prevails, perhaps because the object-centric bias of supervised pretraining makes the model more resilient to common corruptions and spurious foreground-background correlations. These results underscore the need to characterize tradeoffs of different pretraining objectives across a wider range of contexts and training regimes. </br></br>

<a href='http://arxiv.org/pdf/2111.15414.pdf'>2111.15414</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0900баллов, №532</br>
<b>Neuron with Steady Response Leads to Better Generalization</b></br>
Authors: , Fu, Qiang, Du, Lun, Mao, Haitao, Chen, Xu, Fang, Wei, Han, Shi, Zhang, Dongmei</br>
  Regularization can mitigate the generalization gap between training and inference by introducing inductive bias. Existing works have already proposed various inductive biases from diverse perspectives. However, to the best of our knowledge, none of them explores inductive bias from the perspective of class-dependent response distribution of individual neurons. In this paper, we conduct a substantial analysis of the characteristics of such distribution. Based on the analysis results, we articulate the Neuron Steadiness Hypothesis: the neuron with similar responses to instances of the same class leads to better generalization. Accordingly, we propose a new regularization method called Neuron Steadiness Regularization to reduce neuron intra-class response variance. We conduct extensive experiments on Multilayer Perceptron, Convolutional Neural Network, and Graph Neural Network with popular benchmark datasets of diverse domains, which show that our Neuron Steadiness Regularization consistently <font color="#00be00">outperform</font>s the vanilla version of models with significant gain and low additional overhead. </br></br>

<a href='http://arxiv.org/pdf/2112.06712.pdf'>2112.06712</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0891баллов, №533</br>
<b>A Case For Noisy Shallow Gate-Based Circuits In Quantum Machine Learning</b></br>
Authors: , Selig, Patrick, Murphy, Niall, R, Ashwin Sundareswaran, Redmond, David, Caton, Simon</br>
  There is increasing interest in the development of gate-based quantum circuits for the training of machine learning models. Yet, little is understood concerning the parameters of circuit design, and the effects of noise and other measurement errors on the performance of quantum machine learning models. In this paper, we explore the practical implications of key circuit design parameters (number of qubits, depth etc.) using several standard machine learning datasets and IBM\'s Qiskit simulator. In total we evaluate over 6500 unique circuits with $n \\approx 120700$ individual runs. We find that in general shallow (low depth) wide (more qubits) circuit topologies tend to <font color="#00be00">outperform</font> deeper ones in settings without noise. We also explore the implications and effects of different notions of noise and discuss circuit topologies that are more / less robust to noise for classification machine learning tasks. Based on the findings we define guidelines for circuit topologies that show near-term promise for the realisation of quantum machine learning algorithms using gate-based NISQ quantum computer. </br></br>

<a href='http://arxiv.org/pdf/2112.07088.pdf'>2112.07088</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.0884баллов, №534</br>
<b>ElePose: Unsupervised 3D Human <font color="#be00be">Pose Estimation</font> by Predicting Camera\n  Elevation and Learning Normalizing Flows on 2D Poses</b></br>
Authors: , Wandt, Bastian, Little, James J., Rhodin, Helge</br>
  Human <font color="#be00be">pose estimation</font> from single images is a challenging problem that is typically solved by supervised learning. Unfortunately, labeled training data does not yet exist for many human activities since 3D annotation requires dedicated motion capture systems. Therefore, we propose an unsupervised approach that learns to predict a 3D human pose from a single image while only being trained with 2D pose data, which can be crowd-sourced and is already widely available. To this end, we estimate the 3D pose that is most likely over random projections, with the likelihood estimated using normalizing flows on 2D poses. While previous work requires strong priors on camera rotations in the training data set, we learn the distribution of camera angles which significantly improves the performance. Another part of our contribution is to stabilize training with normalizing flows on high-dimensional 3D pose data by first projecting the 2D poses to a linear subspace. We <font color="#00be00">outperform</font> the <font color="#00be00">state-of-the-art</font> unsupervised human pose estimation methods on the benchmark datasets Human3.6M and MPI-INF-3DHP in many metrics. </br></br>

<a href='http://arxiv.org/pdf/2112.06166.pdf'>2112.06166</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0882баллов, №535</br>
<b>Topic Detection and <font color="#be00be">Tracking</font> with Time-Aware Document Embeddings</b></br>
Authors: , Jiang, Hang, Beeferman, Doug, Mao, Weiquan, Roy, Deb</br>
  The time at which a message is communicated is a vital piece of metadata in many <font color="#009600">real-world</font> natural language processing tasks such as Topic Detection and <font color="#be00be">Tracking</font> (TDT). TDT systems aim to cluster a corpus of news articles by event, and in that context, stories that describe the same event are likely to have been written at around the same time. Prior work on time modeling for TDT takes this into account, but does not well capture how time interacts with the semantic nature of the event. For example, stories about a tropical storm are likely to be written within a short time interval, while stories about a movie release may appear over weeks or months. In our work, we design a neural method that fuses temporal and textual information into a single representation of news documents for event detection. We fine-tune these time-aware document embeddings with a triplet loss architecture, integrate the model into downstream TDT systems, and evaluate the systems on two benchmark TDT data sets in English. In the retrospective setting, we apply <font color="#be00be">clustering</font> algorithms to the time-aware embeddings and show substantial improvements over baselines on the News2013 data set. In the online streaming setting, we add our document encoder to an existing <font color="#00be00">state-of-the-art</font> TDT pipeline and demonstrate that it can benefit the overall performance. We conduct ablation studies on the time representation and fusion algorithm strategies, showing that our proposed model <font color="#00be00">outperform</font>s alternative strategies. Finally, we probe the model to examine how it handles recurring events more effectively than previous TDT systems. </br></br>

<a href='http://arxiv.org/pdf/2112.08541.pdf'>2112.08541</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0852баллов, №536</br>
<b>BGL: GPU-Efficient GNN Training by Optimizing Graph Data I/O and\n  Preprocessing</b></br>
Authors: , Liu, Tianfeng, Chen, Yangrui, Li, Dan, Wu, Chuan, Zhu, Yibo, He, Jun, Peng, Yanghua, Chen, Hongzheng, Chen, Hongzhi, Guo, Chuanxiong</br>
  Graph neural networks (GNNs) have extended the success of deep neural networks (DNNs) to non-Euclidean graph data, achieving ground-breaking performance on various tasks such as node classification and graph property prediction. Nonetheless, existing systems are inefficient to train large graphs with billions of nodes and edges with GPUs. The main bottlenecks are the process of preparing data for GPUs - subgraph sampling and feature retrieving. This paper proposes BGL, a distributed GNN training system designed to address the bottlenecks with a few key ideas. First, we propose a dynamic cache engine to minimize feature retrieving traffic. By a co-design of caching policy and the order of sampling, we find a sweet spot of low overhead and high cache hit ratio. Second, we improve the graph partition algorithm to reduce cross-partition communication during subgraph sampling. Finally, careful resource isolation reduces contention between different data preprocessing stages. Extensive experiments on various GNN models and large graph datasets show that BGL significantly <font color="#00be00">outperform</font>s existing GNN training systems by 20.68x on average. </br></br>

<a href='http://arxiv.org/pdf/2111.09272.pdf'>2111.09272</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp 0.0850баллов, №537</br>
<b>ReaLPrune: ReRAM Crossbar-aware Lottery Ticket Pruned CNNs</b></br>
Authors: , Joardar, Biresh Kumar, Doppa, Janardhan Rao, Li, Hai, Chakrabarty, Krishnendu, Pande, Partha Pratim</br>
  ReRAM-based architectures offer high-performance yet energy efficient computing platforms for CNN training/inferencing. However, ReRAM-based architectures are not scalable with the size of the CNN. Larger CNNs have more weights, which requires more ReRAM cells that cannot be integrated in a single chip. Pruning is an effective way to solve this problem. However, existing pruning techniques are either targeted for inferencing only, or they are not crossbar-aware. This leads to sub-optimal hardware savings and performance benefits for CNN training on ReRAM-based architectures. In this paper, we address this problem by proposing a novel crossbar-aware pruning strategy, referred as ReaLPrune, which can prune more than 90% of CNN weights. The pruned model can be trained from scratch without any accuracy loss. Experimental results indicate that ReaLPrune reduces hardware requirements by 77.2% and accelerates CNN training by ~20x compared to unpruned CNNs. ReaLPrune also <font color="#00be00">outperform</font>s other crossbar-aware pruning techniques in terms of both performance and hardware savings. In addition, ReaLPrune is equally effective for diverse datasets. </br></br>

<a href='http://arxiv.org/pdf/2111.09749.pdf'>2111.09749</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0845баллов, №538</br>
<b>Detecting Cross-Language Plagiarism using Open <font color="#960096">Knowledge Graph</font>s</b></br>
Authors: , Stegm&#xfc;ller, Johannes, Bauer-Marquart, Fabian, Meuschke, Norman, Ruas, Terry, Schubotz, Moritz, Gipp, Bela</br>
  Identifying cross-language plagiarism is challenging, especially for distant language pairs and sense-for-sense translations. We introduce the new multilingual <font color="#be00be">retrieval</font> model Cross-Language Ontology-Based Similarity Analysis (CL-OSA) for this task. CL-OSA represents documents as entity vectors obtained from the open <font color="#960096">knowledge graph</font> Wikidata. Opposed to other methods, CL-OSA does not require computationally expensive machine translation, nor pre-training using comparable or parallel corpora. It reliably disambiguates homonyms and scales to allow its application to Web-scale document collections. We show that CL-OSA <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> methods for retrieving candidate documents from five large, topically diverse test corpora that include distant language pairs like <font color="#be00be">Japanese</font>-English. For identifying cross-language plagiarism at the character level, CL-OSA primarily improves the detection of sense-for-sense translations. For these challenging cases, CL-OSA\'s performance in terms of the well-established PlagDet score exceeds that of the best competitor by more than factor two. The code and data of our study are openly available. </br></br>

<a href='http://arxiv.org/pdf/2112.08816.pdf'>2112.08816</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.0799баллов, №539</br>
<b>Self-Distilled Hashing for Deep Image <font color="#be00be">Retrieval</font></b></br>
Authors: , Jang, Young Kyun, Gu, Geonmo, Ko, Byungsoo, Cho, Nam Ik</br>
  In hash-based image <font color="#be00be">retrieval</font> systems, the transformed input from the original usually generates different codes, deteriorating the retrieval accuracy. To mitigate this issue, data augmentation can be applied during training. However, even if the augmented samples of one content are similar in real space, the quantization can scatter them far away in Hamming space. This results in representation discrepancies that can impede training and degrade performance. In this work, we propose a novel self-distilled hashing scheme to minimize the discrepancy while exploiting the potential of augmented data. By transferring the hash knowledge of the weakly-transformed samples to the strong ones, we make the hash code insensitive to various transformations. We also introduce hash proxy-based similarity learning and binary cross entropy-based quantization loss to provide fine quality hash codes. Ultimately, we construct a deep hashing framework that generates discriminative hash codes. Extensive experiments on benchmarks verify that our self-distillation improves the existing deep hashing approaches, and our framework achieves <font color="#00be00">state-of-the-art</font> retrieval results. The code will be released soon. </br></br>

<a href='http://arxiv.org/pdf/2112.08426.pdf'>2112.08426</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.0777баллов, №540</br>
<b>Contact simulation of a 2D Bipedal Robot kicking a ball</b></br>
Authors: , Adu-Bredu, Alphonsus</br>
  This report describes an approach for simulating multi-body contacts of actively-controlled systems. In this work, we focus on the controls and contact simulation of a 2-dimensional bipedal robot kicking a circular ball. </br></br>

<a href='http://arxiv.org/pdf/2112.05754.pdf'>2112.05754</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.0772баллов, №541</br>
<b>PyTorch Connectomics: A Scalable and Flexible <font color="#be00be">Segmentation</font> Framework for\n  EM Connectomics</b></br>
Authors: , Lin, Zudi, Wei, Donglai, Lichtman, Jeff, Pfister, Hanspeter</br>
  We present PyTorch Connectomics (PyTC), an open-source deep-learning framework for the semantic and instance <font color="#be00be">segmentation</font> of volumetric microscopy images, built upon PyTorch. We demonstrate the effectiveness of PyTC in the field of connectomics, which aims to segment and reconstruct neurons, synapses, and other organelles like mitochondria at nanometer resolution for understanding neuronal communication, metabolism, and development in animal <font color="#00be00">brain</font>s. PyTC is a scalable and flexible toolbox that tackles datasets at different scales and supports multi-task and semi-supervised learning to better exploit expensive expert annotations and the vast amount of unlabeled data during training. Those functionalities can be easily realized in PyTC by changing the configuration options without coding and adapted to other 2D and 3D segmentation tasks for different tissues and imaging modalities. Quantitatively, our framework achieves the best performance in the CREMI challenge for synaptic cleft segmentation (<font color="#00be00">outperform</font>s existing best result by relatively 6.1$\\%$) and <font color="#960096">competitive</font> performance on mitochondria and neuronal nuclei segmentation. Code and tutorials are <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://connectomics.readthedocs.io. </br></br>

<a href='http://arxiv.org/pdf/2111.14271.pdf'>2111.14271</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp 0.0731баллов, №542</br>
<b>ExCon: Explanation-driven Supervised Contrastive Learning for Image\n  Classification</b></br>
Authors: , Zhang, Zhibo, Jang, Jongseong, Trabelsi, Chiheb, Li, Ruiwen, Sanner, Scott, Jeong, Yeonjeong, Shim, Dongsub</br>
  Contrastive learning has led to substantial improvements in the quality of learned embedding representations for tasks such as image classification. However, a key drawback of existing contrastive augmentation methods is that they may lead to the modification of the image content which can yield undesired alterations of its semantics. This can affect the performance of the model on downstream tasks. Hence, in this paper, we ask whether we can augment image data in contrastive learning such that the task-relevant semantic content of an image is preserved. For this purpose, we propose to leverage saliency-based explanation methods to create content-preserving masked augmentations for contrastive learning. Our novel explanation-driven supervised contrastive learning (ExCon) methodology critically serves the dual goals of encouraging nearby image embeddings to have similar content and explanation. To quantify the impact of ExCon, we conduct experiments on the CIFAR-100 and the Tiny ImageNet datasets. We demonstrate that ExCon <font color="#00be00">outperform</font>s vanilla supervised contrastive learning in terms of classification, explanation quality, adversarial robustness as well as calibration of probabilistic predictions of the model in the context of distributional shift. </br></br>

<a href='http://arxiv.org/pdf/2112.08766.pdf'>2112.08766</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.0712баллов, №543</br>
<b>CODER: An efficient framework for improving <font color="#be00be">retrieval</font> through\n  COntextualized Document Embedding Reranking</b></br>
Authors: , Zerveas, George, Rekabsaz, Navid, Cohen, Daniel, Eickhoff, Carsten</br>
  We present a framework for improving the performance of a wide class of <font color="#be00be">retrieval</font> models at minimal computational cost. It utilizes precomputed document representations extracted by a base dense retrieval method and involves training a model to jointly score a large set of retrieved candidate documents for each query, while potentially transforming on the fly the representation of each document in the context of the other candidates as well as the query itself. When scoring a document representation based on its similarity to a query, the model is thus aware of the representation of its &quot;peer&quot; documents. We show that our approach leads to substantial improvement in retrieval performance over the base method and over scoring candidate documents in isolation from one another, as in a pair-wise training setting. Crucially, unlike term-interaction rerankers based on BERT-like encoders, it incurs a negligible computational overhead on top of any first-stage method at run time, allowing it to be easily combined with any <font color="#00be00">state-of-the-art</font> dense retrieval method. Finally, concurrently considering a set of candidate documents for a given query enables additional valuable capabilities in retrieval, such as score calibration and mitigating societal biases in ranking. </br></br>

<a href='http://arxiv.org/pdf/2112.07783.pdf'>2112.07783</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0705баллов, №544</br>
<b>Online anti-Semitism across platforms</b></br>
Authors: , De Smedt, Tom</br>
  We created a fine-grained AI system for the detection of anti-Semitism. This Explainable AI will identify English and German anti-Semitic expressions of dehumanization, verbal aggression and conspiracies in online social media messages across platforms, to support high-level decision making. </br></br>

<a href='http://arxiv.org/pdf/2112.06126.pdf'>2112.06126</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0678баллов, №545</br>
<b>Neural Network Quantization for Efficient Inference: A Survey</b></br>
Authors: , Weng, Olivia</br>
  As neural networks have become more powerful, there has been a rising desire to deploy them in the <font color="#009600">real world</font>; however, the power and accuracy of neural networks is largely due to their depth and complexity, making them difficult to deploy, especially in resource-constrained devices. Neural network quantization has recently arisen to meet this demand of reducing the size and complexity of neural networks by reducing the precision of a network. With smaller and simpler networks, it becomes possible to run neural networks within the constraints of their target hardware. This paper surveys the many neural network quantization techniques that have been developed in the last decade. Based on this survey and comparison of neural network quantization techniques, we propose future directions of research in the area. </br></br>

<a href='http://arxiv.org/pdf/2112.05820.pdf'>2112.05820</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp 0.0651баллов, №546</br>
<b>Building a great multi-lingual teacher with sparsely-gated mixture of\n  experts for <font color="#be00be">speech recognition</font></b></br>
Authors: , Kumatani, Kenichi, Gmyr, Robert, Salinas, Felipe Cruz, Liu, Linquan, Zuo, Wei, Patel, Devang, Sun, Eric, Shi, Yu</br>
  The sparsely-gated Mixture of Experts (MoE) can magnify a network capacity with a little computational complexity. In this work, we investigate how multi-lingual Automatic <font color="#be00be">Speech Recognition</font> (ASR) networks can be scaled up with a simple routing algorithm in order to achieve better accuracy. More specifically, we apply the sparsely-gated MoE technique to two types of networks: Sequence-to-Sequence <font color="#00be00">Transformer</font> (S2S-T) and Transformer Transducer (T-T). We demonstrate through a set of ASR experiments on multiple language data that the MoE networks can reduce the relative word error rates by 16.5% and 4.7% with the S2S-T and T-T, respectively. Moreover, we thoroughly investigate the effect of the MoE on the T-T architecture in various conditions: streaming mode, non-streaming mode, the use of language ID and the label decoder with the MoE. </br></br>

<a href='http://arxiv.org/pdf/2112.04749.pdf'>2112.04749</a> &nbsp&nbsp (cs:NE, cs:ET) &nbsp&nbsp 0.0601баллов, №547</br>
<b>Experimental Demonstration of Neuromorphic Network with STT MTJ Synapses</b></br>
Authors: , Zhou, Peng, Edwards, Alexander J., Mancoff, Fred B., Houssameddine, Dimitri, Aggarwal, Sanjeev, Friedman, Joseph S.</br>
  We present the first experimental demonstration of a neuromorphic network with magnetic tunnel junction (MTJ) synapses, which performs image recognition via vector-matrix multiplication. We also simulate a large MTJ network performing MNIST handwritten digit recognition, demonstrating that MTJ crossbars can match memristor accuracy while providing increased precision, stability, and endurance. </br></br>

<a href='http://arxiv.org/pdf/2112.07794.pdf'>2112.07794</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.0595баллов, №548</br>
<b>Review of Factor Graphs for Robust GNSS Applications</b></br>
Authors: , Das, Shounak, Watson, Ryan, Gross, Jason</br>
  Factor graphs have recently emerged as an alternative solution method for GNSS positioning. In this article, we review how factor graphs are implemented in GNSS, some of their advantages over Kalman Filters, and their importance in making positioning solutions more robust to degraded measurements. We also talk about how factor graphs can be an important tool for the field radio-navigation community. </br></br>

<a href='http://arxiv.org/pdf/2112.08355.pdf'>2112.08355</a> &nbsp&nbsp (cs:ML, cs:RO, stat:ML) &nbsp&nbsp 0.0550баллов, №549</br>
<b>Estimating Uncertainty For Vehicle Motion Prediction on Yandex Shifts\n  Dataset</b></br>
Authors: , Pustynnikov, Alexey, Eremeev, Dmitry</br>
  Motion prediction of surrounding agents is an important task in context of autonomous driving since it is closely related to driver\'s safety. Vehicle Motion Prediction (VMP) track of Shifts Challenge focuses on developing models which are robust to distributional shift and able to measure uncertainty of their predictions. In this work we present the approach that significantly improved provided benchmark and took 2nd place on the leaderboard. </br></br>

<a href='http://arxiv.org/pdf/2112.08198.pdf'>2112.08198</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.0547баллов, №550</br>
<b>Single Image Automatic Radial Distortion Compensation Using Deep\n  Convolutional Network</b></br>
Authors: , Janos, Igor, Benesova, Wanda</br>
  In many computer vision domains, the input images must conform with the pinhole camera model, where straight lines in the <font color="#009600">real world</font> are projected as straight lines in the image. Performing computer vision tasks on live sports broadcast footage imposes challenging requirements where the algorithms cannot rely on a specific calibration pattern must be able to cope with unknown and uncalibrated cameras, radial distortion originating from complex television lenses, few visual clues to compensate distortion by, and the necessity for real-time performance. We present a novel method for single-image automatic lens distortion compensation based on deep convolutional neural networks, capable of real-time performance and accuracy using two highest-order coefficients of the polynomial distortion model operating in the application domain of sports broadcast. Keywords: Deep Convolutional Neural Network, Radial Distortion, Single Image Rectification </br></br>

<a href='http://arxiv.org/pdf/2112.08776.pdf'>2112.08776</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.0492баллов, №551</br>
<b>Unsupervised Matching of Data and Text</b></br>
Authors: , Ahmadi, Naser, Sand, Hansjorg, Papotti, Paolo</br>
  Entity resolution is a widely studied problem with several proposals to match records across relations. Matching textual content is a widespread task in many applications, such as question answering and search. While recent methods achieve promising results for these two tasks, there is no clear solution for the more general problem of matching textual content and structured data. We introduce a framework that supports this new task in an unsupervised setting for any pair of corpora, being relational tables or text documents. Our method builds a fine-grained graph over the content of the corpora and derives word embeddings to represent the objects to match in a low dimensional space. The learned representation enables effective and efficient matching at different granularity, from relational tuples to text sentences and paragraphs. Our flexible framework can exploit pre-trained resources, but it does not depends on their existence and achieves better quality performance in matching content when the vocabulary is domain specific. We also introduce optimizations in the graph creation process with an &quot;expand and compress&quot; approach that first identifies new valid relationships across elements, to improve matching, and then prunes nodes and edges, to reduce the graph size. Experiments on real use cases and public datasets show that our framework produces embeddings that <font color="#00be00">outperform</font> word embeddings and fine-tuned language models both in results\' quality and in execution times. </br></br>

<a href='http://arxiv.org/pdf/2112.08919.pdf'>2112.08919</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0488баллов, №552</br>
<b>Deep Generative Models for Geometric Design Under Uncertainty</b></br>
Authors: , Wei, Chen, Lee, Doksoo, Chen, Wei</br>
  Deep generative models have demonstrated effectiveness in learning compact and expressive design representations that significantly improve geometric design optimization. However, these models do not consider the uncertainty introduced by manufacturing or fabrication. Past work that quantifies such uncertainty often makes simplified assumptions on geometric variations, while the &quot;<font color="#009600">real-world</font>&quot; uncertainty and its impact on design performance are difficult to quantify due to the high dimensionality. To address this issue, we propose a Generative Adversarial Network-based Design under Uncertainty Framework (GAN-DUF), which contains a deep generative model that simultaneously learns a compact representation of nominal (ideal) designs and the conditional distribution of fabricated designs given any nominal design. We demonstrated the framework on two real-world engineering design examples and showed its capability of finding the solution that possesses better performances after fabrication. </br></br>

<a href='http://arxiv.org/pdf/2112.07835.pdf'>2112.07835</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp 0.0487баллов, №553</br>
<b>Mining Minority-class Examples With Uncertainty Estimates</b></br>
Authors: , Singh, Gursimran, Chu, Lingyang, Wang, Lanjun, Pei, Jian, Tian, Qi, Zhang, Yong</br>
  In the <font color="#009600">real world</font>, the frequency of occurrence of objects is naturally skewed forming long-tail class distributions, which results in poor performance on the statistically rare classes. A promising solution is to mine tail-class examples to balance the training dataset. However, mining tail-class examples is a very challenging task. For instance, most of the otherwise successful uncertainty-based mining approaches struggle due to distortion of class probabilities resulting from skewness in data. In this work, we propose an effective, yet simple, approach to overcome these challenges. Our framework enhances the subdued tail-class activations and, thereafter, uses a one-class data-centric approach to effectively identify tail-class examples. We carry out an exhaustive evaluation of our framework on three datasets spanning over two computer vision tasks. Substantial improvements in the minority-class mining and fine-tuned model\'s performance strongly corroborate the value of our proposed solution. </br></br>

<a href='http://arxiv.org/pdf/2112.08596.pdf'>2112.08596</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0468баллов, №554</br>
<b>Guiding Neural Story Generation with Reader Models</b></br>
Authors: , Peng, Xiangyu, Xie, Kaige, Alabdulkarim, Amal, Kayam, Harshith, Dani, Samihan, Riedl, Mark O.</br>
  Automated storytelling has long captured the attention of researchers for the ubiquity of narratives in everyday life. However, it is challenging to maintain coherence and stay on-topic toward a specific ending when generating narratives with neural language models. In this paper, we introduce Story generation with Reader Models (StoRM), a framework in which a reader model is used to reason about the story should progress. A reader model infers what a human reader believes about the concepts, entities, and relations about the fictional story world. We show how an explicit reader model represented as a <font color="#960096">knowledge graph</font> affords story coherence and provides controllability in the form of achieving a given story world state goal. Experiments show that our model produces significantly more coherent and on-topic stories, <font color="#00be00">outperform</font>ing baselines in dimensions including plot plausibility and staying on topic. Our system also outperforms outline-guided story generation baselines in composing given concepts without ordering. </br></br>

<a href='http://arxiv.org/pdf/2112.07534.pdf'>2112.07534</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0467баллов, №555</br>
<b>Reinforced Abstractive <font color="#be00be">Summarization</font> with Adaptive Length Controlling</b></br>
Authors: , Song, Mingyang, Feng, Yi, Jing, Liping</br>
  Document <font color="#be00be">summarization</font>, as a fundamental task in natural language generation, aims to generate a short and coherent summary for a given document. Controllable summarization, especially of the length, is an important issue for some practical applications, especially how to trade-off the length constraint and information integrity. In this paper, we propose an \\textbf{A}daptive \\textbf{L}ength \\textbf{C}ontrolling \\textbf{O}ptimization (\\textbf{ALCO}) method to leverage two-stage abstractive summarization model via <font color="#00be00">reinforcement learning</font>. ALCO incorporates length constraint into the stage of sentence extraction to penalize the overlength extracted sentences. Meanwhile, a saliency estimation mechanism is designed to preserve the salient information in the generated sentences. A series of experiments have been conducted on a wildly-used benchmark dataset \\textit{CNN/Daily Mail}. The results have shown that ALCO performs better than the popular baselines in terms of length controllability and content preservation. </br></br>

<a href='http://arxiv.org/pdf/2112.09037.pdf'>2112.09037</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0460баллов, №556</br>
<b>A Static Analyzer for Detecting Tensor Shape Errors in Deep Neural\n  Network Training Code</b></br>
Authors: , Jhoo, Ho Young, Kim, Sehoon, Song, Woosung, Park, Kyuyeon, Lee, DongKwon, Yi, Kwangkeun</br>
  We present an automatic static analyzer PyTea that detects tensor-shape errors in PyTorch code. The tensor-shape error is critical in the deep neural net code; much of the training cost and intermediate results are to be lost once a tensor shape mismatch occurs in the midst of the training phase. Given the input PyTorch source, PyTea statically traces every possible execution path, collects tensor shape constraints required by the tensor operation sequence of the path, and decides if the constraints are unsatisfiable (hence a shape error can occur). PyTea\'s scalability and precision hinges on the characteristics of <font color="#009600">real-world</font> PyTorch applications: the number of execution paths after PyTea\'s conservative pruning rarely explodes and loops are simple enough to be circumscribed by our symbolic abstraction. We tested PyTea against the projects in the official PyTorch repository and some tensor-error code questioned in the StackOverflow. PyTea successfully detects tensor shape errors in these codes, each within a few seconds. </br></br>

<a href='http://arxiv.org/pdf/2112.05198.pdf'>2112.05198</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0451баллов, №557</br>
<b><font color="#00be00">Reinforcement Learning</font> with Almost Sure Constraints</b></br>
Authors: , Castellano, Agustin, Min, Hancheng, Bazerque, Juan, Mallada, Enrique</br>
  In this work we address the problem of finding feasible policies for Constrained Markov Decision Processes under probability one constraints. We argue that stationary policies are not sufficient for solving this problem, and that a rich class of policies can be found by endowing the controller with a scalar quantity, so called budget, that tracks how close the agent is to violating the constraint. We show that the minimal budget required to act safely can be obtained as the smallest fixed point of a Bellman-like operator, for which we analyze its convergence properties. We also show how to learn this quantity when the true <font color="#be00be">kernel</font> of the Markov decision process is not known, while providing sample-complexity bounds. The utility of knowing this minimal budget relies in that it can aid in the search of optimal or near-optimal policies by shrinking down the region of the state space the agent must navigate. Simulations illustrate the different nature of probability one constraints against the typically used constraints in expectation. </br></br>

<a href='http://arxiv.org/pdf/2112.08462.pdf'>2112.08462</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0444баллов, №558</br>
<b>Applying SoftTriple Loss for Supervised Language Model Fine Tuning</b></br>
Authors: , Sosnowski, Witold, Wroblewska, Anna, Gawrysiak, Piotr</br>
  We introduce a new loss function TripleEntropy, to improve classification performance for fine-tuning general knowledge pre-trained language models based on cross-entropy and SoftTriple loss. This loss function can improve the robust RoBERTa baseline model fine-tuned with cross-entropy loss by about (0.02% - 2.29%). Thorough tests on popular datasets indicate a steady gain. The fewer samples in the training dataset, the higher gain -- thus, for small-sized dataset it is 0.78%, for medium-sized -- 0.86% for large -- 0.20% and for extra-large 0.04%. </br></br>

<a href='http://arxiv.org/pdf/2112.05497.pdf'>2112.05497</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.0431баллов, №559</br>
<b>An Adaptive Observer for Uncertain Linear Time-Varying Systems with\n  Unknown Additive Perturbations</b></br>
Authors: , Pyrkin, Anton, Bobtsov, Alexey, Ortega, Romeo, Isidori, Alberto</br>
  In this paper we are interested in the problem of adaptive state observation of linear time-varying (LTV) systems where the system and the input matrices depend on unknown time-varying parameters. It is assumed that these parameters satisfy some known LTV dynamics, but with unknown initial conditions. Moreover, the state equation is perturbed by an additive signal generated from an exosystem with uncertain constant parameters. Our main contribution is to propose a globally convergent state observer that requires only a weak excitation assumption on the system. </br></br>

<a href='http://arxiv.org/pdf/2112.07711.pdf'>2112.07711</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0426баллов, №560</br>
<b>Representing Inferences and their Lexicalization</b></br>
Authors: , McDonald, David, Pustejovsky, James</br>
  We have recently begun a project to develop a more effective and efficient way to marshal inferences from background knowledge to facilitate deep natural language understanding. The meaning of a word is taken to be the entities, predications, presuppositions, and potential inferences that it adds to an ongoing situation. As words compose, the minimal model in the situation evolves to limit and direct inference. At this point we have developed our computational architecture and implemented it on real text. Our focus has been on proving the feasibility of our design. </br></br>

<a href='http://arxiv.org/pdf/2111.02916.pdf'>2111.02916</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp 0.0423баллов, №561</br>
<b>A Unified View of Relational Deep Learning for <font color="#00be00">Drug</font> Pair Scoring</b></br>
Authors: , Rozemberczki, Benedek, Bonner, Stephen, Nikolov, Andriy, Ughetto, Michael, Nilsson, Sebastian, Papa, Eliseo</br>
  In recent years, numerous machine learning models which attempt to solve polypharmacy side effect identification, <font color="#00be00">drug</font>-drug interaction prediction and combination therapy design tasks have been proposed. Here, we present a unified <font color="#be00be">theor</font>etical view of relational machine learning models which can address these tasks. We provide fundamental definitions, compare existing model architectures and discuss performance metrics, datasets and evaluation protocols. In addition, we emphasize possible high impact applications and important future research directions in this domain. </br></br>

<a href='http://arxiv.org/pdf/2112.07176.pdf'>2112.07176</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.0396баллов, №562</br>
<b>ZUPT Aided GNSS Factor Graph with Inertial Navigation Integration for\n  Wheeled Robots</b></br>
Authors: , Kilic, Cagri, Das, Shounak, Gutierrez, Eduardo, Watson, Ryan, Gross, Jason</br>
  In this work, we demonstrate the importance of zero velocity information for global navigation satellite system (GNSS) based navigation. The effectiveness of using the zero velocity information with zero velocity update (ZUPT) for inertial navigation applications have been shown in the literature. Here we leverage this information and add it as a position constraint in a GNSS factor graph. We also compare its performance to a GNSS/inertial navigation system (INS) coupled factor graph. We tested our ZUPT aided factor graph method on three datasets and compared it with the GNSS-only factor graph. </br></br>

<a href='http://arxiv.org/pdf/2112.08288.pdf'>2112.08288</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0345баллов, №563</br>
<b>Improving both domain robustness and domain adaptability in machine\n  translation</b></br>
Authors: , Lai, Wen, Libovick&#xfd;, Jind&#x159;ich, Fraser, Alexander</br>
  We address two problems of domain adaptation in neural machine translation. First, we want to reach domain robustness, i.e., good quality of both domains from the training data, and domains unseen in the training data. Second, we want our systems to be adaptive, i.e., making it possible to finetune systems with just hundreds of in-domain parallel sentences. In this paper, we introduce a novel combination of two previous approaches, word adaptive modelling, which addresses domain robustness, and meta-learning, which addresses domain adaptability, and we present empirical results showing that our new combination improves both of these properties. </br></br>

<a href='http://arxiv.org/pdf/2112.04910.pdf'>2112.04910</a> &nbsp&nbsp (cs:RO, cs:CV) &nbsp&nbsp 0.0317баллов, №564</br>
<b><font color="#00be00">Few-Shot</font> Keypoint Detection as Task Adaptation via Latent Embeddings</b></br>
Authors: , Vecerik, Mel, Kay, Jackie, Hadsell, Raia, Agapito, Lourdes, Scholz, Jon</br>
  Dense object <font color="#be00be">tracking</font>, the ability to localize specific object points with pixel-level accuracy, is an important computer vision task with numerous downstream applications in robotics. Existing approaches either compute dense keypoint embeddings in a single forward pass, meaning the model is trained to track everything at once, or allocate their full capacity to a sparse predefined set of points, trading generality for accuracy. In this paper we explore a middle ground based on the observation that the number of relevant points at a given time are typically relatively few, e.g. grasp points on a target object. Our main contribution is a novel architecture, inspired by <font color="#00be00">few-shot</font> task adaptation, which allows a sparse-<font color="#be00be">style</font> network to condition on a keypoint embedding that indicates which point to track. Our central finding is that this approach provides the generality of dense-embedding models, while offering accuracy significantly closer to sparse-keypoint approaches. We present results illustrating this capacity vs. accuracy trade-off, and demonstrate the ability to <font color="#00be00">zero-shot</font> transfer to new object instances (within-class) using a real-robot pick-and-place task. </br></br>

<a href='http://arxiv.org/pdf/2112.05256.pdf'>2112.05256</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.0307баллов, №565</br>
<b>Semantic Construction Grammar: Bridging the NL / Logic Divide</b></br>
Authors: , Schneider, Dave, Witbrock, Michael</br>
  In this paper, we discuss Semantic Construction Grammar (SCG), a system developed over the past several years to facilitate translation between natural language and logical representations. Crucially, SCG is designed to support a variety of different methods of representation, ranging from those that are fairly close to the NL structure (e.g. so-called \'logical forms\'), to those that are quite different from the NL structure, with higher-order and high-arity relations. Semantic constraints and checks on representations are integral to the process of NL understanding with SCG, and are easily carried out due to the SCG\'s integration with Cyc\'s Knowledge Base and inference engine. </br></br>

<a href='http://arxiv.org/pdf/2112.06563.pdf'>2112.06563</a> &nbsp&nbsp (cs:ML, cs:NE) &nbsp&nbsp 0.0299баллов, №566</br>
<b>On the Choice of General Purpose Classifiers in Learned Bloom Filters:\n  An Initial Analysis Within Basic Filters</b></br>
Authors: , Fumagalli, Giacomo, Raimondi, Davide, Giancarlo, Raffaele, Malchiodi, Dario, Frasca, Marco</br>
  Bloom Filters are a fundamental and pervasive data structure. Within the growing area of Learned Data Structures, several Learned versions of Bloom Filters have been considered, yielding advantages over classic Filters. Each of them uses a classifier, which is the Learned part of the data structure. Although it has a central role in those new filters, and its space footprint as well as classification time may affect the performance of the Learned Filter, no systematic study of which specific classifier to use in which circumstances is available. We report progress in this area here, providing also initial guidelines on which classifier to choose among five classic classification paradigms. </br></br>

<a href='http://arxiv.org/pdf/2112.06199.pdf'>2112.06199</a> &nbsp&nbsp (cs:CL, cs:SD) &nbsp&nbsp 0.0293баллов, №567</br>
<b>Learning Nigerian accent embeddings from speech: preliminary results\n  based on SautiDB-Naija corpus</b></br>
Authors: , Afonja, Tejumade, Mudele, Oladimeji, Orife, Iroro, Dukor, Kenechi, Francis, Lawrence, Goodness, Duru, Azeez, Oluwafemi, Malomo, Ademola, Mbataku, Clinton</br>
  This paper describes foundational efforts with SautiDB-Naija, a novel corpus of non-native (L2) Nigerian English speech. We describe how the corpus was created and curated as well as preliminary experiments with accent classification and learning Nigerian accent embeddings. The initial version of the corpus includes over 900 recordings from L2 English speakers of Nigerian languages, such as Yoruba, Igbo, Edo, Efik-Ibibio, and Igala. We further demonstrate how fine-tuning on a pre-trained model like wav2vec can yield representations suitable for related speech tasks such as accent classification. SautiDB-Naija has been published to Zenodo for general use under a flexible Creative Commons License. </br></br>

<a href='http://arxiv.org/pdf/2112.08152.pdf'>2112.08152</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0291баллов, №568</br>
<b>Faster <font color="#be00be">Nearest Neighbo</font>r Machine Translation</b></br>
Authors: , Wang, Shuhe, Li, Jiwei, Meng, Yuxian, Ouyang, Rongbin, Wang, Guoyin, Li, Xiaoya, Zhang, Tianwei, Zong, Shi</br>
  $k$NN based neural machine translation ($k$NN-MT) has achieved <font color="#00be00">state-of-the-art</font> results in a variety of MT tasks. One significant shortcoming of $k$NN-MT lies in its inefficiency in identifying the $k$ <font color="#be00be">nearest neighbo</font>rs of the query representation from the entire datastore, which is prohibitively time-intensive when the datastore size is large. In this work, we propose \\textbf{Faster $k$NN-MT} to address this issue. The core idea of Faster $k$NN-MT is to use a <font color="#00be00">hierarchical</font> <font color="#be00be">clustering</font> strategy to approximate the distance between the query and a data point in the datastore, which is decomposed into two parts: the distance between the query and the center of the cluster that the data point belongs to, and the distance between the data point and the cluster center. We propose practical ways to compute these two parts in a significantly faster manner. Through extensive experiments on different MT benchmarks, we show that \\textbf{Faster $k$NN-MT} is faster than Fast $k$NN-MT \\citep{meng2021fast} and only slightly (1.2 times) slower than its vanilla counterpart while preserving model performance as $k$NN-MT. Faster $k$NN-MT enables the deployment of $k$NN-MT models on <font color="#009600">real-world</font> MT services. </br></br>

<a href='http://arxiv.org/pdf/2112.08098.pdf'>2112.08098</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp 0.0279баллов, №569</br>
<b>Mask-combine Decoding and Classification Approach for Punctuation\n  Prediction with real-time Inference Constraints</b></br>
Authors: , Minixhofer, Christoph, Klejch, Ond&#x159;ej, Bell, Peter</br>
  In this work, we unify several existing decoding strategies for punctuation prediction in one framework and introduce a novel strategy which utilises multiple predictions at each word across different windows. We show that significant improvements can be achieved by optimising these strategies after training a model, only leading to a potential increase in inference time, with no requirement for retraining. We further use our decoding strategy framework for the first comparison of tagging and classification approaches for punctuation prediction in a real-time setting. Our results show that a classification approach for punctuation prediction can be beneficial when little or no right-side context is available. </br></br>

<a href='http://arxiv.org/pdf/2112.06170.pdf'>2112.06170</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.0276баллов, №570</br>
<b>Deep network for rolling shutter rectification</b></br>
Authors: , K, Praveen, T, Lokesh Kumar, Rajagopalan, A. N.</br>
  CMOS sensors employ row-wise acquisition mechanism while imaging a scene, which can result in undesired motion artifacts known as rolling shutter (RS) distortions in the captured image. Existing single image RS rectification methods attempt to account for these distortions by either using algorithms tailored for specific class of scenes which warrants information of intrinsic camera parameters or a learning-based framework with known ground truth motion parameters. In this paper, we propose an end-to-end deep neural network for the challenging task of single image RS rectification. Our network consists of a motion block, a trajectory module, a row block, an RS rectification module and an RS regeneration module (which is used only during training). The motion block predicts camera pose for every row of the input RS distorted image while the trajectory module fits estimated motion parameters to a third-order polynomial. The row block predicts the camera motion that must be associated with every pixel in the target i.e, RS rectified image. Finally, the RS rectification module uses motion trajectory and the output of row block to warp the input RS image to arrive at a distortionfree image. For faster convergence during training, we additionally use an RS regeneration module which compares the input RS image with the ground truth image distorted by estimated motion parameters. The end-to-end formulation in our model does not constrain the estimated motion to ground-truth motion parameters, thereby successfully rectifying the RS images with complex real-life camera motion. Experiments on synthetic and real datasets reveal that our network <font color="#00be00">outperform</font>s prior art both qualitatively and quantitatively. </br></br>

<a href='http://arxiv.org/pdf/2112.08851.pdf'>2112.08851</a> &nbsp&nbsp (stat:ML, cs:CV, cs:ML) &nbsp&nbsp 0.0269баллов, №571</br>
<b>Classification Under Ambiguity: When Is Average-K Better Than Top-K?</b></br>
Authors: , Lorieul, Titouan, Joly, Alexis, Shasha, Dennis</br>
  When many labels are possible, choosing a single one can lead to low precision. A common alternative, referred to as top-$K$ classification, is to choose some number $K$ (commonly around 5) and to return the $K$ labels with the highest scores. Unfortunately, for unambiguous cases, $K&gt;1$ is too many and, for very ambiguous cases, $K \\leq 5$ (for example) can be too small. An alternative sensible strategy is to use an adaptive approach in which the number of labels returned varies as a function of the computed ambiguity, but must average to some particular $K$ over all the samples. We denote this alternative average-$K$ classification. This paper formally characterizes the ambiguity profile when average-$K$ classification can achieve a lower error rate than a fixed top-$K$ classification. Moreover, it provides natural estimation procedures for both the fixed-size and the adaptive classifier and proves their consistency. Finally, it reports experiments on <font color="#009600">real-world</font> image data sets revealing the benefit of average-$K$ classification over top-$K$ in practice. Overall, when the ambiguity is known precisely, average-$K$ is never worse than top-$K$, and, in our experiments, when it is estimated, this also holds. </br></br>

<a href='http://arxiv.org/pdf/2112.08608.pdf'>2112.08608</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0266баллов, №572</br>
<b>QuALITY: Question Answering with Long Input Texts, Yes!</b></br>
Authors: , Pang, Richard Yuanzhe, Parrish, Alicia, Joshi, Nitish, Nangia, Nikita, Phang, Jason, Chen, Angelica, Padmakumar, Vishakh, Ma, Johnny, Thompson, Jana, He, He, Bowman, Samuel R.</br>
  To enable building and testing models on long-document comprehension, we introduce QuALITY, a multiple-choice QA dataset with context passages in English that have an average length of about 5,000 tokens, much longer than typical current models can process. Unlike in prior work with passages, our questions are written and validated by contributors who have read the entire passage, rather than relying on summaries or excerpts. In addition, only half of the questions are answerable by annotators working under tight time constraints, indicating that skimming and simple search are not enough to consistently perform well. Current models perform poorly on this task (55.4%) and significantly lag behind human performance (93.5%). </br></br>

<a href='http://arxiv.org/pdf/2112.07909.pdf'>2112.07909</a> &nbsp&nbsp (cs:CV, cs:RO) &nbsp&nbsp 0.0252баллов, №573</br>
<b>Homography Decomposition Networks for Planar Object <font color="#be00be">Tracking</font></b></br>
Authors: , Zhan, Xinrui, Liu, Yueran, Zhu, Jianke, Li, Yang</br>
  Planar object <font color="#be00be">tracking</font> plays an important role in AI applications, such as robotics, visual servoing, and visual SLAM. Although the previous planar <font color="#be00be">tracker</font>s work well in most scenarios, it is still a challenging task due to the rapid motion and large transformation between two consecutive frames. The essential reason behind this problem is that the condition number of such a non-linear system changes unstably when the searching range of the homography parameter space becomes larger. To this end, we propose a novel Homography Decomposition Networks~(HDN) approach that drastically reduces and stabilizes the condition number by decomposing the homography transformation into two groups. Specifically, a similarity transformation estimator is designed to predict the first group robustly by a deep convolution equivariant network. By taking advantage of the scale and rotation estimation with high confidence, a residual transformation is estimated by a simple <font color="#be00be">regression</font> model. Furthermore, the proposed end-to-end network is trained in a semi-supervised fashion. Extensive experiments show that our proposed approach <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> planar tracking methods at a large margin on the challenging POT, UCSB and POIC datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.07392.pdf'>2112.07392</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0246баллов, №574</br>
<b>Do You Think It\'s Biased? How To Ask For The Perception Of Media Bias</b></br>
Authors: , Spinde, Timo, Kreuter, Christina, Gaissmaier, Wolfgang, Hamborg, Felix, Gipp, Bela, Giese, Helge</br>
  Media coverage possesses a substantial effect on the public perception of events. The way media frames events can significantly alter the beliefs and perceptions of our society. Nevertheless, nearly all media outlets are known to report news in a biased way. While such bias can be introduced by altering the word choice or omitting information, the perception of bias also varies largely depending on a reader\'s personal background. Therefore, media bias is a very complex construct to identify and analyze. Even though media bias has been the subject of many studies, previous assessment strategies are oversimplified, lack overlap and empirical evaluation. Thus, this study aims to develop a scale that can be used as a reliable standard to evaluate article bias. To name an example: Intending to measure bias in a news article, should we ask, &quot;How biased is the article?&quot; or should we instead ask, &quot;How did the article treat the American president?&quot;. We conducted a literature search to find 824 relevant questions about text perception in previous research on the topic. In a multi-iterative process, we summarized and condensed these questions semantically to conclude a complete and representative set of possible question types about bias. The final set consisted of 25 questions with varying answering formats, 17 questions using semantic differentials, and six ratings of feelings. We tested each of the questions on 190 articles with overall 663 participants to identify how well the questions measure an article\'s perceived bias. Our results show that 21 final items are suitable and reliable for measuring the perception of media bias. We publish the final set of questions on <font color="#006400">http</font>://bias-question-tree.gipplab.org/. </br></br>

<a href='http://arxiv.org/pdf/2111.09100.pdf'>2111.09100</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.0239баллов, №575</br>
<b>The Unified Mathematical Framework for IMU Preintegration in\n  Inertial-Aided Navigation System</b></br>
Authors: , Luo, Yarong, Liu, Yang, Guo, Chi, Liu, Jingnan</br>
  This paper proposes a unified mathematical framework for inertial measurement unit (IMU) preintegration in inertial-aided navigation system in different frames under different motion condition. The navigation state is precisely discretized as three part: local increment, global state, and global increment. The global increment can be calculated in different frames such as local geodetic navigation frame and earth-centered-earth-fixed frame. The local increment which is referred as the IMU preintegration can be calculated under different assumptions according to the motion of the agent and the grade of the IMU. Thus, it more accurate and more convenient for online state estimation of inertial-integrated navigation system under different environment. </br></br>

<a href='http://arxiv.org/pdf/2112.08331.pdf'>2112.08331</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0232баллов, №576</br>
<b>Model Stealing Attacks Against Inductive Graph Neural Networks</b></br>
Authors: , Shen, Yun, He, Xinlei, Han, Yufei, Zhang, Yang</br>
  Many <font color="#009600">real-world</font> data come in the form of graphs. Graph neural networks (GNNs), a new family of machine learning (ML) models, have been proposed to fully leverage graph data to build powerful applications. In particular, the inductive GNNs, which can generalize to unseen data, become mainstream in this direction. Machine learning models have shown great potential in various tasks and have been deployed in many real-world scenarios. To train a good model, a large amount of data as well as computational resources are needed, leading to valuable intellectual property. Previous research has shown that ML models are prone to model stealing attacks, which aim to steal the functionality of the target models. However, most of them focus on the models trained with images and texts. On the other hand, little attention has been paid to models trained with graph data, i.e., GNNs. In this paper, we fill the gap by proposing the first model stealing attacks against inductive GNNs. We systematically define the threat model and propose six attacks based on the adversary\'s background knowledge and the responses of the target models. Our evaluation on six benchmark datasets shows that the proposed model stealing attacks against GNNs achieve promising performance. </br></br>

<a href='http://arxiv.org/pdf/2112.07254.pdf'>2112.07254</a> &nbsp&nbsp (cs:CL, cs:SD) &nbsp&nbsp 0.0226баллов, №577</br>
<b>Improving Hybrid CTC/Attention End-to-end <font color="#be00be">Speech Recognition</font> with\n  Pretrained Acoustic and Language Model</b></br>
Authors: , Deng, Keqi, Cao, Songjun, Zhang, Yike, Ma, Long</br>
  Recently, self-supervised pretraining has achieved impressive results in end-to-end (E2E) automatic <font color="#be00be">speech recognition</font> (ASR). However, the dominant sequence-to-sequence (S2S) E2E model is still hard to fully utilize the self-supervised pre-training methods because its decoder is conditioned on acoustic representation thus cannot be pretrained separately. In this paper, we propose a pretrained <font color="#00be00">Transformer</font> (Preformer) S2S ASR architecture based on hybrid CTC/attention E2E models to fully utilize the pretrained acoustic models (AMs) and language models (LMs). In our framework, the encoder is initialized with a pretrained AM (wav2vec2.0). The Preformer leverages CTC as an auxiliary task during training and inference. Furthermore, we design a one-cross decoder (OCD), which relaxes the dependence on acoustic representations so that it can be initialized with pretrained LM (DistilGPT2). Experiments are conducted on the AISHELL-1 corpus and achieve a $4.6\\%$ character error rate (CER) on the test set. Compared with our vanilla hybrid CTC/attention Transformer baseline, our proposed CTC/attention-based Preformer yields $27\\%$ relative CER reduction. To the best of our knowledge, this is the first work to utilize both pretrained AM and LM in a S2S ASR system. </br></br>

<a href='http://arxiv.org/pdf/2112.05707.pdf'>2112.05707</a> &nbsp&nbsp (cs:NE) &nbsp&nbsp 0.0220баллов, №578</br>
<b>Synchronous Unsupervised STDP Learning with Stochastic STT-MRAM\n  Switching</b></br>
Authors: , Zhou, Peng, Smith, Julie A., Deremo, Laura, Heinrich-Barna, Stephen K., Friedman, Joseph S.</br>
  The use of analog resistance states for storing weights in neuromorphic systems is impeded by fabrication imprecision and device stochasticity that limit the precision of synapse weights. This challenge can be resolved by emulating analog behavior with the stochastic switching of the binary states of spin-transfer torque magnetoresistive random-access memory (STT-MRAM). However, previous approaches based on STT-MRAM operate in an asynchronous manner that is difficult to implement experimentally. This paper proposes a synchronous spiking neural network system with clocked circuits that perform unsupervised learning leveraging the stochastic switching of STT-MRAM. The proposed system enables a single-layer network to achieve 90% inference accuracy on the MNIST dataset. </br></br>

<a href='http://arxiv.org/pdf/2112.09120.pdf'>2112.09120</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML, cs:RO) &nbsp&nbsp 0.0208баллов, №579</br>
<b>Human Hands as Probes for Interactive Object Understanding</b></br>
Authors: , Goyal, Mohit, Modi, Sahil, Goyal, Rishabh, Gupta, Saurabh</br>
  Interactive object understanding, or what we can do to objects and how is a long-standing goal of computer vision. In this paper, we tackle this problem through observation of human hands in in-the-wild egocentric videos. We demonstrate that observation of what human hands interact with and how can provide both the relevant data and the necessary supervision. Attending to hands, readily localizes and stabilizes active objects for learning and reveals places where interactions with objects occur. Analyzing the hands shows what we can do to objects and how. We apply these basic principles on the EPIC-KITCHENS dataset, and successfully learn state-sensitive features, and object affordances (regions of interaction and afforded grasps), purely by observing hands in egocentric videos. </br></br>

<a href='http://arxiv.org/pdf/2112.07772.pdf'>2112.07772</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0195баллов, №580</br>
<b>Do Answers to Boolean Questions Need Explanations? Yes</b></br>
Authors: , Rosenthal, Sara, Bornea, Mihaela, Sil, Avirup, Florian, Radu, McCarley, Scott</br>
  Existing datasets that contain boolean questions, such as BoolQ and TYDI QA , provide the user with a YES/NO response to the question. However, a one word response is not sufficient for an explainable system. We promote explainability by releasing a new set of annotations marking the evidence in existing TyDi QA and BoolQ datasets. We show that our annotations can be used to train a model that extracts improved evidence spans compared to models that rely on existing resources. We confirm our findings with a user study which shows that our extracted evidence spans enhance the user experience. We also provide further insight into the challenges of answering boolean questions, such as passages containing conflicting YES and NO answers, and varying degrees of relevance of the predicted evidence. </br></br>

<a href='http://arxiv.org/pdf/2112.06991.pdf'>2112.06991</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.0179баллов, №581</br>
<b>Biomorphic propulsion system diving thunniform robotic fish</b></br>
Authors: , Mitin, I. V., Korotaev, R. A., Ermolaev, A. A., Kazantsev, V. B.</br>
  A biomorphic propulsion systemfor underwater robotic fish is presented. The system is based on a combination of an elastic chord with a tail fin fixed on it. The tail fin is connected to servomotor by two symmetric movable thrusts simulating muscle contraction. The propulsion system provides oscillatory tail movement with controllable amplitude and frequency. Tail oscillations results in translational movement of the robotic fish implementing the thunniform principle of locomotion. The shape of the body of the robotic fish and the tail fin were designed using computational model simulating virtual body in an aquatic medium. A prototype of robotic fish device was constructed and tested in experimental conditions. Dependencies of fish velocity on the amplitude and frequency of tail oscillations were analyzed. </br></br>

<a href='http://arxiv.org/pdf/2112.08548.pdf'>2112.08548</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0179баллов, №582</br>
<b>Prosody-Aware Neural Machine Translation for Dubbing</b></br>
Authors: , Tam, Derek, Lakew, Surafel M., Virkar, Yogesh, Mathur, Prashant, Federico, Marcello</br>
  We introduce the task of prosody-aware machine translation which aims at generating translations suitable for dubbing. Dubbing of a spoken sentence requires transferring the content as well as the prosodic structure of the source into the target language to preserve timing information. Practically, this implies correctly projecting pauses from the source to the target and ensuring that target speech segments have roughly the same duration of the corresponding source segments. In this work, we propose an implicit and explicit modeling approaches to integrate prosody information into neural machine translation. Experiments on English-German/French with automatic metrics show that the simplest of the considered approaches works best. Results are confirmed by human evaluations of translations and dubbed videos. </br></br>

<a href='http://arxiv.org/pdf/2112.04294.pdf'>2112.04294</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.0178баллов, №583</br>
<b>A <font color="#00be00">Hierarchical</font> Spatio-Temporal Graph Convolutional Neural Network for\n  <font color="#be00be">Anomal</font>y Detection in Videos</b></br>
Authors: , Zeng, Xianlin, Jiang, Yalong, Ding, Wenrui, Li, Hongguang, Hao, Yafeng, Qiu, Zifeng</br>
  Deep learning models have been widely used for <font color="#be00be">anomal</font>y detection in <font color="#be00be">surveillance</font> videos. Typical models are equipped with the capability to reconstruct normal videos and evaluate the reconstruction errors on anomalous videos to indicate the extent of abnormalities. However, existing approaches suffer from two disadvantages. Firstly, they can only encode the movements of each identity independently, without considering the interactions among identities which may also indicate anomalies. Secondly, they leverage inflexible models whose structures are fixed under different scenes, this configuration disables the understanding of scenes. In this paper, we propose a <font color="#00be00">Hierarchical</font> Spatio-Temporal Graph Convolutional Neural Network (HSTGCNN) to address these problems, the HSTGCNN is composed of multiple branches that correspond to different levels of graph representations. High-level graph representations encode the trajectories of people and the interactions among multiple identities while low-level graph representations encode the local body postures of each person. Furthermore, we propose to weightedly combine multiple branches that are better at different scenes. An improvement over single-level graph representations is achieved in this way. An understanding of scenes is achieved and serves anomaly detection. High-level graph representations are assigned higher weights to encode moving speed and directions of people in low-resolution videos while low-level graph representations are assigned higher weights to encode human skeletons in high-resolution videos. Experimental results show that the proposed HSTGCNN significantly <font color="#00be00">outperform</font>s current <font color="#00be00">state-of-the-art</font> models on four benchmark datasets (UCSD <font color="#be00be">Pedestrian</font>, ShanghaiTech, CUHK Avenue and IITB-Corridor) by using much less learnable parameters. </br></br>

<a href='http://arxiv.org/pdf/2112.05438.pdf'>2112.05438</a> &nbsp&nbsp (cs:AI, cs:CL, cs:ML) &nbsp&nbsp 0.0146баллов, №584</br>
<b>DEBACER: a method for slicing moderated debates</b></br>
Authors: , Ferraz, Thomas Palmeira, Alcoforado, Alexandre, Bustos, Enzo, Oliveira, Andr&#xe9; Seidel, Gerber, Rodrigo, M&#xfc;ller, Na&#xed;de, d\'Almeida, Andr&#xe9; Corr&#xea;a, Veloso, Bruno Miguel, Costa, Anna Helena Reali</br>
  Subjects change frequently in moderated debates with several participants, such as in parliamentary sessions, electoral debates, and trials. Partitioning a debate into blocks with the same subject is essential for understanding. Often a moderator is responsible for defining when a new block begins so that the task of automatically partitioning a moderated debate can focus solely on the moderator\'s behavior. In this paper, we (i) propose a new algorithm, DEBACER, which partitions moderated debates; (ii) carry out a comparative study between conventional and BERTimbau pipelines; and (iii) validate DEBACER applying it to the minutes of the Assembly of the Republic of Portugal. Our results show the effectiveness of DEBACER. Keywords: Natural Language Processing, Political Documents, Spoken Text Processing, Speech Split, Dialogue Partitioning. </br></br>

<a href='http://arxiv.org/pdf/2112.06730.pdf'>2112.06730</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.0146баллов, №585</br>
<b>VirtualCube: An Immersive 3D Video Communication System</b></br>
Authors: , Zhang, Yizhong, Yang, Jiaolong, Liu, Zhen, Wang, Ruicheng, Chen, Guojun, Tong, Xin, Guo, Baining</br>
  The VirtualCube system is a 3D video conference system that attempts to overcome some limitations of conventional technologies. The key ingredient is VirtualCube, an abstract representation of a <font color="#009600">real-world</font> cubicle instrumented with RGBD cameras for capturing the 3D geometry and texture of a user. We design VirtualCube so that the task of data capturing is standardized and significantly simplified, and everything can be built using off-the-shelf hardware. We use VirtualCubes as the basic building blocks of a virtual conferencing environment, and we provide each VirtualCube user with a surrounding display showing life-size videos of remote participants. To achieve real-time rendering of remote participants, we develop the V-Cube View algorithm, which uses multi-view stereo for more accurate depth estimation and Lumi-Net rendering for better rendering quality. The VirtualCube system correctly preserves the mutual eye gaze between participants, allowing them to establish eye contact and be aware of who is visually paying attention to them. The system also allows a participant to have side discussions with remote participants as if they were in the same room. Finally, the system sheds lights on how to support the shared space of work items (e.g., documents and applications) and track the visual attention of participants to work items. </br></br>

<a href='http://arxiv.org/pdf/2112.05434.pdf'>2112.05434</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp 0.0142баллов, №586</br>
<b>A <font color="#00be00">Reinforcement Learning</font>-based Adaptive Control Model for Future Street\n  Planning, An Algorithm and A Case Study</b></br>
Authors: , Ye, Qiming, Feng, Yuxiang, Han, Jing, Stettler, Marc, Angeloudis, Panagiotis</br>
  With the emerging technologies in Intelligent Transportation System (ITS), the adaptive operation of road space is likely to be realised within decades. An intelligent street can learn and improve its decision-making on the right-of-way (ROW) for road users, liberating more active <font color="#be00be">pedestrian</font> space while maintaining traffic safety and efficiency. However, there is a lack of effective controlling techniques for these adaptive street infrastructures. To fill this gap in existing studies, we formulate this control problem as a Markov Game and develop a solution based on the multi-agent Deep Deterministic Policy Gradient (MADDPG) algorithm. The proposed model can dynamically assign ROW for sidewalks, autonomous vehicles (AVs) driving lanes and on-street parking areas in real-time. Integrated with the SUMO traffic simulator, this model was evaluated using the road network of the South Kensington District against three cases of divergent traffic conditions: pedestrian flow rates, AVs traffic flow rates and parking demands. Results reveal that our model can achieve an average reduction of 3.87% and 6.26% in street space assigned for on-street parking and vehicular operations. Combined with space gained by limiting the number of driving lanes, the average proportion of sidewalks to total widths of streets can significantly increase by 10.13%. </br></br>

<a href='http://arxiv.org/pdf/2112.06435.pdf'>2112.06435</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.0135баллов, №587</br>
<b><font color="#960096">Competitive</font> Car Racing with Multiple Vehicles using a Parallelized\n  Optimization with Safety Guarantee</b></br>
Authors: , He, Suiyi, Zeng, Jun, Sreenath, Koushil</br>
  This paper presents a novel planning and control strategy for competing with multiple vehicles in a car racing scenario. The proposed racing strategy switches between two modes. When there are no surrounding vehicles, a learning-based model predictive control (MPC) trajectory planner is used to guarantee that the ego vehicle achieves better lap timing. When the ego vehicle is competing with other surrounding vehicles to overtake, an optimization-based planner generates multiple dynamically-feasible trajectories through parallel computation. Each trajectory is optimized under a MPC formulation with different homotopic Bezier-curve reference paths lying laterally between surrounding vehicles. The time-optimal trajectory among these different homotopic trajectories is selected and a low-level MPC controller with obstacle avoidance constraints is used to guarantee system safety-critical performance. The proposed algorithm has the capability to generate collision-free trajectories and track them while enhancing the lap timing performance with steady low computational complexity, <font color="#00be00">outperform</font>ing existing approaches in both timing and performance for a car racing environment. To demonstrate the performance of our racing strategy, we simulate with multiple randomly generated moving vehicles on the track and test the ego vehicle\'s overtake maneuvers. </br></br>

<a href='http://arxiv.org/pdf/2112.08256.pdf'>2112.08256</a> &nbsp&nbsp (cs:AI, cs:CL) &nbsp&nbsp 0.0134баллов, №588</br>
<b>Est-ce que vous compute? Code-switching, cultural identity, and AI</b></br>
Authors: , Falbo, Arianna, LaCroix, Travis</br>
  Cultural code-switching concerns how we adjust our overall behaviours, manners of speaking, and appearance in response to a perceived change in our social environment. We defend the need to investigate cultural code-switching capacities in artificial intelligence systems. We explore a series of ethical and epistemic issues that arise when bringing cultural code-switching to bear on artificial intelligence. Building upon Dotson\'s (2014) analysis of testimonial smothering, we discuss how emerging technologies in AI can give rise to epistemic oppression, and specifically, a form of self-silencing that we call \'cultural smothering\'. By leaving the socio-dynamic features of cultural code-switching unaddressed, AI systems risk negatively impacting already-marginalised social groups by widening opportunity gaps and further entrenching social inequalities. </br></br>

<a href='http://arxiv.org/pdf/2112.06594.pdf'>2112.06594</a> &nbsp&nbsp (cs:RO, cs:AI) &nbsp&nbsp 0.0132баллов, №589</br>
<b>Multi-agent Soft Actor-Critic Based Hybrid Motion Planner for Mobile\n  Robots</b></br>
Authors: , He, Zichen, Dong, Lu, Song, Chunwei, Sun, Changyin</br>
  In this paper, a novel hybrid multi-robot motion planner that can be applied under non-communication and local observable conditions is presented. The planner is model-free and can realize the end-to-end mapping of multi-robot state and observation information to final smooth and continuous trajectories. The planner is a front-end and back-end separated architecture. The design of the front-end collaborative waypoints searching module is based on the multi-agent soft actor-critic algorithm under the centralized training with decentralized execution diagram. The design of the back-end trajectory optimization module is based on the minimal snap method with safety zone constraints. This module can output the final dynamic-feasible and executable trajectories. Finally, multi-group experimental results verify the effectiveness of the proposed motion planner. </br></br>

<a href='http://arxiv.org/pdf/2112.08588.pdf'>2112.08588</a> &nbsp&nbsp (cs:NE, cs:AI) &nbsp&nbsp 0.0128баллов, №590</br>
<b>Learning to acquire novel cognitive tasks with evolution, plasticity and\n  meta-meta-learning</b></br>
Authors: , Miconi, Thomas</br>
  In meta-learning, networks are trained with external algorithms to learn tasks that require acquiring, storing and exploiting unpredictable information for each new instance of the task. However, animals are able to pick up such cognitive tasks automatically, as a result of their evolved neural architecture and synaptic plasticity mechanisms. Here we evolve neural networks, endowed with plastic connections, over a sizable set of simple meta-learning tasks based on a neuroscience modelling framework. The resulting evolved network can automatically acquire a novel simple cognitive task, never seen during training, through the spontaneous operation of its evolved neural organization and plasticity structure. We suggest that attending to the multiplicity of loops involved in natural learning may provide useful insight into the emergence of intelligent behavior. </br></br>

<a href='http://arxiv.org/pdf/2111.12783.pdf'>2111.12783</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0116баллов, №591</br>
<b>For the Purpose of Curry: A UD Treebank for Ashokan Prakrit</b></br>
Authors: , Farris, Adam, Arora, Aryaman</br>
  We present the first linguistically annotated treebank of Ashokan Prakrit, an early Middle Indo-Aryan dialect continuum attested through Emperor Ashoka Maurya\'s 3rd century BCE rock and pillar edicts. For annotation, we used the multilingual Universal Dependencies (UD) formalism, following recent UD work on Sanskrit and other Indo-Aryan languages. We touch on some interesting linguistic features that posed issues in annotation: regnal names and other nominal compounds, &quot;proto-ergative&quot; participial constructions, and possible grammaticalizations evidenced by sandhi (phonological assimilation across morpheme boundaries). Eventually, we plan for a complete annotation of all attested Ashokan texts, towards the larger goals of improving UD coverage of different diachronic stages of Indo-Aryan and studying language change in Indo-Aryan using computational methods. </br></br>

<a href='http://arxiv.org/pdf/2112.05452.pdf'>2112.05452</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0111баллов, №592</br>
<b>Improving the Question Answering Quality using Answer Candidate\n  Filtering based on Natural-Language Features</b></br>
Authors: , Gashkov, Aleksandr, Perevalov, Aleksandr, Eltsova, Maria, Both, Andreas</br>
  Software with natural-language user interfaces has an ever-increasing importance. However, the quality of the included Question Answering (QA) functionality is still not sufficient regarding the number of questions that are answered correctly. In our work, we address the research problem of how the QA quality of a given system can be improved just by evaluating the natural-language input (i.e., the user\'s question) and output (i.e., the system\'s answer). Our main contribution is an approach capable of identifying wrong answers provided by a QA system. Hence, filtering incorrect answers from a list of answer candidates is leading to a highly improved QA quality. In particular, our approach has shown its potential while removing in many cases the majority of incorrect answers, which increases the QA quality significantly in comparison to the non-filtered output of a system. </br></br>

<a href='http://arxiv.org/pdf/2111.00199.pdf'>2111.00199</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp 0.0105баллов, №593</br>
<b>Personal thermal comfort models using digital twins: Preference\n  prediction with BIM-extracted spatial-temporal proximity data from Build2Vec</b></br>
Authors: , Abdelrahman, Mahmoud, Chong, Adrian, Miller, Clayton</br>
  Conventional thermal preference prediction in buildings has limitations due to the difficulty in capturing all environmental and personal factors. New model features can improve the ability of a machine learning model to classify a person\'s thermal preference. The spatial context of a building can provide information to models about the windows, walls, heating and cooling sources, air diffusers, and other factors that create micro-environments that influence thermal comfort. Due to spatial heterogeneity, it is impractical to position sensors at a high enough resolution to capture all conditions. This research aims to build upon an existing vector-based spatial model, called Build2Vec, for predicting spatial-temporal occupants\' indoor environmental preferences. Build2Vec utilizes the spatial data from the Building Information Model (BIM) and indoor localization in a <font color="#009600">real-world</font> setting. This framework uses longitudinal intensive thermal comfort subjective feedback from smart watch-based ecological momentary assessments (EMA). The aggregation of these data is combined into a graph network structure (i.e., objects and relations) and used as input for a classification model to predict occupant thermal preference. The results of a test implementation show 14-28% accuracy improvement over a set of baselines that use conventional thermal preference prediction input variables. </br></br>

<a href='http://arxiv.org/pdf/2112.07812.pdf'>2112.07812</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp 0.0099баллов, №594</br>
<b>Image <font color="#be00be">Segmentation</font> with Homotopy Warping</b></br>
Authors: , Hu, Xiaoling, Chen, Chao</br>
  Besides per-pixel accuracy, topological correctness is also crucial for the <font color="#be00be">segmentation</font> of images with fine-scale structures, e.g., satellite images and bio<font color="#640064">medic</font>al images. In this paper, by leveraging the <font color="#be00be">theor</font>y of digital topology, we identify locations in an image that are critical for topology. By focusing on these critical locations, we propose a new homotopy warping loss to train deep image segmentation networks for better topological accuracy. To efficiently identity these topologically critical locations, we propose a new algorithm exploiting the distance transform. The proposed algorithm, as well as the loss function, naturally generalize to different topological structures in both 2D and 3D settings. The proposed loss function helps deep nets achieve better performance in terms of topology-aware metrics, <font color="#00be00">outperform</font>ing <font color="#00be00">state-of-the-art</font> topology-preserving segmentation methods. </br></br>

<a href='http://arxiv.org/pdf/2112.07663.pdf'>2112.07663</a> &nbsp&nbsp (cs:RO, cs:ML) &nbsp&nbsp 0.0098баллов, №595</br>
<b>Learning Connectivity-Maximizing Network Configurations</b></br>
Authors: , Mox, Daniel, Kumar, Vijay, Ribeiro, Alejandro</br>
  In this work we propose a data-driven approach to optimizing the algebraic connectivity of a team of robots. While a considerable amount of research has been devoted to this problem, we lack a method that scales in a manner suitable for online applications for more than a handful of agents. To that end, we propose a supervised learning approach with a convolutional neural network (CNN) that learns to place communication agents from an expert that uses an optimization-based strategy. We demonstrate the performance of our CNN on canonical line and ring topologies, 105k randomly generated test cases, and larger teams not seen during training. We also show how our system can be applied to dynamic robot teams through a Unity-based simulation. After training, our system produces connected configurations 2 orders of magnitude faster than the optimization-based scheme for teams of 10-20 agents. </br></br>

<a href='http://arxiv.org/pdf/2112.08445.pdf'>2112.08445</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.0094баллов, №596</br>
<b>Safety-Critical Control with Input Delay in Dynamic Environment</b></br>
Authors: , Molnar, Tamas G., Kiss, Adam K., Ames, Aaron D., Orosz, G&#xe1;bor</br>
  Endowing nonlinear systems with safe behavior is increasingly important in modern control. This task is particularly challenging for real-life control systems that must operate safely in dynamically changing environments. This paper develops a framework for safety-critical control in dynamic environments, by establishing the notion of environmental control barrier functions (ECBFs). The framework is able to guarantee safety even in the presence of input delay, by accounting for the evolution of the environment during the delayed response of the system. The underlying control synthesis relies on predicting the future state of the system and the environment over the delay interval, with robust safety guarantees against prediction errors. The efficacy of the proposed method is demonstrated by a simple adaptive cruise control problem and a more complex robotics application on a Segway platform. </br></br>

<a href='http://arxiv.org/pdf/2112.07605.pdf'>2112.07605</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp 0.0093баллов, №597</br>
<b>The King is Naked: on the Notion of Robustness for Natural Language\n  Processing</b></br>
Authors: , La Malfa, Emanuele, Kwiatkowska, Marta</br>
  There is growing evidence that the classical notion of adversarial robustness originally introduced for images has been adopted as a de facto standard by a large part of the NLP research community. We show that this notion is problematic in the context of NLP as it considers a narrow spectrum of linguistic phenomena. In this paper, we argue for semantic robustness, which is better aligned with the human concept of linguistic fidelity. We characterize semantic robustness in terms of biases that it is expected to induce in a model. We study semantic robustness of a range of vanilla and robustly trained architectures using a template-based generative test bed. We complement the analysis with empirical evidence that, despite being harder to implement, semantic robustness can improve performance %gives guarantees for on complex linguistic phenomena where models robust in the classical sense fail. </br></br>

<a href='http://arxiv.org/pdf/2112.07566.pdf'>2112.07566</a> &nbsp&nbsp (cs:CL, cs:CV) &nbsp&nbsp 0.0077баллов, №598</br>
<b>VALSE: A Task-Independent Benchmark for Vision and Language Models\n  Centered on Linguistic Phenomena</b></br>
Authors: , Parcalabescu, Letitia, Cafagna, Michele, Muradjan, Lilitta, Frank, Anette, Calixto, Iacer, Gatt, Albert</br>
  We propose VALSE (Vision And Language Structured Evaluation), a novel benchmark designed for testing general-purpose pretrained vision and language (V&amp;L) models for their visio-linguistic grounding capabilities on specific linguistic phenomena. VALSE offers a suite of six tests covering various linguistic constructs. Solving these requires models to ground linguistic phenomena in the visual modality, allowing more fine-grained evaluations than hitherto possible. We build VALSE using methods that support the construction of valid foils, and report results from evaluating five widely-used V&amp;L models. Our experiments suggest that current models have considerable difficulty addressing most phenomena. Hence, we expect VALSE to serve as an important benchmark to measure future progress of pretrained V&amp;L models from a linguistic perspective, complementing the canonical task-centred V&amp;L evaluations. </br></br>

<a href='http://arxiv.org/pdf/2112.08516.pdf'>2112.08516</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp 0.0053баллов, №599</br>
<b>Safety-Aware Preference-Based Learning for Safety-Critical Control</b></br>
Authors: , Cosner, Ryan K., Tucker, Maegan, Taylor, Andrew J., Li, Kejun, Moln&#xe1;r, Tam&#xe1;s G., Ubellacker, Wyatt, Alan, Anil, Orosz, G&#xe1;bor, Yue, Yisong, Ames, Aaron D.</br>
  Bringing dynamic robots into the wild requires a tenuous balance between performance and safety. Yet controllers designed to provide robust safety guarantees often result in conservative behavior, and tuning these controllers to find the ideal trade-off between performance and safety typically requires domain expertise or a carefully constructed reward function. This work presents a design paradigm for systematically achieving behaviors that balance performance and robust safety by integrating safety-aware Preference-Based Learning (PBL) with Control Barrier Functions (CBFs). Fusing these concepts -- safety-aware learning and safety-critical control -- gives a robust means to achieve safe behaviors on complex robotic systems in practice. We demonstrate the capability of this design paradigm to achieve safe and performant perception-based autonomous operation of a quadrupedal robot both in simulation and experimentally on hardware. </br></br>

<a href='http://arxiv.org/pdf/2111.15318.pdf'>2111.15318</a> &nbsp&nbsp (cs:CV, cs:ML, cs:RO) &nbsp&nbsp 0.0052баллов, №600</br>
<b>DiffSDFSim: Differentiable Rigid-Body Dynamics With Implicit Shapes</b></br>
Authors: , Strecke, Michael, Stueckler, Joerg</br>
  Differentiable physics is a powerful tool in computer vision and robotics for scene understanding and reasoning about interactions. Existing approaches have frequently been limited to objects with simple shape or shapes that are known in advance. In this paper, we propose a novel approach to differentiable physics with frictional contacts which represents object shapes implicitly using signed distance fields (SDFs). Our simulation supports contact point calculation even when the involved shapes are nonconvex. Moreover, we propose ways for differentiating the dynamics for the object shape to facilitate shape optimization using gradient-based methods. In our experiments, we demonstrate that our approach allows for model-based inference of physical parameters such as friction coefficients, mass, forces or shape parameters from trajectory and depth image observations in several challenging synthetic scenarios and a real image sequence. </br></br>

<a href='http://arxiv.org/pdf/2112.08550.pdf'>2112.08550</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0046баллов, №601</br>
<b>Neural Content Extraction for Poster Generation of Scientific Papers</b></br>
Authors: , Xu, Sheng, Wan, Xiaojun</br>
  The problem of poster generation for scientific papers is under-investigated. Posters often present the most important information of papers, and the task can be considered as a special form of document <font color="#be00be">summarization</font>. Previous studies focus mainly on poster layout and panel composition, while neglecting the importance of content extraction. Besides, their datasets are not <font color="#00be00">publicly available</font>, which hinders further research. In this paper, we construct a benchmark dataset from scratch for this task. Then we propose a three-step framework to tackle this task and focus on the content extraction step in this study. To get both textual and visual elements of a poster panel, a neural extractive model is proposed to extract text, figures and tables of a paper section simultaneously. We conduct experiments on the dataset and also perform ablation study. Results demonstrate the efficacy of our proposed model. The dataset and code will be released. </br></br>

<a href='http://arxiv.org/pdf/2112.05657.pdf'>2112.05657</a> &nbsp&nbsp (cs:AI, cs:CV, cs:ML, cs:NE) &nbsp&nbsp 0.0039баллов, №602</br>
<b>Artificial Intellgence -- Application in Life Sciences and Beyond. The\n  Upper Rhine Artificial Intelligence Symposium UR-AI 2021</b></br>
Authors: , Sch&#xe4;fer, Karl-Herbert, Quint, Franz</br>
  The TriRhenaTech alliance presents the accepted papers of the \'Upper-Rhine Artificial Intelligence Symposium\' held on October 27th 2021 in Kaiserslautern, Germany. Topics of the conference are applications of Artificial Intellgence in life sciences, intelligent systems, industry 4.0, mobility and others. The TriRhenaTech alliance is a network of universities in the Upper-Rhine Trinational Metropolitan Region comprising of the German universities of applied sciences in Furtwangen, Kaiserslautern, Karlsruhe, Offenburg and Trier, the Baden-Wuerttemberg Cooperative State University Loerrach, the French university network Alsace Tech (comprised of 14 \'grandes \\\'ecoles\' in the fields of engineering, architecture and management) and the University of Applied Sciences and Arts Northwestern Switzerland. The alliance\'s common goal is to reinforce the transfer of knowledge, research, and technology, as well as the cross-border mobility of students. </br></br>

<a href='http://arxiv.org/pdf/2112.01488.pdf'>2112.01488</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp 0.0038баллов, №603</br>
<b>ColBERTv2: Effective and Efficient <font color="#be00be">Retrieval</font> via <font color="#be00be">Lightweight</font> Late\n  Interaction</b></br>
Authors: , Santhanam, Keshav, Khattab, Omar, Saad-Falcon, Jon, Potts, Christopher, Zaharia, Matei</br>
  Neural information <font color="#be00be">retrieval</font> (IR) has greatly advanced search and other knowledge-intensive language tasks. While many neural IR methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. This decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude. In this work, we introduce ColBERTv2, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction. We evaluate ColBERTv2 across a wide range of benchmarks, establishing <font color="#00be00">state-of-the-art</font> quality within and outside the training domain while reducing the space footprint of late interaction models by 5--8$\\times$. </br></br>

<a href='http://arxiv.org/pdf/2112.07421.pdf'>2112.07421</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.0010баллов, №604</br>
<b>Towards A Reliable Ground-Truth For Biased Language Detection</b></br>
Authors: , Spinde, Timo, Krieger, David, Plank, Manuel, Gipp, Bela</br>
  Reference texts such as encyclopedias and news articles can manifest biased language when objective reporting is substituted by subjective writing. Existing methods to detect bias mostly rely on annotated data to train machine learning models. However, low annotator agreement and comparability is a substantial drawback in available media bias corpora. To evaluate data collection options, we collect and compare labels obtained from two popular crowdsourcing platforms. Our results demonstrate the existing crowdsourcing approaches\' lack of data quality, underlining the need for a trained expert framework to gather a more reliable dataset. By creating such a framework and gathering a first dataset, we are able to improve Krippendorff\'s $\\alpha$ = 0.144 (crowdsourcing labels) to $\\alpha$ = 0.419 (expert labels). We conclude that detailed annotator training increases data quality, improving the performance of existing bias detection systems. We will continue to extend our dataset in the future. </br></br>

<a href='http://arxiv.org/pdf/2111.08788.pdf'>2111.08788</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.0014баллов, №605</br>
<b>Facilitating reflection in teletandem through automatically generated\n  conversation metrics and playback video</b></br>
Authors: , Dey-Plissonneau, Aparajita, Lee, Hyowon, Scriney, Michael, Smeaton, Alan F., Pradier, Vincent, Riaz, Hamza</br>
  This pilot study focuses on a tool called L2L that allows second language (L2) learners to visualise and analyse their Zoom interactions with native speakers. L2L uses the Zoom transcript to automatically generate conversation metrics and its playback feature with timestamps allows students to replay any chosen portion of the conversation for post-session reflection and self-review. This exploratory study investigates a seven-week teletandem project, where undergraduate students from an Irish University learning French (B2) interacted with their peers from a French University learning English (B2+) via Zoom. The data collected from a survey (N=43) and semi-structured interviews (N=35) show that the quantitative conversation metrics and qualitative review of the synchronous content helped raise students\' confidence levels while engaging with native speakers. Furthermore, it allowed them to set tangible goals to improve their participation, and be more aware of what, why and how they are learning. </br></br>

<a href='http://arxiv.org/pdf/2112.08772.pdf'>2112.08772</a> &nbsp&nbsp (cs:ML, cs:CL) &nbsp&nbsp -0.0026баллов, №606</br>
<b>{\\delta}-SAM: Sharpness-Aware Minimization with Dynamic Reweighting</b></br>
Authors: , Zhou, Wenxuan, Chen, Muhao</br>
  Deep neural networks are often overparameterized and may not easily achieve model generalization. Adversarial training has shown effectiveness in improving generalization by regularizing the change of loss on top of adversarially chosen perturbations. The recently proposed sharpness-aware minimization (SAM) algorithm adopts adversarial weight perturbation, encouraging the model to converging to a flat minima. Unfortunately, due to increased computational cost, adversarial weight perturbation can only be efficiently approximated per-batch instead of per-instance, leading to degraded performance. In this paper, we propose that dynamically reweighted perturbation within each batch, where unguarded instances are up-weighted, can serve as a better approximation to per-instance perturbation. We propose sharpness-aware minimization with dynamic reweighting ({\\delta}-SAM), which realizes the idea with efficient guardedness estimation. Experiments on the GLUE benchmark demonstrate the effectiveness of {\\delta}-SAM. </br></br>

<a href='http://arxiv.org/pdf/2112.08597.pdf'>2112.08597</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0039баллов, №607</br>
<b>Reprogrammable Surfaces Through Star Graph Metamaterials</b></br>
Authors: , Thomas, Sawyer, Lipton, Jeffrey</br>
  The ability to change a surface\'s profile allows biological systems to effectively manipulate and blend into their surroundings. Current surface morphing techniques rely either on having a small number of fixed states or on directly driving the entire system. We discovered a subset of scale-independent auxetic metamaterials have a state trajectory with a star-graph structure. At the central node, small nudges can move the material between trajectories, allowing us to locally shift Poisson\'s ratio, causing the material to take on different shapes under loading. While the number of possible shapes grows exponentially with the size of the material, the probability of finding one at random is vanishingly small. By actively guiding the material through the node points, we produce a reprogrammable surface that does not require inputs to maintain shape and can display arbitrary 2D information and take on complex 3D shapes. Our work opens new opportunities in micro devices, tactile displays, manufacturing, and robotic systems. </br></br>

<a href='http://arxiv.org/pdf/2112.06409.pdf'>2112.06409</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0046баллов, №608</br>
<b>Data Collection and Quality Challenges in Deep Learning: A Data-Centric\n  AI Perspective</b></br>
Authors: , Whang, Steven Euijong, Roh, Yuji, Song, Hwanjun, Lee, Jae-Gil</br>
  Software 2.0 is a fundamental shift in software engineering where machine learning becomes the new software, powered by big data and computing infrastructure. As a result, software engineering needs to be re-thought where data becomes a first-class citizen on par with code. One striking observation is that 80-90% of the machine learning process is spent on data preparation. Without good data, even the best machine learning algorithms cannot perform well. As a result, data-centric AI practices are now becoming mainstream. Unfortunately, many datasets in the <font color="#009600">real world</font> are small, dirty, biased, and even poisoned. In this survey, we study the research landscape for data collection and data quality primarily for deep learning applications. Data collection is important because there is lesser need for feature engineering for recent deep learning approaches, but instead more need for large amounts of data. For data quality, we study data validation and data cleaning techniques. Even if the data cannot be fully cleaned, we can still cope with imperfect data during model training where using robust model training techniques. In addition, while bias and fairness have been less studied in traditional data management research, these issues become essential topics in modern machine learning applications. We thus study fairness measures and unfairness mitigation techniques that can be applied before, during, or after model training. We believe that the data management community is well poised to solve problems in these directions. </br></br>

<a href='http://arxiv.org/pdf/2112.07586.pdf'>2112.07586</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0056баллов, №609</br>
<b>Real-time SIL Emulation Architecture for Cooperative Automated Vehicles</b></br>
Authors: , Gupta, Nitish</br>
  The development of safety applications for Connected Automated Vehicles requires testing in many different scenarios. However, the recreation of test scenarios for evaluating safety applications is a very challenging task. This is mainly due to the randomness in communication, difficulty in recreating vehicle movements precisely, and safety concerns for certain scenarios. We propose to develop a standalone Remote Vehicle Emulator that can reproduce V2V messages of remote vehicles from simulations or previous tests. This is expected to accelerate the development cycle significantly. Remote Vehicle Emulator is a unique and easily configurable emulation cum simulation setup to allow Software in the Loop (SIL) testing of connected vehicle applications realistically and safely. It will help in tailoring numerous test scenarios, expediting algorithm development and validation, and increasing the probability of finding failure modes. This, in turn, will help improve the quality of safety applications while saving testing time and reducing cost. </br></br>

<a href='http://arxiv.org/pdf/2112.07475.pdf'>2112.07475</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.0072баллов, №610</br>
<b>Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks</b></br>
Authors: , R&#xf6;ttger, Paul, Vidgen, Bertie, Hovy, Dirk, Pierrehumbert, Janet B.</br>
  Labelled data is the foundation of most natural language processing tasks. However, labelling data is difficult and there often are diverse valid beliefs about what the correct data labels should be. So far, dataset creators have acknowledged annotator subjectivity, but not actively managed it in the annotation process. This has led to partly-subjective datasets that fail to serve a clear downstream use. To address this issue, we propose two contrasting paradigms for data annotation. The descriptive paradigm encourages annotator subjectivity, whereas the prescriptive paradigm discourages it. Descriptive annotation allows for the surveying and modelling of different beliefs, whereas prescriptive annotation enables the training of models that consistently apply one belief. We discuss benefits and challenges in implementing both paradigms, and argue that dataset creators should explicitly aim for one or the other to facilitate the intended use of their dataset. Lastly, we design an annotation experiment to illustrate the contrast between the two paradigms. </br></br>

<a href='http://arxiv.org/pdf/2112.07327.pdf'>2112.07327</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.0080баллов, №611</br>
<b>Model Uncertainty-Aware Knowledge Amalgamation for Pre-Trained Language\n  Models</b></br>
Authors: , Li, Lei, Lin, Yankai, Ren, Xuancheng, Zhao, Guangxiang, Li, Peng, Zhou, Jie, Sun, Xu</br>
  As many fine-tuned pre-trained language models~(PLMs) with promising performance are generously released, investigating better ways to reuse these models is vital as it can greatly reduce the retraining computational cost and the potential environmental side-effects. In this paper, we explore a novel model reuse paradigm, Knowledge Amalgamation~(KA) for PLMs. Without human annotations available, KA aims to merge the knowledge from different teacher-PLMs, each of which specializes in a different classification problem, into a versatile student model. The achieve this, we design a Model Uncertainty--aware Knowledge Amalgamation~(MUKA) framework, which identifies the potential adequate teacher using Monte-Carlo Dropout for approximating the golden supervision to guide the student. Experimental results demonstrate that MUKA achieves substantial improvements over baselines on benchmark datasets. Further analysis shows that MUKA can generalize well under several complicate settings with multiple teacher models, heterogeneous teachers, and even cross-dataset teachers. </br></br>

<a href='http://arxiv.org/pdf/2112.05555.pdf'>2112.05555</a> &nbsp&nbsp (cs:CL, cs:SD) &nbsp&nbsp -0.0085баллов, №612</br>
<b>Shennong: a Python toolbox for audio speech features extraction</b></br>
Authors: , Bernard, Mathieu, Poli, Maxime, Karadayi, Julien, Dupoux, Emmanuel</br>
  We introduce Shennong, a Python toolbox and command-line utility for speech features extraction. It implements a wide range of well-established state of art algorithms including spectro-temporal filters such as Mel-Frequency Cepstral Filterbanks or Predictive Linear Filters, pre-trained neural networks, pitch estimators as well as speaker normalization methods and post-processing algorithms. Shennong is an open source, easy-to-use, reliable and extensible framework. The use of Python makes the integration to others speech modeling and machine learning tools easy. It aims to replace or complement several heterogeneous software, such as Kaldi or Praat. After describing the Shennong software architecture, its core components and implemented algorithms, this paper illustrates its use on three applications: a comparison of speech features performances on a phones discrimination task, an analysis of a Vocal Tract Length Normalization model as a function of the speech duration used for training and a comparison of pitch estimation algorithms under various noise conditions. </br></br>

<a href='http://arxiv.org/pdf/2112.07447.pdf'>2112.07447</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.0085баллов, №613</br>
<b>Measuring Fairness with Biased Rulers: A Survey on Quantifying Biases in\n  Pretrained Language Models</b></br>
Authors: , Delobelle, Pieter, Tokpo, Ewoenam Kwaku, Calders, Toon, Berendt, Bettina</br>
  An increasing awareness of biased patterns in natural language processing resources, like BERT, has motivated many metrics to quantify `bias\' and `fairness\'. But comparing the results of different metrics and the works that evaluate with such metrics remains difficult, if not outright impossible. We survey the existing literature on fairness metrics for pretrained language models and experimentally evaluate compatibility, including both biases in language models as in their downstream tasks. We do this by a mixture of traditional literature survey and correlation analysis, as well as by running empirical evaluations. We find that many metrics are not compatible and highly depend on (i) templates, (ii) attribute and target seeds and (iii) the choice of embeddings. These results indicate that fairness or bias evaluation remains challenging for contextualized language models, if not at least highly subjective. To improve future comparisons and fairness evaluations, we recommend avoiding embedding-based metrics and focusing on fairness evaluations in downstream tasks. </br></br>

<a href='http://arxiv.org/pdf/2111.00107.pdf'>2111.00107</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.0095баллов, №614</br>
<b>The Golden Rule as a Heuristic to Measure the Fairness of Texts Using\n  Machine Learning</b></br>
Authors: , Izzidien, Ahmed, Stillwell, David</br>
  To treat others as one would wish to be treated is a common formulation of the golden rule (GR). Yet, despite its prevalence as an axiom throughout history, no transfer of this moral philosophy into computational systems exists. In this paper we consider how to algorithmically operationalise this rule so that it may be used to measure sentences such as the boy harmed the girl, and categorise them as fair or unfair. For the purposes of the paper, we define a fair act as one that one would be accepting of if it were done to oneself. A review and reply to criticisms of the GR is made. We share the code for the digitisation of the GR, and test it with a list of sentences. Implementing it within two language models, the USE, and ALBERT, we find F1 scores of 78.0, 85.0, respectively. A suggestion of how the technology may be implemented to avoid unfair biases in word embeddings is made - given that individuals would typically not wish to be on the receiving end of an unfair act, such as racism, irrespective of whether the corpus being used deems such discrimination as praiseworthy. </br></br>

<a href='http://arxiv.org/pdf/2111.00086.pdf'>2111.00086</a> &nbsp&nbsp (cs:AI, cs:CL) &nbsp&nbsp -0.0097баллов, №615</br>
<b>Measuring a Texts Fairness Dimensions Using Machine Learning Based on\n  Social Psychological Factors</b></br>
Authors: , Izzidien, Ahmed, Stillwell, David</br>
  Fairness is a principal social value that can be observed in civilisations around the world. A manifestation of this is in social agreements, often described in texts, such as contracts. Yet, despite the prevalence of such, a fairness metric for texts describing a social act remains wanting. To address this, we take a step back to consider the problem based on first principals. Instead of using rules or templates, we utilise social psychology literature to determine the principal factors that humans use when making a fairness assessment. We then attempt to digitise these using word embeddings into a multi-dimensioned sentence level fairness perceptions vector to serve as an approximation for these fairness perceptions. The method leverages a pro-social bias within word embeddings, for which we obtain an F1= 81.0. A second approach, using PCA and ML based on the said fairness approximation vector produces an F1 score of 86.2. We detail improvements that can be made in the methodology to incorporate the projection of sentence embedding on to a subspace representation of fairness. </br></br>

<a href='http://arxiv.org/pdf/2112.05135.pdf'>2112.05135</a> &nbsp&nbsp (cs:ML, cs:CV) &nbsp&nbsp -0.0097баллов, №616</br>
<b>PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures</b></br>
Authors: , Hendrycks, Dan, Zou, Andy, Mazeika, Mantas, Tang, Leonard, Li, Bo, Song, Dawn, Steinhardt, Jacob</br>
  In <font color="#009600">real-world</font> applications of machine learning, reliable and safe systems must consider measures of performance beyond standard test set accuracy. These other goals include out-of-distribution (OOD) robustness, prediction consistency, resilience to adversaries, calibrated uncertainty estimates, and the ability to detect <font color="#be00be">anomal</font>ous inputs. However, improving performance towards these goals is often a balancing act that today\'s methods cannot achieve without sacrificing performance on other safety axes. For instance, adversarial training improves adversarial robustness but sharply degrades other classifier performance metrics. Similarly, strong data augmentation and regularization techniques often improve OOD robustness but harm anomaly detection, raising the question of whether a Pareto improvement on all existing safety measures is possible. To meet this challenge, we design a new data augmentation strategy utilizing the natural structural complexity of pictures such as fractals, which <font color="#00be00">outperform</font>s numerous baselines, is near Pareto-optimal, and roundly improves safety measures. </br></br>

<a href='http://arxiv.org/pdf/2112.05383.pdf'>2112.05383</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0099баллов, №617</br>
<b>Dandelion-Picking Legged Robot</b></br>
Authors: , Garimella, Sandilya Sai, Revzen, Shai</br>
  Agriculture is currently undergoing a robotics revolution, but robots using wheeled or treads suffer from known disadvantages: they are unable to move over rubble and steep or loose ground, and they trample continuous strips of land thereby reducing the viable crop area. Legged robots offer an alternative, but existing commercial legged robots are complex, expensive, and hard to maintain. We propose the use of multilegged robots using low-degree-of-freedom (low-DoF) legs and demonstrate our approach with a lawn pest control task: picking dandelions using our inexpensive and easy to fabricate BigANT robot. For this task we added an RGB-D camera to the robot. We also rigidly attached a flower picking appendage to the robot chassis. Thanks to the versatility of legs, the robot could be programmed to perform a ``swooping\'\' motion that allowed this 0-DoF appendage to pluck the flowers. Our results suggest that robots with six or more low-DoF legs may hit a sweet-spot for legged robots designed for agricultural applications by providing enough mobility, stability, and low complexity. </br></br>

<a href='http://arxiv.org/pdf/2112.05194.pdf'>2112.05194</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.0114баллов, №618</br>
<b>Word Embeddings via Causal Inference: <font color="#be00be">Gender Bias</font> Reducing and Semantic\n  Information Preserving</b></br>
Authors: , Ding, Lei, Yu, Dengdeng, Xie, Jinhan, Guo, Wenxing, Hu, Shenggang, Liu, Meichen, Kong, Linglong, Dai, Hongsheng, Bao, Yanchun, Jiang, Bei</br>
  With widening deployments of natural language processing (NLP) in daily life, inherited social biases from NLP models have become more severe and problematic. Previous studies have shown that word embeddings trained on human-generated corpora have strong <font color="#be00be">gender bias</font>es that can produce discriminative results in downstream tasks. Previous debiasing methods focus mainly on modeling bias and only implicitly consider semantic information while completely overlooking the complex underlying causal structure among bias and semantic components. To address these issues, we propose a novel methodology that leverages a causal inference framework to effectively remove gender bias. The proposed method allows us to construct and analyze the complex causal mechanisms facilitating gender information flow while retaining oracle semantic information within word embeddings. Our comprehensive experiments show that the proposed method achieves <font color="#00be00">state-of-the-art</font> results in gender-debiasing tasks. In addition, our methods yield better performance in word similarity evaluation and various extrinsic downstream NLP tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.06918.pdf'>2112.06918</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0125баллов, №619</br>
<b>Automated Customization of On-Thing Inference for Quality-of-Experience\n  Enhancement</b></br>
Authors: , Bai, Yang, Chen, Lixing, Ren, Shaolei, Xu, Jie</br>
  The rapid uptake of intelligent applications is pushing deep learning (DL) capabilities to Internet-of-Things (IoT). Despite the emergence of new tools for embedding deep neural networks (DNNs) into IoT devices, providing satisfactory Quality of Experience (QoE) to users is still challenging due to the heterogeneity in DNN architectures, IoT devices, and user preferences. This paper studies automated customization for DL inference on IoT devices (termed as on-thing inference), and our goal is to enhance user QoE by configuring the on-thing inference with an appropriate DNN for users under different usage scenarios. The core of our method is a DNN selection module that learns user QoE patterns on-the-fly and identifies the best-fit DNN for on-thing inference with the learned knowledge. It leverages a novel online learning algorithm, NeuralUCB, that has excellent generalization ability for handling various user QoE patterns. We also embed the knowledge transfer technique in NeuralUCB to expedite the learning process. However, NeuralUCB frequently solicits QoE ratings from users, which incurs non-negligible inconvenience. To address this problem, we design feedback solicitation schemes to reduce the number of QoE solicitations while maintaining the learning efficiency of NeuralUCB. A pragmatic problem, aggregated QoE, is further investigated to improve the practicality of our framework. We conduct experiments on both synthetic and <font color="#009600">real-world</font> data. The results indicate that our method efficiently learns the user QoE pattern with few solicitations and provides drastic QoE enhancement for IoT devices. </br></br>

<a href='http://arxiv.org/pdf/2112.08733.pdf'>2112.08733</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.0138баллов, №620</br>
<b>Self-Supervised Dynamic Graph Representation Learning via Temporal\n  Subgraph Contrast</b></br>
Authors: , Jiang, Linpu, Chen, Ke-Jia, Chen, Jingqiang</br>
  Self-supervised learning on graphs has recently drawn a lot of attention due to its independence from labels and its robustness in representation. Current studies on this topic mainly use static information such as graph structures but cannot well capture dynamic information such as timestamps of edges. Realistic graphs are often dynamic, which means the interaction between nodes occurs at a specific time. This paper proposes a self-supervised dynamic graph representation learning framework (DySubC), which defines a temporal subgraph contrastive learning task to simultaneously learn the structural and evolutional features of a dynamic graph. Specifically, a novel temporal subgraph sampling strategy is firstly proposed, which takes each node of the dynamic graph as the central node and uses both neighborhood structures and edge timestamps to sample the corresponding temporal subgraph. The subgraph representation function is then designed according to the influence of neighborhood nodes on the central node after encoding the nodes in each subgraph. Finally, the structural and temporal contrastive loss are defined to maximize the mutual information between node representation and temporal subgraph representation. Experiments on five <font color="#009600">real-world</font> datasets demonstrate that (1) DySubC performs better than the related baselines including two graph contrastive learning models and four dynamic graph representation learning models in the downstream link prediction task, and (2) the use of temporal information can not only sample more effective subgraphs, but also learn better representation by temporal contrastive loss. </br></br>

<a href='http://arxiv.org/pdf/2112.05614.pdf'>2112.05614</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0141баллов, №621</br>
<b>AAAI FSS-21: Artificial Intelligence in Government and Public Sector\n  Proceedings</b></br>
Authors: , Boicu, Mihai, Blasch, Erik, Preece, Alun</br>
  Proceedings of the AAAI Fall Symposium on Artificial Intelligence in Government and Public Sector, Washington, DC, USA, November 4-6, 2021 </br></br>

<a href='http://arxiv.org/pdf/2112.07080.pdf'>2112.07080</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0142баллов, №622</br>
<b>Fast Footstep Planning on Uneven Terrain Using Deep Sequential Models</b></br>
Authors: , Sanghvi, Hersh, Taylor, Camillo Jose</br>
  One of the fundamental challenges in realizing the potential of legged robots is generating plans to traverse challenging terrains. Control actions must be carefully selected so the robot will not crash or slip. The high dimensionality of the joint space makes directly planning low-level actions from onboard perception difficult, and control stacks that do not consider the low-level mechanisms of the robot in planning are ill-suited to handle fine-grained obstacles. One method for dealing with this is selecting footstep locations based on terrain characteristics. However, incorporating robot dynamics into footstep planning requires significant computation, much more than in the quasi-static case. In this work, we present an LSTM-based planning framework that learns probability distributions over likely footstep locations using both terrain lookahead and the robot\'s dynamics, and leverages the LSTM\'s sequential nature to find footsteps in linear time. Our framework can also be used as a module to speed up sampling-based planners. We validate our approach on a simulated one-legged hopper over a variety of uneven terrains. </br></br>

<a href='http://arxiv.org/pdf/2112.06751.pdf'>2112.06751</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0146баллов, №623</br>
<b>Role of Human-AI Interaction in Selective Prediction</b></br>
Authors: , Bondi, Elizabeth, Koster, Raphael, Sheahan, Hannah, Chadwick, Martin, Bachrach, Yoram, Cemgil, Taylan, Paquet, Ulrich, Dvijotham, Krishnamurthy</br>
  Recent work has shown the potential benefit of selective prediction systems that can learn to defer to a human when the predictions of the AI are unreliable, particularly to improve the reliability of AI systems in high-stakes applications like healthcare or conservation. However, most prior work assumes that human behavior remains unchanged when they solve a prediction task as part of a human-AI team as opposed to by themselves. We show that this is not the case by performing experiments to quantify human-AI interaction in the context of selective prediction. In particular, we study the impact of communicating different types of information to humans about the AI system\'s decision to defer. Using <font color="#009600">real-world</font> conservation data and a selective prediction system that improves expected accuracy over that of the human or AI system working individually, we show that this messaging has a significant impact on the accuracy of human judgements. Our results study two components of the messaging strategy: 1) Whether humans are informed about the prediction of the AI system and 2) Whether they are informed about the decision of the selective prediction system to defer. By manipulating these messaging components, we show that it is possible to significantly boost human performance by informing the human of the decision to defer, but not revealing the prediction of the AI. We therefore show that it is vital to consider how the decision to defer is communicated to a human when designing selective prediction systems, and that the composite accuracy of a human-AI team must be carefully evaluated using a human-in-the-loop framework. </br></br>

<a href='http://arxiv.org/pdf/2112.08048.pdf'>2112.08048</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.0159баллов, №624</br>
<b>Dynamic Human Evaluation for Relative Model Comparisons</b></br>
Authors: , Thorleiksd&#xf3;ttir, Th&#xf3;rhildur, Renggli, Cedric, Hollenstein, Nora, Zhang, Ce</br>
  Collecting human judgements is currently the most reliable evaluation method for natural language generation systems. Automatic metrics have reported flaws when applied to measure quality aspects of generated text and have been shown to correlate poorly with human judgements. However, human evaluation is time and cost-intensive, and we lack consensus on designing and conducting human evaluation experiments. Thus there is a need for streamlined approaches for efficient collection of human judgements when evaluating natural language generation systems. Therefore, we present a dynamic approach to measure the required number of human annotations when evaluating generated outputs in relative comparison settings. We propose an agent-based framework of human evaluation to assess multiple labelling strategies and methods to decide the better model in a simulation and a crowdsourcing case study. The main results indicate that a decision about the superior model can be made with high probability across different labelling strategies, where assigning a single random worker per task requires the least overall labelling effort and thus the least cost. </br></br>

<a href='http://arxiv.org/pdf/2112.06020.pdf'>2112.06020</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0164баллов, №625</br>
<b>Learn from Human Teams: a Probabilistic Solution to Real-Time\n  Collaborative Robot Handling with Dynamic Gesture Commands</b></br>
Authors: , Chen, Rui, Shek, Alvin, Liu, Changliu</br>
  We study real-time collaborative robot (cobot) handling, where the cobot maneuvers a workpiece under human commands. This is useful when it is risky for humans to directly handle the workpiece. However, it is hard to make the cobot both easy to command and flexible in possible operations. In this work, we propose a Real-Time Collaborative Robot Handling (RTCoHand) framework that allows the control of cobot via user-customized dynamic gestures. This is hard due to variations among users, human motion uncertainties, and noisy human input. We model the task as a probabilistic generative process, referred to as Conditional Collaborative Handling Process (CCHP), and learn from human-human collaboration. We thoroughly evaluate the adaptability and robustness of CCHP and apply our approach to a real-time cobot handling task with Kinova Gen3 robot arm. We achieve seamless human-robot collaboration with both experienced and new users. Compared to classical controllers, RTCoHand allows significantly more complex maneuvers and lower user cognitive burden. It also eliminates the need for trial-and-error, rendering it advantageous in safety-critical tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.08540.pdf'>2112.08540</a> &nbsp&nbsp (cs:AI, cs:RO) &nbsp&nbsp -0.0170баллов, №626</br>
<b>Integrated Guidance and Control for Lunar Landing using a Stabilized\n  Seeker</b></br>
Authors: , Gaudet, Brian, Furfaro, Roberto</br>
  We develop an integrated guidance and control system that in conjunction with a stabilized seeker and landing site detection software can achieve precise and safe planetary landing. The seeker tracks the designated landing site by adjusting seeker elevation and azimuth angles to center the designated landing site in the sensor field of view. The seeker angles, closing speed, and range to the designated landing site are used to formulate a velocity field that is used by the guidance and control system to achieve a safe landing at the designated landing site. The guidance and control system maps this velocity field, attitude, and rotational velocity directly to a commanded thrust vector for the lander\'s four engines. The guidance and control system is implemented as a policy optimized using reinforcement meta learning. We demonstrate that the guidance and control system is compatible with multiple diverts during the powered descent phase, and is robust to seeker lag, actuator lag and degradation, and center of mass variation induced by fuel consumption. We outline several concepts of operations, including an approach using a preplaced landing beacon. </br></br>

<a href='http://arxiv.org/pdf/2111.02643.pdf'>2111.02643</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.0177баллов, №627</br>
<b>Response Generation with Context-Aware Prompt Learning</b></br>
Authors: , Gu, Xiaodong, Yoo, Kang Min, Lee, Sang-Woo</br>
  Pre-trained language models (PLM) have marked a huge leap in neural dialogue modeling. While PLMs are pre-trained on large-scale text corpora, they are usually fine-tuned on scarce dialogue data with specific domain knowledge and dialogue <font color="#be00be">style</font>s. However, tailoring the language models while fully utilizing prior knowledge in large pre-trained models remains a challenge. In this paper, we present a novel approach for pre-trained dialogue modeling that casts the dialogue generation problem as a prompt-learning task. Instead of fine-tuning on limited dialogue data, our approach, DialogPrompt, learns continuous prompt embeddings optimized for dialogue contexts, which appropriately elicit knowledge from the large pre-trained model. To encourage the model to better utilize the prompt embeddings, the prompt encoders are designed to be dynamically generated based on the dialogue context. Experiments on popular conversation datasets show that our approach significantly <font color="#00be00">outperform</font>s the fine-tuning baseline and the generic prompt-learning methods. Furthermore, human evaluations strongly support the superiority of DialogPrompt in regard to response generation quality. </br></br>

<a href='http://arxiv.org/pdf/2112.08106.pdf'>2112.08106</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0186баллов, №628</br>
<b>Enhance Connectivity of Promising Regions for Sampling-based Path\n  Planning</b></br>
Authors: , Ma, Han, Li, Chenming, Liu, Jianbang, Wang, Jiankun, Meng, Max Q. -H.</br>
  Sampling-based path planning algorithms usually implement uniform sampling methods to search the state space. However, uniform sampling may lead to unnecessary exploration in many scenarios, such as the environment with a few dead ends. Our previous work proposes to use the promising region to guide the sampling process to address the issue. However, the predicted promising regions are often disconnected, which means they cannot connect the start and goal state, resulting in a lack of probabilistic completeness. This work focuses on enhancing the connectivity of predicted promising regions. Our proposed method regresses the connectivity probability of the edges in the x and y directions. In addition, it calculates the weight of the promising edges in loss to guide the neural network to pay more attention to the connectivity of the promising regions. We conduct a series of simulation experiments, and the results show that the connectivity of promising regions improves significantly. Furthermore, we analyze the effect of connectivity on sampling-based path planning algorithms and conclude that connectivity plays an essential role in maintaining algorithm performance. </br></br>

<a href='http://arxiv.org/pdf/2112.08657.pdf'>2112.08657</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.0187баллов, №629</br>
<b>Taming Repetition in Dialogue Generation</b></br>
Authors: , Xi, Yadong, Pu, Jiashu, Mao, Xiaoxi</br>
  The wave of pre-training language models has been continuously improving the quality of the machine-generated conversations, however, some of the generated responses still suffer from excessive repetition, sometimes repeating words from utterance, sometimes repeating words within self-generated responses, or both. Inappropriate repetition of words can significantly degrade the quality of the generated texts. Penalized sampling is one popular solution, reducing the sampling probability of existing words during inference, however, it is highly vulnerable to the inappropriate setting of the static weight. Setting it too high can yield strange and unrealistic sentences while setting it too low makes the task of suppressing repetition trivial. To remedy the shortcomings of the above methods, we design a context-aware classifier to explicitly decide when to allow repetition and when to employ penalized sampling. Such a classifier can be easily integrated with existing decoding methods, reducing repetitions where appropriate while preserving the diversity of the text. Experimental results demonstrate that our method can generate higher quality and more authentic dialogues. </br></br>

<a href='http://arxiv.org/pdf/2112.05558.pdf'>2112.05558</a> &nbsp&nbsp (cs:ET, cs:NE) &nbsp&nbsp -0.0190баллов, №630</br>
<b>Universal computation using localized limit-cycle attractors in neural\n  networks</b></br>
Authors: , Baumgarten, Lorenz, Bornholdt, Stefan</br>
  Neural networks are dynamical systems that compute with their dynamics. One example is the Hopfield model, forming an associative memory which stores patterns as global attractors of the network dynamics. From studies of dynamical networks it is well known that localized attractors also exist. Yet, they have not been used in computing paradigms. Here we show that interacting localized attractors in threshold networks can result in universal computation. We develop a rewiring algorithm that builds universal Boolean gates in a biologically inspired two-dimensional threshold network with randomly placed and connected nodes using collision-based computing. We aim at demonstrating the computational capabilities and the ability to control local limit cycle attractors in such networks by creating simple Boolean gates by means of these local activations. The gates use glider guns, i.e., localized activity that periodically generates &quot;gliders&quot; of activity that propagate through space. Several such gliders are made to collide, and the result of their interaction is used as the output of a Boolean gate. We show that these gates can be used to build a universal computer. </br></br>

<a href='http://arxiv.org/pdf/2112.08125.pdf'>2112.08125</a> &nbsp&nbsp (cs:ML, cs:NE) &nbsp&nbsp -0.0190баллов, №631</br>
<b>Exponential Convergence of Deep Operator Networks for Elliptic Partial\n  Differential Equations</b></br>
Authors: , Marcati, Carlo, Schwab, Christoph</br>
  We construct deep operator networks (ONets) between infinite-dimensional spaces that emulate with an exponential rate of convergence the coefficient-to-solution map of elliptic second-order PDEs. In particular, we consider problems set in $d$-dimensional periodic domains, $d=1, 2, \\dots$, and with analytic right-hand sides and coefficients. Our analysis covers diffusion-reaction problems, parametric diffusion equations, and elliptic systems such as linear isotropic elastostatics in heterogeneous materials.   We leverage the exponential convergence of spectral collocation methods for boundary value problems whose solutions are analytic. In the present periodic and analytic setting, this follows from classical elliptic regularity. Within the ONet branch and trunk construction of [Chen and Chen, 1993] and of [Lu et al., 2021], we show the existence of deep ONets which emulate the coefficient-to-solution map to accuracy $\\varepsilon&gt;0$ in the $H^1$ norm, uniformly over the coefficient set. We prove that the neural networks in the ONet have size $\\mathcal{O}(\\left|\\log(\\varepsilon)\\right|^\\kappa)$ for some $\\kappa&gt;0$ depending on the physical space dimension. </br></br>

<a href='http://arxiv.org/pdf/2112.09062.pdf'>2112.09062</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.0205баллов, №632</br>
<b>Models in the Loop: Aiding Crowdworkers with Generative Annotation\n  Assistants</b></br>
Authors: , Bartolo, Max, Thrush, Tristan, Riedel, Sebastian, Stenetorp, Pontus, Jia, Robin, Kiela, Douwe</br>
  In Dynamic Adversarial Data Collection (DADC), human annotators are tasked with finding examples that models struggle to predict correctly. Models trained on DADC-collected training data have been shown to be more robust in adversarial and out-of-domain settings, and are considerably harder for humans to fool. However, DADC is more time-consuming than traditional data collection and thus more costly per example. In this work, we examine if we can maintain the advantages of DADC, without suffering the additional cost. To that end, we introduce Generative Annotation Assistants (GAAs), generator-in-the-loop models that provide real-time suggestions that annotators can either approve, modify, or reject entirely. We collect training datasets in twenty experimental settings and perform a detailed analysis of this approach for the task of extractive question answering (QA) for both standard and adversarial data collection. We demonstrate that GAAs provide significant efficiency benefits in terms of annotation speed, while leading to improved model fooling rates. In addition, we show that GAA-assisted data leads to higher downstream model performance on a variety of question answering tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.06098.pdf'>2112.06098</a> &nbsp&nbsp (cs:ET, cs:ML) &nbsp&nbsp -0.0248баллов, №633</br>
<b>CHAMP: Coherent Hardware-Aware Magnitude Pruning of Integrated Photonic\n  Neural Networks</b></br>
Authors: , Banerjee, Sanmitra, Nikdast, Mahdi, Pasricha, Sudeep, Chakrabarty, Krishnendu</br>
  We propose a novel hardware-aware magnitude pruning technique for coherent photonic neural networks. The proposed technique can prune 99.45% of network parameters and reduce the static power consumption by 98.23% with a negligible accuracy loss. </br></br>

<a href='http://arxiv.org/pdf/2112.05665.pdf'>2112.05665</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0253баллов, №634</br>
<b>Deep <font color="#be00be">Odometry</font> Systems on Edge with EKF-LoRa Backend for Real-Time\n  Positioning in Adverse Environment</b></br>
Authors: , Dai, Zhuangzhuang, Saputra, Muhamad Risqi U., Lu, Chris Xiaoxuan, Markham, Andrew, Trigoni, Niki</br>
  Ubiquitous positioning for <font color="#be00be">pedestrian</font> in adverse environment has served a long standing challenge. Despite dramatic progress made by Deep Learning, multi-sensor deep <font color="#be00be">odometry</font> systems yet pose a high computational cost and suffer from cumulative drifting errors over time. Thanks to the increasing computational power of edge devices, we propose a novel ubiquitous positioning solution by integrating <font color="#00be00">state-of-the-art</font> deep odometry models on edge with an EKF (Extended Kalman Filter)-LoRa backend. We carefully compare and select three sensor modalities, i.e., an Inertial Measurement Unit (IMU), a millimetre-wave (mmWave) radar, and a thermal infrared camera, and realise their deep odometry inference engines which runs in real-time. A pipeline of deploying deep odometry considering accuracy, complexity, and edge platform is proposed. We design a LoRa link for positional data backhaul and projecting aggregated positions of deep odometry into the global frame. We find that a simple EKF based fusion module is sufficient for generic positioning calibration with over 34% accuracy gains against any standalone deep odometry system. Extensive tests in different environments validate the efficiency and efficacy of our proposed positioning system. </br></br>

<a href='http://arxiv.org/pdf/2112.06442.pdf'>2112.06442</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0279баллов, №635</br>
<b>Contact-Rich Manipulation of a Flexible Object based on Deep Predictive\n  Learning using Vision and Tactility</b></br>
Authors: , Ichiwara, Hideyuki, Ito, Hiroshi, Yamamoto, Kenjiro, Mori, Hiroki, Ogata, Tetsuya</br>
  We achieved contact-rich flexible object manipulation, which was difficult to control with vision alone. In the unzipping task we chose as a validation task, the gripper grasps the puller, which hides the bag state such as the direction and amount of deformation behind it, making it difficult to obtain information to perform the task by vision alone. Additionally, the flexible fabric bag state constantly changes during operation, so the robot needs to dynamically respond to the change. However, the appropriate robot behavior for all bag states is difficult to prepare in advance. To solve this problem, we developed a model that can perform contact-rich flexible object manipulation by real-time prediction of vision with tactility. We introduced a point-based attention mechanism for extracting image features, softmax transformation for predicting motions, and convolutional neural network for extracting tactile features. The results of experiments using a real robot arm revealed that our method can realize motions responding to the deformation of the bag while reducing the load on the zipper. Furthermore, using tactility improved the success rate from 56.7% to 93.3% compared with vision alone, demonstrating the effectiveness and high performance of our method. </br></br>

<a href='http://arxiv.org/pdf/2112.06320.pdf'>2112.06320</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0295баллов, №636</br>
<b><font color="#be00be">Anomal</font>y Crossing: A New Method for Video Anomaly Detection as\n  Cross-domain <font color="#00be00">Few-shot</font> Learning</b></br>
Authors: , Sun, Guangyu, Liu, Zhang, Wen, Lianggong, Shi, Jing, Xu, Chenliang</br>
  Video <font color="#be00be">anomal</font>y detection aims to identify abnormal events that occurred in videos. Since anomalous events are relatively rare, it is not feasible to collect a balanced dataset and train a binary classifier to solve the task. Thus, most previous approaches learn only from normal videos using unsupervised or semi-supervised methods. Obviously, they are limited in capturing and utilizing discriminative abnormal characteristics, which leads to compromised anomaly detection performance. In this paper, to address this issue, we propose a new learning paradigm by making full use of both normal and abnormal videos for video anomaly detection. In particular, we formulate a new learning task: cross-domain <font color="#00be00">few-shot</font> anomaly detection, which can transfer knowledge learned from numerous videos in the source domain to help solve few-shot abnormality detection in the target domain. Concretely, we leverage self-supervised training on the target normal videos to reduce the domain gap and devise a meta context perception module to explore the video context of the event in the few-shot setting. Our experiments show that our method significantly <font color="#00be00">outperform</font>s baseline methods on DoTA and UCF-Crime datasets, and the new task contributes to a more practical training paradigm for anomaly detection. </br></br>

<a href='http://arxiv.org/pdf/2112.07210.pdf'>2112.07210</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.0295баллов, №637</br>
<b>Simple Local Attentions Remain <font color="#960096">Competitive</font> for Long-Context Tasks</b></br>
Authors: , Xiong, Wenhan, O&#x11f;uz, Barlas, Gupta, Anchit, Chen, Xilun, Liskovich, Diana, Levy, Omer, Yih, Wen-tau, Mehdad, Yashar</br>
  Many NLP tasks require processing long contexts beyond the length limit of pretrained models. In order to scale these models to longer text sequences, many efficient long-range attention variants have been proposed. Despite the abundance of research along this direction, it is still difficult to gauge the relative effectiveness of these models in practical use cases, e.g., if we apply these models following the pretrain-and-finetune paradigm. In this work, we aim to conduct a thorough analysis of these emerging models with large-scale and controlled experiments. For each attention variant, we pretrain large-size models using the same long-doc corpus and then finetune these models for <font color="#009600">real-world</font> long-context tasks. Our findings reveal pitfalls of an existing widely-used long-range benchmark and show none of the tested efficient attentions can beat a simple local window attention under standard pretraining paradigms. Further analysis on local attention variants suggests that even the commonly used attention-window overlap is not necessary to achieve good downstream results -- using disjoint local attentions, we are able to build a simpler and more efficient long-doc QA model that matches the performance of Longformer~\\citep{longformer} with half of its pretraining compute. </br></br>

<a href='http://arxiv.org/pdf/2112.08954.pdf'>2112.08954</a> &nbsp&nbsp (cs:NE, cs:ML) &nbsp&nbsp -0.0304баллов, №638</br>
<b>Advancing Residual Learning towards Powerful Deep Spiking Neural\n  Networks</b></br>
Authors: , Hu, Yifan, Wu, Yujie, Deng, Lei, Li, Guoqi</br>
  Despite the rapid progress of neuromorphic computing, inadequate capacity and insufficient representation power of spiking neural networks (SNNs) severely restrict their application scope in practice. Residual learning and shortcuts have been evidenced as an important approach for training deep neural networks, but rarely did previous work assess their applicability to the characteristics of spike-based communication and spatiotemporal dynamics. In this paper, we first identify that this negligence leads to impeded information flow and accompanying degradation problem in previous residual SNNs. Then we propose a novel SNN-oriented residual block, MS-ResNet, which is able to significantly extend the depth of directly trained SNNs, e.g. up to 482 layers on CIFAR-10 and 104 layers on ImageNet, without observing any slight degradation problem. We validate the effectiveness of MS-ResNet on both frame-based and neuromorphic datasets, and MS-ResNet104 achieves a superior result of 76.02% accuracy on ImageNet, the first time in the domain of directly trained SNNs. Great energy efficiency is also observed that on average only one spike per neuron is needed to classify an input sample. We believe our powerful and scalable models will provide a strong support for further exploration of SNNs. </br></br>

<a href='http://arxiv.org/pdf/2112.08691.pdf'>2112.08691</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0312баллов, №639</br>
<b>Towards Robust Neural Image Compression: <font color="#be00be">Adversarial Att</font>ack and Model\n  Finetuning</b></br>
Authors: , Chen, Tong, Ma, Zhan</br>
  Deep neural network based image compression has been extensively studied. Model robustness is largely overlooked, though it is crucial to service enabling. We perform the <font color="#be00be">adversarial att</font>ack by injecting a small amount of noise perturbation to original source images, and then encode these adversarial examples using prevailing learnt image compression models. Experiments report severe distortion in the reconstruction of adversarial examples, revealing the general vulnerability of existing methods, regardless of the settings used in underlying compression model (e.g., network architecture, loss function, quality scale) and optimization strategy used for injecting perturbation (e.g., noise threshold, signal distance measurement). Later, we apply the iterative adversarial finetuning to refine pretrained models. In each iteration, random source images and adversarial examples are mixed to update underlying model. Results show the effectiveness of the proposed finetuning strategy by substantially improving the compression model robustness. Overall, our methodology is simple, effective, and generalizable, making it attractive for developing robust learnt image compression solution. All materials have been made publicly accessible at <font color="#006400">http</font>s://njuvision.<font color="#00be00">github</font>.io/RobustNIC for reproducible research. </br></br>

<a href='http://arxiv.org/pdf/2112.06879.pdf'>2112.06879</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0321баллов, №640</br>
<b>Multi-Robot On-site Shared Analytics Information and Computing</b></br>
Authors: , Hook, Joshua Vander, Rossi, Federico, Vaquero, Tiago, Troesch, Martina, Net, Marc Sanchez, Schoolcraft, Joshua, de la Croix, Jean-Pierre, Chien, Steve</br>
  Computation load-sharing across a network of heterogeneous robots is a promising approach to increase robots capabilities and efficiency as a team in extreme environments. However, in such environments, communication links may be intermittent and connections to the cloud or internet may be nonexistent. In this paper we introduce a communication-aware, computation task scheduling problem for multi-robot systems and propose an integer linear program (ILP) that optimizes the allocation of computational tasks across a network of heterogeneous robots, accounting for the networked robots\' computational capabilities and for available (and possibly time-varying) communication links. We consider scheduling of a set of inter-dependent required and optional tasks modeled by a dependency graph. We present a consensus-backed scheduling architecture for shared-world, distributed systems. We validate the ILP formulation and the distributed implementation in different computation platforms and in simulated scenarios with a bias towards lunar or planetary exploration scenarios. Our results show that the proposed implementation can optimize schedules to allow a threefold increase the amount of rewarding tasks performed (e.g., science measurements) compared to an analogous system with no computational load-sharing. </br></br>

<a href='http://arxiv.org/pdf/2112.08511.pdf'>2112.08511</a> &nbsp&nbsp (cs:NE, cs:ML) &nbsp&nbsp -0.0321баллов, №641</br>
<b>OptABC: an Optimal Hyperparameter Tuning Approach for Machine Learning\n  Algorithms</b></br>
Authors: , Zahedi, Leila, Mohammadi, Farid Ghareh, Amini, M. Hadi</br>
  Hyperparameter tuning in machine learning algorithms is a computationally challenging task due to the large-scale nature of the problem. In order to develop an efficient strategy for hyper-parameter tuning, one promising solution is to use swarm intelligence algorithms. Artificial Bee Colony (ABC) optimization lends itself as a promising and efficient optimization algorithm for this purpose. However, in some cases, ABC can suffer from a slow convergence rate or execution time due to the poor initial population of solutions and expensive objective functions. To address these concerns, a novel algorithm, OptABC, is proposed to help ABC algorithm in faster convergence toward a near-optimum solution. OptABC integrates artificial bee colony algorithm, <font color="#be00be">K-Mean</font>s <font color="#be00be">clustering</font>, greedy algorithm, and opposition-based learning strategy for tuning the hyper-parameters of different machine learning models. OptABC employs these techniques in an attempt to diversify the initial population, and hence enhance the convergence ability without significantly decreasing the accuracy. In order to validate the performance of the proposed method, we compare the results with previous <font color="#00be00">state-of-the-art</font> approaches. Experimental results demonstrate the effectiveness of the OptABC compared to existing approaches in the literature. </br></br>

<a href='http://arxiv.org/pdf/2112.06637.pdf'>2112.06637</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0329баллов, №642</br>
<b>Efficient Training of Volterra Series-Based Pre-distortion Filter Using\n  Neural Networks</b></br>
Authors: , Bajaj, Vinod, Chagnon, Mathieu, Wahls, Sander, Aref, Vahid</br>
  We present a simple, efficient &quot;direct learning&quot; approach to train Volterra series-based digital pre-distortion filters using neural networks. We show its superior performance over conventional training methods using a 64-QAM 64-GBaud simulated transmitter with varying transmitter nonlinearity and noisy conditions. </br></br>

<a href='http://arxiv.org/pdf/2112.09078.pdf'>2112.09078</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0329баллов, №643</br>
<b>SenSnake: A snake robot with contact force sensing for studying\n  locomotion in complex 3-D terrain</b></br>
Authors: , Ramesh, Divya, Fu, Qiyuan, Li, Chen</br>
  Despite advances in a diversity of environments, snake robots are still far behind snakes in traversing complex 3-D terrain with large obstacles. This is due to a lack of understanding of how to control 3-D body bending to push against terrain features to generate and control propulsion. Biological studies suggested that generalist snakes use contact force sensing to adjust body bending in real time to do so. However, studying this sensory-modulated force control in snakes is challenging, due to a lack of basic knowledge of how their force sensing organs work. Here, we take a robophysics approach to make progress, starting by developing a snake robot capable of 3-D body bending with contact force sensing to enable systematic locomotion experiments and force measurements. Through two development and testing iterations, we created a 12-segment robot with 36 piezo-resistive sheet sensors distributed on all segments with compliant shells with a sampling frequency of 30 Hz. The robot measured contact forces while traversing a large obstacle using vertical bending with high repeatability, achieving the goal of providing a platform for systematic experiments. Finally, we explored model-based calibration considering the viscoelastic behavior of the piezo-resistive sensor, which will for useful for future studies. </br></br>

<a href='http://arxiv.org/pdf/2112.07173.pdf'>2112.07173</a> &nbsp&nbsp (cs:CV, cs:AI, cs:NE) &nbsp&nbsp -0.0335баллов, №644</br>
<b>On the use of Cortical Magnification and Saccades as Biological Proxies\n  for Data Augmentation</b></br>
Authors: , Wang, Binxu, Mayo, David, Deza, Arturo, Barbu, Andrei, Conwell, Colin</br>
  Self-supervised learning is a powerful way to learn useful representations from natural data. It has also been suggested as one possible means of building visual representation in humans, but the specific objective and algorithm are unknown. Currently, most self-supervised methods encourage the system to learn an invariant representation of different transformations of the same image in contrast to those of other images. However, such transformations are generally non-biologically plausible, and often consist of contrived perceptual schemes such as random cropping and color jittering. In this paper, we attempt to reverse-engineer these augmentations to be more biologically or perceptually plausible while still conferring the same benefits for encouraging robust representation. Critically, we find that random cropping can be substituted by cortical magnification, and saccade-like sampling of the image could also assist the representation learning. The feasibility of these transformations suggests a potential way that biological visual systems could implement self-supervision. Further, they break the widely accepted spatially-uniform processing assumption used in many computer vision algorithms, suggesting a role for spatially-adaptive computation in humans and machines alike. Our code and demo can be found here. </br></br>

<a href='http://arxiv.org/pdf/2112.05695.pdf'>2112.05695</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.0349баллов, №645</br>
<b>Causal Knowledge Guided Societal Event Forecasting</b></br>
Authors: , Deng, Songgaojun, Rangwala, Huzefa, Ning, Yue</br>
  Data-driven societal event forecasting methods exploit relevant historical information to predict future events. These methods rely on historical labeled data and cannot accurately predict events when data are limited or of poor quality. Studying causal effects between events goes beyond correlation analysis and can contribute to a more robust prediction of events. However, incorporating causality analysis in data-driven event forecasting is challenging due to several factors: (i) Events occur in a complex and dynamic social environment. Many unobserved variables, i.e., hidden confounders, affect both potential causes and outcomes. (ii) Given spatiotemporal non-independent and identically distributed (non-IID) data, modeling hidden confounders for accurate causal effect estimation is not trivial. In this work, we introduce a deep learning framework that integrates causal effect estimation into event forecasting. We first study the problem of Individual Treatment Effect (ITE) estimation from observational event data with spatiotemporal attributes and present a novel causal inference model to estimate ITEs. We then incorporate the learned event-related causal information into event prediction as prior knowledge. Two robust learning modules, including a feature reweighting module and an approximate constraint loss, are introduced to enable prior knowledge injection. We evaluate the proposed causal inference model on <font color="#009600">real-world</font> event datasets and validate the effectiveness of proposed robust learning modules in event prediction by feeding learned causal information into different deep learning methods. Experimental results demonstrate the strengths of the proposed causal inference model for ITE estimation in societal events and showcase the beneficial properties of robust learning modules in societal event forecasting. </br></br>

<a href='http://arxiv.org/pdf/2112.07900.pdf'>2112.07900</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0349баллов, №646</br>
<b>Environmental force sensing enables robots to traverse cluttered\n  obstacles with interaction</b></br>
Authors: , Xuan, Qihan, Wang, Yaqing, Li, Chen</br>
  Many applications require robots to move through terrain with large obstacles, such as self-driving, search and rescue, and extraterrestrial exploration. Although robots are already excellent at avoiding sparse obstacles, they still struggle in traversing cluttered obstacles. Inspired by cockroaches that use and respond to physical interaction with obstacles in various ways to traverse grass-like beams with different stiffness, here we developed a physics model of a minimalistic robot capable of environmental force sensing propelled forward to traverse two beams to simulate and understand the traversal of cluttered obstacles. Beam properties like stiffness and deflection locations could be estimated from the noisy beam contact forces measured, whose fidelity increased with sensing time. Using these estimates, the model predicted the cost of traversal defined using potential energy barriers and used it to plan and control the robot to generate and track a trajectory to traverse with minimal cost. When encountering stiff beams, the simulation robot transitioned from a more costly pitch mode to a less costly roll mode to traverse. When encountering flimsy beams, it chose to push cross beams with less energy cost than avoiding beams. Finally, we developed a physical robot and demonstrated the usefulness of the estimation method. </br></br>

<a href='http://arxiv.org/pdf/2112.05878.pdf'>2112.05878</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0388баллов, №647</br>
<b>Online Information-Aware Motion Planning with Inertial Parameter\n  Learning for Robotic Free-Flyers</b></br>
Authors: , Ekal, Monica, Albee, Keenan, Coltin, Brian, Ventura, Rodrigo, Linares, Richard, Miller, David W.</br>
  Space free-flyers like the Astrobee robots currently operating aboard the International Space Station must operate with inherent system uncertainties. Parametric uncertainties like mass and moment of inertia are especially important to quantify in these safety-critical space systems and can change in scenarios such as on-orbit cargo movement, where unknown grappled payloads significantly change the system dynamics. Cautiously learning these uncertainties en route can potentially avoid time- and fuel-consuming pure system identification maneuvers. Recognizing this, this work proposes RATTLE, an online information-aware motion planning algorithm that explicitly weights parametric model-learning coupled with real-time replanning capability that can take advantage of improved system models. The method consists of a two-tiered (global and local) planner, a low-level model predictive controller, and an online parameter estimator that produces estimates of the robot\'s inertial properties for more informed control and replanning on-the-fly; all levels of the planning and control feature online update-able models. Simulation results of RATTLE for the Astrobee free-flyer grappling an uncertain payload are presented alongside results of a hardware demonstration showcasing the ability to explicitly encourage model parametric learning while achieving otherwise useful motion. </br></br>

<a href='http://arxiv.org/pdf/2112.05465.pdf'>2112.05465</a> &nbsp&nbsp (cs:RO, cs:AI) &nbsp&nbsp -0.0397баллов, №648</br>
<b>Autonomous Aerial Robot for High-Speed Search and Intercept Applications</b></br>
Authors: , Rodriguez-Ramos, Alejandro, Bavle, Adrian Alvarez-Fernandez Hriday, Rodriguez-Vazquez, Javier, Fernandez-Cortizas, Liang Lu Miguel, Fernandez, Ramon A. Suarez, Rodelgo, Alberto, Santos, Carlos, Molina, Martin, Merino, Luis, Caballero, Fernando, Campoy, Pascual</br>
  In recent years, high-speed navigation and environment interaction in the context of aerial robotics has become a field of interest for several academic and industrial research studies. In particular, Search and Intercept (SaI) applications for aerial robots pose a compelling research area due to their potential usability in several environments. Nevertheless, SaI tasks involve a challenging development regarding sensory weight, on-board computation resources, actuation design and algorithms for perception and control, among others. In this work, a fully-autonomous aerial robot for high-speed object grasping has been proposed. As an additional sub-task, our system is able to autonomously pierce balloons located in poles close to the surface. Our first contribution is the design of the aerial robot at an actuation and sensory level consisting of a novel gripper design with additional sensors enabling the robot to grasp objects at high speeds. The second contribution is a complete software framework consisting of perception, state estimation, motion planning, motion control and mission control in order to rapid- and robustly perform the autonomous grasping mission. Our approach has been validated in a challenging international competition and has shown outstanding results, being able to autonomously search, follow and grasp a moving object at 6 m/s in an outdoor environment </br></br>

<a href='http://arxiv.org/pdf/2112.09117.pdf'>2112.09117</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0408баллов, №649</br>
<b>Machine Learning Kreuzer--Skarke Calabi--Yau Threefolds</b></br>
Authors: , Berglund, Per, Campbell, Ben, Jejjala, Vishnu</br>
  Using a fully connected feedforward neural network we study topological invariants of a class of Calabi--Yau manifolds constructed as hypersurfaces in toric varieties associated with reflexive polytopes from the Kreuzer--Skarke database. In particular, we find the existence of a simple expression for the Euler number that can be learned in terms of limited data extracted from the polytope and its dual. </br></br>

<a href='http://arxiv.org/pdf/2111.08162.pdf'>2111.08162</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0415баллов, №650</br>
<b>On Bock\'s Conjecture Regarding the Adam Optimizer</b></br>
Authors: , Akrout, Mohamed, Tweed, Douglas</br>
  In 2014, Kingma and Ba published their Adam optimizer algorithm, together with a mathematical argument that was meant to help justify it. In 2018, Bock and colleagues reported that a key piece was missing from that argument $-$ an unproven lemma which we will call Bock\'s conjecture. Here we show that this conjecture is false, but we prove a modified version of it which can take its place in analyses of Adam. </br></br>

<a href='http://arxiv.org/pdf/2112.05151.pdf'>2112.05151</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0422баллов, №651</br>
<b>Report-Guided Automatic Lesion Annotation for Deep Learning-Based\n  Prostate <font color="#be00be">Cancer</font> Detection in bpMRI</b></br>
Authors: , Bosma, Joeran S., Saha, Anindo, Hosseinzadeh, Matin, Slootweg, Ilse, de Rooij, Maarten, Huisman, Henkjan</br>
  Deep learning-based <font color="#be00be">diagnos</font>tic performance increases with more annotated data, but manual annotation is a bottleneck in most fields. Experts evaluate diagnostic images during <font color="#be00be">clinic</font>al routine, and write their findings in reports. Automatic annotation based on clinical reports could overcome the manual labelling bottleneck. We hypothesise that dense annotations for detection tasks can be generated using model predictions, guided by sparse information from these reports. To demonstrate efficacy, we generated clinically significant prostate <font color="#be00be">cancer</font> (csPCa) annotations, guided by the number of clinically significant findings in the radiology reports. We included 7,756 prostate<font color="#be00be"> MRI </font>examinations, of which 3,050 were manually annotated and 4,706 were automatically annotated. We evaluated the automatic annotation quality on the manually annotated subset: our score extraction correctly identified the number of csPCa lesions for $99.3\\%$ of the reports and our csPCa <font color="#be00be">segmentation</font> model correctly localised $83.8 \\pm 1.1\\%$ of the lesions. We evaluated prostate cancer detection performance on 300 exams from an external centre with histo<font color="#be00be">patholog</font>y-confirmed ground truth. Augmenting the training set with automatically labelled exams improved <font color="#be00be">patient</font>-based diagnostic area under the receiver operating characteristic curve from $88.1\\pm 1.1\\%$ to $89.8\\pm 1.0\\%$ ($P = 1.2 \\cdot 10^{-4}$) and improved lesion-based sensitivity at one false positive per case from $79.2 \\pm 2.8\\%$ to $85.4 \\pm 1.9\\%$ ($P&lt;10^{-4}$), with $mean \\pm std.$ over 15 independent runs. This improved performance demonstrates the feasibility of our report-guided automatic annotations. <font color="#00be00">Source code</font> is made <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/DIAGNijmegen/Report-Guided-Annotation. Best csPCa detection algorithm is made available at https://grand-challenge.org/algorithms/bpmri-cspca-detection-report-guided-annotations/. </br></br>

<a href='http://arxiv.org/pdf/2112.07426.pdf'>2112.07426</a> &nbsp&nbsp (cs:NE, cs:ML) &nbsp&nbsp -0.0424баллов, №652</br>
<b>Direct Training via Backpropagation for Ultra-low Latency Spiking Neural\n  Networks with Multi-threshold</b></br>
Authors: , Xu, Changqing, Liu, Yi, Yang, Yintang</br>
  Spiking neural networks (SNNs) can utilize spatio-temporal information and have a nature of energy efficiency which is a good alternative to deep neural networks(DNNs). The event-driven information processing makes SNNs can reduce the expensive computation of DNNs and save a lot of energy consumption. However, high training and inference latency is a limitation of the development of deeper SNNs. SNNs usually need tens or even hundreds of time steps during the training and inference process which causes not only the increase of latency but also the waste of energy consumption. To overcome this problem, we proposed a novel training method based on backpropagation (BP) for ultra-low latency(1-2 time steps) SNN with multi-threshold. In order to increase the information capacity of each spike, we introduce the multi-threshold Leaky Integrate and Fired (LIF) model. In our proposed training method, we proposed three approximated derivative for spike activity to solve the problem of the non-differentiable issue which cause difficulties for direct training SNNs based on BP. The experimental results show that our proposed method achieves an average accuracy of 99.56%, 93.08%, and 87.90% on MNIST, FashionMNIST, and CIFAR10, respectively with only 2 time steps. For the CIFAR10 dataset, our proposed method achieve 1.12% accuracy improvement over the previously reported direct trained SNNs with fewer time steps. </br></br>

<a href='http://arxiv.org/pdf/2112.05597.pdf'>2112.05597</a> &nbsp&nbsp (cs:RO, cs:AI) &nbsp&nbsp -0.0432баллов, №653</br>
<b>Marvin: Innovative Omni-Directional Robotic Assistant for Domestic\n  Environments</b></br>
Authors: , Eirale, Andrea, Martini, Mauro, Tagliavini, Luigi, Chiaberge, Marcello, Quaglia, Giuseppe</br>
  Technology is progressively reshaping the domestic environment as we know it, enhancing home security and the overall ambient quality through smart connected devices. However, demographic shift and pandemics recently demonstrate to cause isolation of elderly people in their houses, generating the need for a reliable assistive figure. Robotic assistants are the new frontier of innovation for domestic welfare. Elderly monitoring is only one of the possible service applications an intelligent robotic platform can handle for collective wellbeing. In this paper, we present Marvin, a novel assistive robot we developed with a modular layer-based architecture, merging a flexible mechanical design with <font color="#00be00">state-of-the-art</font> Artificial Intelligence for perception and vocal control. With respect to previous works on robotic assistants, we propose an omnidirectional platform provided with four mecanum wheels, which enable autonomous navigation in conjunction with efficient obstacle avoidance in cluttered environments. Moreover, we design a controllable positioning device to extend the visual range of sensors and to improve the access to the user interface for telepresence and connectivity. <font color="#be00be">Lightweight</font> deep learning solutions for visual perception, person pose classification and vocal command completely run on the embedded hardware of the robot, avoiding <font color="#be00be">privacy</font> issues arising from <font color="#be00be">private</font> data collection on cloud services. </br></br>

<a href='http://arxiv.org/pdf/2112.08717.pdf'>2112.08717</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0433баллов, №654</br>
<b>GIMIRec: Global Interaction Information Aware Multi-Interest Framework\n  for Sequential <font color="#be00be">Recommendat</font>ion</b></br>
Authors: , Zhang, Jie, Chen, Ke-Jia, Chen, Jingqiang</br>
  Sequential <font color="#be00be">recommendat</font>ion based on multi-interest framework models the user\'s recent interaction sequence into multiple different interest vectors, since a single low-dimensional vector cannot fully represent the diversity of user interests. However, most existing models only intercept users\' recent interaction behaviors as training data, discarding a large amount of historical interaction sequences. This may raise two issues. On the one hand, data reflecting multiple interests of users is missing; on the other hand, the co-occurrence between items in historical user-item interactions is not fully explored. To tackle the two issues, this paper proposes a novel sequential recommendation model called &quot;Global Interaction Aware Multi-Interest Framework for Sequential Recommendation (GIMIRec)&quot;. Specifically, a global context extraction module is firstly proposed without introducing any external information, which calculates a weighted co-occurrence matrix based on the constrained co-occurrence number of each item pair and their time interval from the historical interaction sequences of all users and then obtains the global context embedding of each item by using a simplified graph convolution. Secondly, the time interval of each item pair in the recent interaction sequence of each user is captured and combined with the global context item embedding to get the personalized item embedding. Finally, a self-attention based multi-interest framework is applied to learn the diverse interests of users for sequential recommendation. Extensive experiments on the three <font color="#009600">real-world</font> datasets of Amazon-Books, Taobao-Buy and Amazon-Hybrid show that the performance of GIMIRec on the Recall, NDCG and Hit Rate indicators is significantly superior to that of the <font color="#00be00">state-of-the-art</font> methods. Moreover, the proposed global context extraction module can be easily transplanted to most sequential recommendation models. </br></br>

<a href='http://arxiv.org/pdf/2112.06775.pdf'>2112.06775</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0439баллов, №655</br>
<b>On the Value of ML Models</b></br>
Authors: , Casati, Fabio, No&#xeb;l, Pierre-Andr&#xe9;, Yang, Jie</br>
  We argue that, when establishing and benchmarking Machine Learning (ML) models, the research community should favour evaluation metrics that better capture the value delivered by their model in practical applications. For a specific class of use cases -- selective classification -- we show that not only can it be simple enough to do, but that it has import consequences and provides insights what to look for in a ``good\'\' ML model. </br></br>

<a href='http://arxiv.org/pdf/2112.07019.pdf'>2112.07019</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0441баллов, №656</br>
<b>Synapse Compression for Event-Based Convolutional-Neural-Network\n  Accelerators</b></br>
Authors: , Bamberg, Lennart, Pourtaherian, Arash, Waeijen, Luc, Chahar, Anupam, Moreira, Orlando</br>
  Manufacturing-viable neuromorphic chips require novel computer architectures to achieve the massively parallel and efficient information processing the <font color="#00be00">brain</font> supports so effortlessly. Emerging event-based architectures are making this dream a reality. However, the large memory requirements for synaptic connectivity are a showstopper for the execution of modern convolutional neural networks (CNNs) on massively parallel, event-based (spiking) architectures. This work overcomes this roadblock by contributing a <font color="#be00be">lightweight</font> hardware scheme to compress the synaptic memory requirements by several thousand times, enabling the execution of complex CNNs on a single chip of small form factor. A silicon implementation in a 12-nm technology shows that the technique increases the system\'s implementation cost by only 2%, despite achieving a total memory-footprint reduction of up to 374x compared to the best previously published technique. </br></br>

<a href='http://arxiv.org/pdf/2112.06792.pdf'>2112.06792</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0443баллов, №657</br>
<b>Nonlinear pile-up separation with LSTM neural networks for cryogenic\n  particle detectors</b></br>
Authors: , Wagner, Felix</br>
  In high-background or calibration measurements with cryogenic particle detectors, a significant share of the exposure is lost due to pile-up of recoil events. We propose a method for the separation of pile-up events with an LSTM neural network and evaluate its performance on an exemplary data set. Despite a non-linear detector response function, we can reconstruct the ground truth of a severely distorted energy spectrum reasonably well. </br></br>

<a href='http://arxiv.org/pdf/2112.05587.pdf'>2112.05587</a> &nbsp&nbsp (cs:CV, cs:CL, cs:ML) &nbsp&nbsp -0.0454баллов, №658</br>
<b>Unified Multimodal Pre-training and Prompt-based Tuning for\n  Vision-Language Understanding and Generation</b></br>
Authors: , Liu, Tianyi, Wu, Zuxuan, Xiong, Wenhan, Chen, Jingjing, Jiang, Yu-Gang</br>
  Most existing vision-language pre-training methods focus on understanding tasks and use BERT-like objectives (masked language modeling and image-text matching) during pretraining. Although they perform well in many understanding downstream tasks, e.g., visual question answering, image-text <font color="#be00be">retrieval</font> and visual entailment, they do not possess the ability to generate. To tackle this problem, we propose Unified multimodal pre-training for both Vision-Language understanding and generation (UniVL). The proposed UniVL is capable of handling both understanding tasks and generative tasks. We augment existing pretraining paradigms that only use random masks with causal masks, i.e., triangular masks that mask out future tokens, such that the pre-trained models can have autoregressive generation abilities by design. We formulate several previous understanding tasks as a text generation task and propose to use prompt-based method for fine-tuning on different downstream tasks. Our experiments show that there is a trade-off between understanding tasks and generation tasks while using the same model, and a feasible way to improve both tasks is to use more data. Our UniVL framework attains comparable performance to recent vision-language pre-training methods on both understanding tasks and generation tasks. Moreover, we demostrate that prompt-based finetuning is more data-efficient - it <font color="#00be00">outperform</font>s discriminative methods in <font color="#00be00">few-shot</font> scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.05615.pdf'>2112.05615</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0454баллов, №659</br>
<b>Intelligent Transportation Systems With The Use of External\n  Infrastructure: A Literature Survey</b></br>
Authors: , Cre&#xdf;, Christian, Knoll, Alois C.</br>
  Increasing problems in the transportation segment are accidents, bad traffic flow and pollution. The Intelligent Transportation System with the use of external infrastructure (ITS) can tackle these problems. To the best of our knowledge, there exists no current systematic review of the existing solutions. To fill this knowledge gap, this paper provides an overview about existing ITS which use external infrastructure. Furthermore, this paper discovers the currently not adequately answered research questions. For this reason, we performed a literature review to documents, which describes existing ITS solutions since 2009 until today. We categorized the results according to his technology level and analyzed their properties. Thereby, we made the several ITS comparable and highlighted the past development as well as the current trends. According to the mentioned method, we analyzed more than 346 papers, which includes 40 test bed projects. In summary, the current ITS can deliver high accurate information about individuals in traffic situations in real-time. However, further research in ITS should focus on more reliable perception of the traffic with the use of modern sensors, plug and play mechanism as well as secure real-time distribution in decentralized manner for a high amount of data. With addressing these topics, the development of Intelligent Transportation Systems is in a correction direction for the comprehensive roll-out. </br></br>

<a href='http://arxiv.org/pdf/2112.05536.pdf'>2112.05536</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0457баллов, №660</br>
<b>Rapid manufacturing of color-based hemispherical soft tactile fingertips</b></br>
Authors: , Scharff, Rob B. N., Boonstra, Dirk-Jan, Willemet, Laurence, Lin, Xi, Wiertlewski, Micha&#xeb;l</br>
  Tactile sensing can provide access to information about the contact (i.e. slippage, surface feature, friction), which is out of reach of vision but crucial for manipulation. To access this information, a dense measurement of the deformation of soft fingertips is necessary. Recently, tactile sensors that rely on a camera looking at a deformable membrane have demonstrated that a dense measurement of the contact is possible. However, their manufacturing can be time-consuming and labor-intensive. Here, we show a new design method that uses multi-color additive manufacturing and silicone casting to efficiently manufacture soft marker-based tactile sensors that are able to capture with high-resolution the three-dimensional deformation field at the interface. Each marker is composed of two superimposed color filters. The subtractive color mixing encodes the normal deformation of the membrane, and the lateral deformation is found by centroid detection. With this manufacturing method, we can reach a density of 400 markers on a 21 mm radius hemisphere, allowing for regular and dense measurement of the deformation. We calibrated and validated the approach by finding the curvature of objects with a threefold increase in accuracy as compared to previous implementations. The results demonstrate a simple yet effective approach to manufacturing artificial fingertips for capturing a rich image of the tactile interaction at the location of contact. </br></br>

<a href='http://arxiv.org/pdf/2112.08637.pdf'>2112.08637</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.0467баллов, №661</br>
<b>Analyzing the Limits of Self-Supervision in Handling Bias in Language</b></br>
Authors: , Bauer, Lisa, Gopalakrishnan, Karthik, Gella, Spandana, Liu, Yang, Bansal, Mohit, Hakkani-Tur, Dilek</br>
  Prompting inputs with natural language task descriptions has emerged as a popular mechanism to elicit reasonably accurate outputs from large-scale generative language models with little to no in-context supervision. This also helps gain insight into how well language models capture the semantics of a wide range of downstream tasks purely from self-supervised pre-training on massive corpora of unlabeled text. Such models have naturally also been exposed to a lot of undesirable content like racist and sexist language and there is limited work on awareness of models along these dimensions. In this paper, we define and comprehensively evaluate how well such language models capture the semantics of four tasks for bias: <font color="#be00be">diagnos</font>is, identification, extraction and rephrasing. We define three broad classes of task descriptions for these tasks: statement, question, and completion, with numerous lexical variants within each class. We study the efficacy of prompting for each task using these classes and the null task description across several decoding methods and <font color="#00be00">few-shot</font> examples. Our analyses indicate that language models are capable of performing these tasks to widely varying degrees across different bias dimensions, such as gender and political affiliation. We believe our work is an important step towards unbiased language models by quantifying the limits of current self-supervision objectives at accomplishing such sociologically challenging tasks. </br></br>

<a href='http://arxiv.org/pdf/2111.03470.pdf'>2111.03470</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.0483баллов, №662</br>
<b>ParsiNorm: A Persian Toolkit for Speech Processing Normalization</b></br>
Authors: , Oji, Romina, Razavi, Seyedeh Fatemeh, Dehsorkh, Sajjad Abdi, Hariri, Alireza, Asheri, Hadi, Hosseini, Reshad</br>
  In general, speech processing models consist of a language model along with an acoustic model. Regardless of the language model\'s complexity and variants, three critical pre-processing steps are needed in language models: cleaning, normalization, and tokenization. Among mentioned steps, the normalization step is so essential to format unification in pure textual applications. However, for embedded language models in speech processing modules, normalization is not limited to format unification. Moreover, it has to convert each readable symbol, number, etc., to how they are pronounced. To the best of our knowledge, there is no Persian normalization toolkits for embedded language models in speech processing modules, So in this paper, we propose an open-source normalization toolkit for text processing in speech applications. Briefly, we consider different readable Persian text like symbols (common currencies, #, @, URL, etc.), numbers (date, time, phone number, national code, etc.), and so on. Comparison with other available Persian textual normalization tools indicates the superiority of the proposed method in speech processing. Also, comparing the model\'s performance for one of the proposed functions (sentence separation) with other common natural language libraries such as HAZM and Parsivar indicates the proper performance of the proposed method. Besides, its evaluation of some Persian Wikipedia data confirms the proper performance of the proposed method. </br></br>

<a href='http://arxiv.org/pdf/2112.07232.pdf'>2112.07232</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0488баллов, №663</br>
<b>Structure-Exploiting Newton-Type Method for Optimal Control of Switched\n  Systems</b></br>
Authors: , Katayama, Sotaro, Ohtsuka, Toshiyuki</br>
  This study proposes an efficient Newton-type method for the optimal control of switched systems under a given mode sequence. A mesh-refinement-based approach is utilized to discretize continuous-time optimal control problems (OCPs) and formulate a nonlinear program (NLP), which guarantees the local convergence of a Newton-type method. A dedicated structure-exploiting algorithm (Riccati recursion) is proposed to perform a Newton-type method for the NLP efficiently because its sparsity structure is different from a standard OCP. The proposed method computes each Newton step with linear time-complexity for the total number of discretization grids as the standard Riccati recursion algorithm. Additionally, the computation is always successful if the solution is sufficiently close to a local minimum. Conversely, general quadratic programming (QP) solvers cannot accomplish this because the Hessian matrix is inherently indefinite. Moreover, a modification on the reduced Hessian matrix is proposed using the nature of the Riccati recursion algorithm as the dynamic programming for a QP subproblem to enhance the convergence. A numerical comparison is conducted with off-the-shelf NLP solvers, which demonstrates that the proposed method is up to two orders of magnitude faster. Whole-body optimal control of quadrupedal gaits is also demonstrated and shows that the proposed method can achieve the whole-body model predictive control (MPC) of robotic systems with rigid contacts. </br></br>

<a href='http://arxiv.org/pdf/2112.09075.pdf'>2112.09075</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0494баллов, №664</br>
<b>A minimalistic stochastic dynamics model of cluttered obstacle traversal</b></br>
Authors: , Zheng, Bokun, Xuan, Qihan, Li, Chen</br>
  Robots are still poor at traversing cluttered large obstacles required for important applications like search and rescue. By contrast, animals are excellent at doing so, often using direct physical interaction with obstacles rather than avoiding them. Here, towards understanding the dynamics of cluttered obstacle traversal, we developed a minimalistic stochastic dynamics simulation inspired by our recent study of insects traversing grass-like beams. The 2-D model system consists of a forward self-propelled circular locomotor translating on a frictionless level plane with a lateral random force and interacting with two adjacent horizontal beams that form a gate. We found that traversal probability increases monotonically with propulsive force, but first increases then decreases with random force magnitude. For asymmetric beams with different stiffness, traversal is more likely towards the side of the less stiff beam. These observations are in accord with those expected from a potential energy landscape approach. Furthermore, we extended the single gate in a lattice configuration to form a large cluttered obstacle field. A Markov chain Monte Carlo method was applied to predict traversal in the large field, using the input-output probability map obtained from single gate simulations. This method achieved high accuracy in predicting the statistical distribution of the final location of the body within the obstacle field, while saving computation time by a factor of 10^5. </br></br>

<a href='http://arxiv.org/pdf/2112.08069.pdf'>2112.08069</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.0534баллов, №665</br>
<b>Funnels: Exact maximum likelihood with dimensionality reduction</b></br>
Authors: , Klein, Samuel, Raine, John A., Pina-Otey, Sebastian, Voloshynovskiy, Slava, Golling, Tobias</br>
  Normalizing flows are diffeomorphic, typically dimension-preserving, models trained using the likelihood of the model. We use the SurVAE framework to construct dimension reducing surjective flows via a new layer, known as the funnel. We demonstrate its efficacy on a variety of datasets, and show it improves upon or matches the performance of existing flows while having a reduced latent space size. The funnel layer can be constructed from a wide range of transformations including restricted convolution and feed forward layers. </br></br>

<a href='http://arxiv.org/pdf/2112.05298.pdf'>2112.05298</a> &nbsp&nbsp (cs:CV, cs:AI, cs:RO) &nbsp&nbsp -0.0555баллов, №666</br>
<b>IFR-Explore: Learning Inter-object Functional Relationships in 3D Indoor\n  Scenes</b></br>
Authors: , Li, Qi, Mo, Kaichun, Yang, Yanchao, Zhao, Hang, Guibas, Leonidas</br>
  Building embodied intelligent agents that can interact with 3D indoor environments has received increasing research attention in recent years. While most works focus on single-object or agent-object visual functionality and affordances, our work proposes to study a new kind of visual relationship that is also important to perceive and model -- inter-object functional relationships (e.g., a switch on the wall turns on or off the light, a remote control operates the TV). Humans often spend little or no effort to infer these relationships, even when entering a new room, by using our strong prior knowledge (e.g., we know that buttons control electrical devices) or using only a few exploratory interactions in cases of uncertainty (e.g., multiple switches and lights in the same room). In this paper, we take the first step in building AI system learning inter-object functional relationships in 3D indoor environments with key technical contributions of modeling prior knowledge by training over large-scale scenes and designing interactive policies for effectively exploring the training scenes and quickly adapting to novel test scenes. We create a new benchmark based on the AI2Thor and PartNet datasets and perform extensive experiments that prove the effectiveness of our proposed method. Results show that our model successfully learns priors and fast-interactive-adaptation strategies for exploring inter-object functional relationships in complex 3D scenes. Several ablation studies further validate the usefulness of each proposed module. </br></br>

<a href='http://arxiv.org/pdf/2112.05729.pdf'>2112.05729</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0582баллов, №667</br>
<b>Learning soft interventions in complex equilibrium systems</b></br>
Authors: , Besserve, Michel, Sch&#xf6;lkopf, Bernhard</br>
  Complex systems often contain feedback loops that can be described as cyclic causal models. Intervening in such systems may lead to counter-intuitive effects, which cannot be inferred directly from the graph structure. After establishing a framework for differentiable interventions based on Lie groups, we take advantage of modern automatic differentiation techniques and their application to implicit functions in order to optimize interventions in cyclic causal models. We illustrate the use of this framework by investigating scenarios of transition to sustainable economies. </br></br>

<a href='http://arxiv.org/pdf/2112.06080.pdf'>2112.06080</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0585баллов, №668</br>
<b>UPV at TREC Health Misinformation Track 2021 Ranking with SBERT and\n  Quality Estimators</b></br>
Authors: , Schlicht, Ipek Baris, de Paula, Angel Felipe Magnoss&#xe3;o, Rosso, Paolo</br>
  Health misinformation on search engines is a significant problem that could negatively affect individuals or public health. To mitigate the problem, TREC organizes a health misinformation track. This paper presents our submissions to this track. We use a BM25 and a domain-specific semantic search engine for retrieving initial documents. Later, we examine a health news schema for quality assessment and apply it to re-rank documents. We merge the scores from the different components by using reciprocal rank fusion. Finally, we discuss the results and conclude with future works. </br></br>

<a href='http://arxiv.org/pdf/2112.06920.pdf'>2112.06920</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.0587баллов, №669</br>
<b>Boosting Independent Component Analysis</b></br>
Authors: , Li, Yunpeng, Ye, ZhaoHui</br>
  Independent component analysis is intended to recover the unknown components as independent as possible from their linear mixtures. This technique has been widely used in many fields, such as data analysis, signal processing, and machine learning. In this paper, we present a novel boosting-based algorithm for independent component analysis. Our algorithm fills the gap in the nonparametric independent component analysis by introducing boosting to maximum likelihood estimation. A variety of experiments validate its performance compared with many of the presently known algorithms. </br></br>

<a href='http://arxiv.org/pdf/2111.14039.pdf'>2111.14039</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0627баллов, №670</br>
<b>Generalization Performance of Empirical Risk Minimization on\n  Over-parameterized Deep ReLU Nets</b></br>
Authors: , Lin, Shao-Bo, Wang, Yao, Zhou, Ding-Xuan</br>
  In this paper, we study the generalization performance of global minima for implementing empirical risk minimization (ERM) on over-parameterized deep ReLU nets. Using a novel deepening scheme for deep ReLU nets, we rigorously prove that there exist perfect global minima achieving almost optimal generalization error bounds for numerous types of data under mild conditions. Since over-parameterization is crucial to guarantee that the global minima of ERM on deep ReLU nets can be realized by the widely used stochastic gradient descent (SGD) algorithm, our results indeed fill a gap between optimization and generalization. </br></br>

<a href='http://arxiv.org/pdf/2112.05478.pdf'>2112.05478</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0627баллов, №671</br>
<b>Critical configurations for three projective views</b></br>
Authors: , Br&#xe5;telund, Martin</br>
  The problem of structure from motion is concerned with recovering the 3-dimensional structure of an object from a set of 2-dimensional images. Generally, all information can be uniquely recovered if enough images and image points are provided, yet there are certain cases where unique recovery is impossible; these are called critical configurations. In this paper we use an algebraic approach to study the critical configurations for three projective cameras. We show that all critical configurations lie on the intersection of quadric surfaces, and classify exactly which intersections constitute a critical configuration. </br></br>

<a href='http://arxiv.org/pdf/2112.08172.pdf'>2112.08172</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.0628баллов, №672</br>
<b>Binary Polarization Shift Keying with Reconfigurable Intelligent\n  Surfaces</b></br>
Authors: , Ibrahim, Emad, Nilsson, Rickard, van de Beek, Jaap</br>
  We propose a novel binary polarization shift keying modulation scheme for a line-of-sight environment by exploiting the polarization control ability of the reconfigurable intelligent surface (RIS). The RIS encodes the information data in terms of the polarization states of either the reflected wave from the RIS or the composite wireless channel between an RF source and receiver. In the first case, polarization mismatch correction becomes essential at the receiver. In the second case, the RIS pre-codes the reflected wave to compensate for the polarization mismatch which allows non-coherent demodulation at the receiver. </br></br>

<a href='http://arxiv.org/pdf/2112.08093.pdf'>2112.08093</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.0633баллов, №673</br>
<b>Towards Controllable Agent in MOBA Games with Generative Modeling</b></br>
Authors: , Zhang, Shubao</br>
  We propose novel methods to develop action controllable agent that behaves like a human and has the ability to align with human players in Multiplayer Online Battle Arena (MOBA) games. By modeling the control problem as an action generation process, we devise a deep latent alignment neural network model for training agent, and a corresponding sampling algorithm for controlling an agent\'s action. Particularly, we propose deterministic and stochastic attention implementations of the core latent alignment model. Both simulated and online experiments in the game Honor of Kings demonstrate the efficacy of the proposed methods. </br></br>

<a href='http://arxiv.org/pdf/2112.03815.pdf'>2112.03815</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0634баллов, №674</br>
<b>Accurate parameter estimation using scan-specific unsupervised deep\n  learning for relaxometry and MR fingerprinting</b></br>
Authors: , Gao, Mengze, Ye, Huihui, Kim, Tae Hyung, Zhang, Zijing, So, Seohee, Bilgic, Berkin</br>
  We propose an unsupervised convolutional neural network (CNN) for relaxation parameter estimation. This network incorporates signal relaxation and Bloch simulations while taking advantage of residual learning and spatial relations across neighboring voxels. Quantification accuracy and robustness to noise is shown to be significantly improved compared to standard parameter estimation methods in numerical simulations and in vivo data for multi-echo T2 and T2* mapping. The combination of the proposed network with subspace modeling and MR fingerprinting (MRF) from highly undersampled data permits high quality T1 and T2 mapping. </br></br>

<a href='http://arxiv.org/pdf/2112.07508.pdf'>2112.07508</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0649баллов, №675</br>
<b>Anti-Money Laundering Alert Optimization Using Machine Learning with\n  Graphs</b></br>
Authors: , Eddin, Ahmad Naser, Bono, Jacopo, Apar&#xed;cio, David, Polido, David, Ascens&#xe3;o, Jo&#xe3;o Tiago, Bizarro, Pedro, Ribeiro, Pedro</br>
  Money laundering is a global problem that concerns legitimizing proceeds from serious felonies (1.7-4 trillion euros annually) such as <font color="#00be00">drug</font> dealing, human trafficking, or corruption. The anti-money laundering systems deployed by <font color="#be00be">financ</font>ial institutions typically comprise rules aligned with regulatory frameworks. Human investigators review the alerts and report suspicious cases. Such systems suffer from high false-positive rates, undermining their effectiveness and resulting in high operational costs. We propose a machine learning triage model, which complements the rule-based system and learns to predict the risk of an alert accurately. Our model uses both entity-centric engineered features and attributes characterizing inter-entity relations in the form of graph-based features. We leverage time windows to construct the dynamic graph, optimizing for time and space efficiency. We validate our model on a <font color="#009600">real-world</font> banking dataset and show how the triage model can reduce the number of false positives by 80% while detecting over 90% of true positives. In this way, our model can significantly improve anti-money laundering operations. </br></br>

<a href='http://arxiv.org/pdf/2112.07349.pdf'>2112.07349</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.0657баллов, №676</br>
<b>Supervised Learning for Multi Zone Sound Field Reproduction under Harsh\n  Environmental Conditions</b></br>
Authors: , Sallandt, Henry, Krah, Philipp, Lemke, Mathias</br>
  This manuscript presents an approach for multi zone sound field reproduction using supervised learning. Traditional multi zone sound field reproduction methods assume constant speed of sound, neglecting nonlinear effects like wind and temperature stratification. We show how to overcome these restrictions using supervised learning of transfer functions. The quality of the solution is measured by the acoustic contrast and the reproduction error. Our results show that for the chosen setup, even with relatively small wind speeds, the acoustic contrast and reproduction error can be improved by up to 16 dB, when wind is considered in the trained model. </br></br>

<a href='http://arxiv.org/pdf/2112.05982.pdf'>2112.05982</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.0659баллов, №677</br>
<b>Overview of The MediaEval 2021 Predicting Media Memorability Task</b></br>
Authors: , Kiziltepe, Rukiye Savran, Constantin, Mihai Gabriel, Demarty, Claire-Helene, Healy, Graham, Fosco, Camilo, de Herrera, Alba Garcia Seco, Halder, Sebastian, Ionescu, Bogdan, Matran-Fernandez, Ana, Smeaton, Alan F., Sweeney, Lorin</br>
  This paper describes the MediaEval 2021 Predicting Media Memorability}task, which is in its 4th edition this year, as the prediction of short-term and long-term video memorability remains a challenging task. In 2021, two datasets of videos are used: first, a subset of the TRECVid 2019 Video-to-Text dataset; second, the Memento10K dataset in order to provide opportunities to explore cross-dataset generalisation. In addition, an Electroencephalography (EEG)-based prediction pilot subtask is introduced. In this paper, we outline the main aspects of the task and describe the datasets, evaluation metrics, and requirements for participants\' submissions. </br></br>

<a href='http://arxiv.org/pdf/2112.06380.pdf'>2112.06380</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.0694баллов, №678</br>
<b>Robust Voting Rules from Algorithmic Robust Statistics</b></br>
Authors: , Liu, Allen, Moitra, Ankur</br>
  In this work we study the problem of robustly learning a Mallows model. We give an algorithm that can accurately estimate the central ranking even when a constant fraction of its samples are arbitrarily corrupted. Moreover our robustness guarantees are dimension-independent in the sense that our overall accuracy does not depend on the number of alternatives being ranked. Our work can be thought of as a natural infusion of perspectives from algorithmic robust statistics into one of the central inference problems in voting and information-aggregation. Specifically, our voting rule is efficiently computable and its outcome cannot be changed by much by a large group of colluding voters. </br></br>

<a href='http://arxiv.org/pdf/2112.05664.pdf'>2112.05664</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0699баллов, №679</br>
<b>On the Relationships between Transform-Learning NMF and\n  Joint-Diagonalization</b></br>
Authors: , Zhang, Sixin, Soubies, Emmanuel, F&#xe9;votte, C&#xe9;dric</br>
  Non-negative matrix factorization with transform learning (TL-NMF) is a recent idea that aims at learning data representations suited to NMF. In this work, we relate TL-NMF to the classical matrix joint-diagonalization (JD) problem. We show that, when the number of data realizations is sufficiently large, TL-NMF can be replaced by a two-step approach -- termed as JD+NMF -- that estimates the transform through JD, prior to NMF computation. In contrast, we found that when the number of data realizations is limited, not only is JD+NMF no longer equivalent to TL-NMF, but the inherent low-rank constraint of TL-NMF turns out to be an essential ingredient to learn meaningful transforms for NMF. </br></br>

<a href='http://arxiv.org/pdf/2112.07485.pdf'>2112.07485</a> &nbsp&nbsp (cs:ET, cs:ML) &nbsp&nbsp -0.0703баллов, №680</br>
<b>Pruning Coherent Integrated Photonic Neural Networks Using the Lottery\n  Ticket Hypothesis</b></br>
Authors: , Banerjee, Sanmitra, Nikdast, Mahdi, Pasricha, Sudeep, Chakrabarty, Krishnendu</br>
  Singular-value-decomposition-based coherent integrated photonic neural networks (SC-IPNNs) have a large footprint, suffer from high static power consumption for training and inference, and cannot be pruned using conventional DNN pruning techniques. We leverage the lottery ticket hypothesis to propose the first hardware-aware pruning method for SC-IPNNs that alleviates these challenges by minimizing the number of weight parameters. We prune a multi-layer perceptron-based SC-IPNN and show that up to 89% of the phase angles, which correspond to weight parameters in SC-IPNNs, can be pruned with a negligible accuracy loss (smaller than 5%) while reducing the static power consumption by up to 86%. </br></br>

<a href='http://arxiv.org/pdf/2112.08018.pdf'>2112.08018</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.0704баллов, №681</br>
<b>MissMarple : A Novel Socio-inspired Feature-transfer Learning Deep\n  Network for Image Splicing Detection</b></br>
Authors: , Gokhale, Angelina L., Pramod, Dhanya, Thepade, Sudeep D., Kulkarni, Ravi</br>
  In this paper we propose a novel socio-inspired convolutional neural network (CNN) deep learning model for image splicing detection. Based on the premise that learning from the detection of coarsely spliced image regions can improve the detection of visually imperceptible finely spliced image forgeries, the proposed model referred to as, MissMarple, is a twin CNN network involving feature-transfer learning. Results obtained from training and testing the proposed model using the benchmark datasets like Columbia splicing, WildWeb, DSO1 and a proposed dataset titled AbhAS consisting of realistic splicing forgeries revealed improvement in detection accuracy over the existing deep learning models. </br></br>

<a href='http://arxiv.org/pdf/2112.06087.pdf'>2112.06087</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp -0.0705баллов, №682</br>
<b>Convergence of Generalized Belief Propagation Algorithm on Graphs with\n  Motifs</b></br>
Authors: , Chen, Yitao, Vasal, Deepanshu</br>
  Belief propagation is a fundamental message-passing algorithm for numerous applications in machine learning. It is known that belief propagation algorithm is exact on tree graphs. However, belief propagation is run on loopy graphs in most applications. So, understanding the behavior of belief propagation on loopy graphs has been a major topic for researchers in different areas. In this paper, we study the convergence behavior of generalized belief propagation algorithm on graphs with motifs (triangles, loops, etc.) We show under a certain initialization, generalized belief propagation converges to the global optimum of the Bethe free energy for ferromagnetic Ising models on graphs with motifs. </br></br>

<a href='http://arxiv.org/pdf/2112.06864.pdf'>2112.06864</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0718баллов, №683</br>
<b>Frontiers in Collective Intelligence: A Workshop Report</b></br>
Authors: , Millhouse, Tyler, Moses, Melanie, Mitchell, Melanie</br>
  In August of 2021, the Santa Fe Institute hosted a workshop on collective intelligence as part of its Foundations of Intelligence project. This project seeks to advance the field of artificial intelligence by promoting interdisciplinary research on the nature of intelligence. The workshop brought together computer scientists, biologists, philosophers, social scientists, and others to share their insights about how intelligence can emerge from interactions among multiple agents--whether those agents be machines, animals, or human beings. In this report, we summarize each of the talks and the subsequent discussions. We also draw out a number of key themes and identify important frontiers for future research. </br></br>

<a href='http://arxiv.org/pdf/2111.07173.pdf'>2111.07173</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.0719баллов, №684</br>
<b>Finite State Markov Modeling of C-V2X Erasure Links For Performance and\n  Stability Analysis of Platooning Applications</b></br>
Authors: , Razzaghpour, Mahdi, Datar, Adwait, Schneider, Daniel, Zaman, Mahdi, Werner, Herbert, Frey, Hannes, Velni, Javad Mohammadpour, Fallah, Yaser P.</br>
  Cooperative driving systems, such as platooning, rely on communication and information exchange to create situational awareness for each agent. Design and performance of control components are therefore tightly coupled with communication component performance. The information flow between vehicles can significantly affect the dynamics of a platoon. Therefore, both the performance and the stability of a platoon depend not only on the vehicle\'s controller but also on the information flow Topology (IFT). The IFT can cause limitations for certain platoon properties, i.e., stability and scalability. Cellular Vehicle-To-Everything (C-V2X) has emerged as one of the main communication technologies to support connected and automated vehicle applications. As a result of packet loss, wireless channels create random link interruption and changes in network topologies. In this paper, we model the communication links between vehicles with a first-order Markov model to capture the prevalent time correlations for each link. These models enable performance evaluation through better approximation of communication links during system design stages. Our approach is to use data from experiments to model the Inter-Packet Gap (IPG) using Markov chains and derive transition probability matrices for consecutive IPG states. Training data is collected from high fidelity simulations using models derived based on empirical data for a variety of different vehicle densities and communication rates. Utilizing the IPG models, we analyze the mean-square stability of a platoon of vehicles with the standard consensus protocol tuned for ideal communication and compare the degradation in performance for different scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.06288.pdf'>2112.06288</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.0725баллов, №685</br>
<b>Fairness for Robust Learning to Rank</b></br>
Authors: , Memarrast, Omid, Rezaei, Ashkan, Fathony, Rizal, Ziebart, Brian</br>
  While conventional ranking systems focus solely on maximizing the utility of the ranked items to users, fairness-aware ranking systems additionally try to balance the exposure for different protected attributes such as gender or race. To achieve this type of group fairness for ranking, we derive a new ranking system based on the first principles of distributional robustness. We formulate a minimax game between a player choosing a distribution over rankings to maximize utility while satisfying fairness constraints against an adversary seeking to minimize utility while matching statistics of the training data. We show that our approach provides better utility for highly fair rankings than existing baseline methods. </br></br>

<a href='http://arxiv.org/pdf/2111.05530.pdf'>2111.05530</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0740баллов, №686</br>
<b>Nearly Optimal Linear Convergence of Stochastic Primal-Dual Methods for\n  Linear Programming</b></br>
Authors: , Lu, Haihao, Yang, Jinwen</br>
  There is a recent interest on first-order methods for linear programming (LP). In this paper,we propose a stochastic algorithm using variance reduction and restarts for solving sharp primal-dual problems such as LP. We show that the proposed stochastic method exhibits a linear convergence rate for solving sharp instances with a high probability. In addition, we propose an efficient coordinate-based stochastic oracle for unconstrained bilinear problems, which has $\\mathcal O(1)$ per iteration cost and improves the complexity of the existing deterministic and stochastic algorithms. Finally, we show that the obtained linear convergence rate is nearly optimal (upto $\\log$ terms) for a wide class of stochastic primal dual methods. </br></br>

<a href='http://arxiv.org/pdf/2112.08361.pdf'>2112.08361</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0750баллов, №687</br>
<b>Deep Generative Models for Vehicle Speed Trajectories</b></br>
Authors: , Behnia, Farnaz, Karbowski, Dominik, Sokolov, Vadim</br>
  Generating realistic vehicle speed trajectories is a crucial component in evaluating vehicle fuel economy and in predictive control of self-driving cars. Traditional generative models rely on Markov chain methods and can produce accurate synthetic trajectories but are subject to the curse of dimensionality. They do not allow to include conditional input variables into the generation process. In this paper, we show how extensions to deep generative models allow accurate and scalable generation. Proposed architectures involve recurrent and feed-forward layers and are trained using adversarial techniques. Our models are shown to perform well on generating vehicle trajectories using a model trained on GPS data from Chicago metropolitan area. </br></br>

<a href='http://arxiv.org/pdf/2112.06467.pdf'>2112.06467</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0767баллов, №688</br>
<b>An Informative <font color="#be00be">Tracking</font> Benchmark</b></br>
Authors: , Li, Xin, Liu, Qiao, Pei, Wenjie, Shen, Qiuhong, Wang, Yaowei, Lu, Huchuan, Yang, Ming-Hsuan</br>
  Along with the rapid progress of visual <font color="#be00be">tracking</font>, existing benchmarks become less informative due to redundancy of samples and weak discrimination between current <font color="#be00be">tracker</font>s, making evaluations on all datasets extremely time-consuming. Thus, a small and informative benchmark, which covers all typical challenging scenarios to facilitate assessing the tracker performance, is of great interest. In this work, we develop a principled way to construct a small and informative tracking benchmark (ITB) with 7% out of 1.2 M frames of existing and newly collected datasets, which enables efficient evaluation while ensuring effectiveness. Specifically, we first design a quality assessment mechanism to select the most informative sequences from existing benchmarks taking into account 1) challenging level, 2) discriminative strength, 3) and density of appearance variations. Furthermore, we collect additional sequences to ensure the diversity and balance of tracking scenarios, leading to a total of 20 sequences for each scenario. By analyzing the results of 15 <font color="#00be00">state-of-the-art</font> trackers re-trained on the same data, we determine the effective methods for robust tracking under each scenario and demonstrate new challenges for future research direction in this field. </br></br>

<a href='http://arxiv.org/pdf/2112.07640.pdf'>2112.07640</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.0775баллов, №689</br>
<b>How and Why to Manipulate Your Own Agent</b></br>
Authors: , Kolumbus, Yoav, Nisan, Noam</br>
  We consider strategic settings where several users engage in a repeated online interaction, assisted by regret-minimizing agents that repeatedly play a &quot;game&quot; on their behalf. We study the dynamics and average outcomes of the repeated game of the agents, and view it as inducing a meta-game between the users. Our main focus is on whether users can benefit in this meta-game from &quot;manipulating&quot; their own agent by mis-reporting their parameters to it. We formally define this &quot;user-agent meta-game&quot; model for general games, discuss its properties under different notions of convergence of the dynamics of the automated agents and analyze the equilibria induced on the users in 2x2 games in which the dynamics converge to a single equilibrium. </br></br>

<a href='http://arxiv.org/pdf/2112.06587.pdf'>2112.06587</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0778баллов, №690</br>
<b>An Introduction to Quantum Computing for Statisticians</b></br>
Authors: , Lopatnikova, Anna, Tran, Minh-Ngoc</br>
  Quantum computing has the potential to revolutionise and change the way we live and understand the world. This review aims to provide an accessible introduction to quantum computing with a focus on applications in statistics and data analysis. We start with an introduction to the basic concepts necessary to understand quantum computing and the differences between quantum and classical computing. We describe the core quantum subroutines that serve as the building blocks of quantum algorithms. We then review a range of quantum algorithms expected to deliver a computational advantage in statistics and machine learning. We highlight the challenges and opportunities in applying quantum computing to problems in statistics and discuss potential future research directions. </br></br>

<a href='http://arxiv.org/pdf/2112.03528.pdf'>2112.03528</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0786баллов, №691</br>
<b>Physics guided deep learning generative models for crystal materials\n  discovery</b></br>
Authors: , Zhao, Yong, Siriwardane, Edirisuriya MD, Hu, Jianjun</br>
  Deep learning based generative models such as deepfake have been able to generate amazing images and videos. However, these models may need significant transformation when applied to generate crystal materials structures in which the building blocks, the physical atoms are very different from the pixels. Naively transferred generative models tend to generate a large portion of physically infeasible crystal structures that are not stable or synthesizable. Herein we show that by exploiting and adding physically oriented data augmentation, loss function terms, and post processing, our deep adversarial network (GAN) based generative models can now generate crystal structures with higher physical feasibility and expand our previous models which can only create cubic structures. </br></br>

<a href='http://arxiv.org/pdf/2112.07512.pdf'>2112.07512</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.0791баллов, №692</br>
<b>Adversarial Examples for Extreme Multilabel Text Classification</b></br>
Authors: , Qaraei, Mohammadreza, Babbar, Rohit</br>
  Extreme Multilabel Text Classification (XMTC) is a text classification problem in which, (i) the output space is extremely large, (ii) each data point may have multiple positive labels, and (iii) the data follows a strongly imbalanced distribution. With applications in <font color="#be00be">recommendat</font>ion systems and automatic tagging of web-scale documents, the research on XMTC has been focused on improving prediction accuracy and dealing with imbalanced data. However, the robustness of deep learning based XMTC models against adversarial examples has been largely underexplored.   In this paper, we investigate the behaviour of XMTC models under <font color="#be00be">adversarial att</font>acks. To this end, first, we define adversarial attacks in multilabel text classification problems. We categorize attacking multilabel text classifiers as (a) positive-targeted, where the target positive label should fall out of top-k predicted labels, and (b) negative-targeted, where the target negative label should be among the top-k predicted labels. Then, by experiments on APLC-XLNet and AttentionXML, we show that XMTC models are highly vulnerable to positive-targeted attacks but more robust to negative-targeted ones. Furthermore, our experiments show that the success rate of positive-targeted adversarial attacks has an imbalanced distribution. More precisely, tail classes are highly vulnerable to adversarial attacks for which an attacker can generate adversarial samples with high similarity to the actual data-points. To overcome this problem, we explore the effect of rebalanced loss functions in XMTC where not only do they increase accuracy on tail classes, but they also improve the robustness of these classes against adversarial attacks. The code for our experiments is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/xmc-aalto/adv-xmtc </br></br>

<a href='http://arxiv.org/pdf/2112.06287.pdf'>2112.06287</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0793баллов, №693</br>
<b>Identifying bias in cluster quality metrics</b></br>
Authors: , Renedo-Mirambell, Mart&#xed;, Arratia, Argimiro</br>
  We study potential biases of popular cluster quality metrics, such as conductance or modularity. We propose a method that uses both stochastic and preferential attachment block models construction to generate networks with preset community structures, to which quality metrics will be applied. These models also allow us to generate multi-level structures of varying strength, which will show if metrics favour partitions into a larger or smaller number of clusters. Additionally, we propose another quality metric, the density ratio.   We observed that most of the studied metrics tend to favour partitions into a smaller number of big clusters, even when their relative internal and external connectivity are the same. The metrics found to be less biased are modularity and density ratio. </br></br>

<a href='http://arxiv.org/pdf/2111.11249.pdf'>2111.11249</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0798баллов, №694</br>
<b>LeQua@CLEF2022: Learning to Quantify</b></br>
Authors: , Esuli, Andrea, Moreo, Alejandro, Sebastiani, Fabrizio</br>
  LeQua 2022 is a new lab for the evaluation of methods for &quot;learning to quantify&quot; in textual datasets, i.e., for training predictors of the relative frequencies of the classes of interest in sets of unlabelled textual documents. While these predictions could be easily achieved by first classifying all documents via a text classifier and then counting the numbers of documents assigned to the classes, a growing body of literature has shown this approach to be suboptimal, and has proposed better methods. The goal of this lab is to provide a setting for the comparative evaluation of methods for learning to quantify, both in the binary setting and in the single-label multiclass setting. For each such setting we provide data either in ready-made vector form or in raw document form. </br></br>

<a href='http://arxiv.org/pdf/2112.05561.pdf'>2112.05561</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0833баллов, №695</br>
<b>Global Attention Mechanism: Retain Information to Enhance\n  Channel-Spatial Interactions</b></br>
Authors: , Liu, Yichao, Shao, Zongru, Hoffmann, Nico</br>
  A variety of attention mechanisms have been studied to improve the performance of various computer vision tasks. However, the prior methods overlooked the significance of retaining the information on both channel and spatial aspects to enhance the cross-dimension interactions. Therefore, we propose a global attention mechanism that boosts the performance of deep neural networks by reducing information reduction and magnifying the global interactive representations. We introduce 3D-permutation with multilayer-perceptron for channel attention alongside a convolutional spatial attention submodule. The evaluation of the proposed mechanism for the image classification task on CIFAR-100 and ImageNet-1K indicates that our method stably <font color="#00be00">outperform</font>s several recent attention mechanisms with both ResNet and <font color="#be00be">lightweight</font> MobileNet. </br></br>

<a href='http://arxiv.org/pdf/2112.06888.pdf'>2112.06888</a> &nbsp&nbsp (cs:CL, cs:CV, cs:ML) &nbsp&nbsp -0.0833баллов, №696</br>
<b>Improving and <font color="#be00be">Diagnos</font>ing Knowledge-Based Visual Question Answering via\n  Entity Enhanced Knowledge Injection</b></br>
Authors: , Garcia-Olano, Diego, Onoe, Yasumasa, Ghosh, Joydeep</br>
  Knowledge-Based Visual Question Answering (KBVQA) is a bi-modal task requiring external world knowledge in order to correctly answer a text question and associated image. Recent single modality text work has shown knowledge injection into pre-trained language models, specifically entity enhanced <font color="#960096">knowledge graph</font> embeddings, can improve performance on downstream entity-centric tasks. In this work, we empirically study how and whether such methods, applied in a bi-modal setting, can improve an existing VQA system\'s performance on the KBVQA task. We experiment with two large <font color="#00be00">publicly available</font> VQA datasets, (1) KVQA which contains mostly rare Wikipedia entities and (2) OKVQA which is less entity-centric and more aligned with common sense reasoning. Both lack explicit entity spans and we study the effect of different weakly supervised and manual methods for obtaining them. Additionally we analyze how recently proposed bi-modal and single modal attention explanations are affected by the incorporation of such entity enhanced representations. Our results show substantial improved performance on the KBVQA task without the need for additional costly pre-training and we provide insights for when entity knowledge injection helps improve a model\'s understanding. We provide code and enhanced datasets for reproducibility. </br></br>

<a href='http://arxiv.org/pdf/2112.06774.pdf'>2112.06774</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.0840баллов, №697</br>
<b>Mean-square-error-based secondary source placement in sound field\n  synthesis with prior information on desired field</b></br>
Authors: , Kimura, Keisuke, Koyama, Shoichi, Ueno, Natsuki, Saruwatari, Hiroshi</br>
  A method of optimizing secondary source placement in sound field synthesis is proposed. Such an optimization method will be useful when the allowable placement region and available number of loudspeakers are limited. We formulate a mean-square-error-based cost function, incorporating the statistical properties of possible desired sound fields, for general linear-least-squares-based sound field synthesis methods, including pressure matching and (weighted) mode matching, whereas most of the current methods are applicable only to the pressure-matching method. An efficient greedy algorithm for minimizing the proposed cost function is also derived. Numerical experiments indicated that a high reproduction accuracy can be achieved by the placement optimized by the proposed method compared with the empirically used regular placement. </br></br>

<a href='http://arxiv.org/pdf/2112.07785.pdf'>2112.07785</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.0841баллов, №698</br>
<b>Variable Selection and Regularization via Arbitrary Rectangle-range\n  Generalized Elastic Net</b></br>
Authors: , Ding, Yujia, Peng, Qidi, Song, Zhengming, Chen, Hansen</br>
  We introduce the arbitrary rectangle-range generalized elastic net penalty method, abbreviated to ARGEN, for performing constrained variable selection and regularization in high-dimensional sparse linear models. As a natural extension of the nonnegative elastic net penalty method, ARGEN is proved to have variable selection consistency and estimation consistency under some conditions. The asymptotic behavior in distribution of the ARGEN estimators have been studied. We also propose an algorithm called MU-QP-RR-W-$l_1$ to efficiently solve ARGEN. By conducting simulation study we show that ARGEN <font color="#00be00">outperform</font>s the elastic net in a number of settings. Finally an application of S&amp;P 500 index <font color="#be00be">tracking</font> with constraints on the stock allocations is performed to provide general guidance for adapting ARGEN to solve <font color="#009600">real-world</font> problems. </br></br>

<a href='http://arxiv.org/pdf/2112.08644.pdf'>2112.08644</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0844баллов, №699</br>
<b>A comparative study of paired versus unpaired deep learning methods for\n  physically enhancing digital rock image resolution</b></br>
Authors: , Niu, Yufu, Jackson, Samuel J., Alqahtani, Naif, Mostaghimi, Peyman, Armstrong, Ryan T.</br>
  X-ray micro-computed <font color="#be00be">tomography</font> (micro-CT) has been widely leveraged to characterise pore-scale geometry in subsurface porous rock. Recent developments in super resolution (SR) methods using deep learning allow the digital enhancement of low resolution (LR) images over large spatial scales, creating SR images comparable to the high resolution (HR) ground truth. This circumvents traditional resolution and field-of-view trade-offs. An outstanding issue is the use of paired (registered) LR and HR data, which is often required in the training step of such methods but is difficult to obtain. In this work, we rigorously compare two different <font color="#00be00">state-of-the-art</font> SR deep learning techniques, using both paired and unpaired data, with like-for-like ground truth data. The first approach requires paired images to train a convolutional neural network (CNN) while the second approach uses unpaired images to train a generative adversarial network (GAN). The two approaches are compared using a micro-CT carbonate rock sample with complicated micro-porous textures. We implemented various image based and numerical verifications and experimental validation to quantitatively evaluate the physical accuracy and sensitivities of the two methods. Our quantitative results show that unpaired GAN approach can reconstruct <font color="#be00be">super-resolution</font> images as precise as paired CNN method, with comparable training times and dataset requirement. This unlocks new applications for micro-CT image enhancement using unpaired deep learning methods; image registration is no longer needed during the data processing stage. Decoupled images from data storage platforms can be exploited more efficiently to train networks for SR digital rock applications. This opens up a new pathway for various applications of multi-scale flow simulation in heterogeneous porous media. </br></br>

<a href='http://arxiv.org/pdf/2112.07045.pdf'>2112.07045</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0847баллов, №700</br>
<b>Fuzzy Win-Win: A Novel Approach to Quantify Win-Win Using Fuzzy Logic</b></br>
Authors: , Hassanat, Ahmad B., Altarawneh, Ghada A., Tarawneh, Ahmad S.</br>
  The classic win-win has a key flaw in that it cannot offer the parties the right amounts of winning because each party believes they are winners. In reality, one party may win more than the other. This strategy is not limited to a single product or negotiation; it may be applied to a variety of situations in life. We present a novel way to measure the win-win situation in this paper. The proposed method employs Fuzzy logic to create a mathematical model that aids negotiators in quantifying their winning percentages. The model is put to the test on real-life negotiations scenarios such as the Iranian uranium enrichment negotiations, the Iraqi-Jordanian oil deal, and the iron ore negotiation (2005-2009). The presented model has shown to be a useful tool in practice and can be easily generalized to be utilized in other domains as well. </br></br>

<a href='http://arxiv.org/pdf/2112.03415.pdf'>2112.03415</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.0848баллов, №701</br>
<b>Producing augmentation-invariant embeddings from real-life imagery</b></br>
Authors: , Papadakis, Sergio Manuel, Addicam, Sanjay</br>
  This article presents an efficient way to produce feature-rich, high-dimensionality embedding spaces from real-life images. The features produced are designed to be independent from augmentations used in real-life cases which appear on social media. Our approach uses convolutional neural networks (CNN) to produce an embedding space. An ArcFace head was used to train the model by employing automatically produced augmentations. Additionally, we present a way to make an ensemble out of different embeddings containing the same semantic information, a way to normalize the resulting embedding using an external dataset, and a novel way to perform quick training of these models with a high number of classes in the ArcFace head. Using this approach we achieved the 2nd place in the 2021 Facebook AI Image Similarity Challenge: Descriptor Track. </br></br>

<a href='http://arxiv.org/pdf/2112.07344.pdf'>2112.07344</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0849баллов, №702</br>
<b>SC-Reg: Training Overparameterized Neural Networks under Self-Concordant\n  Regularization</b></br>
Authors: , Adeoye, Adeyemi D., Bemporad, Alberto</br>
  In this paper we propose the SC-Reg (self-concordant regularization) framework for learning overparameterized feedforward neural networks by incorporating second-order information in the \\emph{Newton decrement} framework for convex problems. We propose the generalized Gauss-Newton with Self-Concordant Regularization (SCoRe-GGN) algorithm that updates the network parameters each time it receives a new input batch. The proposed algorithm exploits the structure of the second-order information in the Hessian matrix, thereby reducing the training computational overhead. Although our current analysis considers only the convex case, numerical experiments show the efficiency of our method and its fast convergence under both convex and non-convex settings, which compare favorably against baseline first-order methods and a quasi-Newton method. </br></br>

<a href='http://arxiv.org/pdf/2112.00649.pdf'>2112.00649</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0852баллов, №703</br>
<b>Digital Twinning Remote Laboratories for Online Practical Learning</b></br>
Authors: , Palmer, Claire, Roullier, Ben, Aamir, Muhammad, McQuade, Frank, Stella, Leonardo, Anjum, Ashiq</br>
  The COVID19 pandemic has demonstrated a need for remote learning and virtual learning applications such as virtual reality (VR) and tablet-based solutions. Creating complex learning scenarios by developers is highly time-consuming and can take over a year. It is also costly to employ teams of system analysts, developers and 3D artists. There is a requirement to provide a simple method to enable lecturers to create their own content for their laboratory tutorials. Research has been undertaken into developing generic models to enable the semi-automatic creation of a virtual learning tools for subjects that require practical interactions with the lab resources. In addition to the system for creating digital twins, a case study describing the creation of a virtual learning application for an electrical laboratory tutorial has been presented. </br></br>

<a href='http://arxiv.org/pdf/2112.07395.pdf'>2112.07395</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0853баллов, №704</br>
<b>Handwritten text generation and strikethrough characters augmentation</b></br>
Authors: , Shonenkov, Alex, Karachev, Denis, Novopoltsev, Max, Potanin, Mark, Dimitrov, Denis, Chertok, Andrey</br>
  We introduce two data augmentation techniques, which, used with a Resnet-BiLSTM-CTC network, significantly reduce Word Error Rate (WER) and Character Error Rate (CER) beyond best-reported results on handwriting text recognition (HTR) tasks. We apply a novel augmentation that simulates strikethrough text (HandWritten Blots) and a handwritten text generation method based on printed text (StackMix), which proved to be very effective in HTR tasks. StackMix uses weakly-supervised framework to get character boundaries. Because these data augmentation techniques are independent of the network used, they could also be applied to enhance the performance of other networks and approaches to HTR. Extensive experiments on ten handwritten text datasets show that HandWritten Blots augmentation and StackMix significantly improve the quality of HTR models </br></br>

<a href='http://arxiv.org/pdf/2112.07765.pdf'>2112.07765</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0861баллов, №705</br>
<b>Nonlinear Discrete-time Systems\' Identification without Persistence of\n  Excitation: A Finite-time Concurrent Learning</b></br>
Authors: , Tatari, Farzaneh, Panayiotou, Chiristos, Polycarpou, Marios</br>
  This paper deals with the problem of finite-time learning for unknown discrete-time nonlinear systems\' dynamics, without the requirement of the persistence of excitation. A finite-time concurrent learning approach is presented to approximate the uncertainties of the discrete-time nonlinear systems in an on-line fashion by employing current data along with recorded experienced data satisfying an easy-to-check rank condition on the richness of the recorded data which is less restrictive in comparison with persistence of excitation condition. Rigorous proofs guarantee the finite-time convergence of the estimated parameters to their optimal values based on a discrete-time Lyapunov analysis. Compared with the existing work in the literature, simulation results illustrate that the proposed method can timely and precisely approximate the uncertainties. </br></br>

<a href='http://arxiv.org/pdf/2112.06917.pdf'>2112.06917</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0863баллов, №706</br>
<b>Branching Strategy Selection Approach Based on Vivification Ratio</b></br>
Authors: , Luo, Mao, Li, Chu-Min, Wu, Xinyun, Li, Shuolin, L&#xfc;, Zhipeng</br>
  The two most effective branching strategies LRB and VSIDS perform differently on different types of instances. Generally, LRB is more effective on crafted instances, while VSIDS is more effective on application ones. However, distinguishing the types of instances is difficult. To overcome this drawback, we propose a branching strategy selection approach based on the vivification ratio. This approach uses the LRB branching strategy more to solve the instances with a very low vivification ratio. We tested the instances from the main track of SAT competitions in recent years. The results show that the proposed approach is robust and it significantly increases the number of solved instances. It is worth mentioning that, with the help of our approach, the solver Maple\\_CM can solve more than 16 instances for the benchmark from the 2020 SAT competition. </br></br>

<a href='http://arxiv.org/pdf/2112.07499.pdf'>2112.07499</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0864баллов, №707</br>
<b>Reconfiguring Shortest Paths in Graphs</b></br>
Authors: , Gajjar, Kshitij, Jha, Agastya Vibhuti, Kumar, Manish, Lahiri, Abhiruk</br>
  Reconfiguring two shortest paths in a graph means modifying one shortest path to the other by changing one vertex at a time so that all the intermediate paths are also shortest paths. This problem has several natural applications, namely: (a) revamping road networks, (b) rerouting data packets in synchronous multiprocessing setting, (c) the shipping container stowage problem, and (d) the train marshalling problem.   When modelled as graph problems, (a) is the most general case while (b), (c) and (d) are restrictions to different graph classes. We show that (a) is intractable, even for relaxed variants of the problem. For (b), (c) and (d), we present efficient algorithms to solve the respective problems. We also generalize the problem to when at most $k$ (for a fixed integer $k\\geq 2$) contiguous vertices on a shortest path can be changed at a time. </br></br>

<a href='http://arxiv.org/pdf/2112.07216.pdf'>2112.07216</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.0868баллов, №708</br>
<b>Spatiogram: A phase based directional angular measure and perceptual\n  weighting for ensemble source width</b></br>
Authors: , S, Arthi, T V, Sreenivas</br>
  In concert hall studies, inter-aural cross-correlation (IACC), which is signal dependent, is used as a measure of perceptual source width. The same measure is used for perceptual source width in the case of distributed sources also. In this work, we examine the validity of IACC for both the cases and develop an improved measure for ensemble-like distributed sources. We decompose the new objective measure for perceptual ensemble source width (ESW) into two components (i) phase based directional angular measure, which is timbre independent (spatial measure) and (ii) mean time-bandwidth energy (MTBE), a perceptual weight, (timbre measure). This combination of spatial and timbral measures can be extended as an alternate measure for determining auditory source width (ASW) and listener envelopment (LEV) of arbitrary signals in concert-hall and room acoustics. </br></br>

<a href='http://arxiv.org/pdf/2112.08984.pdf'>2112.08984</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.0885баллов, №709</br>
<b>Object-based synthesis of scraping and rolling sounds based on\n  non-linear physical constraints</b></br>
Authors: , Agarwal, Vinayak, Cusimano, Maddie, Traer, James, McDermott, Josh</br>
  Sustained contact interactions like scraping and rolling produce a wide variety of sounds. Previous studies have explored ways to synthesize these sounds efficiently and intuitively but could not fully mimic the rich structure of real instances of these sounds. We present a novel source-filter model for realistic synthesis of scraping and rolling sounds with physically and perceptually relevant controllable parameters constrained by principles of mechanics. Key features of our model include non-linearities to constrain the contact force, naturalistic normal force variation for different motions, and a method for morphing impulse responses within a material to achieve location-dependence. Perceptual experiments show that the presented model is able to synthesize realistic scraping and rolling sounds while conveying physical information similar to that in recorded sounds. </br></br>

<a href='http://arxiv.org/pdf/2112.08429.pdf'>2112.08429</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0892баллов, №710</br>
<b>torch.fx: Practical Program Capture and Transformation for Deep Learning\n  in Python</b></br>
Authors: , Reed, James K., DeVito, Zachary, He, Horace, Ussery, Ansley, Ansel, Jason</br>
  Modern deep learning frameworks provide imperative, eager execution programming interfaces embedded in Python to provide a productive development experience. However, deep learning practitioners sometimes need to capture and transform program structure for performance optimization, visualization, analysis, and hardware integration. We study the different designs for program capture and transformation used in deep learning. By designing for typical deep learning use cases rather than long tail ones, it is possible to create a simpler framework for program capture and transformation. We apply this principle in torch.fx, a program capture and transformation library for PyTorch written entirely in Python and optimized for high developer productivity by ML practitioners. We present case studies showing how torch.fx enables workflows previously inaccessible in the PyTorch ecosystem. </br></br>

<a href='http://arxiv.org/pdf/2112.07782.pdf'>2112.07782</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0903баллов, №711</br>
<b>Deciphering antibody affinity maturation with language models and weakly\n  supervised learning</b></br>
Authors: , Ruffolo, Jeffrey A., Gray, Jeffrey J., Sulam, Jeremias</br>
  In response to pathogens, the adaptive immune system generates specific antibodies that bind and neutralize foreign antigens. Understanding the composition of an individual\'s immune repertoire can provide insights into this process and reveal potential therapeutic antibodies. In this work, we explore the application of antibody-specific language models to aid understanding of immune repertoires. We introduce AntiBERTy, a language model trained on 558M natural antibody sequences. We find that within repertoires, our model clusters antibodies into trajectories resembling affinity maturation. Importantly, we show that models trained to predict highly redundant sequences under a multiple instance learning framework identify key binding residues in the process. With further development, the methods presented here will provide new insights into antigen binding from repertoire sequences alone. </br></br>

<a href='http://arxiv.org/pdf/2111.15178.pdf'>2111.15178</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0907баллов, №712</br>
<b>Sparse deep computer-generated holography for optical microscopy</b></br>
Authors: , Liu, Alex, Xue, Yi, Waller, Laura</br>
  Computer-generated holography (CGH) has broad applications such as direct-view display, virtual and augmented reality, as well as optical microscopy. CGH usually utilizes a spatial light modulator that displays a computer-generated phase mask, modulating the phase of coherent light in order to generate customized patterns. The algorithm that computes the phase mask is the core of CGH and is usually tailored to meet different applications. CGH for optical microscopy usually requires 3D accessibility (i.e., generating overlapping patterns along the $z$-axis) and micron-scale spatial precision. Here, we propose a CGH algorithm using an unsupervised generative model designed for optical microscopy to synthesize 3D selected illumination. The algorithm, named sparse deep CGH, is able to generate sparsely distributed points in a large 3D volume with higher contrast than conventional CGH algorithms. </br></br>

<a href='http://arxiv.org/pdf/2112.05295.pdf'>2112.05295</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0922баллов, №713</br>
<b>3D Scene Understanding at Urban Intersection using Stereo Vision and\n  Digital Map</b></br>
Authors: , Bhattacharyya, Prarthana, Gu, Yanlei, Bao, Jiali, Liu, Xu, Kamijo, Shunsuke</br>
  The driving behavior at urban intersections is very complex. It is thus crucial for autonomous vehicles to comprehensively understand challenging urban traffic scenes in order to navigate intersections and prevent accidents. In this paper, we introduce a stereo vision and 3D digital map based approach to spatially and temporally analyze the traffic situation at urban intersections. Stereo vision is used to detect, classify and track obstacles, while a 3D digital map is used to improve ego-localization and provide context in terms of road-layout information. A probabilistic approach that temporally integrates these geometric, semantic, dynamic and contextual cues is presented. We qualitatively and quantitatively evaluate our proposed technique on real traffic data collected at an urban canyon in Tokyo to demonstrate the efficacy of the system in providing comprehensive awareness of the traffic surroundings. </br></br>

<a href='http://arxiv.org/pdf/2112.07207.pdf'>2112.07207</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.0923баллов, №714</br>
<b>Modeling Image Quantization Tradeoffs for Optimal Compression</b></br>
Authors: , Chiu, Johnathan</br>
  All Lossy compression algorithms employ similar compression schemes -- frequency domain transform followed by quantization and lossless encoding schemes. They target tradeoffs by quantizating high frequency data to increase compression rates which come at the cost of higher image distortion. We propose a new method of optimizing quantization tables using Deep Learning and a minimax loss function that more accurately measures the tradeoffs between rate and distortion parameters (RD) than previous methods. We design a convolutional neural network (CNN) that learns a mapping between image blocks and quantization tables in an unsupervised manner. By processing images across all channels at once, we can achieve stronger performance by also measuring tradeoffs in information loss between different channels. We initially target optimization on JPEG images but feel that this can be expanded to any lossy compressor. </br></br>

<a href='http://arxiv.org/pdf/2112.07846.pdf'>2112.07846</a> &nbsp&nbsp (cs:AI, cs:ET) &nbsp&nbsp -0.0930баллов, №715</br>
<b>Probabilistic Logic Gate in Asynchronous Game of Life with Critical\n  Property</b></br>
Authors: , Gunji, Yukio-Pegio, Ohzawa, Yoshihiko, Tanaka, Terutaka</br>
  Metaheuristic and self-organizing criticality (SOC) could contribute to robust computation under perturbed environments. Implementing a logic gate in a computing system in a critical state is one of the intriguing ways to study the role of metaheuristics and SOCs. Here, we study the behavior of cellular automaton, game of life (GL), in asynchronous updating and implement probabilistic logic gates by using asynchronous GL. We find that asynchronous GL shows a phase transition, that the density of the state of 1 decays with the power law at the critical point, and that systems at the critical point have the most computability in asynchronous GL. We implement AND and OR gates in asynchronous GL with criticality, which shows good performance. Since tuning perturbations play an essential role in operating logic gates, our study reveals the interference between manipulation and perturbation in probabilistic logic gates. </br></br>

<a href='http://arxiv.org/pdf/2112.05489.pdf'>2112.05489</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0940баллов, №716</br>
<b>Surrogate-data-enriched Physics-Aware Neural Networks</b></br>
Authors: , Leiteritz, Raphael, Buchfink, Patrick, Haasdonk, Bernard, Pfl&#xfc;ger, Dirk</br>
  Neural networks can be used as surrogates for PDE models. They can be made physics-aware by penalizing underlying equations or the conservation of physical properties in the loss function during training. Current approaches allow to additionally respect data from numerical simulations or experiments in the training process. However, this data is frequently expensive to obtain and thus only scarcely available for complex models. In this work, we investigate how physics-aware models can be enriched with computationally cheaper, but inexact, data from other surrogate models like Reduced-Order Models (ROMs). In order to avoid trusting too-low-fidelity surrogate solutions, we develop an approach that is sensitive to the error in inexact data. As a proof of concept, we consider the one-dimensional wave equation and show that the training accuracy is increased by two orders of magnitude when inexact data from ROMs is incorporated. </br></br>

<a href='http://arxiv.org/pdf/2112.06305.pdf'>2112.06305</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0950баллов, №717</br>
<b>Recalibrating probabilistic forecasts of epidemics</b></br>
Authors: , Rumack, Aaron, Tibshirani, Ryan J., Rosenfeld, Roni</br>
  Distributional forecasts are important for a wide variety of applications, including forecasting epidemics. Often, forecasts are miscalibrated, or unreliable in assigning uncertainty to future events. We present a recalibration method that can be applied to a black-box forecaster given retrospective forecasts and observations, as well as an extension to make this method more effective in recalibrating epidemic forecasts. This method is guaranteed to improve calibration and log score performance when trained and measured in-sample. We also prove that the increase in expected log score of a recalibrated forecaster is equal to the entropy of the PIT distribution. We apply this recalibration method to the 27 influenza forecasters in the FluSight Network and show that recalibration reliably improves forecast accuracy and calibration. This method is effective, robust, and easy to use as a post-processing tool to improve epidemic forecasts. </br></br>

<a href='http://arxiv.org/pdf/2112.07067.pdf'>2112.07067</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.0953баллов, №718</br>
<b>Dynamic Learning of Correlation Potentials for a Time-Dependent\n  Kohn-Sham System</b></br>
Authors: , Bhat, Harish S., Collins, Kevin, Gupta, Prachi, Isborn, Christine M.</br>
  We develop methods to learn the correlation potential for a time-dependent Kohn-Sham (TDKS) system in one spatial dimension. We start from a low-dimensional two-electron system for which we can numerically solve the time-dependent Schr\\&quot;odinger equation; this yields electron densities suitable for training models of the correlation potential. We frame the learning problem as one of optimizing a least-squares objective subject to the constraint that the dynamics obey the TDKS equation. Applying adjoints, we develop efficient methods to compute gradients and thereby learn models of the correlation potential. Our results show that it is possible to learn values of the correlation potential such that the resulting electron densities match ground truth densities. We also show how to learn correlation potential functionals with memory, demonstrating one such model that yields reasonable results for trajectories outside the training set. </br></br>

<a href='http://arxiv.org/pdf/2111.02636.pdf'>2111.02636</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.0960баллов, №719</br>
<b>A novel control method for solving high-dimensional Hamiltonian systems\n  through deep neural networks</b></br>
Authors: , Ji, Shaolin, Peng, Shige, Peng, Ying, Zhang, Xichuan</br>
  In this paper, we mainly focus on solving high-dimensional stochastic Hamiltonian systems with boundary condition, which is essentially a Forward Backward Stochastic Differential Equation (FBSDE in short), and propose a novel method from the view of the stochastic control. In order to obtain the approximated solution of the Hamiltonian system, we first introduce a corresponding stochastic optimal control problem such that the extended Hamiltonian system of the control problem is exactly what we need to solve, then we develop two different algorithms suitable for different cases of the control problem and approximate the stochastic control via deep neural networks. From the numerical results, comparing with the Deep FBSDE method developed previously from the view of solving FBSDEs, the novel algorithms converge faster, which means that they require fewer training steps, and demonstrate more stable convergences for different Hamiltonian systems. </br></br>

<a href='http://arxiv.org/pdf/2112.06397.pdf'>2112.06397</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0967баллов, №720</br>
<b>N-Cloth: Predicting 3D Cloth Deformation with Mesh-Based Networks</b></br>
Authors: , Li, Yudi, Tang, Min, Yang, Yun, Huang, Zi, Tong, Ruofeng, Yang, Shuangcai, Li, Yao, Manocha, Dinesh</br>
  We present a novel mesh-based learning approach (N-Cloth) for plausible 3D cloth deformation prediction. Our approach is general and can handle cloth or obstacles represented by triangle meshes with arbitrary topology. We use graph convolution to transform the cloth and object meshes into a latent space to reduce the non-linearity in the mesh space. Our network can predict the target 3D cloth mesh deformation based on the state of the initial cloth mesh template and the target obstacle mesh. Our approach can handle complex cloth meshes with up to $100$K triangles and scenes with various objects corresponding to SMPL humans, Non-SMPL humans, or rigid bodies. In practice, our approach demonstrates good temporal coherence between successive input frames and can be used to generate plausible cloth simulation at $30-45$ fps on an NVIDIA GeForce RTX 3090 GPU. We highlight its benefits over prior learning-based methods and physically-based cloth simulators. </br></br>

<a href='http://arxiv.org/pdf/2112.05682.pdf'>2112.05682</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.0968баллов, №721</br>
<b>Self-attention Does Not Need $O(n^2)$ Memory</b></br>
Authors: , Rabe, Markus N., Staats, Charles</br>
  We present a very simple algorithm for attention that requires $O(1)$ memory with respect to sequence length and an extension to self-attention that requires $O(\\log n)$ memory. This is in contrast with the frequently stated belief that self-attention requires $O(n^2)$ memory. While the time complexity is still $O(n^2)$, device memory rather than compute capability is often the limiting factor on modern accelerators. Thus, reducing the memory requirements of attention allows processing of longer sequences than might otherwise be feasible. We provide a practical implementation for accelerators that requires $O(\\sqrt{n})$ memory, is numerically stable, and is within a few percent of the runtime of the standard implementation of attention. We also demonstrate how to differentiate the function while remaining memory-efficient. For sequence length 16384, the memory overhead of self-attention is reduced by 59X for inference and by 32X for differentiation. </br></br>

<a href='http://arxiv.org/pdf/2112.06031.pdf'>2112.06031</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0969баллов, №722</br>
<b>Unsupervised Image to Image Translation for Multiple Retinal <font color="#be00be">Patholog</font>y\n  Synthesis in Optical Coherence <font color="#be00be">Tomography</font> Scans</b></br>
Authors: , Pasupuleti, Hemanth, Girish, G. N.</br>
  Image to Image Translation (I2I) is a challenging computer vision problem used in numerous domains for multiple tasks. Recently, ophthalmology became one of the major fields where the application of I2I is increasing rapidly. One such application is the generation of synthetic retinal optical coherence tomographic (OCT) scans. Existing I2I methods require training of multiple models to translate images from normal scans to a specific <font color="#be00be">patholog</font>y: limiting the use of these models due to their complexity. To address this issue, we propose an unsupervised multi-domain I2I network with pre-trained <font color="#be00be">style</font> encoder that translates retinal OCT images in one domain to multiple domains. We assume that the image splits into domain-invariant content and domain-specific style codes, and pre-train these style codes. The performed experiments show that the proposed model <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> models like MUNIT and CycleGAN synthesizing diverse pathological scans. </br></br>

<a href='http://arxiv.org/pdf/2112.05756.pdf'>2112.05756</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.0999баллов, №723</br>
<b>Enhancing Multi-Scale Implicit Learning in Image <font color="#be00be">Super-Resolution</font> with\n  Integrated Positional Encoding</b></br>
Authors: , Liu, Ying-Tian, Guo, Yuan-Chen, Zhang, Song-Hai</br>
  Is the center position fully capable of representing a pixel? There is nothing wrong to represent pixels with their centers in a discrete image representation, but it makes more sense to consider each pixel as the aggregation of signals from a local area in an image <font color="#be00be">super-resolution</font> (SR) context. Despite the great capability of coordinate-based implicit representation in the field of arbitrary-scale image SR, this area\'s nature of pixels is not fully considered. To this end, we propose integrated positional encoding (IPE), extending traditional positional encoding by aggregating frequency information over the pixel area. We apply IPE to the <font color="#00be00">state-of-the-art</font> arbitrary-scale image super-resolution method: local implicit image function (LIIF), presenting IPE-LIIF. We show the effectiveness of IPE-LIIF by quantitative and qualitative evaluations, and further demonstrate the generalization ability of IPE to larger image scales and multiple implicit-based methods. Code will be released. </br></br>

<a href='http://arxiv.org/pdf/2112.05195.pdf'>2112.05195</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1006баллов, №724</br>
<b>Context-aware Health Event Prediction via Transition Functions on\n  Dynamic <font color="#be00be">Diseas</font>e Graphs</b></br>
Authors: , Lu, Chang, Han, Tian, Ning, Yue</br>
  With the wide application of electronic health records (EHR) in healthcare facilities, health event prediction with deep learning has gained more and more attention. A common feature of EHR data used for deep-learning-based predictions is historical <font color="#be00be">diagnos</font>es. Existing work mainly regards a diagnosis as an independent <font color="#be00be">diseas</font>e and does not consider <font color="#be00be">clinic</font>al relations among diseases in a visit. Many machine learning approaches assume disease representations are static in different visits of a <font color="#be00be">patient</font>. However, in real practice, multiple diseases that are frequently diagnosed at the same time reflect hidden patterns that are conducive to prognosis. Moreover, the development of a disease is not static since some diseases can emerge or disappear and show various symptoms in different visits of a patient. To effectively utilize this combinational disease information and explore the dynamics of diseases, we propose a novel context-aware learning framework using transition functions on dynamic disease graphs. Specifically, we construct a global disease co-occurrence graph with multiple node properties for disease combinations. We design dynamic subgraphs for each patient\'s visit to leverage global and local contexts. We further define three diagnosis roles in each visit based on the variation of node properties to model disease transition processes. Experimental results on two <font color="#009600">real-world</font> EHR datasets show that the proposed model <font color="#00be00">outperform</font>s <font color="#00be00">state of the art</font> in predicting health events. </br></br>

<a href='http://arxiv.org/pdf/2112.07669.pdf'>2112.07669</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1018баллов, №725</br>
<b>AI and extreme scale computing to learn and infer the physics of higher\n  order gravitational wave modes of quasi-circular, spinning, non-precessing\n  binary black hole mergers</b></br>
Authors: , Khan, Asad, Huerta, E. A.</br>
  We use artificial intelligence (AI) to learn and infer the physics of higher order gravitational wave modes of quasi-circular, spinning, non precessing binary black hole mergers. We trained AI models using 14 million waveforms, produced with the surrogate model NRHybSur3dq8, that include modes up to $\\ell \\leq 4$ and $(5,5)$, except for $(4,0)$ and $(4,1)$, that describe binaries with mass-ratios $q\\leq8$ and individual spins $s^z_{\\{1,2\\}}\\in[-0.8, 0.8]$. We use our AI models to obtain deterministic and probabilistic estimates of the mass-ratio, individual spins, effective spin, and inclination angle of numerical relativity waveforms that describe such signal manifold. Our studies indicate that AI provides informative estimates for these physical parameters. This work marks the first time AI is capable of characterizing this high-dimensional signal manifold. Our AI models were trained within 3.4 hours using distributed training on 256 nodes (1,536 NVIDIA V100 GPUs) in the Summit supercomputer. </br></br>

<a href='http://arxiv.org/pdf/2112.06071.pdf'>2112.06071</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1019баллов, №726</br>
<b>Multi-Attention Multiple Instance Learning</b></br>
Authors: , Konstantinov, Andrei V., Utkin, Lev V.</br>
  A new multi-attention based method for solving the MIL problem (MAMIL), which takes into account the neighboring patches or instances of each analyzed patch in a bag, is proposed. In the method, one of the attention modules takes into account adjacent patches or instances, several attention modules are used to get a diverse feature representation of patches, and one attention module is used to unite different feature representations to provide an accurate classification of each patch (instance) and the whole bag. Due to MAMIL, a combined representation of patches and their neighbors in the form of embeddings of a small dimensionality for simple classification is realized. Moreover, different types of patches are efficiently processed, and a diverse feature representation of patches in a bag by using several attention modules is implemented. A simple approach for explaining the classification predictions of patches is proposed. Numerical experiments with various datasets illustrate the proposed method. </br></br>

<a href='http://arxiv.org/pdf/2112.08814.pdf'>2112.08814</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.1025баллов, №727</br>
<b>An Unsupervised Way to Understand Artifact Generating Internal Units in\n  Generative Neural Networks</b></br>
Authors: , Jeong, Haedong, Han, Jiyeon, Choi, Jaesik</br>
  Despite significant improvements on the image generation performance of Generative Adversarial Networks (GANs), generations with low visual fidelity still have been observed. As widely used metrics for GANs focus more on the overall performance of the model, evaluation on the quality of individual generations or detection of defective generations is challenging. While recent studies try to detect featuremap units that cause artifacts and evaluate individual samples, these approaches require additional resources such as external networks or a number of training data to approximate the real data manifold. In this work, we propose the concept of local activation, and devise a metric on the local activation to detect artifact generations without additional supervision. We empirically verify that our approach can detect and correct artifact generations from GANs with various datasets. Finally, we discuss a geometrical analysis to partially reveal the relation between the proposed concept and low visual fidelity. </br></br>

<a href='http://arxiv.org/pdf/2112.05861.pdf'>2112.05861</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1038баллов, №728</br>
<b>A Discriminative Channel Diversification Network for Image\n  Classification</b></br>
Authors: , Patel, Krushi, Wang, Guanghui</br>
  Channel attention mechanisms in convolutional neural networks have been proven to be effective in various computer vision tasks. However, the performance improvement comes with additional model complexity and computation cost. In this paper, we propose a light-weight and effective attention module, called channel diversification block, to enhance the global context by establishing the channel relationship at the global level. Unlike other channel attention mechanisms, the proposed module focuses on the most discriminative features by giving more attention to the spatially distinguishable channels while taking account of the channel activation. Different from other attention models that plugin the module in between several intermediate layers, the proposed module is embedded at the end of the backbone networks, making it easy to implement. Extensive experiments on CIFAR-10, SVHN, and Tiny-ImageNet datasets demonstrate that the proposed module improves the performance of the baseline networks by a margin of 3% on average. </br></br>

<a href='http://arxiv.org/pdf/2112.08798.pdf'>2112.08798</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1046баллов, №729</br>
<b>Understanding Memorization from the Perspective of Optimization via\n  Efficient Influence Estimation</b></br>
Authors: , Liu, Futong, Lin, Tao, Jaggi, Martin</br>
  Over-parameterized deep neural networks are able to achieve excellent training accuracy while maintaining a small generalization error. It has also been found that they are able to fit arbitrary labels, and this behaviour is referred to as the phenomenon of memorization. In this work, we study the phenomenon of memorization with turn-over dropout, an efficient method to estimate influence and memorization, for data with true labels (real data) and data with random labels (random data). Our main findings are: (i) For both real data and random data, the optimization of easy examples (e.g., real data) and difficult examples (e.g., random data) are conducted by the network simultaneously, with easy ones at a higher speed; (ii) For real data, a correct difficult example in the training dataset is more informative than an easy one. By showing the existence of memorization on random data and real data, we highlight the consistency between them regarding optimization and we emphasize the implication of memorization during optimization. </br></br>

<a href='http://arxiv.org/pdf/2112.06070.pdf'>2112.06070</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1047баллов, №730</br>
<b>A Comparative Study on Robust Graph Neural Networks to Structural Noises</b></br>
Authors: , Zhang, Zeyu, Pei, Yulong</br>
  Graph neural networks (GNNs) learn node representations by passing and aggregating messages between neighboring nodes. GNNs have been applied successfully in several application domains and achieved promising performance. However, GNNs could be vulnerable to structural noise because of the message passing mechanism where noise may be propagated through the entire graph. Although a series of robust GNNs have been proposed, they are evaluated with different structural noises, and it lacks a systematic comparison with consistent settings. In this work, we conduct a comprehensive and systematical comparative study on different types of robust GNNs under consistent structural noise settings. From the noise aspect, we design three different levels of structural noises, i.e., local, community, and global noises. From the model aspect, we select some representative models from sample-based, revision-based, and construction-based robust GNNs. Based on the empirical results, we provide some practical suggestions for robust GNNs selection. </br></br>

<a href='http://arxiv.org/pdf/2112.06206.pdf'>2112.06206</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1047баллов, №731</br>
<b>Automatic differentiation approach for reconstructing spectral functions\n  with neural networks</b></br>
Authors: , Wang, Lingxiao, Shi, Shuzhe, Zhou, Kai</br>
  Reconstructing spectral functions from Euclidean Green\'s functions is an important inverse problem in physics. The prior knowledge for specific physical systems routinely offers essential regularization schemes for solving the ill-posed problem approximately. Aiming at this point, we propose an automatic differentiation framework as a generic tool for the reconstruction from observable data. We represent the spectra by neural networks and set chi-square as loss function to optimize the parameters with backward automatic differentiation unsupervisedly. In the training process, there is no explicit physical prior embedding into neural networks except the positive-definite form. The reconstruction accuracy is assessed through Kullback-Leibler(KL) divergence and mean square error(MSE) at multiple noise levels. It should be noted that the automatic differential framework and the freedom of introducing regularization are inherent advantages of the present approach and may lead to improvements of solving inverse problem in the future. </br></br>

<a href='http://arxiv.org/pdf/2112.08055.pdf'>2112.08055</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1053баллов, №732</br>
<b>Building separable approximations for quantum states via neural networks</b></br>
Authors: , Girardin, Antoine, Brunner, Nicolas, Kriv&#xe1;chy, Tam&#xe1;s</br>
  Finding the closest separable state to a given target state is a notoriously difficult task, even more difficult than deciding whether a state is entangled or separable. To tackle this task, we parametrize separable states with a neural network and train it to minimize the distance to a given target state, with respect to a differentiable distance, such as the trace distance or Hilbert-Schmidt distance. By examining the output of the algorithm, we can deduce whether the target state is entangled or not, and construct an approximation for its closest separable state. We benchmark the method on a variety of well-known classes of bipartite states and find excellent agreement, even up to local dimension of $d=10$. Moreover, we show our method to be efficient in the multipartite case, considering different notions of separability. Examining three and four-party GHZ and W states we recover known bounds and obtain novel ones, for instance for triseparability. Finally, we show how to use the neural network\'s results to gain analytic insight. </br></br>

<a href='http://arxiv.org/pdf/2112.06331.pdf'>2112.06331</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.1055баллов, №733</br>
<b>Graph-based <font color="#00be00">hierarchical</font> record <font color="#be00be">clustering</font> for unsupervised entity\n  resolution</b></br>
Authors: , Ebeid, Islam Akef, Talburt, John R., Siddique, Md Abdus Salam</br>
  Here we study the problem of matched record <font color="#be00be">clustering</font> in unsupervised entity resolution. We build upon a <font color="#00be00">state-of-the-art</font> probabilistic framework named the Data Washing Machine (DWM). We introduce a graph-based <font color="#00be00">hierarchical</font> 2-step record clustering method (GDWM) that first identifies large, connected components or, as we call them, soft clusters in the matched record pairs using a graph-based transitive closure algorithm utilized in the DWM. That is followed by breaking down the discovered soft clusters into more precise entity clusters in a hierarchical manner using an adapted graph-based modularity optimization method. Our approach provides several advantages over the original implementation of the DWM, mainly a significant speed-up, increased precision, and overall increased F1 scores. We demonstrate the efficacy of our approach using experiments on multiple synthetic datasets. Our results also provide evidence of the utility of graph <font color="#be00be">theor</font>y-based algorithms despite their sparsity in the literature on unsupervised entity resolution. </br></br>

<a href='http://arxiv.org/pdf/2111.07737.pdf'>2111.07737</a> &nbsp&nbsp (cs:ML, cs:CV) &nbsp&nbsp -0.1057баллов, №734</br>
<b>Progress in Self-Certified Neural Networks</b></br>
Authors: , Perez-Ortiz, Maria, Rivasplata, Omar, Parrado-Hernandez, Emilio, Guedj, Benjamin, Shawe-Taylor, John</br>
  A learning method is self-certified if it uses all available data to simultaneously learn a predictor and certify its quality with a tight statistical certificate that is valid on unseen data. Recent work has shown that neural network models trained by optimising PAC-<font color="#be00be">Bayes</font> bounds lead not only to accurate predictors, but also to tight risk certificates, bearing promise towards achieving self-certified learning. In this context, learning and certification strategies based on PAC-Bayes bounds are especially attractive due to their ability to leverage all data to learn a posterior and simultaneously certify its risk with a tight numerical certificate. In this paper, we assess the progress towards self-certification in probabilistic neural networks learnt by PAC-Bayes inspired objectives. We empirically compare (on 4 classification datasets) classical test set bounds for deterministic predictors and a PAC-Bayes bound for randomised self-certified predictors. We first show that both of these generalisation bounds are not too far from out-of-sample test set errors. We then show that in data starvation regimes, holding out data for the test set bounds adversely affects generalisation performance, while self-certified strategies based on PAC-Bayes bounds do not suffer from this drawback, proving that they might be a suitable choice for the small data regime. We also find that probabilistic neural networks learnt by PAC-Bayes inspired objectives lead to certificates that can be <font color="#00be00">surprisin</font>gly <font color="#960096">competitive</font> with commonly used test set bounds. </br></br>

<a href='http://arxiv.org/pdf/2112.06642.pdf'>2112.06642</a> &nbsp&nbsp (cs:ML, cs:CL) &nbsp&nbsp -0.1059баллов, №735</br>
<b>Unraveling Social Perceptions &amp; Behaviors towards Migrants on Twitter</b></br>
Authors: , Khatua, Aparup, Nejdl, Wolfgang</br>
  We draw insights from the social psychology literature to identify two facets of Twitter deliberations about migrants, i.e., perceptions about migrants and behaviors towards mi-grants. Our <font color="#be00be">theor</font>etical anchoring helped us in identifying two prevailing perceptions (i.e., sympathy and antipathy) and two dominant behaviors (i.e., so<font color="#be00be">lidar</font>ity and animosity) of social media users towards migrants. We have employed unsuper-vised and supervised approaches to identify these perceptions and behaviors. In the domain of applied NLP, our study of-fers a nuanced understanding of migrant-related Twitter de-liberations. Our proposed <font color="#00be00">transformer</font>-based model, i.e.,<font color="#00be00"> BERT </font>+ CNN, has reported an F1-score of 0.76 and outper-formed other models. Additionally, we argue that tweets con-veying antipathy or animosity can be broadly considered hate speech towards migrants, but they are not the same. Thus, our approach has fine-tuned the binary hate speech detection task by highlighting the granular differences between perceptual and behavioral aspects of hate speeches. </br></br>

<a href='http://arxiv.org/pdf/2112.07236.pdf'>2112.07236</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.1059баллов, №736</br>
<b>Logics in fungal mycelium networks</b></br>
Authors: , Adamatzky, Andrew, Ayres, Phil, Beasley, Alexander E., Roberts, Nic, Tegelaar, Martin, Tsompanas, Michail-Antisthenis, W&#xf6;sten, Han A. B.</br>
  The living mycelium networks are capable of efficient sensorial fusion over very large areas and distributed decision making. The information processing in the mycelium networks is implemented via propagation of electrical and chemical signals en pair with morphological changes in the mycelium structure. These information processing mechanisms are manifested in experimental laboratory findings that show that the mycelium networks exhibit rich dynamics of neuron-like spiking behaviour and a wide range of non-linear electrical properties. On an example of a single real colony of \\emph{Aspergillus niger}, we demonstrate that the non-linear transformation of electrical signals and trains of extracellular voltage spikes can be used to implement logical gates and circuits. The approaches adopted include numerical modelling of excitation propagation on the mycelium network, representation of the mycelium network as a resistive and capacitive (RC) network and an experimental laboratory study on mining logical circuits in mycelium bound composites. </br></br>

<a href='http://arxiv.org/pdf/2112.07806.pdf'>2112.07806</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.1064баллов, №737</br>
<b>Understanding Feature Transfer Through Representation Alignment</b></br>
Authors: , Imani, Ehsan, Hu, Wei, White, Martha</br>
  Training with the true labels of a dataset as opposed to randomized labels leads to faster optimization and better generalization. This difference is attributed to a notion of alignment between inputs and labels in natural datasets. We find that training neural networks with different architectures and optimizers on random or true labels enforces the same relationship between the hidden representations and the training labels, elucidating why neural network representations have been so successful for transfer. We first highlight why aligned features promote transfer and show in a classic synthetic transfer problem that alignment is the determining factor for positive and negative transfer to similar and dissimilar tasks. We then investigate a variety of neural network architectures and find that (a) alignment emerges across a variety of different architectures and optimizers, with more alignment arising from depth (b) alignment increases for layers closer to the output and (c) existing high-performance deep CNNs exhibit high levels of alignment. </br></br>

<a href='http://arxiv.org/pdf/2112.07628.pdf'>2112.07628</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1071баллов, №738</br>
<b>Training Multi-Layer Over-Parametrized Neural Network in Subquadratic\n  Time</b></br>
Authors: , Song, Zhao, Zhang, Lichen, Zhang, Ruizhe</br>
  We consider the problem of training a multi-layer over-parametrized neural networks to minimize the empirical risk induced by a loss function. In the typical setting of over-parametrization, the network width $m$ is much larger than the data dimension $d$ and number of training samples $n$ ($m=\\mathrm{poly}(n,d)$), which induces a prohibitive large weight matrix $W\\in \\mathbb{R}^{m\\times m}$ per layer. Naively, one has to pay $O(m^2)$ time to read the weight matrix and evaluate the neural network function in both forward and backward computation. In this work, we show how to reduce the training cost per iteration, specifically, we propose a framework that uses $m^2$ cost only in the initialization phase and achieves a truly subquadratic cost per iteration in terms of $m$, i.e., $m^{2-\\Omega(1)}$ per iteration.   To obtain this result, we make use of various techniques, including a shifted ReLU-based sparsifier, a lazy low rank maintenance data structure, fast rectangular matrix multiplication, tensor-based sketching techniques and preconditioning. </br></br>

<a href='http://arxiv.org/pdf/2112.08165.pdf'>2112.08165</a> &nbsp&nbsp (cs:ML, cs:SD) &nbsp&nbsp -0.1074баллов, №739</br>
<b>Chimpanzee voice prints? Insights from transfer learning experiments\n  from human voices</b></br>
Authors: , Leroux, Mael, Al-Khudhairy, Orestes Gutierrez, Perony, Nicolas, Townsend, Simon W.</br>
  Individual vocal differences are ubiquitous in the animal kingdom. In humans, these differences pervade the entire vocal repertoire and constitute a &quot;voice print&quot;. Apes, our closest-living relatives, possess individual signatures within specific call types, but the potential for a unique voice print has been little investigated. This is partially attributed to the limitations associated with extracting meaningful features from small data sets. Advances in machine learning have highlighted an alternative to traditional acoustic features, namely pre-trained learnt extractors. Here, we present an approach building on these developments: leveraging a feature extractor based on a deep neural network trained on over 10,000 human voice prints to provide an informative space over which we identify chimpanzee voice prints. We compare our results with those obtained by using traditional acoustic features and discuss the benefits of our methodology and the significance of our findings for the identification of &quot;voice prints&quot; in non-human animals. </br></br>

<a href='http://arxiv.org/pdf/2111.09823.pdf'>2111.09823</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.1082баллов, №740</br>
<b>NetQASM -- A low-level instruction set architecture for hybrid\n  quantum-classical programs in a quantum internet</b></br>
Authors: , Dahlberg, Axel, van der Vecht, Bart, Donne, Carlo Delle, Skrzypczyk, Matthew, Raa, Ingmar te, Kozlowski, Wojciech, Wehner, Stephanie</br>
  We introduce NetQASM, a low-level instruction set architecture for quantum internet applications. NetQASM is a universal, platform-independent and extendable instruction set with support for local quantum gates, powerful classical logic and quantum networking operations for remote entanglement generation. Furthermore, NetQASM allows for close integration of classical logic and communication at the application layer with quantum operations at the physical layer. This enables quantum network applications to be programmed in high-level platform-independent software, which is not possible using any other QASM variants. We implement NetQASM in a series of tools to write, parse, encode and run NetQASM code, which are available online. Our tools include a higher-level SDK in Python, which allows an easy way of programming applications for a quantum internet. Our SDK can be used at home by making use of our existing quantum simulators, NetSquid and SimulaQron, and will also provide a public interface to hardware released on a future iteration of Quantum Network Explorer. </br></br>

<a href='http://arxiv.org/pdf/2112.07884.pdf'>2112.07884</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1083баллов, №741</br>
<b>Experimental quantum advantage with quantum coupon collector</b></br>
Authors: , Zhou, Min-Gang, Cao, Xiao-Yu, Lu, Yu-Shuo, Wang, Yang, Bao, Yu, Jia, Zhao-Ying, Fu, Yao, Yin, Hua-Lei, Chen, Zeng-Bing</br>
  An increasing number of communication and computational schemes with quantum advantages have recently been proposed, which implies that quantum technology has fertile application prospects. However, demonstrating these schemes experimentally continues to be a central challenge because of the difficulty in preparing high-dimensional states or highly entangled states. In this study, we introduce and analyse a quantum coupon collector protocol by employing coherent states and simple linear optical elements, which was successfully demonstrated using realistic experimental equipment. We showed that our protocol can significantly reduce the number of samples needed to learn a specific set compared with the classical limit of the coupon collector problem. We also discuss the potential values and expansions of the quantum coupon collector by constructing a quantum blind box game. The information transmitted by the proposed game also broke the classical limit. These results strongly prove the advantages of quantum mechanics in machine learning and communication complexity. </br></br>

<a href='http://arxiv.org/pdf/2112.06048.pdf'>2112.06048</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1096баллов, №742</br>
<b>Behavior measures are predicted by how information is encoded in an\n  individual\'s <font color="#00be00">brain</font></b></br>
Authors: , Williams, Jennifer, Wehbe, Leila</br>
  Similar to how differences in the proficiency of the cardiovascular and musculoskeletal system predict an individual\'s athletic ability, differences in how the same <font color="#00be00">brain</font> region encodes information across individuals may explain their behavior. However, when studying how the brain encodes information, researchers choose different neuroimaging tasks (e.g., language or motor tasks), which can rely on processing different types of information and can modulate different brain regions. We hypothesize that individual differences in how information is encoded in the brain are task-specific and predict different behavior measures. We propose a framework using encoding-models to identify individual differences in brain encoding and test if these differences can predict behavior. We evaluate our framework using task functional <font color="#be00be">magnetic resonance</font> imaging data. Our results indicate that individual differences revealed by encoding-models are a powerful tool for predicting behavior, and that researchers should optimize their choice of task and encoding-model for their behavior of interest. </br></br>

<a href='http://arxiv.org/pdf/2112.04274.pdf'>2112.04274</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.1104баллов, №743</br>
<b>On the Use of Unrealistic Predictions in Hundreds of Papers Evaluating\n  Graph Representations</b></br>
Authors: , Lin, Li-Chung, Liu, Cheng-Hung, Chen, Chih-Ming, Hsu, Kai-Chin, Wu, I-Feng, Tsai, Ming-Feng, Lin, Chih-Jen</br>
  Prediction using the ground truth sounds like an oxymoron in machine learning. However, such an unrealistic setting was used in hundreds, if not thousands of papers in the area of finding graph representations. To evaluate the multi-label problem of node classification by using the obtained representations, many works assume in the prediction stage that the number of labels of each test instance is known. In practice such ground truth information is rarely available, but we point out that such an inappropriate setting is now ubiquitous in this research area. We detailedly investigate why the situation occurs. Our analysis indicates that with unrealistic information, the performance is likely over-estimated. To see why suitable predictions were not used, we identify difficulties in applying some multi-label techniques. For the use in future studies, we propose simple and effective settings without using practically unknown information. Finally, we take this chance to conduct a fair and serious comparison of major graph-representation learning methods on multi-label node classification. </br></br>

<a href='http://arxiv.org/pdf/2112.07824.pdf'>2112.07824</a> &nbsp&nbsp (cs:ET, cs:ML) &nbsp&nbsp -0.1104баллов, №744</br>
<b>Analog/Mixed-Signal Circuit Synthesis Enabled by the Advancements of\n  Circuit Architectures and Machine Learning Algorithms</b></br>
Authors: , Su, Shiyu, Zhang, Qiaochu, Hassanpourghadi, Mohsen, Liu, Juzheng, Rasul, Rezwan A, Chen, Mike Shuo-Wei</br>
  Analog mixed-signal (AMS) circuit architecture has evolved towards more digital friendly due to technology scaling and demand for higher flexibility/reconfigurability. Meanwhile, the design complexity and cost of AMS circuits has substantially increased due to the necessity of optimizing the circuit sizing, layout, and verification of a complex AMS circuit. On the other hand, machine learning (ML) algorithms have been under exponential growth over the past decade and actively exploited by the electronic design automation (EDA) community. This paper will identify the opportunities and challenges brought about by this trend and overview several emerging AMS design methodologies that are enabled by the recent evolution of AMS circuit architectures and machine learning algorithms. Specifically, we will focus on using neural-network-based surrogate models to expedite the circuit design parameter search and layout iterations. Lastly, we will demonstrate the rapid synthesis of several AMS circuit examples from specification to silicon prototype, with significantly reduced human intervention. </br></br>

<a href='http://arxiv.org/pdf/2112.08418.pdf'>2112.08418</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1112баллов, №745</br>
<b>Neural Network-based Power Flow Model</b></br>
Authors: , Pham, Thuan, Li, Xingpeng</br>
  Power flow analysis is used to evaluate the flow of electricity in the power system network. Power flow calculation is used to determine the steady-state variables of the system, such as the voltage magnitude /phase angle of each bus and the active/reactive power flow on each branch. The DC power flow model is a popular linear power flow model that is widely used in the power industry. Although it is fast and robust, it may lead to inaccurate line flow results for some critical transmission lines. This drawback can be partially addressed by data-driven methods that take advantage of historical grid profiles. In this paper, a neural network (NN) model is trained to predict power flow results using historical power system data. Although the training process may take time, once trained, it is very fast to estimate line flows. A comprehensive performance analysis between the proposed NN-based power flow model and the traditional DC power flow model is conducted. It can be concluded that the proposed NN-based power flow model can find solutions quickly and more accurately than DC power flow model. </br></br>

<a href='http://arxiv.org/pdf/2112.08878.pdf'>2112.08878</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.1125баллов, №746</br>
<b>Knowledge Distillation Leveraging Alternative Soft Targets from\n  Non-Parallel Qualified Speech Data</b></br>
Authors: , Nagano, Tohru, Fukuda, Takashi, Kurata, Gakuto</br>
  This paper describes a novel knowledge distillation framework that leverages acoustically qualified speech data included in an existing training data pool as privileged information. In our proposed framework, a student network is trained with multiple soft targets for each utterance that consist of main soft targets from original speakers\' utterance and alternative targets from other speakers\' utterances spoken under better acoustic conditions as a secondary view. These qualified utterances from other speakers, used to generate better soft targets, are collected from a qualified data pool by using strict constraints in terms of word/phone/state durations. Our proposed method is a form of target-side data augmentation that creates multiple copies of data with corresponding better soft targets obtained from a qualified data pool. We show in our experiments under acoustic model adaptation settings that the proposed method, exploiting better soft targets obtained from various speakers, can further improve recognition accuracy compared with conventional methods using only soft targets from original speakers. </br></br>

<a href='http://arxiv.org/pdf/2112.07858.pdf'>2112.07858</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1128баллов, №747</br>
<b>EDAssistant: Supporting Exploratory Data Analysis in Computational\n  Notebooks with In-Situ Code Search and <font color="#be00be">Recommendat</font>ion</b></br>
Authors: , Li, Xingjun, Zhang, Yizhi, Leung, Justin, Sun, Chengnian, Zhao, Jian</br>
  Using computational notebooks (e.g., Jupyter Notebook), data scientists rationalize their exploratory data analysis (EDA) based on their prior experience and external knowledge such as online examples. For novices or data scientists who lack specific knowledge about the dataset or problem to investigate, effectively obtaining and understanding the external information is critical to carry out EDA. This paper presents EDAssistant, a JupyterLab extension that supports EDA with in-situ search of example notebooks and <font color="#be00be">recommendat</font>ion of useful APIs, powered by novel interactive visualization of search results. The code search and recommendation are enabled by <font color="#00be00">state-of-the-art</font> machine learning models, trained on a large corpus of EDA notebooks collected online. A user study is conducted to investigate both EDAssistant and data scientists\' current practice (i.e., using external search engines). The results demonstrate the effectiveness and usefulness of EDAssistant, and participants appreciated its smooth and in-context support of EDA. We also report several design implications regarding code recommendation tools. </br></br>

<a href='http://arxiv.org/pdf/2112.05148.pdf'>2112.05148</a> &nbsp&nbsp (cs:ML, cs:SD) &nbsp&nbsp -0.1134баллов, №748</br>
<b>Classification of Anuran Frog Species Using Machine Learning</b></br>
Authors: , Alabi, Miriam</br>
  Acoustic classification of frogs has gotten a lot of attention recently due to its potential applicability in ecological investigations. Numerous studies have been presented for identifying frog species, although the majority of recorded species are thought to be monotypic. The purpose of this study is to demonstrate a method for classifying various frog species using an audio recording. To be more exact, continuous frog recordings are cut into audio snippets first (10 seconds). Then, for each ten-second recording, several time-frequency representations are constructed. Following that, rather than using manually created features, Machine Learning methods are employed to classify the frog species. Data reduction techniques; Principal Component Analysis (PCA) and Independent Component Analysis (ICA) are used to extract the most important features before classification. Finally, to validate our classification accuracy, cross validation and prediction accuracy are used. Experimental results show that PCA extracted features that achieved better classification accuracy both with cross validation and prediction accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.08867.pdf'>2112.08867</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1136баллов, №749</br>
<b>GRAM: Generative Radiance Manifolds for 3D-Aware Image Generation</b></br>
Authors: , Deng, Yu, Yang, Jiaolong, Xiang, Jianfeng, Tong, Xin</br>
  3D-aware image generative modeling aims to generate 3D-consistent images with explicitly controllable camera poses. Recent works have shown promising results by training neural radiance field (NeRF) generators on unstructured 2D images, but still can not generate highly-realistic images with fine details. A critical reason is that the high memory and computation cost of volumetric representation learning greatly restricts the number of point samples for radiance integration during training. Deficient sampling not only limits the expressive power of the generator to handle fine details but also impedes effective GAN training due to the noise caused by unstable Monte Carlo sampling. We propose a novel approach that regulates point sampling and radiance field learning on 2D manifolds, embodied as a set of learned implicit surfaces in the 3D volume. For each viewing ray, we calculate ray-surface intersections and accumulate their radiance generated by the network. By training and rendering such radiance manifolds, our generator can produce high quality images with realistic fine details and strong visual 3D consistency. </br></br>

<a href='http://arxiv.org/pdf/2112.05837.pdf'>2112.05837</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1147баллов, №750</br>
<b>Learning distributed channel access policies for networked estimation:\n  data-driven optimization in the mean-field regime</b></br>
Authors: , Vasconcelos, Marcos M.</br>
  The problem of communicating sensor measurements over shared networks is prevalent in many modern large-scale distributed systems such as cyber-physical systems, wireless sensor networks, and the internet of things. Due to bandwidth constraints, the system designer must jointly design decentralized medium access transmission and estimation policies that accommodate a very large number of devices in extremely contested environments such that the collection of all observations is reproduced at the destination with the best possible fidelity. We formulate a remote estimation problem in the mean-field regime where a very large number of sensors communicate their observations to an access point, or base station, under a strict constraint on the maximum fraction of transmitting devices. We show that in the mean-field regime, this problem exhibits a structure that enables tractable optimization algorithms. More importantly, we obtain a data-driven learning scheme that admits a finite sample-complexity guarantee on the performance of the resulting estimation system under minimal assumptions on the data\'s probability density function. </br></br>

<a href='http://arxiv.org/pdf/2112.02789.pdf'>2112.02789</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1153баллов, №751</br>
<b>HumanNeRF: Generalizable Neural Human Radiance Field from Sparse Inputs</b></br>
Authors: , Zhao, Fuqiang, Yang, Wei, Zhang, Jiakai, Lin, Pei, Zhang, Yingliang, Yu, Jingyi, Xu, Lan</br>
  Recent neural human representations can produce high-quality multi-view rendering but require using dense multi-view inputs and costly training. They are hence largely limited to static models as training each frame is infeasible. We present HumanNeRF - a generalizable neural representation - for high-fidelity free-view synthesis of dynamic humans. Analogous to how IBRNet assists NeRF by avoiding per-scene training, HumanNeRF employs an aggregated pixel-alignment feature across multi-view inputs along with a pose embedded non-rigid deformation field for tackling dynamic motions. The raw HumanNeRF can already produce reasonable rendering on sparse video inputs of unseen subjects and camera settings. To further improve the rendering quality, we augment our solution with an appearance blending module for combining the benefits of both neural volumetric rendering and neural texture blending. Extensive experiments on various multi-view dynamic human datasets demonstrate the generalizability and effectiveness of our approach in synthesizing photo-realistic free-view humans under challenging motions and with very sparse camera view inputs. </br></br>

<a href='http://arxiv.org/pdf/2112.05677.pdf'>2112.05677</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1157баллов, №752</br>
<b>Concept Representation Learning with Contrastive Self-Supervised\n  Learning</b></br>
Authors: , Chang, Daniel T.</br>
  Concept-oriented deep learning (CODL) is a general approach to meet the future challenges for deep learning: (1) learning with little or no external supervision, (2) coping with test examples that come from a different distribution than the training examples, and (3) integrating deep learning with symbolic AI. In CODL, as in human learning, concept representations are learned based on concept exemplars. Contrastive self-supervised learning (CSSL) provides a promising approach to do so, since it: (1) uses data-driven associations, to get away from semantic labels, (2) supports incremental and continual learning, to get away from (large) fixed datasets, and (3) accommodates emergent objectives, to get away from fixed objectives (tasks). We discuss major aspects of concept representation learning using CSSL. These include dual-level concept representations, CSSL for feature representations, exemplar similarity measures and self-supervised relational reasoning, incremental and continual CSSL, and contrastive self-supervised concept (class) incremental learning. The discussion leverages recent findings from cognitive neural science and CSSL. </br></br>

<a href='http://arxiv.org/pdf/2112.07225.pdf'>2112.07225</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp -0.1157баллов, №753</br>
<b>Margin Calibration for Long-Tailed Visual Recognition</b></br>
Authors: , Wang, Yidong, Zhang, Bowen, Hou, Wenxin, Wu, Zhen, Wang, Jindong, Shinozaki, Takahiro</br>
  The long-tailed class distribution in visual recognition tasks poses great challenges for neural networks on how to handle the biased predictions between head and tail classes, i.e., the model tends to classify tail classes as head classes. While existing research focused on data resampling and loss function engineering, in this paper, we take a different perspective: the classification margins. We study the relationship between the margins and logits (classification scores) and empirically observe the biased margins and the biased logits are positively correlated. We propose MARC, a simple yet effective MARgin Calibration function to dynamically calibrate the biased margins for unbiased logits. We validate MARC through extensive experiments on common long-tailed benchmarks including CIFAR-LT, ImageNet-LT, Places-LT, and iNaturalist-LT. Experimental results demonstrate that our MARC achieves favorable results on these benchmarks. In addition, MARC is extremely easy to implement with just three lines of code. We hope this simple method will motivate people to rethink the biased margins and biased logits in long-tailed visual recognition. </br></br>

<a href='http://arxiv.org/pdf/2112.07718.pdf'>2112.07718</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1161баллов, №754</br>
<b>Scatter<font color="#00be00">brain</font>ed: A flexible and expandable pattern for decentralized\n  machine learning</b></br>
Authors: , Wilt, Miller, Matelsky, Jordan K., Gearhart, Andrew S.</br>
  <font color="#be00be">Federated</font> machine learning is a technique for training a model across multiple devices without exchanging data between them. Because data remains local to each compute node, federated learning is well-suited for use-cases in fields where data is carefully controlled, such as <font color="#640064">medic</font>ine, or in domains with bandwidth constraints. One weakness of this approach is that most federated learning tools rely upon a central server to perform workload delegation and to produce a single shared model. Here, we suggest a flexible framework for decentralizing the federated learning pattern, and provide an open-source, reference implementation compatible with PyTorch. </br></br>

<a href='http://arxiv.org/pdf/2112.02936.pdf'>2112.02936</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.1172баллов, №755</br>
<b>Pairwise Learning for Neural Link Prediction</b></br>
Authors: , Wang, Zhitao, Zhou, Yong, Hong, Litao, Zou, Yuanhang, Su, Hanjing, Chen, Shouzhi</br>
  In this paper, we aim at providing an effective Pairwise Learning Neural Link Prediction (PLNLP) framework. The framework treats link prediction as a pairwise learning to rank problem and consists of four main components, i.e., neighborhood encoder, link predictor, negative sampler and objective function. The framework is flexible that any generic graph neural convolution or link prediction specific neural architecture could be employed as neighborhood encoder. For link predictor, we design different scoring functions, which could be selected based on different types of graphs. In negative sampler, we provide several sampling strategies, which are problem specific. As for objective function, we propose to use an effective ranking loss, which approximately maximizes the standard ranking metric AUC. We evaluate the proposed PLNLP framework on 4 link property prediction datasets of Open Graph Benchmark, including ogbl-ddi, ogbl-collab, ogbl-ppa and ogbl-ciation2. PLNLP achieves top 1 performance on ogbl-ddi, and top 2 performance on ogbl-collab and ogbl-ciation2 only with basic neural architecture. The performance demonstrates the effectiveness of PLNLP. </br></br>

<a href='http://arxiv.org/pdf/2112.07144.pdf'>2112.07144</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1172баллов, №756</br>
<b>GEO-BLEU: Similarity Measure for Geospatial Sequences</b></br>
Authors: , Shimizu, Toru, Tsubouchi, Kota, Yabe, Takahiro</br>
  In recent geospatial research, the importance of modeling large-scale human mobility data via self-supervised learning is rising, in parallel with progress in natural language processing driven by self-supervised approaches using large-scale corpora. Whereas there are already plenty of feasible approaches applicable to geospatial sequence modeling itself, there seems to be room to improve with regard to evaluation, specifically about how to measure the similarity between generated and reference sequences. In this work, we propose a novel similarity measure, GEO-BLEU, which can be especially useful in the context of geospatial sequence modeling and generation. As the name suggests, this work is based on BLEU, one of the most popular measures used in machine translation research, while introducing spatial proximity to the idea of n-gram. We compare this measure with an established baseline, dynamic time warping, applying it to actual generated geospatial sequences. Using crowdsourced annotated data on the similarity between geospatial sequences collected from over 12,000 cases, we quantitatively and qualitatively show the proposed method\'s superiority. </br></br>

<a href='http://arxiv.org/pdf/2112.07773.pdf'>2112.07773</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1174баллов, №757</br>
<b>Filling gaps in trustworthy development of AI</b></br>
Authors: , Avin, Shahar, Belfield, Haydn, Brundage, Miles, Krueger, Gretchen, Wang, Jasmine, Weller, Adrian, Anderljung, Markus, Krawczuk, Igor, Krueger, David, Lebensold, Jonathan, Maharaj, Tegan, Zilberman, Noa</br>
  The range of application of artificial intelligence (AI) is vast, as is the potential for harm. Growing awareness of potential risks from AI systems has spurred action to address those risks, while eroding confidence in AI systems and the organizations that develop them. A 2019 study found over 80 organizations that published and adopted &quot;AI ethics principles\'\', and more have joined since. But the principles often leave a gap between the &quot;what&quot; and the &quot;how&quot; of trustworthy AI development. Such gaps have enabled questionable or ethically dubious behavior, which casts doubts on the trustworthiness of specific organizations, and the field more broadly. There is thus an urgent need for concrete methods that both enable AI developers to prevent harm and allow them to demonstrate their trustworthiness through verifiable behavior. Below, we explore mechanisms (drawn from arXiv:2004.07213) for creating an ecosystem where AI developers can earn trust - if they are trustworthy. Better assessment of developer trustworthiness could inform user choice, employee actions, investment decisions, legal recourse, and emerging governance regimes. </br></br>

<a href='http://arxiv.org/pdf/2112.07931.pdf'>2112.07931</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1180баллов, №758</br>
<b>From Noise to Feature: Exploiting Intensity Distribution as a Novel Soft\n  Biometric Trait for Finger Vein Recognition</b></br>
Authors: , Kang, Wenxiong, Lu, Yuting, Li, Dejian, Jia, Wei</br>
  Most finger vein feature extraction algorithms achieve satisfactory performance due to their texture representation abilities, despite simultaneously ignoring the intensity distribution that is formed by the finger tissue, and in some cases, processing it as background noise. In this paper, we exploit this kind of noise as a novel soft biometric trait for achieving better finger vein recognition performance. First, a detailed analysis of the finger vein imaging principle and the characteristics of the image are presented to show that the intensity distribution that is formed by the finger tissue in the background can be extracted as a soft biometric trait for recognition. Then, two finger vein background layer extraction algorithms and three soft biometric trait extraction algorithms are proposed for intensity distribution feature extraction. Finally, a hybrid matching strategy is proposed to solve the issue of dimension difference between the primary and soft biometric traits on the score level. A series of rigorous contrast experiments on three open-access databases demonstrates that our proposed method is feasible and effective for finger vein recognition. </br></br>

<a href='http://arxiv.org/pdf/2112.08219.pdf'>2112.08219</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1183баллов, №759</br>
<b>Quantitative analysis of visual representation of sign elements in\n  COVID-19 context</b></br>
Authors: , Cano-Mart&#xed;nez, Mar&#xed;a Jes&#xfa;s, Carrasco, Miguel, Sandoval, Joaqu&#xed;n, Gonz&#xe1;lez-Mart&#xed;n, C&#xe9;sar</br>
  Representation is the way in which human beings re-present the reality of what is happening, both externally and internally. Thus, visual representation as a means of communication uses elements to build a narrative, just as spoken and written language do. We propose using computer analysis to perform a quantitative analysis of the elements used in the visual creations that have been produced in reference to the epidemic, using the images compiled in The Covid Art Museum\'s Instagram account to analyze the different elements used to represent subjective experiences with regard to a global event. This process has been carried out with techniques based on machine learning to detect objects in the images so that the algorithm can be capable of learning and detecting the objects contained in each study image. This research reveals that the elements that are repeated in images to create narratives and the relations of association that are established in the sample, concluding that, despite the subjectivity that all creation entails, there are certain parameters of shared and reduced decisions when it comes to selecting objects to be included in visual representations </br></br>

<a href='http://arxiv.org/pdf/2112.05841.pdf'>2112.05841</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.1191баллов, №760</br>
<b>Logical <font color="#be00be">Boltzmann</font> Machines</b></br>
Authors: , Tran, Son N., Garcez, Artur d\'Avila</br>
  The idea of representing symbolic knowledge in connectionist systems has been a long-standing endeavour which has attracted much attention recently with the objective of combining machine learning and scalable sound reasoning. Early work has shown a correspondence between propositional logic and symmetrical neural networks which nevertheless did not scale well with the number of variables and whose training regime was inefficient. In this paper, we introduce Logical <font color="#be00be">Boltzmann</font> Machines (LBM), a neurosymbolic system that can represent any propositional logic formula in strict disjunctive normal form. We prove equivalence between energy minimization in LBM and logical satisfiability thus showing that LBM is capable of sound reasoning. We evaluate reasoning empirically to show that LBM is capable of finding all satisfying assignments of a class of logical formulae by searching fewer than 0.75% of the possible (approximately 1 billion) assignments. We compare learning in LBM with a symbolic inductive logic programming system, a <font color="#00be00">state-of-the-art</font> neurosymbolic system and a purely neural network-based system, achieving better learning performance in five out of seven data sets. </br></br>

<a href='http://arxiv.org/pdf/2112.07823.pdf'>2112.07823</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.1191баллов, №761</br>
<b><font color="#be00be">Bayes</font>ian Graph Contrastive Learning</b></br>
Authors: , Hasanzadeh, Arman, Armandpour, Mohammadreza, Hajiramezanali, Ehsan, Zhou, Mingyuan, Duffield, Nick, Narayanan, Krishna</br>
  Contrastive learning has become a key component of self-supervised learning approaches for graph-structured data. However, despite their success, existing graph contrastive learning methods are incapable of uncertainty quantification for node representations or their downstream tasks, limiting their application in high-stakes domains. In this paper, we propose a novel <font color="#be00be">Bayes</font>ian perspective of graph contrastive learning methods showing random augmentations leads to stochastic encoders. As a result, our proposed method represents each node by a distribution in the latent space in contrast to existing techniques which embed each node to a deterministic vector. By learning distributional representations, we provide uncertainty estimates in downstream graph analytics tasks and increase the expressive power of the predictive model. In addition, we propose a Bayesian framework to infer the probability of perturbations in each view of the contrastive model, eliminating the need for a computationally expensive search for hyperparameter tuning. We empirically show a considerable improvement in performance compared to existing <font color="#00be00">state-of-the-art</font> methods on several benchmark datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.07895.pdf'>2112.07895</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.1198баллов, №762</br>
<b>Robust Depth Completion with Uncertainty-Driven Loss Functions</b></br>
Authors: , Zhu, Yufan, Dong, Weisheng, Li, Leida, Wu, Jinjian, Li, Xin, Shi, Guangming</br>
  Recovering a dense depth image from sparse <font color="#be00be">LiDAR</font> scans is a challenging task. Despite the popularity of color-guided methods for sparse-to-dense depth completion, they treated pixels equally during optimization, ignoring the uneven distribution characteristics in the sparse depth map and the accumulated <font color="#be00be">outlier</font>s in the synthesized ground truth. In this work, we introduce uncertainty-driven loss functions to improve the robustness of depth completion and handle the uncertainty in depth completion. Specifically, we propose an explicit uncertainty formulation for robust depth completion with Jeffrey\'s prior. A parametric uncertain-driven loss is introduced and translated to new loss functions that are robust to noisy or missing data. Meanwhile, we propose a multiscale joint prediction model that can simultaneously predict depth and uncertainty maps. The estimated uncertainty map is also used to perform adaptive prediction on the pixels with high uncertainty, leading to a residual map for refining the completion results. Our method has been tested on KITTI Depth Completion Benchmark and achieved the <font color="#00be00">state-of-the-art</font> robustness performance in terms of MAE, IMAE, and IRMSE metrics. </br></br>

<a href='http://arxiv.org/pdf/2112.05887.pdf'>2112.05887</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1200баллов, №763</br>
<b>Distributed Graph Learning with Smooth Data Priors</b></br>
Authors: , Nobre, Isabela Cunha Maia, Gheche, Mireille El, Frossard, Pascal</br>
  Graph learning is often a necessary step in processing or representing structured data, when the underlying graph is not given explicitly. Graph learning is generally performed centrally with a full knowledge of the graph signals, namely the data that lives on the graph nodes. However, there are settings where data cannot be collected easily or only with a non-negligible communication cost. In such cases, distributed processing appears as a natural solution, where the data stays mostly local and all processing is performed among neighbours nodes on the communication graph. We propose here a novel distributed graph learning algorithm, which permits to infer a graph from signal observations on the nodes under the assumption that the data is smooth on the target graph. We solve a distributed optimization problem with local projection constraints to infer a valid graph while limiting the communication costs. Our results show that the distributed approach has a lower communication cost than a centralised algorithm without compromising the accuracy in the inferred graph. It also scales better in communication costs with the increase of the network size, especially for sparse networks. </br></br>

<a href='http://arxiv.org/pdf/2111.06171.pdf'>2111.06171</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.1203баллов, №764</br>
<b>Convergence and Stability of the Stochastic Proximal Point Algorithm\n  with Momentum</b></br>
Authors: , Kim, Junhyung Lyle, Toulis, Panos, Kyrillidis, Anastasios</br>
  Stochastic gradient descent with momentum (SGDM) is the dominant algorithm in many optimization scenarios, including convex optimization instances and non-convex neural network training. Yet, in the stochastic setting, momentum interferes with gradient noise, often leading to specific step size and momentum choices in order to guarantee convergence, set aside acceleration. Proximal point methods, on the other hand, have gained much attention due to their numerical stability and elasticity against imperfect tuning. Their stochastic accelerated variants though have received limited attention: how momentum interacts with the stability of (stochastic) proximal point methods remains largely unstudied. To address this, we focus on the convergence and stability of the stochastic proximal point algorithm with momentum (SPPAM), and show that SPPAM allows a faster linear convergence to a neighborhood compared to stochastic proximal point algorithm (SPPA) with a better contraction factor, under proper hyperparameter tuning. In terms of stability, we show that SPPAM depends on problem constants more favorably than SGDM, allowing a wider range of step size and momentum that lead to convergence. </br></br>

<a href='http://arxiv.org/pdf/2112.06660.pdf'>2112.06660</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1207баллов, №765</br>
<b>Subspace Decomposition based DNN algorithm for elliptic type multi-scale\n  PDEs</b></br>
Authors: , Li, Xi-An, Xu, Zhi-Qin John, Zhang, Lei</br>
  While deep learning algorithms demonstrate a great potential in scientific computing, its application to multi-scale problems remains to be a big challenge. This is manifested by the &quot;frequency principle&quot; that neural networks tend to learn low frequency components first. Novel architectures such as multi-scale deep neural network (MscaleDNN) were proposed to alleviate this problem to some extent. In this paper, we construct a subspace decomposition based DNN (dubbed SD$^2$NN) architecture for a class of multi-scale problems by combining traditional numerical analysis ideas and MscaleDNN algorithms. The proposed architecture includes one low frequency normal DNN submodule, and one (or a few) high frequency MscaleDNN submodule(s), which are designed to capture the smooth part and the oscillatory part of the multi-scale solutions, respectively. In addition, a novel trigonometric activation function is incorporated in the SD$^2$NN model. We demonstrate the performance of the SD$^2$NN architecture through several benchmark multi-scale problems in regular or irregular geometric domains. Numerical results show that the SD$^2$NN model is superior to existing models such as MscaleDNN. </br></br>

<a href='http://arxiv.org/pdf/2112.08947.pdf'>2112.08947</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.1214баллов, №766</br>
<b>Computational metrics and parameters of an injection-locked large area\n  semiconductor laser for neural network computing</b></br>
Authors: , Skalli, Anas, Porte, Xavier, Haghighi, Nasibeh, Reitzenstein, Stephan, Lott, James A., Brunner, D.</br>
  Artificial neural networks have become a staple computing technique in many fields. Yet, they present fundamental differences with classical computing hardware in the way they process information. Photonic implementations of neural network architectures potentially offer fundamental advantages over their electronic counterparts in terms of speed, processing parallelism, scalability and energy efficiency. Scalable and high performance photonic neural networks (PNNs) have been demonstrated, yet they remain scarce. In this work, we study the performance of such a scalable, fully parallel and autonomous PNN based on a large area vertical-cavity surface-emitting laser (LA-VCSEL). We show how the performance varies with different physical parameters, namely, injection wavelength, injection power, and bias current. Furthermore, we link these physical parameters to the general computational measures of consistency and dimensionality. We present a general method of gauging dimensionality in high dimensional nonlinear systems subject to noise, which could be applied to many systems in the context of neuromorphic computing. Our work will inform future implementations of spatially multiplexed VCSEL PNNs. </br></br>

<a href='http://arxiv.org/pdf/2112.05504.pdf'>2112.05504</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.1215баллов, №767</br>
<b>CityNeRF: Building NeRF at City Scale</b></br>
Authors: , Xiangli, Yuanbo, Xu, Linning, Pan, Xingang, Zhao, Nanxuan, Rao, Anyi, Theobalt, Christian, Dai, Bo, Lin, Dahua</br>
  Neural Radiance Field (NeRF) has achieved outstanding performance in modeling 3D objects and controlled scenes, usually under a single scale. In this work, we make the first attempt to bring NeRF to city-scale, with views ranging from satellite-level that captures the overview of a city, to ground-level imagery showing complex details of an architecture. The wide span of camera distance to the scene yields multi-scale data with different levels of detail and spatial coverage, which casts great challenges to vanilla NeRF and biases it towards compromised results. To address these issues, we introduce CityNeRF, a progressive learning paradigm that grows the NeRF model and training set synchronously. Starting from fitting distant views with a shallow base block, as training progresses, new blocks are appended to accommodate the emerging details in the increasingly closer views. The strategy effectively activates high-frequency channels in the positional encoding and unfolds more complex details as the training proceeds. We demonstrate the superiority of CityNeRF in modeling diverse city-scale scenes with drastically varying views, and its support for rendering views in different levels of detail. </br></br>

<a href='http://arxiv.org/pdf/2112.06578.pdf'>2112.06578</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1238баллов, №768</br>
<b>Solving the non-preemptive two queue polling model with generally\n  distributed service and switch-over durations and Poisson arrivals as a\n  Semi-Markov Decision Process</b></br>
Authors: , Solms, Dylan</br>
  The polling system with switch-over durations is a useful model with several practical applications. It is classified as a Discrete Event Dynamic System (DEDS) for which no one agreed upon modelling approach exists. Furthermore, DEDS are quite complex. To date, the most sophisticated approach to modelling the polling system of interest has been a Continuous-time Markov Decision Process (CTMDP). This paper presents a Semi-Markov Decision Process (SMDP) formulation of the polling system as to introduce additional modelling power. Such power comes at the expense of truncation errors and expensive numerical integrals which naturally leads to the question of whether the SMDP policy provides a worthwhile advantage. To further add to this scenario, it is shown how sparsity can be exploited in the CTMDP to develop a computationally efficient model. The discounted performance of the SMDP and CTMDP policies are evaluated using a Semi-Markov Process simulator. The two policies are accompanied by a heuristic policy specifically developed for this polling system a well as an exhaustive service policy. Parametric and non-parametric hypothesis tests are used to test whether differences in performance are statistically significant. </br></br>

<a href='http://arxiv.org/pdf/2112.07369.pdf'>2112.07369</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1253баллов, №769</br>
<b>Convergence proof for stochastic gradient descent in the training of\n  deep neural networks with ReLU activation for constant target functions</b></br>
Authors: , Hutzenthaler, Martin, Jentzen, Arnulf, Pohl, Katharina, Riekert, Adrian, Scarpa, Luca</br>
  In many numerical simulations stochastic gradient descent (SGD) type optimization methods perform very effectively in the training of deep neural networks (DNNs) but till this day it remains an open problem of research to provide a mathematical convergence analysis which rigorously explains the success of SGD type optimization methods in the training of DNNs. In this work we study SGD type optimization methods in the training of fully-connected feedforward DNNs with rectified linear unit (ReLU) activation. We first establish general regularity properties for the risk functions and their generalized gradient functions appearing in the training of such DNNs and, thereafter, we investigate the plain vanilla SGD optimization method in the training of such DNNs under the assumption that the target function under consideration is a constant function. Specifically, we prove under the assumption that the learning rates (the step sizes of the SGD optimization method) are sufficiently small but not $L^1$-summable and under the assumption that the target function is a constant function that the expectation of the riskof the considered SGD process converges in the training of such DNNs to zero as the number of SGD steps increases to infinity. </br></br>

<a href='http://arxiv.org/pdf/2112.08512.pdf'>2112.08512</a> &nbsp&nbsp (cs:ET, cs:ML) &nbsp&nbsp -0.1253баллов, №770</br>
<b>ELight: Enabling Efficient Photonic In-Memory Neurocomputing with Life\n  Enhancement</b></br>
Authors: , Zhu, Hanqing, Gu, Jiaqi, Feng, Chenghao, Liu, Mingjie, Jiang, Zixuan, Chen, Ray T., Pan, David Z.</br>
  With the recent advances in optical phase change material (PCM), photonic in-memory neurocomputing has demonstrated its superiority in optical neural network (ONN) designs with near-zero static power consumption, time-of-light latency, and compact footprint. However, photonic tensor cores require massive hardware reuse to implement large matrix multiplication due to the limited single-core scale. The resultant large number of PCM writes leads to serious dynamic power and overwhelms the fragile PCM with limited write endurance. In this work, we propose a synergistic optimization framework, ELight, to minimize the overall write efforts for efficient and reliable optical in-memory neurocomputing. We first propose write-aware training to encourage the similarity among weight blocks, and combine it with a post-training optimization method to reduce programming efforts by eliminating redundant writes. Experiments show that ELight can achieve over 20X reduction in the total number of writes and dynamic power with comparable accuracy. With our ELight, photonic in-memory neurocomputing will step forward towards viable applications in machine learning with preserved accuracy, order-of-magnitude longer lifetime, and lower programming energy. </br></br>

<a href='http://arxiv.org/pdf/2112.08348.pdf'>2112.08348</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.1273баллов, №771</br>
<b>PROMPT WAYWARDNESS: The Curious Case of Discretized <font color="#be00be">Interpret</font>ation of\n  Continuous Prompts</b></br>
Authors: , Khashabi, Daniel, Lyu, Shane, Min, Sewon, Qin, Lianhui, Richardson, Kyle, Singh, Sameer, Welleck, Sean, Hajishirzi, Hannaneh, Khot, Tushar, Sabharwal, Ashish, Choi, Yejin</br>
  Fine-tuning continuous prompts for target tasks has recently emerged as a compact alternative to full model fine-tuning. Motivated by these promising results, we investigate the feasibility of extracting a discrete (textual) <font color="#be00be">interpret</font>ation of continuous prompts that is faithful to the problem they solve. In practice, we observe a &quot;wayward&quot; behavior between the task solved by continuous prompts and their <font color="#be00be">nearest neighbo</font>r discrete projections: We can find continuous prompts that solve a task while being projected to an arbitrary text (e.g., definition of a different or even a contradictory task), while being within a very small (2%) margin of the best continuous prompt of the same size for the task. We provide intuitions behind this odd and <font color="#00be00">surprisin</font>g behavior, as well as extensive empirical analyses quantifying the effect of various parameters. For instance, for larger model sizes we observe higher waywardness, i.e, we can find prompts that more closely map to any arbitrary text with a smaller drop in accuracy. These findings have important implications relating to the difficulty of faithfully interpreting continuous prompts and their generalization across models and tasks, providing guidance for future progress in prompting language models. </br></br>

<a href='http://arxiv.org/pdf/2112.06148.pdf'>2112.06148</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1280баллов, №772</br>
<b>Programming with Neural Surrogates of Programs</b></br>
Authors: , Renda, Alex, Ding, Yi, Carbin, Michael</br>
  Surrogates, models that mimic the behavior of programs, form the basis of a variety of development workflows. We study three surrogate-based design patterns, evaluating each in case studies on a large-scale CPU simulator.   With surrogate compilation, programmers develop a surrogate that mimics the behavior of a program to deploy to end-users in place of the original program. Surrogate compilation accelerates the CPU simulator under study by $1.6\\times$. With surrogate adaptation, programmers develop a surrogate of a program then retrain that surrogate on a different task. Surrogate adaptation decreases the simulator\'s error by up to $50\\%$. With surrogate optimization, programmers develop a surrogate of a program, optimize input parameters of the surrogate, then plug the optimized input parameters back into the original program. Surrogate optimization finds simulation parameters that decrease the simulator\'s error by $5\\%$ compared to the error induced by expert-set parameters.   In this paper we formalize this taxonomy of surrogate-based design patterns. We further describe the programming methodology common to all three design patterns. Our work builds a foundation for the emerging class of workflows based on programming with surrogates of programs. </br></br>

<a href='http://arxiv.org/pdf/2112.06129.pdf'>2112.06129</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.1296баллов, №773</br>
<b>Online Adaptation of Neural Network Models by Modified Extended Kalman\n  Filter for Customizable and Transferable Driving Behavior Prediction</b></br>
Authors: , Wang, Letian, Hu, Yeping, Liu, Changliu</br>
  High fidelity behavior prediction of human drivers is crucial for efficient and safe deployment of autonomous vehicles, which is challenging due to the stochasticity, heterogeneity, and time-varying nature of human behaviors. On one hand, the trained prediction model can only capture the motion pattern in an average sense, while the nuances among individuals can hardly be reflected. On the other hand, the prediction model trained on the training set may not generalize to the testing set which may be in a different scenario or data distribution, resulting in low transferability and generalizability. In this paper, we applied a $\\tau$-step modified Extended Kalman Filter parameter adaptation algorithm (MEKF$_\\lambda$) to the driving behavior prediction task, which has not been studied before in literature. With the feedback of the observed trajectory, the algorithm is applied to neural-network-based models to improve the performance of driving behavior predictions across different human subjects and scenarios. A new set of metrics is proposed for systematic evaluation of online adaptation performance in reducing the prediction error for different individuals and scenarios. Empirical studies on the best layer in the model and steps of observation to adapt are also provided. </br></br>

<a href='http://arxiv.org/pdf/2112.05280.pdf'>2112.05280</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1303баллов, №774</br>
<b>Long-Range Thermal 3D Perception in Low Contrast Environments</b></br>
Authors: , Filippov, Andrey, Filippova, Olga</br>
  This report discusses the results of SBIR Phase I effort to prove the feasibility of dramatic improvement of the microbolometer-based Long Wave Infrared (LWIR) detectors sensitivity, especially for the 3D measurements. The resulting low SWaP-C thermal depth-sensing system will enable the situational awareness of Autonomous Air Vehicles for Advanced Air Mobility (AAM). It will provide robust 3D information of the surrounding environment, including low-contrast static and moving objects, at far distances in degraded visual conditions and GPS-denied areas. Our multi-sensor 3D perception enabled by COTS uncooled thermal sensors mitigates major weakness of LWIR sensors - low contrast by increasing the system sensitivity over an order of magnitude.   There were no available thermal image sets suitable for evaluating this technology, making datasets acquisition our first goal. We discuss the design and construction of the prototype system with sixteen 640pix x 512pix LWIR detectors, camera calibration to subpixel resolution, capture, and process synchronized image. The results show the 3.84x contrast increase for intrascene-only data and an additional 5.5x - with the interscene accumulation, reaching system noise-equivalent temperature difference (NETD) of 1.9 mK with the 40 mK sensors. </br></br>

<a href='http://arxiv.org/pdf/2112.09020.pdf'>2112.09020</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1305баллов, №775</br>
<b>Classification of diffraction patterns using a convolutional neural\n  network in single particle imaging experiments performed at X-ray\n  free-electron lasers</b></br>
Authors: , Assalauova, Dameli, Ignatenko, Alexandr, Isensee, Fabian, Bobkov, Sergey, Trofimova, Darya, Vartanyants, Ivan A.</br>
  Single particle imaging (SPI) at X-ray free electron lasers (XFELs) is particularly well suited to determine the 3D structure of particles in their native environment. For a successful reconstruction, diffraction patterns originating from a single hit must be isolated from a large number of acquired patterns. We propose to formulate this task as an image classification problem and solve it using convolutional neural network (CNN) architectures. Two CNN configurations are developed: one that maximises the F1-score and one that emphasises high recall. We also combine the CNNs with expectation maximization (EM) selection as well as size filtering. We observed that our CNN selections have lower contrast in power spectral density functions relative to the EM selection, used in our previous work. However, the reconstruction of our CNN-based selections gives similar results. Introducing CNNs into SPI experiments allows streamlining the reconstruction pipeline, enables researchers to classify patterns on the fly, and, as a consequence, enables them to tightly control the duration of their experiments. We think that bringing non-standard artificial intelligence (AI) based solutions in a well-described SPI analysis workflow may be beneficial for the future development of the SPI experiments. </br></br>

<a href='http://arxiv.org/pdf/2112.09072.pdf'>2112.09072</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1309баллов, №776</br>
<b>Sensor Sampling Trade-Offs for Air Quality Monitoring With Low-Cost\n  Sensors</b></br>
Authors: , Ferrer-Cid, Pau, Garcia-Calvete, Julio, Main-Nadal, Aina, Ye, Zhe, Barcelo-Ordinas, Jose M., Garcia-Vidal, Jorge</br>
  The calibration of low-cost sensors using machine learning techniques is a methodology widely used nowadays. Although many challenges remain to be solved in the deployment of low-cost sensors for air quality monitoring, low-cost sensors have been shown to be useful in conjunction with high-precision instrumentation. Thus, most research is focused on the application of different calibration techniques using machine learning. Nevertheless, the successful application of these models depends on the quality of the data obtained by the sensors, and very little attention has been paid to the whole data gathering process, from sensor sampling and data pre-processing, to the calibration of the sensor itself. In this article, we show the main sensor sampling parameters, with their corresponding impact on the quality of the resulting machine learning-based sensor calibration and their impact on energy consumption, thus showing the existing trade-offs. Finally, the results on an experimental node show the impact of the data sampling strategy in the calibration of tropospheric ozone, nitrogen dioxide and nitrogen monoxide low-cost sensors. Specifically, we show how a sampling strategy that minimizes the duty cycle of the sensing subsystem can reduce power consumption while maintaining data quality. </br></br>

<a href='http://arxiv.org/pdf/2112.07464.pdf'>2112.07464</a> &nbsp&nbsp (cs:AI, cs:ML, stat:ML) &nbsp&nbsp -0.1314баллов, №777</br>
<b>Efficient differentiable quadratic programming layers: an ADMM approach</b></br>
Authors: , Butler, Andrew, Kwon, Roy</br>
  Recent advances in neural-network architecture allow for seamless integration of convex optimization problems as differentiable layers in an end-to-end trainable neural network. Integrating medium and large scale quadratic programs into a deep neural network architecture, however, is challenging as solving quadratic programs exactly by interior-point methods has worst-case cubic complexity in the number of variables. In this paper, we present an alternative network layer architecture based on the alternating direction method of multipliers (ADMM) that is capable of scaling to problems with a moderately large number of variables. Backward differentiation is performed by implicit differentiation of the residual map of a modified fixed-point iteration. Simulated results demonstrate the computational advantage of the ADMM layer, which for medium scaled problems is approximately an order of magnitude faster than the OptNet quadratic programming layer. Furthermore, our novel backward-pass routine is efficient, from both a memory and computation standpoint, in comparison to the standard approach based on unrolled differentiation or implicit differentiation of the KKT optimality conditions. We conclude with examples from portfolio optimization in the integrated prediction and optimization paradigm. </br></br>

<a href='http://arxiv.org/pdf/2112.08854.pdf'>2112.08854</a> &nbsp&nbsp (cs:RO, cs:CV) &nbsp&nbsp -0.1316баллов, №778</br>
<b>Multi-Camera <font color="#be00be">LiDAR</font> Inertial Extension to the Newer College Dataset</b></br>
Authors: , Zhang, Lintong, Camurri, Marco, Fallon, Maurice</br>
  In this paper, we present a multi-camera <font color="#be00be">LiDAR</font> inertial dataset of 4.5km walking distance as an expansion to the Newer College Dataset. The global shutter multi-camera device is hardware synchronized with the IMU and the LiDAR. This dataset also provides six Degrees of Freedom (DoF) ground truth poses, at the LiDAR frequency of 10hz. Three data collections are described and example usage of multi-camera visual-inertial <font color="#be00be">odometry</font> is demonstrated. This expansion dataset contains small and narrow passages, large scale open spaces as well as vegetated areas to test localization and mapping systems. Furthermore, some sequences present challenging situations such as abrupt lighting change, textureless surfaces, and aggressive motion. The dataset is available at: <font color="#006400">http</font>s://ori-drs.<font color="#00be00">github</font>.io/newer-college-dataset </br></br>

<a href='http://arxiv.org/pdf/2112.09046.pdf'>2112.09046</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1320баллов, №779</br>
<b>Distributed neural network control with dependability guarantees: a\n  compositional port-Hamiltonian approach</b></br>
Authors: , Furieri, Luca, Galimberti, Clara Luc&#xed;a, Zakwan, Muhammad, Ferrari-Trecate, Giancarlo</br>
  Large-scale cyber-physical systems require that control policies are distributed, that is, that they only rely on local real-time measurements and communication with neighboring agents. Optimal Distributed Control (ODC) problems are, however, highly intractable even in seemingly simple cases. Recent work has thus proposed training Neural Network (NN) distributed controllers. A main challenge of NN controllers is that they are not dependable during and after training, that is, the closed-loop system may be unstable, and the training may fail due to vanishing and exploding gradients. In this paper, we address these issues for networks of nonlinear port-Hamiltonian (pH) systems, whose modeling power ranges from energy systems to non-holonomic vehicles and chemical reactions. Specifically, we embrace the compositional properties of pH systems to characterize deep Hamiltonian control policies with built-in closed-loop stability guarantees, irrespective of the interconnection topology and the chosen NN parameters. Furthermore, our setup enables leveraging recent results on well-behaved neural ODEs to prevent the phenomenon of vanishing gradients by design. Numerical experiments corroborate the dependability of the proposed architecture, while matching the performance of general neural network policies. </br></br>

<a href='http://arxiv.org/pdf/2112.06219.pdf'>2112.06219</a> &nbsp&nbsp (cs:SD, cs:ML) &nbsp&nbsp -0.1321баллов, №780</br>
<b>Visualising and Explaining Deep Learning Models for Speech Quality\n  Prediction</b></br>
Authors: , Tilkorn, H., Mittag, G., M&#xf6;ller, S.</br>
  Estimating quality of transmitted speech is known to be a non-trivial task. While traditionally, test participants are asked to rate the quality of samples; nowadays, automated methods are available. These methods can be divided into: 1) intrusive models, which use both, the original and the degraded signals, and 2) non-intrusive models, which only require the degraded signal. Recently, non-intrusive models based on neural networks showed to <font color="#00be00">outperform</font> signal processing based models. However, the advantages of deep learning based models come with the cost of being more challenging to <font color="#be00be">interpret</font>. To get more insight into the prediction models the non-intrusive speech quality prediction model NISQA is analyzed in this paper. NISQA is composed of a convolutional neural network (CNN) and a recurrent neural network (RNN). The task of the CNN is to compute relevant features for the speech quality prediction on a frame level, while the RNN models time-dependencies between the individual speech frames. Different explanation algorithms are used to understand the automatically learned features of the CNN. In this way, several interpretable features could be identified, such as the sensitivity to noise or strong interruptions. On the other hand, it was found that multiple features carry redundant information. </br></br>

<a href='http://arxiv.org/pdf/2112.03568.pdf'>2112.03568</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.1326баллов, №781</br>
<b>Unsupervised Learning of Compositional Scene Representations from\n  Multiple Unspecified Viewpoints</b></br>
Authors: , Yuan, Jinyang, Li, Bin, Xue, Xiangyang</br>
  Visual scenes are extremely rich in diversity, not only because there are infinite combinations of objects and background, but also because the observations of the same scene may vary greatly with the change of viewpoints. When observing a visual scene that contains multiple objects from multiple viewpoints, humans are able to perceive the scene in a compositional way from each viewpoint, while achieving the so-called &quot;object constancy&quot; across different viewpoints, even though the exact viewpoints are untold. This ability is essential for humans to identify the same object while moving and to learn from vision efficiently. It is intriguing to design models that have the similar ability. In this paper, we consider a novel problem of learning compositional scene representations from multiple unspecified viewpoints without using any supervision, and propose a deep generative model which separates latent representations into a viewpoint-independent part and a viewpoint-dependent part to solve this problem. To infer latent representations, the information contained in different viewpoints is iteratively integrated by neural networks. Experiments on several specifically designed synthetic datasets have shown that the proposed method is able to effectively learn from multiple unspecified viewpoints. </br></br>

<a href='http://arxiv.org/pdf/2112.07435.pdf'>2112.07435</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1327баллов, №782</br>
<b>Multi-Leader Congestion Games with an Adversary</b></br>
Authors: , Harks, Tobias, Henle, Mona, Klimm, Max, Matuschke, Jannik, Schedel, Anja</br>
  We study a multi-leader single-follower congestion game where multiple users (leaders) choose one resource out of a set of resources and, after observing the realized loads, an adversary (single-follower) attacks the resources with maximum loads, causing additional costs for the leaders. For the resulting strategic game among the leaders, we show that pure Nash equilibria may fail to exist and therefore, we consider approximate equilibria instead. As our first main result, we show that the existence of a $K$-approximate equilibrium can always be guaranteed, where $K \\approx 1.1974$ is the unique solution of a cubic polynomial equation. To this end, we give a polynomial time combinatorial algorithm which computes a $K$-approximate equilibrium. The factor $K$ is tight, meaning that there is an instance that does not admit an $\\alpha$-approximate equilibrium for any $\\alpha&lt;K$. Thus $\\alpha=K$ is the smallest possible value of $\\alpha$ such that the existence of an $\\alpha$-approximate equilibrium can be guaranteed for any instance of the considered game. Secondly, we focus on approximate equilibria of a given fixed instance. We show how to compute efficiently a best approximate equilibrium, that is, with smallest possible $\\alpha$ among all $\\alpha$-approximate equilibria of the given instance. </br></br>

<a href='http://arxiv.org/pdf/2112.05637.pdf'>2112.05637</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1328баллов, №783</br>
<b>HeadNeRF: A Real-time NeRF-based Parametric Head Model</b></br>
Authors: , Hong, Yang, Peng, Bo, Xiao, Haiyao, Liu, Ligang, Zhang, Juyong</br>
  In this paper, we propose HeadNeRF, a novel NeRF-based parametric head model that integrates the neural radiance field to the parametric representation of the human head. It can render high fidelity head images in real-time, and supports directly controlling the generated images\' rendering pose and various semantic attributes. Different from existing related parametric models, we use the neural radiance fields as a novel 3D proxy instead of the traditional 3D textured mesh, which makes that HeadNeRF is able to generate high fidelity images. However, the computationally expensive rendering process of the original NeRF hinders the construction of the parametric NeRF model. To address this issue, we adopt the strategy of integrating 2D neural rendering to the rendering process of NeRF and design novel loss terms. As a result, the rendering speed of HeadNeRF can be significantly accelerated, and the rendering time of one frame is reduced from 5s to 25ms. The novel-designed loss terms also improve the rendering accuracy, and the fine-level details of the human head, such as the gaps between teeth, wrinkles, and beards, can be represented and synthesized by HeadNeRF. Extensive experimental results and several applications demonstrate its effectiveness. We will release the code and trained model to the public. </br></br>

<a href='http://arxiv.org/pdf/2112.07289.pdf'>2112.07289</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1328баллов, №784</br>
<b>Why you should learn functional basis</b></br>
Authors: , Marin, Riccardo, Attaiki, Souhaib, Melzi, Simone, Rodol&#xe0;, Emanuele, Ovsjanikov, Maks</br>
  Efficient and practical representation of geometric data is a ubiquitous problem for several applications in geometry processing. A widely used choice is to encode the 3D objects through their spectral embedding, associating to each surface point the values assumed at that point by a truncated subset of the eigenfunctions of a differential operator (typically the Laplacian). Several attempts to define new, preferable embeddings for different applications have seen the light during the last decade. Still, the standard Laplacian eigenfunctions remain solidly at the top of the available solutions, despite their limitations, such as being limited to near-isometries for shape matching. Recently, a new trend shows advantages in learning substitutes for the Laplacian eigenfunctions. At the same time, many research questions remain unsolved: are the new bases better than the LBO eigenfunctions, and how do they relate to them? How do they act in the functional perspective? And how to exploit these bases in new configurations in conjunction with additional features and descriptors? In this study, we properly pose these questions to improve our understanding of this emerging research direction. We show their applicative relevance in different contexts revealing some of their insights and exciting future directions. </br></br>

<a href='http://arxiv.org/pdf/2112.06336.pdf'>2112.06336</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.1367баллов, №785</br>
<b>Representing Knowledge as Predictions (and State as Knowledge)</b></br>
Authors: , Ring, Mark</br>
  This paper shows how a single mechanism allows knowledge to be constructed layer by layer directly from an agent\'s raw sensorimotor stream. This mechanism, the General Value Function (GVF) or &quot;forecast,&quot; captures high-level, abstract knowledge as a set of predictions about existing features and knowledge, based exclusively on the agent\'s low-level senses and actions.   Thus, forecasts provide a representation for organizing raw sensorimotor data into useful abstractions over an unlimited number of layers--a long-sought goal of AI and cognitive science.   The heart of this paper is a detailed thought experiment providing a concrete, step-by-step formal illustration of how an artificial agent can build true, useful, abstract knowledge from its raw sensorimotor experience alone. The knowledge is represented as a set of layered predictions (forecasts) about the agent\'s observed consequences of its actions. This illustration shows twelve separate layers: the lowest consisting of raw pixels, touch and force sensors, and a small number of actions; the higher layers increasing in abstraction, eventually resulting in rich knowledge about the agent\'s world, corresponding roughly to doorways, walls, rooms, and floor plans. I then argue that this general mechanism may allow the representation of a broad spectrum of everyday human knowledge. </br></br>

<a href='http://arxiv.org/pdf/2112.07761.pdf'>2112.07761</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1388баллов, №786</br>
<b>Split Moves for Monte-Carlo Tree Search</b></br>
Authors: , Kowalski, Jakub, Mika, Maksymilian, Pawlik, Wojciech, Sutowicz, Jakub, Szyku&#x142;a, Marek, Winands, Mark H. M.</br>
  In many games, moves consist of several decisions made by the player. These decisions can be viewed as separate moves, which is already a common practice in multi-action games for efficiency reasons. Such division of a player move into a sequence of simpler / lower level moves is called \\emph{splitting}. So far, split moves have been applied only in forementioned straightforward cases, and furthermore, there was almost no study revealing its impact on agents\' playing strength. Taking the knowledge-free perspective, we aim to answer how to effectively use split moves within Monte-Carlo Tree Search (MCTS) and what is the practical impact of split design on agents\' strength. This paper proposes a generalization of MCTS that works with arbitrarily split moves. We design several variations of the algorithm and try to measure the impact of split moves separately on efficiency, quality of MCTS, simulations, and action-based heuristics. The tests are carried out on a set of board games and performed using the Regular Boardgames General Game Playing formalism, where split strategies of different granularity can be automatically derived based on an abstract description of the game. The results give an overview of the behavior of agents using split design in different ways. We conclude that split design can be greatly beneficial for single- as well as multi-action games. </br></br>

<a href='http://arxiv.org/pdf/2112.08444.pdf'>2112.08444</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1394баллов, №787</br>
<b>Combating Collusion Rings is Hard but Possible</b></br>
Authors: , Boehmer, Niclas, Bredereck, Robert, Nichterlein, Andr&#xe9;</br>
  A recent report of Littmann [Commun. ACM \'21] outlines the existence and the fatal impact of collusion rings in academic peer reviewing. We introduce and analyze the problem Cycle-Free Reviewing that aims at finding a review assignment without the following kind of collusion ring: A sequence of reviewers each reviewing a paper authored by the next reviewer in the sequence (with the last reviewer reviewing a paper of the first), thus creating a review cycle where each reviewer gives favorable reviews. As a result, all papers in that cycle have a high chance of acceptance independent of their respective scientific merit.   We observe that review assignments computed using a standard Linear Programming approach typically admit many short review cycles. On the negative side, we show that Cycle-Free Reviewing is NP-hard in various restricted cases (i.e., when every author is qualified to review all papers and one wants to prevent that authors review each other\'s or their own papers or when every author has only one paper and is only qualified to review few papers). On the positive side, among others, we show that, in some realistic settings, an assignment without any review cycles of small length always exists. This result also gives rise to an efficient heuristic for computing (weighted) cycle-free review assignments, which we show to be of excellent quality in practice. </br></br>

<a href='http://arxiv.org/pdf/2112.05577.pdf'>2112.05577</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1396баллов, №788</br>
<b>Towards autonomous artificial agents with an active self: modeling sense\n  of control in situated action</b></br>
Authors: , Kahl, Sebastian, Wiese, Sebastian, Russwinkel, Nele, Kopp, Stefan</br>
  In this paper we present a computational modeling account of an active self in artificial agents. In particular we focus on how an agent can be equipped with a sense of control and how it arises in autonomous situated action and, in turn, influences action control. We argue that this requires laying out an embodied cognitive model that combines bottom-up processes (sensorimotor learning and fine-grained adaptation of control) with top-down processes (cognitive processes for strategy selection and decision-making). We present such a conceptual computational architecture based on principles of predictive processing and free energy minimization. Using this general model, we describe how a sense of control can form across the levels of a control hierarchy and how this can support action control in an unpredictable environment. We present an implementation of this model as well as first evaluations in a simulated task scenario, in which an autonomous agent has to cope with un-/predictable situations and experiences corresponding sense of control. We explore different model parameter settings that lead to different ways of combining low-level and high-level action control. The results show the importance of appropriately weighting information in situations where the need for low/high-level action control varies and they demonstrate how the sense of control can facilitate this. </br></br>

<a href='http://arxiv.org/pdf/2111.07113.pdf'>2111.07113</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.1397баллов, №789</br>
<b>Novel Weight Update Scheme for Hardware Neural Network based on Synaptic\n  Devices Having Abrupt LTP or LTD Characteristics</b></br>
Authors: , Lee, Junmo, Hwang, Joon, Cho, Youngwoon, Kim, Sangbum, Lee, Jongho</br>
  Mitigating nonlinear weight update characteristics is one of the main challenges in designing neural networks based on synaptic devices. This paper presents a novel weight update method named conditional reverse update scheme (CRUS) for hardware neural network (HNN) consisting of synaptic devices with highly nonlinear or abrupt conductance update characteristics. We formulate a linear optimization method of conductance in synaptic devices to reduce the average deviation of weight changes from those calculated by the Stochastic Gradient Rule (SGD) algorithm. We introduce a metric called update noise (UN) to analyze the training dynamics during training. We then design a weight update rule that reduces the UN averaged over the training process. The optimized network achieves &gt;90% accuracy on the MNIST dataset under highly nonlinear long-term potentiation (LTP) and long-term depression (LTD) conditions while using inaccurate and infrequent conductance sensing. Furthermore, the proposed method shows better accuracy than previously reported nonlinear weight update mitigation techniques under the same hardware specifications and device conditions. It also exhibits robustness to temporal variations in conductance updates. We expect our scheme to relieve design requirements in device and circuit engineering and serve as a practical technique that can be applied to future HNNs. </br></br>

<a href='http://arxiv.org/pdf/2112.08070.pdf'>2112.08070</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1409баллов, №790</br>
<b>Depth Refinement for Improved Stereo Reconstruction</b></br>
Authors: , Bracha, Amit, Rotstein, Noam, Bensa&#xef;d, David, Slossberg, Ron, Kimmel, Ron</br>
  Depth estimation is a cornerstone of a vast number of applications requiring 3D assessment of the environment, such as robotics, augmented reality, and autonomous driving to name a few. One prominent technique for depth estimation is stereo matching which has several advantages: it is considered more accessible than other depth-sensing technologies, can produce dense depth estimates in real-time, and has benefited greatly from the advances of deep learning in recent years. However, current techniques for depth estimation from stereoscopic images still suffer from a built-in drawback. To reconstruct depth, a stereo matching algorithm first estimates the disparity map between the left and right images before applying a geometric triangulation. A simple analysis reveals that the depth error is quadratically proportional to the object\'s distance. Therefore, constant disparity errors are translated to large depth errors for objects far from the camera. To mitigate this quadratic relation, we propose a simple but effective method that uses a refinement network for depth estimation. We show analytical and empirical results suggesting that the proposed learning procedure reduces this quadratic relation. We evaluate the proposed refinement procedure on well-known benchmarks and datasets, like Sceneflow and KITTI datasets, and demonstrate significant improvements in the depth accuracy metric. </br></br>

<a href='http://arxiv.org/pdf/2112.06179.pdf'>2112.06179</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1420баллов, №791</br>
<b>BIPS: Bi-modal Indoor Panorama Synthesis via Residual Depth-aided\n  Adversarial Learning</b></br>
Authors: , Oh, Changgyoon, Cho, Wonjune, Park, Daehee, Chae, Yujeong, Wang, Lin, Yoon, Kuk-Jin</br>
  Providing omnidirectional depth along with RGB information is important for numerous applications, eg, VR/AR. However, as omnidirectional RGB-D data is not always available, synthesizing RGB-D panorama data from limited information of a scene can be useful. Therefore, some prior works tried to synthesize RGB panorama images from perspective RGB images; however, they suffer from limited image quality and can not be directly extended for RGB-D panorama synthesis. In this paper, we study a new problem: RGB-D panorama synthesis under the arbitrary configurations of cameras and depth sensors. Accordingly, we propose a novel bi-modal (RGB-D) panorama synthesis (BIPS) framework. Especially, we focus on indoor environments where the RGB-D panorama can provide a complete 3D model for many applications. We design a generator that fuses the bi-modal information and train it with residual-aided adversarial learning (RDAL). RDAL allows to synthesize realistic indoor layout structures and interiors by jointly inferring RGB panorama, layout depth, and residual depth. In addition, as there is no tailored evaluation metric for RGB-D panorama synthesis, we propose a novel metric to effectively evaluate its perceptual quality. Extensive experiments show that our method synthesizes high-quality indoor RGB-D panoramas and provides realistic 3D indoor models than prior methods. Code will be released upon acceptance. </br></br>

<a href='http://arxiv.org/pdf/2112.06197.pdf'>2112.06197</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.1429баллов, №792</br>
<b>Video as Conditional Graph Hierarchy for Multi-Granular Question\n  Answering</b></br>
Authors: , Xiao, Junbin, Yao, Angela, Liu, Zhiyuan, Li, Yicong, Ji, Wei, Chua, Tat-Seng</br>
  Video question answering requires models to understand and reason about both complex video and language data to correctly derive answers. Existing efforts focus on designing sophisticated cross-modal interactions to fuse the information from two modalities, while encoding the video and question holistically as frame and word sequences. Despite their success, these methods are essentially revolving around the sequential nature of video- and question-contents, providing little insight to the problem of question-answering and lacking <font color="#be00be">interpret</font>ability as well. In this work, we argue that while video is presented in frame sequence, the visual elements (eg, objects, actions, activities and events) are not sequential but rather <font color="#00be00">hierarchical</font> in semantic space. To align with the multi-granular essence of linguistic concepts in language queries, we propose to model video as a conditional graph hierarchy which weaves together visual facts of different granularity in a level-wise manner, with the guidance of corresponding textual cues. Despite the simplicity, our extensive experiments demonstrate the superiority of such conditional hierarchical graph architecture, with clear performance improvements over prior methods and also better generalization across different type of questions. Further analyses also consolidate the model\'s reliability as it shows meaningful visual-textual evidences for the predicted answers. </br></br>

<a href='http://arxiv.org/pdf/2111.14250.pdf'>2111.14250</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1441баллов, №793</br>
<b>Learning a model of shape selectivity in V4 cells reveals shape encoding\n  mechanisms in the <font color="#00be00">brain</font></b></br>
Authors: , Mehrani, Paria, Tsotsos, John K.</br>
  The mechanisms involved in transforming early visual signals to curvature representations in V4 are unknown. We propose a <font color="#00be00">hierarchical</font> model that reveals V1/V2 encodings that are essential components for this transformation to the reported curvature representations in V4. Then, by relaxing the often-imposed prior of a single <font color="#be00be">Gaussi</font>an, V4 shape selectivity is learned in the last layer of the hierarchy from Macaque V4 responses. We found that V4 cells integrate multiple shape parts from the full spatial extent of their receptive fields with similar excitatory and inhibitory contributions. Our results uncover new details in existing data about shape selectivity in V4 neurons that with further experiments can enhance our understanding of processing in this area. Accordingly, we propose designs for a stimulus set that allow removing shape parts without disturbing the curvature signal to isolate part contributions to V4 responses. </br></br>

<a href='http://arxiv.org/pdf/2111.04637.pdf'>2111.04637</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.1449баллов, №794</br>
<b>The complex-valued correlation coefficient accounts for binaural\n  detection</b></br>
Authors: , Encke, J&#xf6;rg, Dietz, Mathias</br>
  Binaural hearing is one of the principal mechanisms enabling the localization of sound sources in space. In addition, binaural hearing also significantly improves the detection of signals in noise. Humans can detect interaurally anti-phasic tones in masking noise at sound levels 15 dB below the detection threshold of the equivalent in-phase tones. Intermediate thresholds result from detecting tones in noise with an interaural time difference (ITD). The dependence on ITD has so far been most accurately accounted for by models using an array of internal delays, altering, and ideally compensating for the noise ITD. The array of internal delays, or an equivalent mechanism, however, has not been found in mammals. Alternative coding principles that do not include an array of delays can also explain many aspects of sound localization but have failed to account for some of the available data on binaural detection. By employing the complex-valued correlation coefficient, we show that a minimum assumption model can explain the outcome of a wide range of binaural detection experiments. The proposed mechanism requires fewer degrees of freedom when compared to models with an array of delays while arguably improving compatibility with mammalian physiology. Intriguingly, the 2-dimensional acoustic feature space of variance normalized complex correlation coefficients is at the same time a perceptually uniform space for binaural detection. </br></br>

<a href='http://arxiv.org/pdf/2112.06225.pdf'>2112.06225</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1455баллов, №795</br>
<b>Approximation algorithms for confidence bands for time series</b></br>
Authors: , Tatti, Nikolaj</br>
  Confidence intervals are a standard technique for analyzing data. When applied to time series, confidence intervals are computed for each time point separately. Alternatively, we can compute confidence bands, where we are required to find the smallest area enveloping $k$ time series, where $k$ is a user parameter. Confidence bands can be then used to detect abnormal time series, not just individual observations within the time series. We will show that despite being an NP-hard problem it is possible to find optimal confidence band for some $k$. We do this by considering a different problem: discovering regularized bands, where we minimize the envelope area minus the number of included time series weighted by a parameter $\\alpha$. Unlike normal confidence bands we can solve the problem exactly by using a minimum cut. By varying $\\alpha$ we can obtain solutions for various $k$. If we have a constraint $k$ for which we cannot find appropriate $\\alpha$, we demonstrate a simple algorithm that yields $O(\\sqrt{n})$ approximation guarantee by connecting the problem to a minimum $k$-union problem. This connection also implies that we cannot approximate the problem better than $O(n^{1/4})$ under some (mild) assumptions. Finally, we consider a variant where instead of minimizing the area we minimize the maximum width. Here, we demonstrate a simple 2-approximation algorithm and show that we cannot achieve better approximation guarantee. </br></br>

<a href='http://arxiv.org/pdf/2112.05387.pdf'>2112.05387</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.1457баллов, №796</br>
<b>Layer-Parallel Training of Residual Networks with Auxiliary-Variable\n  Networks</b></br>
Authors: , Sun, Qi, Dong, Hexin, Chen, Zewei, Sun, Jiacheng, Li, Zhenguo, Dong, Bin</br>
  Gradient-based methods for the distributed training of residual networks (ResNets) typically require a forward pass of the input data, followed by back-propagating the error gradient to update model parameters, which becomes time-consuming as the network goes deeper. To break the algorithmic locking and exploit synchronous module parallelism in both the forward and backward modes, auxiliary-variable methods have attracted much interest lately but suffer from significant communication overhead and lack of data augmentation. In this work, a novel joint learning framework for training realistic ResNets across multiple compute devices is established by trading off the storage and recomputation of external auxiliary variables. More specifically, the input data of each independent processor is generated from its low-capacity auxiliary network (AuxNet), which permits the use of data augmentation and realizes forward unlocking. The backward passes are then executed in parallel, each with a local loss function that originates from the penalty or augmented Lagrangian (AL) methods. Finally, the proposed AuxNet is employed to reproduce the updated auxiliary variables through an end-to-end training process. We demonstrate the effectiveness of our methods on ResNets and WideResNets across CIFAR-10, CIFAR-100, and ImageNet datasets, achieving speedup over the traditional layer-serial training method while maintaining comparable testing accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.08618.pdf'>2112.08618</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.1458баллов, №797</br>
<b>A Statistics and Deep Learning Hybrid Method for Multivariate Time\n  Series Forecasting and Mortality Modeling</b></br>
Authors: , Mathonsi, Thabang, van Zyl, Terence L.</br>
  Hybrid methods have been shown to <font color="#00be00">outperform</font> pure statistical and pure deep learning methods at forecasting tasks and quantifying the associated uncertainty with those forecasts (prediction intervals). One example is Exponential Smoothing Recurrent Neural Network (ES-RNN), a hybrid between a statistical forecasting model and a recurrent neural network variant. ES-RNN achieves a 9.4\\% improvement in absolute error in the Makridakis-4 Forecasting Competition. This improvement and similar outperformance from other hybrid models have primarily been demonstrated only on univariate datasets. Difficulties with applying hybrid forecast methods to multivariate data include ($i$) the high computational cost involved in hyperparameter tuning for models that are not parsimonious, ($ii$) challenges associated with auto-correlation inherent in the data, as well as ($iii$) complex dependency (cross-correlation) between the covariates that may be hard to capture. This paper presents Multivariate Exponential Smoothing Long Short Term Memory (MES-LSTM), a generalized multivariate extension to ES-RNN, that overcomes these challenges. MES-LSTM utilizes a vectorized implementation. We test MES-LSTM on several aggregated coronavirus <font color="#be00be">diseas</font>e of 2019 (COVID-19) morbidity datasets and find our hybrid approach shows consistent, significant improvement over pure statistical and deep learning methods at forecast accuracy and prediction interval construction. </br></br>

<a href='http://arxiv.org/pdf/2112.05667.pdf'>2112.05667</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.1461баллов, №798</br>
<b>A Deep Learning Based Automated Hand Hygiene Training System</b></br>
Authors: , Shahbandeh, Mobina, Ghaffarpour, Fatemeh, Vali, Sina, Haghpanah, Mohammad Amin, Torkamani, Amin Mousavi, Masouleh, Mehdi Tale, Kalhor, Ahmad</br>
  Hand hygiene is crucial for preventing viruses and infections. Due to the pervasive outbreak of COVID-19, wearing a mask and hand hygiene appear to be the most effective ways for the public to curb the spread of these viruses. The World Health Organization (WHO) recommends a guideline for alcohol-based hand rub in eight steps to ensure that all surfaces of hands are entirely clean. As these steps involve complex gestures, human assessment of them lacks enough accuracy. However, Deep Neural Network (DNN) and machine vision have made it possible to accurately evaluate hand rubbing quality for the purposes of training and feedback. In this paper, an automated deep learning based hand rub assessment system with real-time feedback is presented. The system evaluates the compliance with the 8-step guideline using a DNN architecture trained on a dataset of videos collected from volunteers with various skin tones and hand characteristics following the hand rubbing guideline. Various DNN architectures were tested, and an Inception-ResNet model led to the best results with 97% test accuracy. In the proposed system, an NVIDIA Jetson AGX Xavier embedded board runs the software. The efficacy of the system is evaluated in a concrete situation of being used by various users, and challenging steps are identified. In this experiment, the average time taken by the hand rubbing steps among volunteers is 27.2 seconds, which conforms to the WHO guidelines. </br></br>

<a href='http://arxiv.org/pdf/2112.06988.pdf'>2112.06988</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1483баллов, №799</br>
<b>Event-guided <font color="#be00be">Deblur</font>ring of Unknown Exposure Time Videos</b></br>
Authors: , Kim, Taewoo, Lee, Jungmin, Wang, Lin, Yoon, Kuk-Jin</br>
  Video <font color="#be00be">deblur</font>ring is a highly ill-posed problem due to the loss of motion information in the blur degradation process. Since event cameras can capture apparent motion with a high temporal resolution, several attempts have explored the potential of events for guiding video deblurring. These methods generally assume that the exposure time is the same as the reciprocal of the video frame rate. However,this is not true in real situations, and the exposure time might be unknown and dynamically varies depending on the video shooting environment(e.g., illumination condition). In this paper, we address the event-guided video deblurring assuming dynamically variable unknown exposure time of the frame-based camera. To this end, we first derive a new formulation for event-guided video deblurring by considering the exposure and readout time in the video frame acquisition process. We then propose a novel end-toend learning framework for event-guided video deblurring. In particular, we design a novel Exposure Time-based Event Selection(ETES) module to selectively use event features by estimating the cross-modal correlation between the features from blurred frames and the events. Moreover, we propose a feature fusion module to effectively fuse the selected features from events and blur frames. We conduct extensive experiments on various datasets and demonstrate that our method achieves <font color="#00be00">state-of-the-art</font> performance. Our project code and pretrained models will be available. </br></br>

<a href='http://arxiv.org/pdf/2111.08994.pdf'>2111.08994</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1504баллов, №800</br>
<b>Nonlinear Intensity Sonar Image Matching based on Deep Convolution\n  Features</b></br>
Authors: , Zhou, Xiaoteng, Yu, Changli, Yuan, Xin, Wu, Yi, Feng, Haijun, Luo, Citong</br>
  With the continuous development of underwater vision technology, more and more remote sensing images could be obtained. In the underwater scene, sonar sensors are currently the most effective remote perception devices, and the sonar images captured by them could provide rich environment information. In order to analyze a certain scene, we often need to merge the sonar images from different periods, various sonar frequencies and distinctive viewpoints. However, the above scenes will bring nonlinear intensity differences to the sonar images, which will make traditional matching methods almost ineffective. This paper proposes a non-linear intensity sonar image matching method that combines local feature points and deep convolution features. This method has two key advantages: (i) we generate data samples related to local feature points based on the self-learning idea; (ii) we use the convolutional neural network (CNN) and Siamese network architecture to measure the similarity of the local position in the sonar image pair. Our method encapsulates the feature extraction and feature matching stage in a model, and directly learns the mapping function from image patch pairs to matching labels, and achieves matching tasks in a near-end-to-end manner. Feature matching experiments are carried out on the sonar images acquired by autonomous underwater vehicle (AUV) in the real underwater environment. Experiment results show that our method has better matching effects and strong robustness. </br></br>

<a href='http://arxiv.org/pdf/2112.07743.pdf'>2112.07743</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.1513баллов, №801</br>
<b>Neighborhood Random Walk Graph Sampling for Regularized <font color="#be00be">Bayes</font>ian Graph\n  Convolutional Neural Networks</b></br>
Authors: , Komanduri, Aneesh, Zhan, Justin</br>
  In the modern age of social media and networks, graph representations of <font color="#009600">real-world</font> phenomena have become an incredibly useful source to mine insights. Often, we are interested in understanding how entities in a graph are interconnected. The Graph Neural Network (GNN) has proven to be a very useful tool in a variety of graph learning tasks including node classification, link prediction, and edge classification. However, in most of these tasks, the graph data we are working with may be noisy and may contain spurious edges. That is, there is a lot of uncertainty associated with the underlying graph structure. Recent approaches to modeling uncertainty have been to use a <font color="#be00be">Bayes</font>ian framework and view the graph as a random variable with probabilities associated with model parameters. Introducing the Bayesian paradigm to graph-based models, specifically for semi-supervised node classification, has been shown to yield higher classification accuracies. However, the method of graph inference proposed in recent work does not take into account the structure of the graph. In this paper, we propose a novel algorithm called Bayesian Graph Convolutional Network using Neighborhood Random Walk Sampling (BGCN-NRWS), which uses a Markov Chain Monte Carlo (MCMC) based graph sampling algorithm utilizing graph structure, reduces overfitting by using a variational inference layer, and yields consistently <font color="#960096">competitive</font> classification results compared to the <font color="#00be00">state-of-the-art</font> in semi-supervised node classification. </br></br>

<a href='http://arxiv.org/pdf/2112.05755.pdf'>2112.05755</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1517баллов, №802</br>
<b>Information Prebuilt Recurrent Reconstruction Network for Video\n  <font color="#be00be">Super-Resolution</font></b></br>
Authors: , Yu, Ming, Wang, Shuyun, Xue, Cuihong, Guo, Yingchun, Yan, Gang</br>
  The video <font color="#be00be">super-resolution</font> (VSR) method based on the recurrent convolutional network has strong temporal modeling capability for video sequences. However, the input information received by different recurrent units in the unidirectional recurrent convolutional network is unbalanced. Early reconstruction frames receive less temporal information, resulting in fuzzy or artifact results. Although the bidirectional recurrent convolution network can alleviate this problem, it greatly increases reconstruction time and computational complexity. It is also not suitable for many application scenarios, such as online super-resolution. To solve the above problems, we propose an end-to-end information prebuilt recurrent reconstruction network (IPRRN), consisting of an information prebuilt network (IPNet) and a recurrent reconstruction network (RRNet). By integrating sufficient information from the front of the video to build the hidden state needed for the initially recurrent unit to help restore the earlier frames, the information prebuilt network balances the input information difference before and after without backward propagation. In addition, we demonstrate a compact recurrent reconstruction network, which has significant improvements in recovery quality and time efficiency. Many experiments have verified the effectiveness of our proposed network, and compared with the existing <font color="#00be00">state-of-the-art</font> methods, our method can effectively achieve higher quantitative and qualitative evaluation performance. </br></br>

<a href='http://arxiv.org/pdf/2112.08300.pdf'>2112.08300</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.1519баллов, №803</br>
<b>Community Detection in Electrical Grids Using Quantum Annealing</b></br>
Authors: , Fern&#xe1;ndez-Campoamor, Marina, O\'Meara, Corey, Cortiana, Giorgio, Peric, Vedran, Bernab&#xe9;-Moreno, Juan</br>
  With the increase of intermittent renewable generation resources feeding into the electrical grid, Distribution System Operators (DSOs) must find ways to incorporate these new actors and adapt the grid to ensure stability and enable flexibility. Dividing the grid into logical clusters entails several organization and technical benefits, helping overcome these challenges.However, finding the optimal grid partitioning remains a challenging task due to its complexity. At the same time, a new technology has gained traction in the last decades for its promising speed-up potential in solving non-trivial combinatorial optimization problems: quantum computing. This work explores its application in Graph Partitioning using electrical modularity. We benchmarked several quantum annealing and hybrid methods on IEEE well-known test cases. The results obtained for the IEEE 14-bus test case show that quantum annealing DWaveSampler brings equal solutions or, for the optimal number partitions, a 1% improvement. For the more significant test cases, hybrid quantum annealing shows a relative error of less than 0.02% compared to the classical benchmark and for IEEE 118-bus test case shows time performance speed-up. The increment in performance would enable real time planning and operations of electrical grids in real time. This work intends to be the first step to showcase the potentials of quantum computing towards the modernization and adaption of electrical grids to the decentralized future of energy systems. </br></br>

<a href='http://arxiv.org/pdf/2112.06160.pdf'>2112.06160</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1524баллов, №804</br>
<b>Maintaining AUC and $H$-measure over time</b></br>
Authors: , Tatti, Nikolaj</br>
  Measuring the performance of a classifier is a vital task in machine learning. The running time of an algorithm that computes the measure plays a very small role in an offline setting, for example, when the classifier is being developed by a researcher. However, the running time becomes more crucial if our goal is to monitor the performance of a classifier over time.   In this paper we study three algorithms for maintaining two measures. The first algorithm maintains area under the ROC curve (AUC) under addition and deletion of data points in $O(\\log n)$ time. This is done by maintaining the data points sorted in a self-balanced search tree. In addition, we augment the search tree that allows us to query the ROC coordinates of a data point in $O(\\log n)$ time. In doing so we are able to maintain AUC in $O(\\log n)$ time. Our next two algorithms involve in maintaining $H$-measure, an alternative measure based on the ROC curve. Computing the measure is a two-step process: first we need to compute a convex hull of the ROC curve, followed by a sum over the convex hull. We demonstrate that we can maintain the convex hull using a minor modification of the classic convex hull maintenance algorithm. We then show that under certain conditions, we can compute the $H$-measure exactly in $O(\\log^2 n)$ time, and if the conditions are not met, then we can estimate the $H$-measure in $O((\\log n + \\epsilon^{-1})\\log n)$ time. We show empirically that our methods are significantly faster than the baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.05702.pdf'>2112.05702</a> &nbsp&nbsp (cs:ML, cs:CL, cs:NE) &nbsp&nbsp -0.1534баллов, №805</br>
<b>Sampling from Discrete Energy-Based Models with Quality/Efficiency\n  Trade-offs</b></br>
Authors: , Eikema, Bryan, Kruszewski, Germ&#xe1;n, Elsahar, Hady, Dymetman, Marc</br>
  Energy-Based Models (EBMs) allow for extremely flexible specifications of probability distributions. However, they do not provide a mechanism for obtaining exact samples from these distributions. Monte Carlo techniques can aid us in obtaining samples if some proposal distribution that we can easily sample from is available. For instance, rejection sampling can provide exact samples but is often difficult or impossible to apply due to the need to find a proposal distribution that upper-bounds the target distribution everywhere. Approximate Markov chain Monte Carlo sampling techniques like Metropolis-Hastings are usually easier to design, exploiting a local proposal distribution that performs local edits on an evolving sample. However, these techniques can be inefficient due to the local nature of the proposal distribution and do not provide an estimate of the quality of their samples. In this work, we propose a new approximate sampling technique, Quasi Rejection Sampling (QRS), that allows for a trade-off between sampling efficiency and sampling quality, while providing explicit convergence bounds and <font color="#be00be">diagnos</font>tics. QRS capitalizes on the availability of high-quality global proposal distributions obtained from deep learning models. We demonstrate the effectiveness of QRS sampling for discrete EBMs over text for the tasks of controlled text generation with distributional constraints and paraphrase generation. We show that we can sample from such EBMs with arbitrary precision at the cost of sampling efficiency. </br></br>

<a href='http://arxiv.org/pdf/2112.05700.pdf'>2112.05700</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1548баллов, №806</br>
<b>A Framework for Fairness: A Systematic Review of Existing Fair AI\n  Solutions</b></br>
Authors: , Richardson, Brianna, Gilbert, Juan E.</br>
  In a world of daily emerging scientific inquisition and discovery, the prolific launch of machine learning across industries comes to little surprise for those familiar with the potential of ML. Neither so should the congruent expansion of ethics-focused research that emerged as a response to issues of bias and unfairness that stemmed from those very same applications. Fairness research, which focuses on techniques to combat algorithmic bias, is now more supported than ever before. A large portion of fairness research has gone to producing tools that machine learning practitioners can use to audit for bias while designing their algorithms. Nonetheless, there is a lack of application of these fairness solutions in practice. This systematic review provides an in-depth summary of the algorithmic bias issues that have been defined and the fairness solution space that has been proposed. Moreover, this review provides an in-depth breakdown of the caveats to the solution space that have arisen since their release and a taxonomy of needs that have been proposed by machine learning practitioners, fairness researchers, and institutional stakeholders. These needs have been organized and addressed to the parties most influential to their implementation, which includes fairness researchers, organizations that produce ML algorithms, and the machine learning practitioners themselves. These findings can be used in the future to bridge the gap between practitioners and fairness experts and inform the creation of usable fair ML toolkits. </br></br>

<a href='http://arxiv.org/pdf/2112.06652.pdf'>2112.06652</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1551баллов, №807</br>
<b>DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG\n  Signals</b></br>
Authors: , Allain, C&#xe9;dric, Gramfort, Alexandre, Moreau, Thomas, Preprint, A</br>
  The quantitative analysis of non-invasive electrophysiology signals from electroencephalography (EEG) and magnetoencephalography (MEG) boils down to the identification of temporal patterns such as evoked responses, transient bursts of neural oscillations but also blinks or heartbeats for data cleaning. Several works have shown that these patterns can be extracted efficiently in an unsupervised way, e.g., using Convolutional Dictionary Learning. This leads to an event-based description of the data. Given these events, a natural question is to estimate how their occurrences are modulated by certain cognitive tasks and experimental manipulations. To address it, we propose a point process approach. While point processes have been used in neuroscience in the past, in particular for single cell recordings (spike trains), techniques such as Convolutional Dictionary Learning make them amenable to human studies based on EEG/MEG signals. We develop a novel statistical point process model-called driven temporal point processes (DriPP)-where the intensity function of the point process model is linked to a set of point processes corresponding to stimulation events. We derive a fast and principled expectation-maximization (EM) algorithm to estimate the parameters of this model. Simulations reveal that model parameters can be identified from long enough signals. Results on standard MEG datasets demonstrate that our methodology reveals event-related neural responses-both evoked and induced-and isolates non-task specific temporal patterns. </br></br>

<a href='http://arxiv.org/pdf/2112.07962.pdf'>2112.07962</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.1571баллов, №808</br>
<b>A learning-based approach to feature recognition of Engineering shapes</b></br>
Authors: , Muraleedharan, Lakshmi Priya, Muthuganapathy, Ramanathan</br>
  In this paper, we propose a machine learning approach to recognise engineering shape features such as holes, slots, etc. in a CAD mesh model. With the advent of digital archiving, newer manufacturing techniques such as 3D printing, scanning of components and reverse engineering, CAD data is proliferated in the form of mesh model representation. As the number of nodes and edges become larger in a mesh model as well as the possibility of presence of noise, direct application of graph-based approaches would not only be expensive but also difficult to be tuned for noisy data. Hence, this calls for newer approaches to be devised for feature recognition for CAD models represented in the form of mesh. Here, we show that a discrete version of Gauss map can be used as a signature for a feature learning. We show that this approach not only requires fewer memory requirements but also the training time is quite less. As no network architecture is involved, the number of hyperparameters are much lesser and can be tuned in a much faster time. The recognition accuracy is also very similar to that of the one obtained using 3D convolutional neural networks (CNN) but in much lesser running time and storage requirements. A comparison has been done with other non-network based machine learning approaches to show that our approach has the highest accuracy. We also show the recognition results for CAD models having multiple features as well as complex/interacting features obtained from public benchmarks. The ability to handle noisy data has also been demonstrated. </br></br>

<a href='http://arxiv.org/pdf/2112.08052.pdf'>2112.08052</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp -0.1575баллов, №809</br>
<b>Optimal Latent Space Forecasting for Large Collections of Short Time\n  Series Using Temporal Matrix Factorization</b></br>
Authors: , Charotia, Himanshi, Garg, Abhishek, Dhama, Gaurav, Maheshwari, Naman</br>
  In the context of time series forecasting, it is a common practice to evaluate multiple methods and choose one of these methods or an ensemble for producing the best forecasts. However, choosing among different ensembles over multiple methods remains a challenging task that undergoes a combinatorial explosion as the number of methods increases. In the context of demand forecasting or revenue forecasting, this challenge is further exacerbated by a large number of time series as well as limited historical data points available due to changing business context. Although deep learning forecasting methods aim to simultaneously forecast large collections of time series, they become challenging to apply in such scenarios due to the limited history available and might not yield desirable results. We propose a framework for forecasting short high-dimensional time series data by combining low-rank temporal matrix factorization and optimal model selection on latent time series using cross-validation. We demonstrate that forecasting the latent factors leads to significant performance gains as compared to directly applying different uni-variate models on time series. Performance has been validated on a truncated version of the M4 monthly dataset which contains time series data from multiple domains showing the general applicability of the method. Moreover, it is amenable to incorporating the analyst view of the future owing to the low number of latent factors which is usually impractical when applying forecasting methods directly to high dimensional datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.08684.pdf'>2112.08684</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.1576баллов, №810</br>
<b>META: Mimicking Embedding via oThers\' Aggregation for Generalizable\n  Person <font color="#be00be">Re-identification</font></b></br>
Authors: , Xu, Boqiang, Liang, Jian, He, Lingxiao, Sun, Zhenan</br>
  Domain generalizable (DG) person <font color="#be00be">re-identification</font> (ReID) aims to test across unseen domains without access to the target domain data at training time, which is a realistic but challenging problem. In contrast to methods assuming an identical model for different domains, Mixture of Experts (MoE) exploits multiple domain-specific networks for leveraging complementary information between domains, obtaining impressive results. However, prior MoE-based DG ReID methods suffer from a large model size with the increase of the number of source domains, and most of them overlook the exploitation of domain-invariant characteristics. To handle the two issues above, this paper presents a new approach called Mimicking Embedding via oThers\' Aggregation (META) for DG ReID. To avoid the large model size, experts in META do not add a branch network for each source domain but share all the parameters except for the batch normalization layers. Besides multiple experts, META leverages Instance Normalization (IN) and introduces it into a global branch to pursue invariant features across domains. Meanwhile, META considers the relevance of an unseen target sample and source domains via normalization statistics and develops an aggregation network to adaptively integrate multiple experts for mimicking unseen target domain. Benefiting from a proposed consistency loss and an episodic training algorithm, we can expect META to mimic embedding for a truly unseen target domain. Extensive experiments verify that META surpasses <font color="#00be00">state-of-the-art</font> DG ReID methods by a large margin. </br></br>

<a href='http://arxiv.org/pdf/2112.05630.pdf'>2112.05630</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1585баллов, №811</br>
<b>On Fair Selection in the Presence of Implicit and Differential Variance</b></br>
Authors: , Emelianov, Vitalii, Gast, Nicolas, Gummadi, Krishna P., Loiseau, Patrick</br>
  Discrimination in selection problems such as hiring or college admission is often explained by implicit bias from the decision maker against disadvantaged demographic groups. In this paper, we consider a model where the decision maker receives a noisy estimate of each candidate\'s quality, whose variance depends on the candidate\'s group -- we argue that such differential variance is a key feature of many selection problems. We analyze two notable settings: in the first, the noise variances are unknown to the decision maker who simply picks the candidates with the highest estimated quality independently of their group; in the second, the variances are known and the decision maker picks candidates having the highest expected quality given the noisy estimate. We show that both baseline decision makers yield discrimination, although in opposite directions: the first leads to underrepresentation of the low-variance group while the second leads to underrepresentation of the high-variance group. We study the effect on the selection utility of imposing a fairness mechanism that we term the $\\gamma$-rule (it is an extension of the classical four-fifths rule and it also includes demographic parity). In the first setting (with unknown variances), we prove that under mild conditions, imposing the $\\gamma$-rule increases the selection utility -- here there is no trade-off between fairness and utility. In the second setting (with known variances), imposing the $\\gamma$-rule decreases the utility but we prove a bound on the utility loss due to the fairness mechanism. </br></br>

<a href='http://arxiv.org/pdf/2112.07414.pdf'>2112.07414</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1602баллов, №812</br>
<b>Deep Sea Bubble Stream Characterization Using Wide-Baseline Stereo\n  Photogrammetry</b></br>
Authors: , She, Mengkun, Song, Yifan, Wei&#xdf;, Tim, Greinert, Jens, K&#xf6;ser, Kevin</br>
  Reliable quantification of natural and anthropogenic gas release (e.g.\\ CO$_2$, methane) from the seafloor into the ocean, and ultimately, the atmosphere, is a challenging task. While ship-based echo sounders allow detection of free gas in the water even from a larger distance, exact quantification requires parameters such as rise speed and bubble size distribution not obtainable by such sensors. Optical methods are complementary in the sense that they can provide high temporal and spatial resolution of single bubbles or bubble streams from close distance. In this contribution we introduce a complete instrument and evaluation method for optical bubble stream characterization. The dedicated instrument employs a high-speed deep sea stereo camera system that can record terabytes of bubble imagery when deployed at a seep site for later automated analysis. Bubble characteristics can be obtained for short sequences of few minutes, then relocating the instrument to other locations, or in autonomous mode of intervals up to several days, in order to capture variations due to current and pressure changes and across tidal cycles. Beside reporting the steps to make bubble characterization robust and autonomous, we carefully evaluate the reachable accuracy and propose a novel calibration procedure that, due to the lack of point correspondences, uses only the silhouettes of bubbles. The system has been operated successfully in up to 1000m water depth in the Pacific Ocean to assess methane fluxes. Besides sample results we also report failure cases and lessons learnt during development. </br></br>

<a href='http://arxiv.org/pdf/2112.08253.pdf'>2112.08253</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1607баллов, №813</br>
<b>Online Feature Selection for Efficient Learning in Networked Systems</b></br>
Authors: , Wang, Xiaoxuan, Stadler, Rolf</br>
  Current AI/ML methods for data-driven engineering use models that are mostly trained offline. Such models can be expensive to build in terms of communication and computing cost, and they rely on data that is collected over extended periods of time. Further, they become out-of-date when changes in the system occur. To address these challenges, we investigate online learning techniques that automatically reduce the number of available data sources for model training. We present an online algorithm called Online Stable Feature Set Algorithm (OSFS), which selects a small feature set from a large number of available data sources after receiving a small number of measurements. The algorithm is initialized with a feature ranking algorithm, a feature set stability metric, and a search policy. We perform an extensive experimental evaluation of this algorithm using traces from an in-house testbed and from a data center in operation. We find that OSFS achieves a massive reduction in the size of the feature set by 1-3 orders of magnitude on all investigated datasets. Most importantly, we find that the accuracy of a predictor trained on a OSFS-produced feature set is somewhat better than when the predictor is trained on a feature set obtained through offline feature selection. OSFS is thus shown to be effective as an online feature selection algorithm and robust regarding the sample interval used for feature selection. We also find that, when concept drift in the data underlying the model occurs, its effect can be mitigated by recomputing the feature set and retraining the prediction model. </br></br>

<a href='http://arxiv.org/pdf/2112.08274.pdf'>2112.08274</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1616баллов, №814</br>
<b>Putting People in their Place: Monocular <font color="#be00be">Regression</font> of 3D People in\n  Depth</b></br>
Authors: , Sun, Yu, Liu, Wu, Bao, Qian, Fu, Yili, Mei, Tao, Black, Michael J.</br>
  Given an image with multiple people, our goal is to directly regress the pose and shape of all the people as well as their relative depth. Inferring the depth of a person in an image, however, is fundamentally ambiguous without knowing their height. This is particularly problematic when the scene contains people of very different sizes, e.g. from infants to adults. To solve this, we need several things. First, we develop a novel method to infer the poses and depth of multiple people in a single image. While previous work that estimates multiple people does so by reasoning in the image plane, our method, called BEV, adds an additional imaginary Bird\'s-Eye-View representation to explicitly reason about depth. BEV reasons simultaneously about body centers in the image and in depth and, by combing these, estimates 3D body position. Unlike prior work, BEV is a single-shot method that is end-to-end differentiable. Second, height varies with age, making it impossible to resolve depth without also estimating the age of people in the image. To do so, we exploit a 3D body model space that lets BEV infer shapes from infants to adults. Third, to train BEV, we need a new dataset. Specifically, we create a &quot;Relative Human&quot; (RH) dataset that includes age labels and relative depth relationships between the people in the images. Extensive experiments on RH and AGORA demonstrate the effectiveness of the model and training scheme. BEV <font color="#00be00">outperform</font>s existing methods on depth reasoning, child shape estimation, and robustness to occlusion. The code and dataset will be released for research purposes. </br></br>

<a href='http://arxiv.org/pdf/2112.06887.pdf'>2112.06887</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.1624баллов, №815</br>
<b>Nonideality-Aware Training for Accurate and Robust Low-Power Memristive\n  Neural Networks</b></br>
Authors: , Joksas, Dovydas, Wang, Erwei, Barmpatsalos, Nikolaos, Ng, Wing H., Kenyon, Anthony J., Constantinides, George A., Mehonic, Adnan</br>
  Recent years have seen a rapid rise of artificial neural networks being employed in a number of cognitive tasks. The ever-increasing computing requirements of these structures have contributed to a desire for novel technologies and paradigms, including memristor-based hardware accelerators. Solutions based on memristive crossbars and analog data processing promise to improve the overall energy efficiency. However, memristor nonidealities can lead to the degradation of neural network accuracy, while the attempts to mitigate these negative effects often introduce design trade-offs, such as those between power and reliability. In this work, we design nonideality-aware training of memristor-based neural networks capable of dealing with the most common device nonidealities. We demonstrate the feasibility of using high-resistance devices that exhibit high $I$-$V$ nonlinearity -- by analyzing experimental data and employing nonideality-aware training, we estimate that the energy efficiency of memristive vector-matrix multipliers is improved by three orders of magnitude ($555\\ \\mathrm{GOPs}^{-1}\\mathrm{W}^{-1}$ to $474\\ \\mathrm{TOPs}^{-1}\\mathrm{W}^{-1}$) while maintaining similar accuracy. We show that associating the parameters of neural networks with individual memristors allows to bias these devices towards less conductive states through regularization of the corresponding optimization problem, while modifying the validation procedure leads to more reliable estimates of performance. We demonstrate the universality and robustness of our approach when dealing with a wide range of nonidealities. </br></br>

<a href='http://arxiv.org/pdf/2112.04947.pdf'>2112.04947</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1628баллов, №816</br>
<b>Automated Side Channel Analysis of Media Software with Manifold Learning</b></br>
Authors: , Yuan, Yuanyuan, Pang, Qi, Wang, Shuai</br>
  The prosperous development of cloud computing and machine learning as a service has led to the widespread use of media software to process confidential media data. This paper explores an adversary\'s ability to launch side channel analyses (SCA) against media software to reconstruct confidential media inputs. Recent advances in representation learning and perceptual learning inspired us to consider the reconstruction of media inputs from side channel traces as a cross-modality manifold learning task that can be addressed in a unified manner with an autoencoder framework trained to learn the mapping between media inputs and side channel observations. We further enhance the autoencoder with attention to localize the program points that make the primary contribution to SCA, thus automatically pinpointing information-leakage points in media software. We also propose a novel and highly effective defensive technique called perception blinding that can perturb media inputs with perception masks and mitigate manifold learning-based SCA.   Our evaluation exploits three popular media software to reconstruct inputs in image, audio, and text formats. We analyze three common side channels - cache bank, cache line, and page tables - and userspace-only cache set accesses logged by standard Prime+Probe. Our framework successfully reconstructs high-quality confidential inputs from the assessed media software and automatically pinpoint their vulnerable program points, many of which are unknown to the public. We further show that perception blinding can mitigate manifold learning-based SCA with negligible extra cost. </br></br>

<a href='http://arxiv.org/pdf/2112.06558.pdf'>2112.06558</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.1649баллов, №817</br>
<b>MAGIC: Multimodal relAtional Graph adversarIal inferenCe for Diverse and\n  Unpaired Text-based Image Captioning</b></br>
Authors: , Zhang, Wenqiao, Shi, Haochen, Guo, Jiannan, Zhang, Shengyu, Cai, Qingpeng, Li, Juncheng, Luo, Sihui, Zhuang, Yueting</br>
  Text-based image captioning (TextCap) requires simultaneous comprehension of visual content and reading the text of images to generate a natural language description. Although a task can teach machines to understand the complex human environment further given that text is omnipresent in our daily surroundings, it poses additional challenges in normal captioning. A text-based image intuitively contains abundant and complex multimodal relational content, that is, image details can be described diversely from multiview rather than a single caption. Certainly, we can introduce additional paired training data to show the diversity of images\' descriptions, this process is labor-intensive and time-consuming for TextCap pair annotations with extra texts. Based on the insight mentioned above, we investigate how to generate diverse captions that focus on different image parts using an unpaired training paradigm. We propose the Multimodal relAtional Graph adversarIal inferenCe (MAGIC) framework for diverse and unpaired TextCap. This framework can adaptively construct multiple multimodal relational graphs of images and model complex relationships among graphs to represent descriptive diversity. Moreover, a cascaded generative adversarial network is developed from modeled graphs to infer the unpaired caption generation in image-sentence feature alignment and linguistic coherence levels. We validate the effectiveness of MAGIC in generating diverse captions from different relational information items of an image. Experimental results show that MAGIC can generate very promising outcomes without using any image-caption training pairs. </br></br>

<a href='http://arxiv.org/pdf/2112.08409.pdf'>2112.08409</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1653баллов, №818</br>
<b>Quantum Model Learning Agent: characterisation of quantum systems\n  through machine learning</b></br>
Authors: , Flynn, Brian, Gentile, Antonio Andreas, Wiebe, Nathan, Santagati, Raffaele, Laing, Anthony</br>
  Accurate models of real quantum systems are important for investigating their behaviour, yet are difficult to distill empirically. Here, we report an algorithm -- the Quantum Model Learning Agent (QMLA) -- to reverse engineer Hamiltonian descriptions of a target system. We test the performance of QMLA on a number of simulated experiments, demonstrating several mechanisms for the design of candidate Hamiltonian models and simultaneously entertaining numerous hypotheses about the nature of the physical interactions governing the system under study. QMLA is shown to identify the true model in the majority of instances, when provided with limited a priori information, and control of the experimental setup. Our protocol can explore Ising, Heisenberg and Hubbard families of models in parallel, reliably identifying the family which best describes the system dynamics. We demonstrate QMLA operating on large model spaces by incorporating a genetic algorithm to formulate new hypothetical models. The selection of models whose features propagate to the next generation is based upon an objective function inspired by the Elo rating scheme, typically used to rate competitors in games such as chess and football. In all instances, our protocol finds models that exhibit $F_1$-score $\\geq 0.88$ when compared with the true model, and it precisely identifies the true model in 72% of cases, whilst exploring a space of over $250,000$ potential models. By testing which interactions actually occur in the target system, QMLA is a viable tool for both the exploration of fundamental physics and the characterisation and calibration of quantum devices. </br></br>

<a href='http://arxiv.org/pdf/2112.06746.pdf'>2112.06746</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.1688баллов, №819</br>
<b>Probability Density Estimation Based Imitation Learning</b></br>
Authors: , Liu, Yang, Chang, Yongzhe, Jiang, Shilei, Wang, Xueqian, Liang, Bin, Yuan, Bo</br>
  Imitation Learning (IL) is an effective learning paradigm exploiting the interactions between agents and environments. It does not require explicit reward signals and instead tries to recover desired policies using expert demonstrations. In general, IL methods can be categorized into Behavioral Cloning (BC) and Inverse <font color="#00be00">Reinforcement Learning</font> (IRL). In this work, a novel reward function based on probability density estimation is proposed for IRL, which can significantly reduce the complexity of existing IRL methods. Furthermore, we prove that the <font color="#be00be">theor</font>etically optimal policy derived from our reward function is identical to the expert policy as long as it is deterministic. Consequently, an IRL problem can be gracefully transformed into a probability density estimation problem. Based on the proposed reward function, we present a &quot;watch-try-learn&quot; <font color="#be00be">style</font> framework named Probability Density Estimation based Imitation Learning (PDEIL), which can work in both discrete and continuous action spaces. Finally, comprehensive experiments in the Gym environment show that PDEIL is much more efficient than existing algorithms in recovering rewards close to the ground truth. </br></br>

<a href='http://arxiv.org/pdf/2112.06772.pdf'>2112.06772</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1698баллов, №820</br>
<b>hARMS: A Hardware Acceleration Architecture for Real-Time Event-Based\n  Optical Flow</b></br>
Authors: , Stumpp, Daniel C., Akolkar, Himanshu, George, Alan D., Benosman, Ryad B.</br>
  Event-based vision sensors produce asynchronous event streams with high temporal resolution based on changes in the visual scene. The properties of these sensors allow for accurate and fast calculation of optical flow as events are generated. Existing solutions for calculating optical flow from event data either fail to capture the true direction of motion due to the aperture problem, do not use the high temporal resolution of the sensor, or are too computationally expensive to be run in real time on embedded platforms. In this research, we first present a faster version of our previous algorithm, ARMS (Aperture Robust Multi-Scale flow). The new optimized software version (fARMS) significantly improves throughput on a traditional CPU. Further, we present hARMS, a hardware realization of the fARMS algorithm allowing for real-time computation of true flow on low-power, embedded platforms. The proposed hARMS architecture targets hybrid system-on-chip devices and was designed to maximize configurability and throughput. The hardware architecture and fARMS algorithm were developed with asynchronous neuromorphic processing in mind, abandoning the common use of an event frame and instead operating using only a small history of relevant events, allowing latency to scale independently of the sensor resolution. This change in processing paradigm improved the estimation of flow directions by up to 73% compared to the existing method and yielded a demonstrated hARMS throughput of up to 1.21 Mevent/s on the benchmark configuration selected. This throughput enables real-time performance and makes it the fastest known realization of aperture-robust, event-based optical flow to date. </br></br>

<a href='http://arxiv.org/pdf/2112.08447.pdf'>2112.08447</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp -0.1698баллов, №821</br>
<b>Positional Encoding Augmented GAN for the Assessment of Wind Flow for\n  <font color="#be00be">Pedestrian</font> Comfort in Urban Areas</b></br>
Authors: , H&#xf8;iness, Henrik, Gjerde, Kristoffer, Oggiano, Luca, Giljarhus, Knut Erik Teigen, Ruocco, Massimiliano</br>
  Approximating wind flows using computational fluid dynamics (CFD) methods can be time-consuming. Creating a tool for interactively designing prototypes while observing the wind flow change requires simpler models to simulate faster. Instead of running numerical approximations resulting in detailed calculations, data-driven methods in deep learning might be able to give similar results in a fraction of the time. This work rephrases the problem from computing 3D flow fields using CFD to a 2D image-to-image translation-based problem on the building footprints to predict the flow field at <font color="#be00be">pedestrian</font> height level. We investigate the use of generative adversarial networks (GAN), such as Pix2Pix [1] and CycleGAN [2] representing <font color="#00be00">state-of-the-art</font> for image-to-image translation task in various domains as well as U-Net autoencoder [3]. The models can learn the underlying distribution of a dataset in a data-driven manner, which we argue can help the model learn the underlying Reynolds-averaged Navier-Stokes (RANS) equations from CFD. We experiment on novel simulated datasets on various three-dimensional bluff-shaped buildings with and without height information. Moreover, we present an extensive qualitative and quantitative evaluation of the generated images for a selection of models and compare their performance with the simulations delivered by CFD. We then show that adding positional data to the input can produce more accurate results by proposing a general framework for injecting such information on the different architectures. Furthermore, we show that the models performances improve by applying attention mechanisms and spectral normalization to facilitate stable training. </br></br>

<a href='http://arxiv.org/pdf/2112.08961.pdf'>2112.08961</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1729баллов, №822</br>
<b>Objective hearing threshold identification from auditory <font color="#00be00">brain</font>stem\n  response measurements using supervised and self-supervised approaches</b></br>
Authors: , Thalmeier, Dominik, Miller, Gregor, Schneltzer, Elida, Hurt, Anja, de Angelis, Martin Hrab&#x11b;, Becker, Lore, M&#xfc;ller, Christian L., Maier, Holger</br>
  Hearing loss is a major health problem and psychological burden in humans. Mouse models offer a possibility to elucidate genes involved in the underlying developmental and pathophysiological mechanisms of hearing impairment. To this end, large-scale mouse phenotyping programs include auditory phenotyping of single-gene knockout mouse lines. Using the auditory <font color="#00be00">brain</font>stem response (ABR) procedure, the German Mouse <font color="#be00be">Clinic</font> and similar facilities worldwide have produced large, uniform data sets of averaged ABR raw data of mutant and wildtype mice. In the course of standard ABR analysis, hearing thresholds are assessed visually by trained staff from series of signal curves of increasing sound pressure level. This is time-consuming and prone to be biased by the reader as well as the graphical display quality and scale. In an attempt to reduce workload and improve quality and reproducibility, we developed and compared two methods for automated hearing threshold identification from averaged ABR raw data: a supervised approach involving two combined neural networks trained on human-generated labels and a self-supervised approach, which exploits the signal power spectrum and combines <font color="#be00be">random forest</font> sound level estimation with a piece-wise curve fitting algorithm for threshold finding. We show that both models work well, <font color="#00be00">outperform</font> human threshold detection, and are suitable for fast, reliable, and unbiased hearing threshold detection and quality control. In a high-throughput mouse phenotyping environment, both methods perform well as part of an automated end-to-end screening pipeline to detect candidate genes for hearing involvement. Code for both models as well as data used for this work are freely available. </br></br>

<a href='http://arxiv.org/pdf/2112.08547.pdf'>2112.08547</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.1734баллов, №823</br>
<b>Learning Rich Representation of Keyphrases from Text</b></br>
Authors: , Kulkarni, Mayank, Mahata, Debanjan, Arora, Ravneet, Bhowmik, Rajarshi</br>
  In this work, we explore how to learn task-specific language models aimed towards learning rich representation of keyphrases from text documents. We experiment with different masking strategies for pre-training <font color="#00be00">transformer</font> language models (LMs) in discriminative as well as generative settings. In the discriminative setting, we introduce a new pre-training objective - Keyphrase Boundary Infilling with Replacement (KBIR), showing large gains in performance (upto 9.26 points in F1) over SOTA, when LM pre-trained using KBIR is fine-tuned for the task of keyphrase extraction. In the generative setting, we introduce a new pre-training setup for BART - KeyBART, that reproduces the keyphrases related to the input text in the CatSeq format, instead of the denoised original input. This also led to gains in performance (upto 4.33 points in F1@M) over SOTA for keyphrase generation. Additionally, we also fine-tune the pre-trained language models on <font color="#be00be">named entity</font> recognition (NER), question answering (QA), relation extraction (RE), abstractive <font color="#be00be">summarization</font> and achieve comparable performance with that of the SOTA, showing that learning rich representation of keyphrases is indeed beneficial for many other fundamental NLP tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.06125.pdf'>2112.06125</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.1741баллов, №824</br>
<b>Extending AdamW by Leveraging Its Second Moment and Magnitude</b></br>
Authors: , Zhang, Guoqiang, Kenta, Niwa, Kleijn, W. Bastiaan</br>
  Recent work [4] analyses the local convergence of Adam in a neighbourhood of an optimal solution for a twice-differentiable function. It is found that the learning rate has to be sufficiently small to ensure local stability of the optimal solution. The above convergence results also hold for AdamW. In this work, we propose a new adaptive optimisation method by extending AdamW in two aspects with the purpose to relax the requirement on small learning rate for local stability, which we refer to as Aida. Firstly, we consider <font color="#be00be">tracking</font> the 2nd moment r_t of the pth power of the gradient-magnitudes. r_t reduces to v_t of AdamW when p=2. Suppose {m_t} is the first moment of AdamW. It is known that the update direction m_{t+1}/(v_{t+1}+epsilon)^0.5 (or m_{t+1}/(v_{t+1}^0.5+epsilon) of AdamW (or Adam) can be decomposed as the sign vector sign(m_{t+1}) multiplied elementwise by a vector of magnitudes |m_{t+1}|/(v_{t+1}+epsilon)^0.5 (or |m_{t+1}|/(v_{t+1}^0.5+epsilon)). Aida is designed to compute the qth power of the magnitude in the form of |m_{t+1}|^q/(r_{t+1}+epsilon)^(q/p) (or |m_{t+1}|^q/((r_{t+1})^(q/p)+epsilon)), which reduces to that of AdamW when (p,q)=(2,1).   Suppose the origin 0 is a local optimal solution of a twice-differentiable function. It is found <font color="#be00be">theor</font>etically that when q&gt;1 and p&gt;1 in Aida, the origin 0 is locally stable only when the weight-decay is non-zero. Experiments are conducted for solving ten toy optimisation problems and training <font color="#00be00">Transformer</font> and Swin-Transformer for two deep learning (DL) tasks. The empirical study demonstrates that in a number of scenarios (including the two DL tasks), Aida with particular setups of (p,q) not equal to (2,1) <font color="#00be00">outperform</font>s the setup (p,q)=(2,1) of AdamW. </br></br>

<a href='http://arxiv.org/pdf/2112.03265.pdf'>2112.03265</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1778баллов, №825</br>
<b>A Deep-Learning Intelligent System Incorporating Data Augmentation for\n  Short-Term Voltage Stability Assessment of Power Systems</b></br>
Authors: , Li, Yang, Zhang, Meng, Chen, Chen</br>
  Facing the difficulty of expensive and trivial data collection and annotation, how to make a deep learning-based short-term voltage stability assessment (STVSA) model work well on a small training dataset is a challenging and urgent problem. Although a big enough dataset can be directly generated by contingency simulation, this data generation process is usually cumbersome and inefficient; while data augmentation provides a low-cost and efficient way to artificially inflate the representative and diversified training datasets with label preserving transformations. In this respect, this paper proposes a novel deep-learning intelligent system incorporating data augmentation for STVSA of power systems. First, due to the unavailability of reliable quantitative criteria to judge the stability status for a specific power system, semi-supervised cluster learning is leveraged to obtain labeled samples in an original small dataset. Second, to make deep learning applicable to the small dataset, conditional least squares generative adversarial networks (LSGAN)-based data augmentation is introduced to expand the original dataset via artificially creating additional valid samples. Third, to extract temporal dependencies from the post-disturbance dynamic trajectories of a system, a bi-directional gated recurrent unit with attention mechanism based assessment model is established, which bi-directionally learns the significant time dependencies and automatically allocates attention weights. The test results demonstrate the presented approach manages to achieve better accuracy and a faster response time with original small datasets. Besides classification accuracy, this work employs statistical measures to comprehensively examine the performance of the proposal. </br></br>

<a href='http://arxiv.org/pdf/2112.08627.pdf'>2112.08627</a> &nbsp&nbsp (cs:NE) &nbsp&nbsp -0.1813баллов, №826</br>
<b>On the Use of Quality Diversity Algorithms for The Traveling Thief\n  Problem</b></br>
Authors: , Nikfarjam, Adel, Neumann, Aneta, Neumann, Frank</br>
  In <font color="#009600">real-world</font> optimisation, it is common to<font color="#be00be"> face </font>several sub-problems interacting and forming the main problem. There is an inter-dependency between the sub-problems, making it impossible to solve such a problem by focusing on only one component. The traveling thief problem~(TTP) belongs to this category and is formed by the integration of the traveling salesperson problem~(TSP) and the knapsack problem~(KP). In this paper, we investigate the inter-dependency of the TSP and the KP by means of quality diversity~(QD) approaches. QD algorithms provide a powerful tool not only to obtain high-quality solutions but also to illustrate the distribution of high-performing solutions in the behavioural space. We introduce a MAP-Elite based evolutionary algorithm using well-known TSP and KP search operators, taking the TSP and KP score as behavioural descriptor. Afterwards, we conduct comprehensive experimental studies that show the usefulness of using the QD approach applied to the TTP. First, we provide insights regarding high-quality TTP solutions in the TSP/KP behavioural space. Afterwards, we show that better solutions for the TTP can be obtained by using our QD approach and show that it can improve the best-known solution for a wide range of TTP instances used for benchmarking in the literature. </br></br>

<a href='http://arxiv.org/pdf/2112.07954.pdf'>2112.07954</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.1825баллов, №827</br>
<b>Object Pursuit: Building a Space of Objects via Discriminative Weight\n  Generation</b></br>
Authors: , Pan, Chuanyu, Yang, Yanchao, Mo, Kaichun, Duan, Yueqi, Guibas, Leonidas</br>
  We propose a framework to continuously learn object-centric representations for visual learning and understanding. Existing object-centric representations either rely on supervisions that individualize objects in the scene, or perform unsupervised disentanglement that can hardly deal with complex scenes in the <font color="#009600">real world</font>. To mitigate the annotation burden and relax the constraints on the statistical complexity of the data, our method leverages interactions to effectively sample diverse variations of an object and the corresponding training signals while learning the object-centric representations. Throughout learning, objects are streamed one by one in random order with unknown identities, and are associated with latent codes that can synthesize discriminative weights for each object through a convolutional hypernetwork. Moreover, <font color="#be00be">re-identification</font> of learned objects and forgetting prevention are employed to make the learning process efficient and robust. We perform an extensive study of the key features of the proposed framework and analyze the characteristics of the learned representations. Furthermore, we demonstrate the capability of the proposed framework in learning representations that can improve label efficiency in downstream tasks. Our code and trained models will be made <font color="#00be00">publicly available</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.07575.pdf'>2112.07575</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1837баллов, №828</br>
<b>Robust Graph Neural Networks via Probabilistic Lipschitz Constraints</b></br>
Authors: , Arghal, Raghu, Lei, Eric, Bidokhti, Shirin Saeedi</br>
  Graph neural networks (GNNs) have recently been demonstrated to perform well on a variety of network-based tasks such as decentralized control and resource allocation, and provide computationally efficient methods for these tasks which have traditionally been challenging in that regard. However, like many neural-network based systems, GNNs are susceptible to shifts and perturbations on their inputs, which can include both node attributes and graph structure. In order to make them more useful for <font color="#009600">real-world</font> applications, it is important to ensure their robustness post-deployment. Motivated by controlling the Lipschitz constant of GNN filters with respect to the node attributes, we propose to constrain the frequency response of the GNN\'s filter banks. We extend this formulation to the dynamic graph setting using a continuous frequency response constraint, and solve a relaxed variant of the problem via the scenario approach. This allows for the use of the same computationally efficient algorithm on sampled constraints, which provides PAC-<font color="#be00be">style</font> guarantees on the stability of the GNN using results in scenario optimization. We also highlight an important connection between this setup and GNN stability to graph perturbations, and provide experimental results which demonstrate the efficacy and broadness of our approach. </br></br>

<a href='http://arxiv.org/pdf/2111.00424.pdf'>2111.00424</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1843баллов, №829</br>
<b>Artificial Association Neural Networks</b></br>
Authors: , Kim, Seokjun, Jang, Jaeeun, Jung, Hee-seok, Kim, Hyeoncheol</br>
  In the field of deep learning, various architectures have been developed. However, most studies are limited to specific tasks or datasets due to their fixed layer structure. This paper does not express the structure delivering information as a network model but as a data structure called a neuro tree(NT). And we propose two artificial association networks(AANs) designed to solve the problems of existing networks by analyzing the structure of human neural networks. Defining the starting and ending points of the path in a single graph is difficult, and a tree cannot express the relationship among sibling nodes. On the contrary, an NT can express leaf and root nodes as the starting and ending points of the path and the relationship among sibling nodes. Instead of using fixed sequence layers, we create a neuro tree for each data and train AANs according to the tree\'s structure. AANs are data-driven learning in which the number of convolutions varies according to the depth of the tree. Moreover, AANs can simultaneously learn various types of datasets through the recursive learning. Depth-first convolution (DFC) encodes the interaction result from leaf nodes to the root node in a bottom-up approach, and depth-first deconvolution (DFD) decodes the interaction result from the root node to the leaf nodes in a top-down approach. We conducted three experiments. The first experiment verified whether it could be processed by combining AANs and feature extraction networks. In the second, we compared the performance of networks that separately learned image, sound, and tree, graph structure datasets with the performance simultaneously learned by connecting these networks. In the third, we verified whether the output of AANs can embed all data in the NT. As a result, AATs learned without significant performance degradation. </br></br>

<a href='http://arxiv.org/pdf/2112.06247.pdf'>2112.06247</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.1846баллов, №830</br>
<b>DeepFIB: Self-Imputation for Time Series <font color="#be00be">Anomal</font>y Detection</b></br>
Authors: , Liu, Minhao, Xu, Zhijian, Xu, Qiang</br>
  Time series (TS) <font color="#be00be">anomal</font>y detection (AD) plays an essential role in various applications, e.g., fraud detection in <font color="#be00be">financ</font>e and healthcare monitoring. Due to the inherently unpredictable and highly varied nature of anomalies and the lack of anomaly labels in historical data, the AD problem is typically formulated as an unsupervised learning problem. The performance of existing solutions is often not satisfactory, especially in data-scarce scenarios. To tackle this problem, we propose a novel self-supervised learning technique for AD in time series, namely \\emph{DeepFIB}. We model the problem as a \\emph{Fill In the Blank} game by masking some elements in the TS and imputing them with the rest. Considering the two common anomaly shapes (point- or sequence-<font color="#be00be">outlier</font>s) in TS data, we implement two masking strategies with many self-generated training samples. The corresponding self-imputation networks can extract more robust temporal relations than existing AD solutions and effectively facilitate identifying the two types of anomalies. For continuous outliers, we also propose an anomaly localization algorithm that dramatically reduces AD errors. Experiments on various <font color="#009600">real-world</font> TS datasets demonstrate that DeepFIB <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> methods by a large margin, achieving up to $65.2\\%$ relative improvement in F1-score. </br></br>

<a href='http://arxiv.org/pdf/2112.05705.pdf'>2112.05705</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.1868баллов, №831</br>
<b>Pruning Pretrained Encoders with a Multitask Objective</b></br>
Authors: , Xia, Patrick, Shin, Richard</br>
  The sizes of pretrained language models make them challenging and expensive to use when there are multiple desired downstream tasks. In this work, we adopt recent strategies for model pruning during finetuning to explore the question of whether it is possible to prune a single encoder so that it can be used for multiple tasks. We allocate a fixed parameter budget and compare pruning a single model with a multitask objective against the best ensemble of single-task models. We find that under two pruning strategies (element-wise and rank pruning), the approach with the multitask objective <font color="#00be00">outperform</font>s training models separately when averaged across all tasks, and it is <font color="#960096">competitive</font> on each individual one. Additional analysis finds that using a multitask objective during pruning can also be an effective method for reducing model sizes for <font color="#be00be">low-resource</font> tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.08140.pdf'>2112.08140</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.1888баллов, №832</br>
<b>Improving Conversational <font color="#be00be">Recommendat</font>ion Systems\' Quality with\n  Context-Aware Item Meta Information</b></br>
Authors: , Yang, Bowen, Han, Cong, Li, Yu, Zuo, Lei, Yu, Zhou</br>
  Conversational <font color="#be00be">recommendat</font>ion systems (CRS) engage with users by inferring user preferences from dialog history, providing accurate recommendations, and generating appropriate responses. Previous CRSs use <font color="#960096">knowledge graph</font> (KG) based recommendation modules and integrate KG with language models for response generation. Although KG-based approaches prove effective, two issues remain to be solved. First, KG-based approaches ignore the information in the conversational context but only rely on entity relations and bag of words to recommend items. Second, it requires substantial engineering efforts to maintain KGs that model domain-specific relations, thus leading to less flexibility. In this paper, we propose a simple yet effective architecture comprising a pre-trained language model (PLM) and an item metadata encoder. The encoder learns to map item metadata to embeddings that can reflect the semantic information in the dialog context. The PLM then consumes the semantic-aligned item embeddings together with dialog context to generate high-quality recommendations and responses. Instead of modeling entity relations with KGs, our model reduces engineering complexity by directly converting each item to an embedding. Experimental results on the benchmark dataset ReDial show that our model obtains <font color="#00be00">state-of-the-art</font> results on both recommendation and response generation tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.07995.pdf'>2112.07995</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1902баллов, №833</br>
<b>Domain-informed neural networks for interaction localization within\n  astroparticle experiments</b></br>
Authors: , Liang, Shixiao, Higuera, Aaron, Peters, Christina, Roy, Venkat, Bajwa, Waheed U., Shatkay, Hagit, Tunnell, Christopher D.</br>
  This work proposes a domain-informed neural network architecture for experimental particle physics, using particle interaction localization with the time-projection chamber (TPC) technology for dark matter research as an example application. A key feature of the signals generated within the TPC is that they allow localization of particle interactions through a process called reconstruction. While multilayer perceptrons (MLPs) have emerged as a leading contender for reconstruction in TPCs, such a black-box approach does not reflect prior knowledge of the underlying scientific processes. This paper looks anew at neural network-based interaction localization and encodes prior detector knowledge, in terms of both signal characteristics and detector geometry, into the feature encoding and the output layers of a multilayer neural network. The resulting Domain-informed Neural Network (DiNN limits the receptive fields of the neurons in the initial feature encoding layers in order to account for the spatially localized nature of the signals produced within the TPC. This aspect of the DiNN, which has similarities with the emerging area of graph neural networks in that the neurons in the initial layers only connect to a handful of neurons in their succeeding layer, significantly reduces the number of parameters in the network in comparison to an MLP. In addition, in order to account for the detector geometry, the output layers of the network are modified using two geometric transformations to ensure the DiNN produces localizations within the interior of the detector. The end result is a neural network architecture that has 60% fewer parameters than an MLP, but that still achieves similar localization performance and provides a path to future architectural developments with improved performance because of their ability to encode additional domain knowledge into the architecture. </br></br>

<a href='http://arxiv.org/pdf/2112.07342.pdf'>2112.07342</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.1908баллов, №834</br>
<b>Learning to Guide and to Be Guided in the Architect-Builder Problem</b></br>
Authors: , Paul, Barde, Tristan, Karch, Derek, Nowrouzezahrai, Cl&#xe9;ment, Moulin-Frier, Christopher, Pal, Pierre-Yves, Oudeyer</br>
  We are interested in interactive agents that learn to coordinate, namely, a $builder$ -- which performs actions but ignores the goal of the task -- and an $architect$ which guides the builder towards the goal of the task. We define and explore a formal setting where artificial agents are equipped with mechanisms that allow them to simultaneously learn a task while at the same time evolving a shared communication protocol. The field of Experimental Semiotics has shown the extent of human proficiency at learning from a priori unknown instructions meanings. Therefore, we take inspiration from it and present the Architect-Builder Problem (ABP): an asymmetrical setting in which an architect must learn to guide a builder towards constructing a specific structure. The architect knows the target structure but cannot act in the environment and can only send arbitrary messages to the builder. The builder on the other hand can act in the environment but has no knowledge about the task at hand and must learn to solve it relying only on the messages sent by the architect. Crucially, the meaning of messages is initially not defined nor shared between the agents but must be negotiated throughout learning. Under these constraints, we propose Architect-Builder Iterated Guiding (ABIG), a solution to the Architect-Builder Problem where the architect leverages a learned model of the builder to guide it while the builder uses self-imitation learning to reinforce its guided behavior. We analyze the key learning mechanisms of ABIG and test it in a 2-dimensional instantiation of the ABP where tasks involve grasping cubes, placing them at a given location, or building various shapes. In this environment, ABIG results in a low-level, high-frequency, guiding communication protocol that not only enables an architect-builder pair to solve the task at hand, but that can also generalize to unseen tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.08592.pdf'>2112.08592</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.1910баллов, №835</br>
<b>Idiomatic Expression Paraphrasing without Strong Supervision</b></br>
Authors: , Zhou, Jianing, Zeng, Ziheng, Gong, Hongyu, Bhat, Suma</br>
  Idiomatic expressions (IEs) play an essential role in natural language. In this paper, we study the task of idiomatic sentence paraphrasing (ISP), which aims to paraphrase a sentence with an IE by replacing the IE with its literal paraphrase. The lack of large-scale corpora with idiomatic-literal parallel sentences is a primary challenge for this task, for which we consider two separate solutions. First, we propose an unsupervised approach to ISP, which leverages an IE\'s contextual information and definition and does not require a parallel sentence training set. Second, we propose a weakly supervised approach using back-translation to jointly perform paraphrasing and generation of sentences with IEs to enlarge the small-scale parallel sentence training dataset. Other significant derivatives of the study include a model that replaces a literal phrase in a sentence with an IE to generate an idiomatic expression and a large scale parallel dataset with idiomatic/literal sentence pairs. The effectiveness of the proposed solutions compared to <font color="#960096">competitive</font> baselines is seen in the relative gains of over 5.16 points in BLEU, over 8.75 points in METEOR, and over 19.57 points in SARI when the generated sentences are empirically validated on a parallel dataset using automatic and manual evaluations. We demonstrate the practical utility of ISP as a preprocessing step in En-De machine translation. </br></br>

<a href='http://arxiv.org/pdf/2112.08844.pdf'>2112.08844</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp -0.1911баллов, №836</br>
<b>Adapting Document-Grounded Dialog Systems to Spoken Conversations using\n  Data Augmentation and a Noisy Channel Model</b></br>
Authors: , Thulke, David, Daheim, Nico, Dugast, Christian, Ney, Hermann</br>
  This paper summarizes our submission to Task 2 of the second track of the 10th Dialog System Technology Challenge (DSTC10) &quot;Knowledge-grounded Task-oriented Dialogue Modeling on Spoken Conversations&quot;. Similar to the previous year\'s iteration, the task consists of three subtasks: detecting whether a turn is knowledge seeking, selecting the relevant knowledge document and finally generating a grounded response. This year, the focus lies on adapting the system to noisy ASR transcripts. We explore different approaches to make the models more robust to this type of input and to adapt the generated responses to the <font color="#be00be">style</font> of spoken conversations. For the latter, we get the best results with a noisy channel model that additionally reduces the number of short and generic responses. Our best system achieved the 1st rank in the automatic and the 3rd rank in the human evaluation of the challenge. </br></br>

<a href='http://arxiv.org/pdf/2112.08988.pdf'>2112.08988</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1916баллов, №837</br>
<b>Interference Suppression Using Deep Learning: Current Approaches and\n  Open Challenges</b></br>
Authors: , Oyedare, Taiwo, Shah, Vijay K, Jakubisin, Daniel J, Reed, Jeff H</br>
  In light of the finite nature of the wireless spectrum and the increasing demand for spectrum use arising from recent technological breakthroughs in wireless communication, the problem of interference continues to persist. Despite recent advancements in resolving interference issues, interference still presents a difficult challenge to effective usage of the spectrum. This is partly due to the rise in the use of license-free and managed shared bands for Wi-Fi, long term evolution (LTE) unlicensed (LTE-U), LTE licensed assisted access (LAA), 5G NR, and other opportunistic spectrum access solutions. As a result of this, the need for efficient spectrum usage schemes that are robust against interference has never been more important. In the past, most solutions to interference have addressed the problem by using avoidance techniques as well as non-AI mitigation approaches (for example, adaptive filters). The key downside to non-AI techniques is the need for domain expertise in the extraction or exploitation of signal features such as cyclostationarity, bandwidth and modulation of the interfering signals. More recently, researchers have successfully explored AI/ML enabled physical (PHY) layer techniques, especially deep learning which reduces or compensates for the interfering signal instead of simply avoiding it. The underlying idea of ML based approaches is to learn the interference or the interference characteristics from the data, thereby sidelining the need for domain expertise in suppressing the interference. In this paper, we review a wide range of techniques that have used deep learning to suppress interference. We provide comparison and guidelines for many different types of deep learning techniques in interference suppression. In addition, we highlight challenges and potential future research directions for the successful adoption of deep learning in interference suppression. </br></br>

<a href='http://arxiv.org/pdf/2112.05928.pdf'>2112.05928</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.1920баллов, №838</br>
<b>Efficient Device Scheduling with Multi-Job <font color="#be00be">Federated</font> Learning</b></br>
Authors: , Zhou, Chendi, Liu, Ji, Jia, Juncheng, Zhou, Jingbo, Zhou, Yang, Dai, Huaiyu, Dou, Dejing</br>
  Recent years have witnessed a large amount of decentralized data in multiple (edge) devices of end-users, while the aggregation of the decentralized data remains difficult for machine learning jobs due to laws or regulations. <font color="#be00be">Federated</font> Learning (FL) emerges as an effective approach to handling decentralized data without sharing the sensitive raw data, while collaboratively training global machine learning models. The servers in FL need to select (and schedule) devices during the training process. However, the scheduling of devices for multiple jobs with FL remains a critical and open problem. In this paper, we propose a novel multi-job FL framework to enable the parallel training process of multiple jobs. The framework consists of a system model and two scheduling methods. In the system model, we propose a parallel training process of multiple jobs, and construct a cost model based on the training time and the data fairness of various devices during the training process of diverse jobs. We propose a <font color="#00be00">reinforcement learning</font>-based method and a <font color="#be00be">Bayes</font>ian optimization-based method to schedule devices for multiple jobs while minimizing the cost. We conduct extensive experimentation with multiple jobs and datasets. The experimental results show that our proposed approaches significantly <font color="#00be00">outperform</font> baseline approaches in terms of training time (up to 8.67 times faster) and accuracy (up to 44.6% higher). </br></br>

<a href='http://arxiv.org/pdf/2112.05934.pdf'>2112.05934</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.1920баллов, №839</br>
<b>SPDCinv: Inverse Quantum-Optical Design of High-Dimensional Qudits</b></br>
Authors: , Rozenberg, Eyal, Karnieli, Aviv, Yesharim, Ofir, Foley-Comer, Joshua, Trajtenberg-Mills, Sivan, Freedman, Daniel, Bronstein, Alex M., Arie, Ady</br>
  Spontaneous parametric down-conversion in quantum optics is an invaluable resource for the realization of high-dimensional qudits with spatial modes of light. One of the main open challenges is how to directly generate a desirable qudit state in the SPDC process. This problem can be addressed through advanced computational learning methods; however, due to difficulties in modeling the SPDC process by a fully differentiable algorithm that takes into account all interaction effects, progress has been limited. Here, we overcome these limitations and introduce a physically-constrained and differentiable model, validated against experimental results for shaped pump beams and structured crystals, capable of learning every interaction parameter in the process. We avoid any restrictions induced by the stochastic nature of our physical model and integrate the dynamic equations governing the evolution under the SPDC Hamiltonian. We solve the inverse problem of designing a nonlinear quantum optical system that achieves the desired quantum state of down-converted photon pairs. The desired states are defined using either the second-order correlations between different spatial modes or by specifying the required density matrix. By learning nonlinear volume holograms as well as different pump shapes, we successfully show how to generate maximally entangled states. Furthermore, we simulate all-optical coherent control over the generated quantum state by actively changing the profile of the pump beam. Our work can be useful for applications such as novel designs of high-dimensional quantum key distribution and quantum information processing protocols. In addition, our method can be readily applied for controlling other degrees of freedom of light in the SPDC process, such as the spectral and temporal properties, and may even be used in condensed-matter systems having a similar interaction Hamiltonian. </br></br>

<a href='http://arxiv.org/pdf/2112.07985.pdf'>2112.07985</a> &nbsp&nbsp (cs:ML, cs:CL) &nbsp&nbsp -0.2005баллов, №840</br>
<b>Solving the Data Sparsity Problem in Predicting the Success of the\n  Startups with Machine Learning Methods</b></br>
Authors: , Yin, Dafei, Li, Jing, Wu, Gaosheng</br>
  Predicting the success of startup companies is of great importance for both startup companies and investors. It is difficult due to the lack of available data and appropriate general methods. With data platforms like Crunchbase aggregating the information of startup companies, it is possible to predict with machine learning algorithms. Existing research suffers from the data sparsity problem as most early-stage startup companies do not have much data available to the public. We try to leverage the recent algorithms to solve this problem. We investigate several machine learning algorithms with a large dataset from Crunchbase. The results suggest that LightGBM and XGBoost perform best and achieve 53.03% and 52.96% F1 scores. We <font color="#be00be">interpret</font> the predictions from the perspective of feature contribution. We construct portfolios based on the models and achieve high success rates. These findings have substantial implications on how machine learning methods can help startup companies and investors. </br></br>

<a href='http://arxiv.org/pdf/2112.07286.pdf'>2112.07286</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.2008баллов, №841</br>
<b>Levels of Autonomous Radiology</b></br>
Authors: , Ghuwalewala, Suraj, Kulkarni, Viraj, Pant, Richa, Kharat, Amit</br>
  Radiology, being one of the younger disciplines of <font color="#640064">medic</font>ine with a history of just over a century, has witnessed tremendous technological advancements and has revolutionized the way we practice medicine today. In the last few decades, medical imaging modalities have generated seismic amounts of medical data. The development and adoption of Artificial Intelligence (AI) applications using this data will lead to the next phase of evolution in radiology. It will include automating laborious manual tasks such as annotations, report-generation, etc., along with the initial radiological assessment of cases to aid radiologists in their evaluation workflow. We propose a level-wise classification for the progression of automation in radiology, explaining AI assistance at each level with corresponding challenges and solutions. We hope that such discussions can help us address the challenges in a structured way and take the necessary steps to ensure the smooth adoption of new technologies in radiology. </br></br>

<a href='http://arxiv.org/pdf/2112.07918.pdf'>2112.07918</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.2058баллов, №842</br>
<b>M-FasterSeg: An Efficient Semantic <font color="#be00be">Segmentation</font> Network Based on Neural\n  <font color="#00be00">Architecture Search</font></b></br>
Authors: , Kuang, Huiyu</br>
  Image semantic <font color="#be00be">segmentation</font> technology is one of the key technologies for intelligent systems to understand natural scenes. As one of the important research directions in the field of visual intelligence, this technology has broad application scenarios in the fields of<font color="#960096"> mobile </font>robots, drones, smart driving, and smart security. However, in the actual application of mobile robots, problems such as inaccurate segmentation semantic label prediction and loss of edge information of segmented objects and background may occur. This paper proposes an improved structure of a semantic segmentation network based on a deep learning network that combines self-attention neural network and neural network <font color="#00be00">architecture search</font> methods. First, a neural network search method NAS (Neural Architecture Search) is used to find a semantic segmentation network with multiple resolution branches. In the search process, combine the self-attention network structure module to adjust the searched neural network structure, and then combine the semantic segmentation network searched by different branches to form a fast semantic segmentation network structure, and input the picture into the network structure to get the final forecast result. The experimental results on the Cityscapes dataset show that the accuracy of the algorithm is 69.8%, and the segmentation speed is 48/s. It achieves a good balance between real-time and accuracy, can optimize edge segmentation, and has a better performance in complex scenes. Good robustness is suitable for practical application. </br></br>

<a href='http://arxiv.org/pdf/2112.05839.pdf'>2112.05839</a> &nbsp&nbsp (cs:NE) &nbsp&nbsp -0.2096баллов, №843</br>
<b>ANA: Ant Nesting Algorithm for Optimizing <font color="#009600">Real-World</font> Problems</b></br>
Authors: , Rashid, Deeam Najmadeen Hama, Rashid, Tarik A., Mirjalili, Seyedali</br>
  In this paper, a novel swarm intelligent algorithm is proposed called ant nesting algorithm (ANA). The algorithm is inspired by Leptothorax ants and mimics the behavior of ants searching for positions to deposit grains while building a new nest. Although the algorithm is inspired by the swarming behavior of ants, it does not have any algorithmic similarity with the ant colony optimization (ACO) algorithm. It is worth mentioning that ANA is considered a continuous algorithm that updates the search agent position by adding the rate of change (e.g., step or velocity). ANA computes the rate of change differently as it uses previous, current solutions, fitness values during the optimization process to generate weights by utilizing the Pythagorean <font color="#be00be">theor</font>em. These weights drive the search agents during the exploration and exploitation phases. The ANA algorithm is benchmarked on 26 well-known test functions, and the results are verified by a comparative study with genetic algorithm (GA), particle swarm optimization (PSO), dragonfly algorithm (DA), five modified versions of PSO, whale optimization algorithm (WOA), salp swarm algorithm (SSA), and fitness dependent optimizer (FDO). ANA <font color="#00be00">outperform</font>ances these prominent metaheuristic algorithms on several test cases and provides quite <font color="#960096">competitive</font> results. Finally, the algorithm is employed for optimizing two well-known <font color="#009600">real-world</font> engineering problems: antenna array design and frequency-modulated synthesis. The results on the engineering case studies demonstrate the proposed algorithm\'s capability in optimizing real-world problems. </br></br>

<a href='http://arxiv.org/pdf/2112.07209.pdf'>2112.07209</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.2117баллов, №844</br>
<b>ACE-BERT: Adversarial Cross-modal Enhanced<font color="#00be00"> BERT </font>for <font color="#be00be">E-commerce</font> <font color="#be00be">Retrieval</font></b></br>
Authors: , Zhang, Boxuan, Wei, Chao, Jin, Yan, Zhang, Weiru</br>
  Nowadays on <font color="#be00be">E-commerce</font> platforms, products are presented to the <font color="#be00be">customer</font>s with multiple modalities. These multiple modalities are significant for a <font color="#be00be">retrieval</font> system while providing attracted products for customers. Therefore, how to take into account those multiple modalities simultaneously to boost the retrieval performance is crucial. This problem is a huge challenge to us due to the following reasons: (1) the way of extracting patch features with the pre-trained image model (e.g., CNN-based model) has much inductive bias. It is difficult to capture the efficient information from the product image in E-commerce. (2) The heterogeneity of multimodal data makes it challenging to construct the representations of query text and product including title and image in a common subspace. We propose a novel Adversarial Cross-modal Enhanced<font color="#00be00"> BERT </font>(ACE-BERT) for efficient E-commerce retrieval. In detail, ACE-BERT leverages the patch features and pixel features as image representation. Thus the <font color="#00be00">Transformer</font> architecture can be applied directly to the raw image sequences. With the pre-trained enhanced BERT as the backbone network, ACE-BERT further adopts adversarial learning by adding a domain classifier to ensure the distribution consistency of different modality representations for the purpose of narrowing down the representation gap between query and product. Experimental results demonstrate that ACE-BERT <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> approaches on the retrieval task. It is remarkable that ACE-BERT has already been deployed in our E-commerce\'s search engine, leading to 1.46% increase in revenue. </br></br>

<a href='http://arxiv.org/pdf/2112.08078.pdf'>2112.08078</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2165баллов, №845</br>
<b>Joint Demand Prediction for Multimodal Systems: A Multi-task\n  Multi-relational Spatiotemporal Graph Neural Network Approach</b></br>
Authors: , Liang, Yuebing, Huang, Guan, Zhao, Zhan</br>
  Dynamic demand prediction is crucial for the efficient operation and management of urban transportation systems. Extensive research has been conducted on single-mode demand prediction, ignoring the fact that the demands for different transportation modes can be correlated with each other. Despite some recent efforts, existing approaches to multimodal demand prediction are generally not flexible enough to account for multiplex networks with diverse spatial units and heterogeneous spatiotemporal correlations across different modes. To tackle these issues, this study proposes a multi-relational spatiotemporal graph neural network (ST-MRGNN) for multimodal demand prediction. Specifically, the spatial dependencies across modes are encoded with multiple intra- and inter-modal relation graphs. A multi-relational graph neural network (MRGNN) is introduced to capture cross-mode heterogeneous spatial dependencies, consisting of generalized graph convolution networks to learn the message passing mechanisms within relation graphs and an attention-based aggregation module to summarize different relations. We further integrate MRGNNs with temporal gated convolution layers to jointly model heterogeneous spatiotemporal correlations. Extensive experiments are conducted using <font color="#009600">real-world</font> subway and ride-hailing datasets from New York City, and the results verify the improved performance of our proposed approach over existing methods across modes. The improvement is particularly large for demand-sparse locations. Further analysis of the attention mechanisms of ST-MRGNN also demonstrates its good <font color="#be00be">interpret</font>ability for understanding cross-mode interactions. </br></br>

<a href='http://arxiv.org/pdf/2112.05913.pdf'>2112.05913</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.2208баллов, №846</br>
<b>Personalized Highway Pilot Assist Considering Leading Vehicle\'s Lateral\n  Behaviours</b></br>
Authors: , Li, Daofei, Liu, Ao</br>
  Highway pilot assist has become the front line of competition in advanced driver assistance systems. The increasing requirements on safety and user acceptance are calling for personalization in the development process of such systems. Inspired by a finding on drivers\' car-following preferences on lateral direction, a personalized highway pilot assist algorithm is proposed, which consists of an Intelligent Driver Model (IDM) based speed control model and a novel lane-keeping model considering the leading vehicle\'s lateral movement. A simulated driving experiment is conducted to analyse driver gaze and lane-keeping Behaviours in free-driving and following driving scenario. Drivers are clustered into two driving <font color="#be00be">style</font> groups referring to their driving Behaviours affected by the leading vehicle, and then the personalization parameters for every specific subject driver are optimized. The proposed algorithm is validated through driver-in-the-loop experiment based on a moving-base simulator. Results show that, compared with the un-personalized algorithms, the personalized highway pilot algorithm can significantly reduce the mental workload and improve user acceptance of the assist functions. </br></br>

<a href='http://arxiv.org/pdf/2111.09492.pdf'>2111.09492</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.2212баллов, №847</br>
<b>Reference-based <font color="#be00be">Magnetic Resonance</font> Image Reconstruction Using Texture\n  <font color="#00be00">Transformer</font></b></br>
Authors: , Guo, Pengfei, Patel, Vishal M.</br>
  Deep Learning (DL) based methods for <font color="#be00be">magnetic resonance</font> (MR) image reconstruction have been shown to produce superior performance in recent years. However, these methods either only leverage under-sampled data or require a paired fully-sampled auxiliary modality to perform multi-modal reconstruction. Consequently, existing approaches neglect to explore attention mechanisms that can transfer textures from reference fully-sampled data to under-sampled data within a single modality, which limits these approaches in challenging cases. In this paper, we propose a novel Texture <font color="#00be00">Transformer</font> Module (TTM) for accelerated<font color="#be00be"> MRI </font>reconstruction, in which we formulate the under-sampled data and reference data as queries and keys in a transformer. The TTM facilitates joint feature learning across under-sampled and reference data, so the feature correspondences can be discovered by attention and accurate texture features can be leveraged during reconstruction. Notably, the proposed TTM can be stacked on prior MRI reconstruction approaches to further improve their performance. Extensive experiments show that TTM can significantly improve the performance of several popular DL-based MRI reconstruction methods. </br></br>

<a href='http://arxiv.org/pdf/2112.07384.pdf'>2112.07384</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.2228баллов, №848</br>
<b>Identification of Biased Terms in News Articles by Comparison of\n  Outlet-specific Word Embeddings</b></br>
Authors: , Spinde, Timo, Rudnitckaia, Lada, Hamborg, Felix, Gipp, Bela</br>
  Slanted news coverage, also called media bias, can heavily influence how news consumers <font color="#be00be">interpret</font> and react to the news. To automatically identify biased language, we present an exploratory approach that compares the context of related words. We train two word embedding models, one on texts of left-wing, the other on right-wing news outlets. Our hypothesis is that a word\'s representations in both word embedding spaces are more similar for non-biased words than biased words. The underlying idea is that the context of biased words in different news outlets varies more strongly than the one of non-biased words, since the perception of a word as being biased differs depending on its context. While we do not find statistical significance to accept the hypothesis, the results show the effectiveness of the approach. For example, after a linear mapping of both word embeddings spaces, 31% of the words with the largest distances potentially induce bias. To improve the results, we find that the dataset needs to be significantly larger, and we derive further methodology as future research direction. To our knowledge, this paper presents the first in-depth look at the context of bias words measured by word embeddings. </br></br>

<a href='http://arxiv.org/pdf/2112.06044.pdf'>2112.06044</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2233баллов, №849</br>
<b>Achieving Low Complexity Neural Decoders via Iterative Pruning</b></br>
Authors: , Malik, Vikrant, Ghosh, Rohan, Motani, Mehul</br>
  The advancement of deep learning has led to the development of neural decoders for low latency communications. However, neural decoders can be very complex which can lead to increased computation and latency. We consider iterative pruning approaches (such as the lottery ticket hypothesis algorithm) to prune weights in neural decoders. Decoders with fewer number of weights can have lower latency and lower complexity while retaining the accuracy of the original model. This will make neural decoders more suitable for<font color="#960096"> mobile </font>and other edge devices with limited computational power. We also propose semi-soft decision decoding for neural decoders which can be used to improve the bit error rate performance of the pruned network. </br></br>

<a href='http://arxiv.org/pdf/2112.07596.pdf'>2112.07596</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.2287баллов, №850</br>
<b>Rushing and Strolling among Answer Sets -- Navigation Made Easy</b></br>
Authors: , Fichte, Johannes K., Gaggl, Sarah Alice, Rusovac, Dominik</br>
  Answer set programming (ASP) is a popular declarative programming paradigm with a wide range of applications in artificial intelligence. Oftentimes, when modeling an AI problem with ASP, and in particular when we are interested beyond simple search for optimal solutions, an actual solution, differences between solutions, or number of solutions of the ASP program matter. For example, when a user aims to identify a specific answer set according to her needs, or requires the total number of diverging solutions to comprehend probabilistic applications such as reasoning in <font color="#640064">medic</font>al domains. Then, there are only certain problem specific and handcrafted encoding techniques available to navigate the solution space of ASP programs, which is oftentimes not enough. In this paper, we propose a formal and general framework for interactive navigation towards desired subsets of answer sets analogous to faceted browsing. Our approach enables the user to explore the solution space by consciously zooming in or out of sub-spaces of solutions at a certain configurable pace. We illustrate that weighted faceted navigation is computationally hard. Finally, we provide an implementation of our approach that demonstrates the feasibility of our framework for incomprehensible solution spaces. </br></br>

<a href='http://arxiv.org/pdf/2112.00695.pdf'>2112.00695</a> &nbsp&nbsp (cs:ML, cs:RO) &nbsp&nbsp -0.2422баллов, №851</br>
<b>DeepAoANet: Learning Angle of Arrival from Software Defined Radios with\n  Deep Neural Networks</b></br>
Authors: , Dai, Zhuangzhuang, He, Yuhang, Vu, Tran, Trigoni, Niki, Markham, Andrew</br>
  Direction finding and positioning systems based on RF signals are significantly impacted by multipath propagation, particularly in indoor environments. Existing algorithms (e.g MUSIC) perform poorly in resolving Angle of Arrival (AoA) in the presence of multipath or when operating in a weak signal regime. We note that digitally sampled RF frontends allow for the easy analysis of signals, and their delayed components. Low-cost Software-Defined Radio (SDR) modules enable Channel State Information (CSI) extraction across a wide spectrum, motivating the design of an enhanced Angle-of-Arrival (AoA) solution. We propose a Deep Learning approach to deriving AoA from a single snapshot of the SDR multichannel data. We compare and contrast deep-learning based angle classification and <font color="#be00be">regression</font> models, to estimate up to two AoAs accurately. We have implemented the inference engines on different platforms to extract AoAs in real-time, demonstrating the computational tractability of our approach. To demonstrate the utility of our approach we have collected IQ (In-phase and Quadrature components) samples from a four-element Universal Linear Array (ULA) in various Light-of-Sight (LOS) and Non-Line-of-Sight (NLOS) environments, and published the dataset. Our proposed method demonstrates excellent reliability in determining number of impinging signals and realized mean absolute AoA errors less than $2^{\\circ}$. </br></br>

<a href='http://arxiv.org/pdf/2112.08342.pdf'>2112.08342</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.2424баллов, №852</br>
<b>DG2: Data Augmentation Through Document Grounded Dialogue Generation</b></br>
Authors: , Wu, Qingyang, Feng, Song, Chen, Derek, Joshi, Sachindra, Lastras, Luis A., Yu, Zhou</br>
  Collecting data for training dialog systems can be extremely expensive due to the involvement of human participants and need for extensive annotation. Especially in document-grounded dialog systems, human experts need to carefully read the unstructured documents to answer the users\' questions. As a result, existing document-grounded dialog datasets are relatively small-scale and obstruct the effective training of dialogue systems. In this paper, we propose an automatic data augmentation technique grounded on documents through a generative dialogue model. The dialogue model consists of a user bot and agent bot that can synthesize diverse dialogues given an input document, which are then used to train a downstream model. When supplementing the original dataset, our method achieves significant improvement over traditional data augmentation methods. We also achieve great performance in the <font color="#be00be">low-resource</font> setting. </br></br>

<a href='http://arxiv.org/pdf/2112.06183.pdf'>2112.06183</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.2447баллов, №853</br>
<b><font color="#00be00">Few-shot</font> Keypoint Detection with Uncertainty Learning for Unseen Species</b></br>
Authors: , Lu, Changsheng, Koniusz, Piotr</br>
  Current non-rigid object keypoint detectors perform well on a chosen kind of species and body parts, and require a large amount of labelled keypoints for training. Moreover, their heatmaps, tailored to specific body parts, cannot recognize novel keypoints (keypoints not labelled for training) on unseen species. We raise an interesting yet challenging question: how to detect both base (annotated for training) and novel keypoints for unseen species given a few annotated samples? Thus, we propose a versatile <font color="#00be00">Few-shot</font> Keypoint Detection (FSKD) pipeline, which can detect a varying number of keypoints of different kinds. Our FSKD provides the uncertainty estimation of predicted keypoints. Specifically, FSKD involves main and auxiliary keypoint representation learning, similarity learning, and keypoint localization with uncertainty modeling to tackle the localization noise. Moreover, we model the uncertainty across groups of keypoints by multivariate <font color="#be00be">Gaussi</font>an distribution to exploit implicit correlations between neighboring keypoints. We show the effectiveness of our FSKD on (i) novel keypoint detection for unseen species, and (ii) few-shot Fine-Grained Visual Recognition (FGVR) and (iii) Semantic Alignment (SA) downstream tasks. For FGVR, detected keypoints improve the classification accuracy. For SA, we showcase a novel thin-plate-spline warping that uses estimated keypoint uncertainty under imperfect keypoint corespondences. </br></br>

<a href='http://arxiv.org/pdf/2112.05620.pdf'>2112.05620</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.2496баллов, №854</br>
<b>How to Avoid Trivial Solutions in Physics-Informed Neural Networks</b></br>
Authors: , Leiteritz, Raphael, Pfl&#xfc;ger, Dirk</br>
  The advent of scientific machine learning (SciML) has opened up a new field with many promises and challenges in the field of simulation science by developing approaches at the interface of physics- and data-based modelling. To this end, physics-informed neural networks (PINNs) have been introduced in recent years, which cope for the scarcity in training data by incorporating physics knowledge of the problem at so-called collocation points. In this work, we investigate the prediction performance of PINNs with respect to the number of collocation points used to enforce the physics-based penalty terms. We show that PINNs can fail, learning a trivial solution that fulfills the physics-derived penalty term by definition. We have developed an alternative sampling approach and a new penalty term enabling us to remedy this core problem of PINNs in data-scarce settings with <font color="#960096">competitive</font> results while reducing the amount of collocation points needed by up to 80 \\% for benchmark problems. </br></br>

<a href='http://arxiv.org/pdf/2112.05673.pdf'>2112.05673</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2526баллов, №855</br>
<b>Neural Multi-Quantile Forecasting for Optimal Inventory Management</b></br>
Authors: , Ram&#xed;rez, Federico Garza</br>
  In this work we propose the use of quantile <font color="#be00be">regression</font> and dilated recurrent neural networks with temporal scaling (MQ-DRNN-s) and apply it to the inventory management task. This model showed a better performance of up to 3.2\\% over a statistical benchmark (the quantile autoregressive model with exogenous variables, QAR-X), being better than the MQ-DRNN without temporal scaling by 6\\%. The above on a set of 10,000 time series of sales of El Globo over a 53-week horizon using rolling windows of 7-day ahead each week. </br></br>

<a href='http://arxiv.org/pdf/2112.07913.pdf'>2112.07913</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.2597баллов, №856</br>
<b>A Comparative Analysis of Machine Learning Approaches for Automated Face\n  Mask Detection During COVID-19</b></br>
Authors: , Khan, Junaed Younus, Alamin, Md Abdullah Al</br>
  The World Health Organization (WHO) has recommended wearing<font color="#be00be"> face </font>masks as one of the most effective measures to prevent COVID-19 transmission. In many countries, it is now mandatory to wear face masks, specially in public places. Since manual monitoring of face masks is often infeasible in the middle of the crowd, automatic detection can be beneficial. To facilitate that, we explored a number of deep learning models (i.e., VGG1, VGG19, ResNet50) for face-mask detection and evaluated them on two benchmark datasets. We also evaluated transfer learning (i.e., VGG19, ResNet50 pre-trained on ImageNet) in this context. We find that while the performances of all the models are quite good, transfer learning models achieve the best performance. Transfer learning improves the performance by 0.10\\%--0.40\\% with 30\\% less training time. Our experiment also shows these high-performing models are not quite robust for <font color="#009600">real-world</font> cases where the test dataset comes from a different distribution. Without any fine-tuning, the performance of these models drops by 47\\% in cross-domain settings. </br></br>

<a href='http://arxiv.org/pdf/2112.07673.pdf'>2112.07673</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2602баллов, №857</br>
<b>Machine learning a manifold</b></br>
Authors: , Craven, Sean, Croon, Djuna, Cutting, Daniel, Houtz, Rachel</br>
  We propose a simple method to identify a continuous Lie algebra symmetry in a dataset through <font color="#be00be">regression</font> by an artificial neural network. Our proposal takes advantage of the $ \\mathcal{O}(\\epsilon^2)$ scaling of the output variable under infinitesimal symmetry transformations on the input variables. As symmetry transformations are generated post-training, the methodology does not rely on sampling of the full representation space or binning of the dataset, and the possibility of false identification is minimised. We demonstrate our method in the SU(3)-symmetric (non-) linear $\\Sigma$ model. </br></br>

<a href='http://arxiv.org/pdf/2112.08178.pdf'>2112.08178</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.2673баллов, №858</br>
<b><font color="#be00be">Interpret</font>able Feature Learning Framework for Smoking Behavior Detection</b></br>
Authors: , Hellen, Nakayiza, Marvin, Ggaliwango</br>
  Smoking in public has been proven to be more harmful to nonsmokers, making it a huge public health concern with urgent need for proactive measures and attention by authorities. With the world moving towards the 4th Industrial Revolution, there is a need for reliable eco-friendly detective measures towards this harmful intoxicating behavior to public health in and out of smart cities. We developed an <font color="#be00be">Interpret</font>able feature learning framework for smoking behavior detection which utilizes a Deep Learning VGG-16 pretrained network to predict and classify the input Image class and a Layer-wise Relevance Propagation (LRP) to explain the network detection or prediction of smoking behavior based on the most relevant learned features or pixels or neurons. The network\'s classification decision is based mainly on features located at the mouth especially the smoke seems to be of high importance to the network\'s decision. The outline of the smoke is highlighted as evidence for the corresponding class. Some elements are seen as having a negative effect on the smoke neuron and are consequently highlighted differently. It is interesting to see that the network distinguishes important from unimportant features based on the image regions. The technology can also detect other smokeable <font color="#00be00">drug</font>s like weed, shisha, marijuana etc. The framework allows for reliable identification of action-based smokers in unsafe zones like schools, shopping malls, bus stops, railway compartments or other violated places for smoking as per the government\'s regulatory health policies. With installation clearly defined in smoking zones, this technology can detect smokers out of range. </br></br>

<a href='http://arxiv.org/pdf/2112.05653.pdf'>2112.05653</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2687баллов, №859</br>
<b><font color="#be00be">Interpret</font>able <font color="#be00be">Clustering</font> via Multi-Polytope Machines</b></br>
Authors: , Lawless, Connor, Kalagnanam, Jayant, Nguyen, Lam M., Phan, Dzung, Reddy, Chandra</br>
  <font color="#be00be">Clustering</font> is a popular unsupervised learning tool often used to discover groups within a larger population such as <font color="#be00be">customer</font> segments, or <font color="#be00be">patient</font> subtypes. However, despite its use as a tool for subgroup discovery and description - few <font color="#00be00">state-of-the-art</font> algorithms provide any rationale or description behind the clusters found. We propose a novel approach for <font color="#be00be">interpret</font>able clustering that both clusters data points and constructs polytopes around the discovered clusters to explain them. Our framework allows for additional constraints on the polytopes - including ensuring that the hyperplanes constructing the polytope are axis-parallel or sparse with integer coefficients. We formulate the problem of constructing clusters via polytopes as a Mixed-Integer Non-Linear Program (MINLP). To solve our formulation we propose a two phase approach where we first initialize clusters and polytopes using alternating minimization, and then use coordinate descent to boost clustering performance. We benchmark our approach on a suite of synthetic and <font color="#009600">real world</font> clustering problems, where our algorithm <font color="#00be00">outperform</font>s <font color="#00be00">state of the art</font> interpretable and non-interpretable clustering algorithms. </br></br>

<a href='http://arxiv.org/pdf/2112.05786.pdf'>2112.05786</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.2714баллов, №860</br>
<b>Guided Generative Models using Weak Supervision for Detecting Object\n  Spatial Arrangement in Overhead Images</b></br>
Authors: , Duan, Weiwei, Chiang, Yao-Yi, Leyk, Stefan, Uhl, Johannes H., Knoblock, Craig A.</br>
  The increasing availability and accessibility of numerous overhead images allows us to estimate and assess the spatial arrangement of groups of geospatial target objects, which can benefit many applications, such as traffic monitoring and agricultural monitoring. Spatial arrangement estimation is the process of identifying the areas which contain the desired objects in overhead images. Traditional supervised <font color="#be00be">object detection</font> approaches can estimate accurate spatial arrangement but require large amounts of bounding box annotations. Recent semi-supervised <font color="#be00be">clustering</font> approaches can reduce manual labeling but still require annotations for all object categories in the image. This paper presents the target-guided generative model (TGGM), under the Variational Auto-encoder (VAE) framework, which uses <font color="#be00be">Gaussi</font>an Mixture Models (GMM) to estimate the distributions of both hidden and decoder variables in VAE. Modeling both hidden and decoder variables by GMM reduces the required manual annotations significantly for spatial arrangement estimation. Unlike existing approaches that the training process can only update the GMM as a whole in the optimization iterations (e.g., a &quot;minibatch&quot;), TGGM allows the update of individual GMM components separately in the same optimization iteration. Optimizing GMM components separately allows TGGM to exploit the semantic relationships in spatial data and requires only a few labels to initiate and guide the generative process. Our experiments shows that TGGM achieves results comparable to the <font color="#00be00">state-of-the-art</font> semi-supervised methods and <font color="#00be00">outperform</font>s unsupervised methods by 10% based on the $F_{1}$ scores, while requiring significantly fewer labeled data. </br></br>

<a href='http://arxiv.org/pdf/2112.08227.pdf'>2112.08227</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.2725баллов, №861</br>
<b>An Experimental Study of the Impact of Pre-training on the Pruning of a\n  Convolutional Neural Network</b></br>
Authors: , Hubens, Nathan, Mancas, Matei, Gosselin, Bernard, Preda, Marius, Zaharia, Titus</br>
  In recent years, deep neural networks have known a wide success in various application domains. However, they require important computational and memory resources, which severely hinders their deployment, notably on<font color="#960096"> mobile </font>devices or for real-time applications. Neural networks usually involve a large number of parameters, which correspond to the weights of the network. Such parameters, obtained with the help of a training process, are determinant for the performance of the network. However, they are also highly redundant. The pruning methods notably attempt to reduce the size of the parameter set, by identifying and removing the irrelevant weights. In this paper, we examine the impact of the training strategy on the pruning efficiency. Two training modalities are considered and compared: (1) fine-tuned and (2) from scratch. The experimental results obtained on four datasets (CIFAR10, CIFAR100, SVHN and Caltech101) and for two different CNNs (VGG16 and MobileNet) demonstrate that a network that has been pre-trained on a large corpus (e.g. ImageNet) and then fine-tuned on a particular dataset can be pruned much more efficiently (up to 80% of parameter reduction) than the same network trained from scratch. </br></br>

<a href='http://arxiv.org/pdf/2111.03882.pdf'>2111.03882</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.2726баллов, №862</br>
<b>Action Recognition using Transfer Learning and Majority Voting for CSGO</b></br>
Authors: , Apon, Tasnim Sakib, Islam, Abrar, Alam, MD. Golam Rabiul</br>
  Presently online video games have become a progressively favorite source of recreation and Counter Strike: Global Offensive (CS: GO) is one of the top-listed online first-person shooting games. Numerous <font color="#960096">competitive</font> games are arranged every year by Esports. Nonetheless, (i) No study has been conducted on video analysis and action recognition of CS: GO game-play which can play a substantial role in the gaming industry for prediction model (ii) No work has been done on the real-time application on the actions and results of a CS: GO match (iii) Game data of a match is usually available in the HLTV as a CSV formatted file however it does not have open access and HLTV tends to prevent users from taking data. This manuscript aims to develop a model for accurate prediction of 4 different actions and compare the performance among the five different transfer learning models with our self-developed deep neural network and identify the best-fitted model and also including major voting later on, which is qualified to provide real time prediction and the result of this model aids to the construction of the automated system of gathering and processing more data alongside solving the issue of collecting data from HLTV. </br></br>

<a href='http://arxiv.org/pdf/2112.05640.pdf'>2112.05640</a> &nbsp&nbsp (cs:NE, cs:AI) &nbsp&nbsp -0.2735баллов, №863</br>
<b>Fast and scalable neuroevolution deep learning <font color="#00be00">architecture search</font> for\n  multivariate <font color="#be00be">anomal</font>y detection</b></br>
Authors: , Pietro&#x144;, M., &#x17b;urek, D., Faber, K.</br>
  The neuroevolution is one of the methodologies that can be used for learning optimal architecture during the training. It uses evolutionary algorithms to generate topology of artificial neural networks (ANN) and its parameters. In this work, a modified neuroevolution technique is presented which incorporates multi-level optimization. The presented approach adapts evolution strategies for evolving ensemble model based on bagging technique, using genetic operators for optimizing single <font color="#be00be">anomal</font>y detection models, reducing the training dataset to speedup the search process and performs non gradient fine tuning. The multivariate anomaly detection as an unsupervised learning task is the case study on which presented approach is tested. Single model optimization is based on mutation, crossover operators and focuses on finding optimal window sizes, the number of layers, layer depths, hyperparameters etc. to boost the anomaly detection scores of new and already known models. The proposed framework and its protocol shows that it is possible to find architecture in a reasonable time which can boost all well known multivariate anomaly detection deep learning architectures. The work concentrates on improvements to multi-level neuroevolution approach for anomaly detection. The main modifications are in the methods of mixing groups and single models evolution, non gradient fine tuning and voting mechanism. The presented framework can be used as an efficient learning network architecture method for any different unsupervised task where autoencoder architectures can be used. The tests were run on SWAT and WADI datasets and presented approach evolved architectures that achieve best scores among other deep learning models. </br></br>

<a href='http://arxiv.org/pdf/2112.07901.pdf'>2112.07901</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2738баллов, №864</br>
<b>Energy-Efficient Real-Time Heart Monitoring on Edge-Fog-Cloud\n  Internet-of-<font color="#640064">Medic</font>al-Things</b></br>
Authors: , Demirel, Berken Utku, Bayoumy, Islam Abdelsalam, Faruque, Mohammad Abdullah Al</br>
  The recent developments in wearable devices and the Internet of <font color="#640064">Medic</font>al Things (IoMT) allow real-time monitoring and recording of electrocardiogram (<font color="#be00be">ECG</font>) signals. However, continuous monitoring of ECG signals is challenging in low-power wearable devices due to energy and memory constraints. Therefore, in this paper, we present a novel and energy-efficient methodology for continuously monitoring the heart for low-power wearable devices. The proposed methodology is composed of three different layers: 1) a Noise/Artifact detection layer to grade the quality of the ECG signals; 2) a Normal/Abnormal beat classification layer to detect the <font color="#be00be">anomal</font>ies in the ECG signals, and 3) an Abnormal beat classification layer to detect <font color="#be00be">diseas</font>es from ECG signals. Moreover, a distributed multi-output Convolutional Neural Network (CNN) architecture is used to decrease the energy consumption and latency between the edge-fog/cloud. Our methodology reaches an accuracy of 99.2% on the well-known MIT-BIH Arrhythmia dataset. Evaluation on real hardware shows that our methodology is suitable for devices having a minimum RAM of 32KB. Moreover, the proposed methodology achieves $7\\times$ more energy efficiency compared to <font color="#00be00">state-of-the-art</font> works. </br></br>

<a href='http://arxiv.org/pdf/2112.08171.pdf'>2112.08171</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.2743баллов, №865</br>
<b>Text Gestalt: Stroke-Aware Scene Text Image <font color="#be00be">Super-Resolution</font></b></br>
Authors: , Chen, Jingye, Yu, Haiyang, Ma, Jianqi, Li, Bin, Xue, Xiangyang</br>
  In the last decade, the blossom of deep learning has witnessed the rapid development of scene text recognition. However, the recognition of low-resolution scene text images remains a challenge. Even though some <font color="#be00be">super-resolution</font> methods have been proposed to tackle this problem, they usually treat text images as general images while ignoring the fact that the visual quality of strokes (the atomic unit of text) plays an essential role for text recognition. According to Gestalt Psychology, humans are capable of composing parts of details into the most similar objects guided by prior knowledge. Likewise, when humans observe a low-resolution text image, they will inherently use partial stroke-level details to recover the appearance of holistic characters. Inspired by Gestalt Psychology, we put forward a Stroke-Aware Scene Text Image Super-Resolution method containing a Stroke-Focused Module (SFM) to concentrate on stroke-level internal structures of characters in text images. Specifically, we attempt to design rules for decomposing English characters and digits at stroke-level, then pre-train a text recognizer to provide stroke-level attention maps as positional clues with the purpose of controlling the consistency between the generated super-resolution image and high-resolution ground truth. The extensive experimental results validate that the proposed method can indeed generate more distinguishable images on TextZoom and manually constructed <font color="#be00be">Chinese</font> character dataset Degraded-IC13. Furthermore, since the proposed SFM is only used to provide stroke-level guidance when training, it will not bring any time overhead during the test phase. Code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/FudanVI/FudanOCR/tree/main/text-gestalt. </br></br>

<a href='http://arxiv.org/pdf/2112.09086.pdf'>2112.09086</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.2748баллов, №866</br>
<b>A new locally linear embedding scheme in light of Hessian eigenmap</b></br>
Authors: , Lin, Liren, Chen, Chih-Wei</br>
  We provide a new <font color="#be00be">interpret</font>ation of Hessian locally linear embedding (HLLE), revealing that it is essentially a variant way to implement the same idea of locally linear embedding (LLE). Based on the new interpretation, a substantial simplification can be made, in which the idea of &quot;Hessian&quot; is replaced by rather arbitrary weights. Moreover, we show by numerical examples that HLLE may produce projection-like results when the dimension of the target space is larger than that of the data manifold, and hence one further modification concerning the manifold dimension is suggested. Combining all the observations, we finally achieve a new LLE-type method, which is called tangential LLE (TLLE). It is simpler and more robust than HLLE. </br></br>

<a href='http://arxiv.org/pdf/2112.08261.pdf'>2112.08261</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.2750баллов, №867</br>
<b>One System to Rule them All: a Universal Intent Recognition System for\n  <font color="#be00be">Customer</font> Service Chatbots</b></br>
Authors: , Vasquez-Correa, Juan Camilo, Guerrero-Sierra, Juan Carlos, Pemberty-Tamayo, Jose Luis, Jaramillo, Juan Esteban, Tejada-Castro, Andres Felipe</br>
  <font color="#be00be">Customer</font> service chatbots are conversational systems designed to provide information to customers about products/services offered by different companies. Particularly, intent recognition is one of the core components in the natural language understating capabilities of a chatbot system. Among the different intents that a chatbot is trained to recognize, there is a set of them that is universal to any customer service chatbot. Universal intents may include salutation, switch the conversation to a human agent, farewells, among others. A system to recognize those universal intents will be very helpful to optimize the training process of specific customer service chatbots. We propose the development of a universal intent recognition system, which is trained to recognize a selected group of 11 intents that are common in 28 different chatbots. The proposed system is trained considering <font color="#00be00">state-of-the-art</font> word-embedding models such as word2vec and BERT, and deep classifiers based on convolutional and recurrent neural networks. The proposed model is able to discriminate between those universal intents with a balanced accuracy up to 80.4\\%. In addition, the proposed system is equally accurate to recognize intents expressed both in short and long text requests. At the same time, misclassification errors often occurs between intents with very similar semantic fields such as farewells and positive comments. The proposed system will be very helpful to optimize the training process of a customer service chatbot because some of the intents will be already available and detected by our system. At the same time, the proposed approach will be a suitable base model to train more specific chatbots by applying transfer learning strategies. </br></br>

<a href='http://arxiv.org/pdf/2112.06780.pdf'>2112.06780</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.2776баллов, №868</br>
<b>Explanation Container in Case-Based Bio<font color="#640064">medic</font>al Question-Answering</b></br>
Authors: , Goel, Prateek, Johs, Adam J., Shrestha, Manil, Weber, Rosina O.</br>
  The National Center for Advancing Translational Sciences(NCATS) Bio<font color="#640064">medic</font>al Data Translator (Translator) aims to attenuate problems faced by translational scientists. Translator is a multi-agent architecture consisting of six autonomous relay agents (ARAs) and eight knowledge providers (KPs). In this paper, we present the design of the Explanatory Agent (xARA), a case-based ARA that answers biomedical queries by accessing multiple KPs, ranking results, and explaining the ranking of results. The Explanatory Agent is designed with five knowledge containers that include the four original knowledge containers and one additional container for explanation - the Explanation Container. The Explanation Container is case-based and designed with its own knowledge containers. </br></br>

<a href='http://arxiv.org/pdf/2112.08655.pdf'>2112.08655</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.2780баллов, №869</br>
<b>Feature Distillation Interaction Weighting Network for <font color="#be00be">Lightweight</font> Image\n  <font color="#be00be">Super-Resolution</font></b></br>
Authors: , Gao, Guangwei, Li, Wenjie, Li, Juncheng, Wu, Fei, Lu, Huimin, Yu, Yi</br>
  Convolutional neural networks based single-image <font color="#be00be">super-resolution</font> (SISR) has made great progress in recent years. However, it is difficult to apply these methods to <font color="#009600">real-world</font> scenarios due to the computational and memory cost. Meanwhile, how to take full advantage of the intermediate features under the constraints of limited parameters and calculations is also a huge challenge. To alleviate these issues, we propose a <font color="#be00be">lightweight</font> yet efficient Feature Distillation Interaction Weighted Network (FDIWN). Specifically, FDIWN utilizes a series of specially designed Feature Shuffle Weighted Groups (FSWG) as the backbone, and several novel mutual Wide-residual Distillation Interaction Blocks (WDIB) form an FSWG. In addition, Wide Identical Residual Weighting (WIRW) units and Wide Convolutional Residual Weighting (WCRW) units are introduced into WDIB for better feature distillation. Moreover, a Wide-Residual Distillation Connection (WRDC) framework and a Self-Calibration Fusion (SCF) unit are proposed to interact features with different scales more flexibly and efficiently.Extensive experiments show that our FDIWN is superior to other models to strike a good balance between model performance and efficiency. The code is available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/IVIPLab/FDIWN. </br></br>

<a href='http://arxiv.org/pdf/2112.05842.pdf'>2112.05842</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.2787баллов, №870</br>
<b>Revisiting the Boundary between ASR and NLU in the Age of Conversational\n  Dialog Systems</b></br>
Authors: , Faruqui, Manaal, Hakkani-T&#xfc;r, Dilek</br>
  As more users across the world are interacting with dialog agents in their daily life, there is a need for better speech understanding that calls for renewed attention to the dynamics between research in automatic <font color="#be00be">speech recognition</font> (ASR) and natural language understanding (NLU). We briefly review these research areas and lay out the current relationship between them. In light of the observations we make in this paper, we argue that (1) NLU should be cognizant of the presence of ASR models being used upstream in a dialog system\'s pipeline, (2) ASR should be able to learn from errors found in NLU, (3) there is a need for end-to-end datasets that provide semantic annotations on spoken input, (4) there should be stronger collaboration between ASR and NLU research communities. </br></br>

<a href='http://arxiv.org/pdf/2111.08008.pdf'>2111.08008</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2788баллов, №871</br>
<b>SPLDExtraTrees: Robust machine learning approach for predicting kinase\n  inhibitor resistance</b></br>
Authors: , Yang, Ziyi, Ye, Zhaofeng, Xiao, Yijia, Hsieh, Changyu</br>
  <font color="#00be00">Drug</font> resistance is a major threat to the global health and a significant concern throughout the <font color="#be00be">clinic</font>al treatment of <font color="#be00be">diseas</font>es and drug development. The mutation in proteins that is related to drug binding is a common cause for adaptive drug resistance. Therefore, quantitative estimations of how mutations would affect the interaction between a drug and the target protein would be of vital significance for the drug development and the clinical practice. Computational methods that rely on molecular dynamics simulations, Rosetta protocols, as well as machine learning methods have been proven to be capable of predicting ligand affinity changes upon protein mutation. However, the severely limited sample size and heavy noise induced overfitting and generalization issues have impeded wide adoption of machine learning for studying drug resistance. In this paper, we propose a robust machine learning method, termed SPLDExtraTrees, which can accurately predict ligand binding affinity changes upon protein mutation and identify resistance-causing mutations. Especially, the proposed method ranks training data following a specific scheme that starts with easy-to-learn samples and gradually incorporates harder and diverse samples into the training, and then iterates between sample weight recalculations and model updates. In addition, we calculate additional physics-based structural features to provide the machine learning model with the valuable domain knowledge on proteins for this data-limited predictive tasks. The experiments substantiate the capability of the proposed method for predicting kinase inhibitor resistance under three scenarios, and achieves predictive accuracy comparable to that of molecular dynamics and Rosetta methods with much less computational costs. </br></br>

<a href='http://arxiv.org/pdf/2112.07882.pdf'>2112.07882</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.2792баллов, №872</br>
<b>Lex Rosetta: Transfer of Predictive Models Across Languages,\n  Jurisdictions, and Legal Domains</b></br>
Authors: , Savelka, Jaromir, Westermann, Hannes, Benyekhlef, Karim, Alexander, Charlotte S., Grant, Jayla C., Amariles, David Restrepo, Hamdani, Rajaa El, Mee&#xf9;s, S&#xe9;bastien, Araszkiewicz, Micha&#x142;, Ashley, Kevin D., Ashley, Alexandra, Branting, Karl, Falduti, Mattia, Grabmair, Matthias, Hara&#x161;ta, Jakub, Novotn&#xe1;, Tereza, Tippett, Elizabeth, Johnson, Shiwanni</br>
  In this paper, we examine the use of multi-lingual sentence embeddings to transfer predictive models for functional <font color="#be00be">segmentation</font> of adjudicatory decisions across jurisdictions, legal systems (common and civil law), languages, and domains (i.e. contexts). Mechanisms for utilizing linguistic resources outside of their original context have significant potential benefits in AI &amp; Law because differences between legal systems, languages, or traditions often block wider adoption of research outcomes. We analyze the use of Language-Agnostic Sentence Representations in sequence labeling models using Gated Recurrent Units (GRUs) that are transferable across languages. To investigate transfer between different contexts we developed an annotation scheme for functional segmentation of adjudicatory decisions. We found that models generalize beyond the contexts on which they were trained (e.g., a model trained on administrative decisions from the US can be applied to criminal law decisions from Italy). Further, we found that training the models on multiple contexts increases robustness and improves overall performance when evaluating on previously unseen contexts. Finally, we found that pooling the training data from all the contexts enhances the models\' in-context performance. </br></br>

<a href='http://arxiv.org/pdf/2112.05564.pdf'>2112.05564</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.2797баллов, №873</br>
<b>A Device and Method to Identify Hip, Knee and Ankle Joint Impedance\n  During Walking</b></br>
Authors: , van der Kooij, Herman, Fricke, Simone S., Veld, Ronald C. van \'t, Prieto, Ander Vallinas, Keemink, Arvid Q. L., Schouten, Alfred C., van Asseldonk, Edwin H. F.</br>
  Knowledge on joint impedance during walking in various conditions is relevant for <font color="#be00be">clinic</font>al decision making and the development of robotic gait trainers, leg prostheses, leg orthotics, and wearable exoskeletons. Whereas ankle impedance during walking has been experimentally assessed, knee and hip joint impedance during walking have not been identified yet. Here we developed and evaluated a lower limb perturbator to identify hip, knee and ankle joint impedance during treadmill walking. The lower limb perturbator (LOPER) consists of an actuator connected to the thigh via rods. The LOPER allows to apply force perturbations to a free-hanging leg, while standing on the contralateral leg, with a bandwidth of up to 39Hz. While walking in minimal impedance mode, the interaction forces between LOPER and the thigh were low (&lt;5N) and the effect on the walking pattern was smaller than the within-subject variability during normal walking. Using a non-linear multibody dynamical model of swing leg dynamics, the hip, knee and ankle joint impedance were estimated at three time points during the swing phase for nine subjects walking at a speed of 0.5 m/s. The identified model was well able to predict the experimental responses, since the mean variance accounted for was 99%, 96%, and 77%, for the hip, knee and ankle respectively. The averaged across subjects stiffness varied between the three time point within 34-66 Nm/rad, 0-3.5 Nm/rad, and 2.5-24 Nm/rad for the hip, knee and ankle joint respectively. The damping varied between 1.9-4.6 Nms/rad, 0.02-0.14 Nms/rad, and 0.2-2.4 Nms/rad for hip, knee, and ankle respectively. The developed LOPER has a negligible effect on the unperturbed walking pattern and allows to identify hip, knee and ankle joint impedance during the swing phase. </br></br>

<a href='http://arxiv.org/pdf/2112.06055.pdf'>2112.06055</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.2810баллов, №874</br>
<b>Towards Autonomous Satellite Communications: An AI-based Framework to\n  Address System-level Challenges</b></br>
Authors: , Garau-Luis, Juan Jose, Eiskowitz, Skylar, Pachler, Nils, Crawley, Edward, Cameron, Bruce</br>
  The next generation of satellite constellations is designed to better address the future needs of our connected society: highly-variable data demand,<font color="#960096"> mobile </font>connectivity, and reaching more under-served regions. Artificial Intelligence (AI) and learning-based methods are expected to become key players in the industry, given the poor scalability and slow reaction time of current resource allocation mechanisms. While AI frameworks have been validated for isolated communication tasks or subproblems, there is still not a clear path to achieve fully-autonomous satellite systems. Part of this issue results from the focus on subproblems when designing models, instead of the necessary system-level perspective. In this paper we try to bridge this gap by characterizing the system-level needs that must be met to increase satellite autonomy, and introduce three AI-based components (Demand Estimator, Offline Planner, and Real Time Engine) that jointly address them. We first do a broad literature review on the different subproblems and identify the missing links to the system-level goals. In response to these gaps, we outline the three necessary components and highlight their interactions. We also discuss how current models can be incorporated into the framework and possible directions of future work. </br></br>

<a href='http://arxiv.org/pdf/2112.05149.pdf'>2112.05149</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.2820баллов, №875</br>
<b>DiffuseMorph: Unsupervised Deformable Image Registration Along\n  Continuous Trajectory Using Diffusion Models</b></br>
Authors: , Kim, Boah, Han, Inhwa, Ye, Jong Chul</br>
  Deformable image registration is one of the fundamental tasks for <font color="#640064">medic</font>al imaging and computer vision. Classical registration algorithms usually rely on iterative optimization approaches to provide accurate deformation, which requires high computational cost. Although many deep-learning-based methods have been developed to carry out fast image registration, it is still challenging to estimate the deformation field with less topological folding problem. Furthermore, these approaches only enable registration to a single fixed image, and it is not possible to obtain continuously varying registration results between the moving and fixed images. To address this, here we present a novel approach of diffusion model-based probabilistic image registration, called DiffuseMorph. Specifically, our model learns the score function of the deformation between moving and fixed images. Similar to the existing diffusion models, DiffuseMorph not only provides synthetic deformed images through a reverse diffusion process, but also enables various levels of deformation of the moving image along with the latent space. Experimental results on 2D<font color="#be00be"> face </font>expression image and 3D <font color="#00be00">brain</font> image registration tasks demonstrate that our method can provide flexible and accurate deformation with a capability of topology preservation. </br></br>

<a href='http://arxiv.org/pdf/2112.06384.pdf'>2112.06384</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.2824баллов, №876</br>
<b>WOOD: Wasserstein-based Out-of-Distribution Detection</b></br>
Authors: , Wang, Yinan, Sun, Wenbo, Jin, Jionghua &quot;Judy&quot;, Kong, Zhenyu &quot;James&quot;, Yue, Xiaowei</br>
  The training and test data for deep-neural-network-based classifiers are usually assumed to be sampled from the same distribution. When part of the test samples are drawn from a distribution that is sufficiently far away from that of the training samples (a.k.a. out-of-distribution (OOD) samples), the trained neural network has a tendency to make high confidence predictions for these OOD samples. Detection of the OOD samples is critical when training a neural network used for image classification, <font color="#be00be">object detection</font>, etc. It can enhance the classifier\'s robustness to irrelevant inputs, and improve the system resilience and security under different forms of attacks. Detection of OOD samples has three main challenges: (i) the proposed OOD detection method should be compatible with various architectures of classifiers (e.g., DenseNet, ResNet), without significantly increasing the model complexity and requirements on computational resources; (ii) the OOD samples may come from multiple distributions, whose class labels are commonly unavailable; (iii) a score function needs to be defined to effectively separate OOD samples from in-distribution (InD) samples. To overcome these challenges, we propose a Wasserstein-based out-of-distribution detection (WOOD) method. The basic idea is to define a Wasserstein-distance-based score that evaluates the dissimilarity between a test sample and the distribution of InD samples. An optimization problem is then formulated and solved based on the proposed score function. The statistical learning bound of the proposed method is investigated to guarantee that the loss value achieved by the empirical optimizer approximates the global optimum. The comparison study results demonstrate that the proposed WOOD consistently <font color="#00be00">outperform</font>s other existing OOD detection methods. </br></br>

<a href='http://arxiv.org/pdf/2112.05209.pdf'>2112.05209</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.2847баллов, №877</br>
<b>Compositional Generalization for Natural Language Interfaces to Web APIs</b></br>
Authors: , Hosseini, Saghar, Awadallah, Ahmed Hassan, Su, Yu</br>
  This paper presents Okapi, a new dataset for Natural Language to executable web Application Programming Interfaces (NL2API). This dataset is in English and contains 22,508 questions and 9,019 unique API calls, covering three domains. We define new compositional generalization tasks for NL2API which explore the models\' ability to extrapolate from simple API calls in the training set to new and more complex API calls in the inference phase. Also, the models are required to generate API calls that execute correctly as opposed to the existing approaches which evaluate queries with placeholder values. Our dataset is different than most of the existing compositional semantic <font color="#be00be">parsing</font> datasets because it is a non-synthetic dataset studying the compositional generalization in a <font color="#be00be">low-resource</font> setting. Okapi is a step towards creating realistic datasets and benchmarks for studying compositional generalization alongside the existing datasets and tasks. We report the generalization capabilities of sequence-to-sequence baseline models trained on a variety of the SCAN and Okapi datasets tasks. The best model achieves 15\\% exact match accuracy when generalizing from simple API calls to more complex API calls. This highlights some challenges for future research. Okapi dataset and tasks are <font color="#00be00">publicly available</font> at <font color="#006400">http</font>s://aka.ms/nl2api/data. </br></br>

<a href='http://arxiv.org/pdf/2112.06102.pdf'>2112.06102</a> &nbsp&nbsp (cs:NE, cs:CV) &nbsp&nbsp -0.2849баллов, №878</br>
<b>NeuroHSMD: Neuromorphic Hybrid Spiking Motion Detector</b></br>
Authors: , Machado, Pedro, Kanjo, Eiman, Lotfi, Andreas Oikonomou Ahmad</br>
  Vertebrate retinas are highly-efficient in processing trivial visual tasks such as detecting moving objects, yet a complex task for modern computers. The detection of object motion is done by specialised retinal ganglion cells named Object-motion-sensitive ganglion cells (OMS-GC). OMS-GC process continuous signals and generate spike patterns that are post-processed by the Visual Cortex. The Neuromorphic Hybrid Spiking Motion Detector (NeuroHSMD) proposed in this work accelerates the HSMD algorithm using Field-Programmable Gate Arrays (<font color="#be00be">FPGA</font>s). The Hybrid Spiking Motion Detector (HSMD) algorithm was the first hybrid algorithm to enhance dynamic background subtraction (DBS) algorithms with a customised 3-layer spiking neural network (SNN) that generates OMS-GC spiking-like responses. The NeuroHSMD algorithm was compared against the HSMD algorithm, using the same 2012 change detection (CDnet2012) and 2014 change detection (CDnet2014) benchmark datasets. The results show that the NeuroHSMD has produced the same results as the HSMD algorithm in real-time without degradation of quality. Moreover, the NeuroHSMD proposed in this paper was completely implemented in Open Computer Language (OpenCL) and therefore is easily replicated in other devices such as Graphical Processor Units (GPUs) and clusters of Central Processor Units (CPUs). </br></br>

<a href='http://arxiv.org/pdf/2112.07184.pdf'>2112.07184</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2891баллов, №879</br>
<b>Calibrated and Sharp Uncertainties in Deep Learning via Simple Density\n  Estimation</b></br>
Authors: , Kuleshov, Volodymyr, Deshpande, Shachi</br>
  Predictive uncertainties can be characterized by two properties--calibration and sharpness. This paper argues for reasoning about uncertainty in terms these properties and proposes simple algorithms for enforcing them in deep learning. Our methods focus on the strongest notion of calibration--distribution calibration--and enforce it by fitting a low-dimensional density or quantile function with a neural estimator. The resulting approach is much simpler and more broadly applicable than previous methods across both classification and <font color="#be00be">regression</font>. Empirically, we find that our methods improve predictive uncertainties on several tasks with minimal computational and implementation overhead. Our insights suggest simple and improved ways of training deep learning models that lead to accurate uncertainties that should be leveraged to improve performance across downstream applications. </br></br>

<a href='http://arxiv.org/pdf/2112.05248.pdf'>2112.05248</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.2909баллов, №880</br>
<b>On the Relation between Prediction and Imputation Accuracy under Missing\n  Covariates</b></br>
Authors: , Ramosaj, Burim, Tulowietzki, Justus, Pauly, Markus</br>
  Missing covariates in <font color="#be00be">regression</font> or classification problems can prohibit the direct use of advanced tools for further analysis. Recent research has realized an increasing trend towards the usage of modern Machine Learning algorithms for imputation. It originates from their capability of showing favourable prediction accuracy in different learning problems. In this work, we analyze through simulation the interaction between imputation accuracy and prediction accuracy in regression learning problems with missing covariates when Machine Learning based methods for both, imputation and prediction are used. In addition, we explore imputation performance when using statistical inference procedures in prediction settings, such as coverage rates of (valid) prediction intervals. Our analysis is based on empirical datasets provided by the UCI Machine Learning repository and an extensive simulation study. </br></br>

<a href='http://arxiv.org/pdf/2112.06571.pdf'>2112.06571</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2920баллов, №881</br>
<b>Extension of Convolutional Neural Network along Temporal and Vertical\n  Directions for Precipitation Downscaling</b></br>
Authors: , Nagasato, Takeyoshi, Ishida, Kei, Ercan, Ali, Tu, Tongbi, Kiyama, Masato, Amagasaki, Motoki, Yokoo, Kazuki</br>
  Deep learning has been utilized for the statistical downscaling of <font color="#be00be">climate</font> data. Specifically, a two-dimensional (2D) convolutional neural network (CNN) has been successfully applied to precipitation estimation. This study implements a three-dimensional (3D) CNN to estimate watershed-scale daily precipitation from 3D atmospheric data and compares the results with those for a 2D CNN. The 2D CNN is extended along the time direction (3D-CNN-Time) and the vertical direction (3D-CNN-Vert). The precipitation estimates of these extended CNNs are compared with those of the 2D CNN in terms of the root-mean-square error (RMSE), Nash-Sutcliffe efficiency (NSE), and 99th percentile RMSE. It is found that both 3D-CNN-Time and 3D-CNN-Vert improve the model accuracy for precipitation estimation compared to the 2D CNN. 3D-CNN-Vert provided the best estimates during the training and test periods in terms of RMSE and NSE. </br></br>

<a href='http://arxiv.org/pdf/2112.07660.pdf'>2112.07660</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.2956баллов, №882</br>
<b>Massive-scale Decoding for Text Generation using Lattices</b></br>
Authors: , Xu, Jiacheng, Durrett, Greg</br>
  Neural text generation models like those used for <font color="#be00be">summarization</font> and translation generate high-quality outputs, but often concentrate around a mode when what we really want is a diverse set of options. We present a search algorithm to construct lattices encoding a massive number of generation options. First, we restructure decoding as a best-first search, which explores the space differently than beam search and improves efficiency by avoiding pruning paths. Second, we revisit the idea of hypothesis recombination: we can identify pairs of similar generation candidates during search and merge them as an approximation. On both document summarization and machine translation, we show that our algorithm encodes hundreds to thousands of diverse options that remain grammatical and high-quality into one linear-sized lattice. This algorithm provides a foundation for building downstream generation applications on top of massive-scale diverse outputs. </br></br>

<a href='http://arxiv.org/pdf/2112.05254.pdf'>2112.05254</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.2961баллов, №883</br>
<b>Addressing Deep Learning Model Uncertainty in Long-Range <font color="#be00be">Climate</font>\n  Forecasting with Late Fusion</b></br>
Authors: , Wong, Ken C. L., Wang, Hongzhi, Vos, Etienne E., Zadrozny, Bianca, Watson, Campbell D., Syeda-Mahmood, Tanveer</br>
  Global warming leads to the increase in frequency and intensity of <font color="#be00be">climate</font> extremes that cause tremendous loss of lives and property. Accurate long-range climate prediction allows more time for preparation and disaster risk management for such extreme events. Although machine learning approaches have shown promising results in long-range climate forecasting, the associated model uncertainties may reduce their reliability. To address this issue, we propose a late fusion approach that systematically combines the predictions from multiple models to reduce the expected errors of the fused results. We also propose a network architecture with the novel denormalization layer to gain the benefits of data normalization without actually normalizing the data. The experimental results on long-range 2m temperature forecasting show that the framework <font color="#00be00">outperform</font>s the 30-year climate normals, and the accuracy can be improved by increasing the number of models. </br></br>

<a href='http://arxiv.org/pdf/2111.04665.pdf'>2111.04665</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.2988баллов, №884</br>
<b>Evaluating Predictive Uncertainty and Robustness to Distributional Shift\n  Using <font color="#009600">Real World</font> Data</b></br>
Authors: , Lakara, Kumud, Bhandari, Akshat, Seth, Pratinav, Verma, Ujjwal</br>
  Most machine learning models operate under the assumption that the training, testing and deployment data is independent and identically distributed (i.i.d.). This assumption doesn\'t generally hold true in a natural setting. Usually, the deployment data is subject to various types of distributional shifts. The magnitude of a model\'s performance is proportional to this shift in the distribution of the dataset. Thus it becomes necessary to evaluate a model\'s uncertainty and robustness to distributional shifts to get a realistic estimate of its expected performance on <font color="#009600">real-world</font> data. Present methods to evaluate uncertainty and model\'s robustness are lacking and often fail to paint the full picture. Moreover, most analysis so far has primarily focused on classification tasks. In this paper, we propose more insightful metrics for general <font color="#be00be">regression</font> tasks using the Shifts <font color="#be00be">Weather</font> Prediction Dataset. We also present an evaluation of the baseline methods using these metrics. </br></br>

<a href='http://arxiv.org/pdf/2112.08554.pdf'>2112.08554</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.3040баллов, №885</br>
<b>A Deep Learning Approach for Ontology Enrichment from Unstructured Text</b></br>
Authors: , Sanagavarapu, Lalit Mohan, Iyer, Vivek, Reddy, Raghu</br>
  Information Security in the cyber world is a major cause for concern, with a significant increase in the number of attack surfaces. Existing information on vulnerabilities, attacks, controls, and advisories available on the web provides an opportunity to represent knowledge and perform security analytics to mitigate some of the concerns. Representing security knowledge in the form of ontology facilitates <font color="#be00be">anomal</font>y detection, threat intelligence, reasoning and relevance attribution of attacks, and many more. This necessitates dynamic and automated enrichment of information security ontologies. However, existing ontology enrichment algorithms based on natural language processing and ML models have issues with contextual extraction of concepts in words, phrases, and sentences. This motivates the need for sequential Deep Learning architectures that traverse through dependency paths in text and extract embedded vulnerabilities, threats, controls, products, and other security-related concepts and instances from learned path representations. In the proposed approach, Bidirectional LSTMs trained on a large DBpedia dataset and Wikipedia corpus of 2.8 GB along with Universal Sentence Encoder is deployed to enrich ISO 27001-based information security ontology. The model is trained and tested on a high-performance computing (HPC) environment to handle Wiki text dimensionality. The approach yielded a test accuracy of over 80% when tested with knocked-out concepts from ontology and web page instances to validate the robustness. </br></br>

<a href='http://arxiv.org/pdf/2112.05812.pdf'>2112.05812</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3041баллов, №886</br>
<b>Edge-Compatible <font color="#00be00">Reinforcement Learning</font> for <font color="#be00be">Recommendat</font>ions</b></br>
Authors: , Kostas, James E., Thomas, Philip S., Theocharous, Georgios</br>
  Most <font color="#00be00">reinforcement learning</font> (RL) <font color="#be00be">recommendat</font>ion systems designed for edge computing must either synchronize during recommendation selection or depend on an unprincipled patchwork collection of algorithms. In this work, we build on asynchronous coagent policy gradient algorithms \\citep{kostas2020asynchronous} to propose a principled solution to this problem. The class of algorithms that we propose can be distributed over the internet and run asynchronously and in real-time. When a given edge fails to respond to a request for data with sufficient speed, this is not a problem; the algorithm is designed to function and learn in the edge setting, and network issues are part of this setting. The result is a principled, <font color="#be00be">theor</font>etically grounded RL algorithm designed to be distributed in and learn in this asynchronous environment. In this work, we describe this algorithm and a proposed class of architectures in detail, and demonstrate that they work well in practice in the asynchronous setting, even as the network quality degrades. </br></br>

<a href='http://arxiv.org/pdf/2112.08195.pdf'>2112.08195</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3047баллов, №887</br>
<b>Generative Adversarial Networks for Labelled Vibration Data Generation</b></br>
Authors: , Luleci, Furkan, Catbas, F. Necati, Avci, Onur</br>
  As Structural Health Monitoring (SHM) being implemented more over the years, the use of operational modal analysis of civil structures has become more significant for the assessment and evaluation of engineering structures. Machine Learning (ML) and Deep Learning (DL) algorithms have been in use for structural damage <font color="#be00be">diagnos</font>tics of civil structures in the last couple of decades. While collecting vibration data from civil structures is a challenging and expensive task for both undamaged and damaged cases, in this paper, the authors are introducing Generative Adversarial Networks (GAN) that is built on the Deep Convolutional Neural Network (DCNN) and using Wasserstein Distance for generating artificial labelled data to be used for structural damage diagnostic purposes. The authors named the developed model 1D W-DCGAN and successfully generated vibration data which is very similar to the input. The methodology presented in this paper will pave the way for vibration data generation for numerous future applications in the SHM domain. </br></br>

<a href='http://arxiv.org/pdf/2112.06748.pdf'>2112.06748</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.3096баллов, №888</br>
<b>Khmer Text Classification Using Word Embedding and Neural Networks</b></br>
Authors: , Buoy, Rina, Taing, Nguonly, Chenda, Sovisal</br>
  Text classification is one of the fundamental tasks in natural language processing to label an open-ended text and is useful for various applications such as <font color="#be00be">sentiment</font> analysis. In this paper, we discuss various classification approaches for Khmer text, ranging from a classical TF-IDF algorithm with support vector machine classifier to modern word embedding-based neural network classifiers including linear layer model, recurrent neural network and convolutional neural network. A Khmer word embedding model is trained on a 30-million-Khmer-word corpus to construct word vector representations that are used to train three different neural network classifiers. We evaluate the performance of different approaches on a news article dataset for both multi-class and multi-label text classification tasks. The result suggests that neural network classifiers using a word embedding model consistently <font color="#00be00">outperform</font> the traditional classifier using TF-IDF. The recurrent neural network classifier provides a slightly better result compared to the convolutional network and the linear layer network. </br></br>

<a href='http://arxiv.org/pdf/2112.05744.pdf'>2112.05744</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.3107баллов, №889</br>
<b>More Control for Free! Image Synthesis with Semantic Diffusion Guidance</b></br>
Authors: , Liu, Xihui, Park, Dong Huk, Azadi, Samaneh, Zhang, Gong, Chopikyan, Arman, Hu, Yuxiao, Shi, Humphrey, Rohrbach, Anna, Darrell, Trevor</br>
  Controllable image synthesis models allow creation of diverse images based on text instructions or guidance from an example image. Recently, denoising diffusion probabilistic models have been shown to generate more realistic imagery than prior methods, and have been successfully demonstrated in unconditional and class-conditional settings. We explore fine-grained, continuous control of this model class, and introduce a novel unified framework for semantic diffusion guidance, which allows either language or image guidance, or both. Guidance is injected into a pretrained unconditional diffusion model using the gradient of image-text or image matching scores. We explore CLIP-based textual guidance as well as both content and <font color="#be00be">style</font>-based image guidance in a unified form. Our text-guided synthesis approach can be applied to datasets without associated text annotations. We conduct experiments on FFHQ and LSUN datasets, and show results on fine-grained text-guided image synthesis, synthesis of images related to a style or content example image, and examples with both textual and image guidance. </br></br>

<a href='http://arxiv.org/pdf/2112.05883.pdf'>2112.05883</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.3153баллов, №890</br>
<b>Self-supervised Spatiotemporal Representation Learning by Exploiting\n  Video Continuity</b></br>
Authors: , Liang, Hanwen, Quader, Niamul, Chi, Zhixiang, Chen, Lizhe, Dai, Peng, Lu, Juwei, Wang, Yang</br>
  Recent self-supervised video representation learning methods have found significant success by exploring essential properties of videos, e.g. speed, temporal order, etc. This work exploits an essential yet under-explored property of videos, the \\textit{video continuity}, to obtain supervision signals for self-supervised representation learning. Specifically, we formulate three novel continuity-related pretext tasks, i.e. continuity justification, discontinuity localization, and missing section approximation, that jointly supervise a shared backbone for video representation learning. This self-supervision approach, termed as Continuity Perception Network (CPNet), solves the three tasks altogether and encourages the backbone network to learn local and long-ranged motion and context representations. It <font color="#00be00">outperform</font>s prior arts on multiple downstream tasks, such as action recognition, video <font color="#be00be">retrieval</font>, and action localization. Additionally, the video continuity can be complementary to other coarse-grained video properties for representation learning, and integrating the proposed pretext task to prior arts can yield much performance gains. </br></br>

<a href='http://arxiv.org/pdf/2112.05215.pdf'>2112.05215</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.3163баллов, №891</br>
<b>Road Extraction from Overhead Images with Graph Neural Networks</b></br>
Authors: , Bahl, Gaetan, Bahri, Mehdi, Lafarge, Florent</br>
  Automatic road graph extraction from aerial and satellite images is a long-standing challenge. Existing algorithms are either based on pixel-level <font color="#be00be">segmentation</font> followed by vectorization, or on iterative graph construction using next move prediction. Both of these strategies suffer from severe drawbacks, in particular high computing resources and incomplete outputs. By contrast, we propose a method that directly infers the final road graph in a single pass. The key idea consists in combining a Fully Convolutional Network in charge of locating points of interest such as intersections, dead ends and turns, and a Graph Neural Network which predicts links between these points. Such a strategy is more efficient than iterative methods and allows us to streamline the training process by removing the need for generation of starting locations while keeping the training end-to-end. We evaluate our method against existing works on the popular RoadTracer dataset and achieve <font color="#960096">competitive</font> results. We also benchmark the speed of our method and show that it <font color="#00be00">outperform</font>s existing approaches. This opens the possibility of in-flight processing on embedded devices. </br></br>

<a href='http://arxiv.org/pdf/2112.07825.pdf'>2112.07825</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3187баллов, №892</br>
<b>TAFA: Design Automation of Analog Mixed-Signal FIR Filters Using Time\n  Approximation Architecture</b></br>
Authors: , Su, Shiyu, Zhang, Qiaochu, Liu, Juzheng, Hassanpourghadi, Mohsen, Rasul, Rezwan, Chen, Mike Shuo-Wei</br>
  A digital finite impulse response (FIR) filter design is fully synthesizable, thanks to the mature CAD support of digital circuitry. On the contrary, analog mixed-signal (AMS) filter design is mostly a manual process, including architecture selection, schematic design, and layout. This work presents a systematic design methodology to automate AMS FIR filter design using a time approximation architecture without any tunable passive component, such as switched capacitor or resistor. It not only enhances the flexibility of the filter but also facilitates design automation with reduced analog complexity. The proposed design flow features a hybrid approximation scheme that automatically optimize the filter\'s impulse response in light of time quantization effects, which shows significant performance improvement with minimum designer\'s efforts in the loop. Additionally, a layout-aware <font color="#be00be">regression</font> model based on an artificial neural network (ANN), in combination with gradient-based search algorithm, is used to automate and expedite the filter design. With the proposed framework, we demonstrate rapid synthesis of AMS FIR filters in 65nm process from specification to layout. </br></br>

<a href='http://arxiv.org/pdf/2112.02814.pdf'>2112.02814</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.3194баллов, №893</br>
<b>A Survey of Deep Learning for Low-Shot <font color="#be00be">Object Detection</font></b></br>
Authors: , Huang, Qihan, Zhang, Haofei, Song, Jie, Song, Mingli</br>
  <font color="#be00be">Object detection</font> is a fundamental task in computer vision and image processing. Current deep learning based object detectors have been highly successful with abundant labeled data. But in real life, it is not guaranteed that each object category has enough labeled samples for training. These large object detectors are easy to overfit when the training data is limited. Therefore, it is necessary to introduce <font color="#00be00">few-shot</font> learning and <font color="#00be00">zero-shot</font> learning into object detection, which can be named low-shot object detection together. Low-Shot Object Detection (LSOD) aims to detect objects from a few or even zero labeled data, which can be categorized into few-shot object detection (FSOD) and zero-shot object detection (ZSD), respectively. This paper conducts a comprehensive survey for deep learning based FSOD and ZSD. First, this survey classifies methods for FSOD and ZSD into different categories and discusses the pros and cons of them. Second, this survey reviews dataset settings and evaluation metrics for FSOD and ZSD, then analyzes the performance of different methods on these benchmarks. Finally, this survey discusses future challenges and promising directions for FSOD and ZSD. </br></br>

<a href='http://arxiv.org/pdf/2111.09065.pdf'>2111.09065</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.3206баллов, №894</br>
<b>Sampling To Improve Predictions For Underrepresented Observations In\n  Imbalanced Data</b></br>
Authors: , Kj&#xe6;rsgaard, Rune D., Gr&#xf8;nberg, Manja G., Clemmensen, Line K. H.</br>
  Data imbalance is common in production data, where controlled production settings require data to fall within a narrow range of variation and data are collected with quality assessment in mind, rather than data analytic insights. This imbalance negatively impacts the predictive performance of models on underrepresented observations. We propose sampling to adjust for this imbalance with the goal of improving the performance of models trained on historical production data. We investigate the use of three sampling approaches to adjust for imbalance. The goal is to downsample the covariates in the training data and subsequently fit a <font color="#be00be">regression</font> model. We investigate how the predictive power of the model changes when using either the sampled or the original data for training. We apply our methods on a large biopharmaceutical manufacturing data set from an advanced simulation of penicillin production and find that fitting a model using the sampled data gives a small reduction in the overall predictive performance, but yields a systematically better performance on underrepresented observations. In addition, the results emphasize the need for alternative, fair, and balanced model evaluations. </br></br>

<a href='http://arxiv.org/pdf/2112.09130.pdf'>2112.09130</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.3206баллов, №895</br>
<b>Ensembling Off-the-shelf Models for GAN Training</b></br>
Authors: , Kumari, Nupur, Zhang, Richard, Shechtman, Eli, Zhu, Jun-Yan</br>
  The advent of large-scale training has produced a cornucopia of powerful visual recognition models. However, generative models, such as GANs, have traditionally been trained from scratch in an unsupervised manner. Can the collective &quot;knowledge&quot; from a large bank of pretrained vision models be leveraged to improve GAN training? If so, with so many models to choose from, which one(s) should be selected, and in what manner are they most effective? We find that pretrained computer vision models can significantly improve performance when used in an ensemble of discriminators. Notably, the particular subset of selected models greatly affects performance. We propose an effective selection mechanism, by probing the linear separability between real and fake samples in pretrained model embeddings, choosing the most accurate model, and progressively adding it to the discriminator ensemble. Interestingly, our method can improve GAN training in both limited data and large-scale settings. Given only 10k training samples, our FID on LSUN Cat matches the <font color="#be00be">Style</font>GAN2 trained on 1.6M images. On the full dataset, our method improves FID by 1.5x to 2x on cat, church, and horse categories of LSUN. </br></br>

<a href='http://arxiv.org/pdf/2112.05219.pdf'>2112.05219</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.3226баллов, №896</br>
<b>CLIP2<font color="#be00be">Style</font>GAN: Unsupervised Extraction of StyleGAN Edit Directions</b></br>
Authors: , Abdal, Rameen, Zhu, Peihao, Femiani, John, Mitra, Niloy J., Wonka, Peter</br>
  The success of <font color="#be00be">Style</font>GAN has enabled unprecedented semantic editing capabilities, on both synthesized and real images. However, such editing operations are either trained with semantic supervision or described using human guidance. In another development, the CLIP architecture has been trained with internet-scale image and text pairings and has been shown to be useful in several <font color="#00be00">zero-shot</font> learning settings. In this work, we investigate how to effectively link the pretrained latent spaces of StyleGAN and CLIP, which in turn allows us to automatically extract semantically labeled edit directions from StyleGAN, finding and naming meaningful edit operations without any additional human guidance. Technically, we propose two novel building blocks; one for finding interesting CLIP directions and one for labeling arbitrary directions in CLIP latent space. The setup does not assume any pre-determined labels and hence we do not require any additional supervised text/attributes to build the editing framework. We evaluate the effectiveness of the proposed method and demonstrate that extraction of disentangled labeled StyleGAN edit directions is indeed possible, and reveals interesting and non-trivial edit directions. </br></br>

<a href='http://arxiv.org/pdf/2112.05496.pdf'>2112.05496</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.3244баллов, №897</br>
<b>Graph-based Generative<font color="#be00be"> Face </font>Anonymisation with Pose Preservation</b></br>
Authors: , Dall\'Asen, Nicola, Wang, Yiming, Tang, Hao, Zanella, Luca, Ricci, Elisa</br>
  We propose AnonyGAN, a GAN-based solution for<font color="#be00be"> face </font>anonymisation which replaces the visual information corresponding to a source identity with a condition identity provided as any single image. With the goal to maintain the geometric attributes of the source face, i.e., the<font color="#be00be"> facial </font>pose and expression, and to promote more natural face generation, we propose to exploit a Bipartite Graph to explicitly model the relations between the facial landmarks of the source identity and the ones of the condition identity through a deep model. We further propose a landmark attention model to relax the manual selection of facial landmarks, allowing the network to weight the landmarks for the best visual naturalness and pose preservation. Finally, to facilitate the appearance learning, we propose a hybrid training strategy to address the challenge caused by the lack of direct pixel-level supervision. We evaluate our method and its variants on two public datasets, CelebA and LFW, in terms of visual naturalness, facial pose preservation and of its impacts on face detection and <font color="#be00be">re-identification</font>. We prove that AnonyGAN significantly <font color="#00be00">outperform</font>s the <font color="#00be00">state-of-the-art</font> methods in terms of visual naturalness, face detection and pose preservation. </br></br>

<a href='http://arxiv.org/pdf/2112.07133.pdf'>2112.07133</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.3305баллов, №898</br>
<b>CLIP-Lite: Information Efficient Visual Representation Learning from\n  Textual Annotations</b></br>
Authors: , Shrivastava, Aman, Selvaraju, Ramprasaath R., Naik, Nikhil, Ordonez, Vicente</br>
  We propose CLIP-Lite, an information efficient method for visual representation learning by feature alignment with textual annotations. Compared to the previously proposed CLIP model, CLIP-Lite requires only one negative image-text sample pair for every positive image-text sample during the optimization of its contrastive learning objective. We accomplish this by taking advantage of an information efficient lower-bound to maximize the mutual information between the two input modalities. This allows CLIP-Lite to be trained with significantly reduced amounts of data and batch sizes while obtaining better performance than CLIP. We evaluate CLIP-Lite by pretraining on the COCO-Captions dataset and testing transfer learning to other datasets. CLIP-Lite obtains a +15.4% mAP absolute gain in performance on Pascal VOC classification, and a +22.1% top-1 accuracy gain on ImageNet, while being comparable or superior to other, more complex, text-supervised models. CLIP-Lite is also superior to CLIP on image and text <font color="#be00be">retrieval</font>, <font color="#00be00">zero-shot</font> classification, and visual grounding. Finally, by performing explicit image-text alignment during representation learning, we show that CLIP-Lite can leverage language semantics to encourage bias-free visual representations that can be used in downstream tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.06922.pdf'>2112.06922</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.3331баллов, №899</br>
<b>Decoding High-level Imagined Speech using Attention-based Deep Neural\n  Networks</b></br>
Authors: , Lee, Dae-Hyeok, Kim, Sung-Jin, Lee, Keon-Woo</br>
  <font color="#00be00">Brain</font>-computer interface (BCI) is the technology that enables the communication between humans and devices by reflecting status and intentions of humans. When conducting imagined speech, the users imagine the pronunciation as if actually speaking. In the case of decoding imagined speech-based<font color="#be00be"> EEG </font>signals, complex task can be conducted more intuitively, but decoding performance is lower than that of other BCI paradigms. We modified our previous model for decoding imagined speech-based EEG signals. Ten subjects participated in the experiment. The average accuracy of our proposed method was 0.5648 for classifying four words. In other words, our proposed method has significant strength in learning local features. Hence, we demonstrated the feasibility of decoding imagined speech-based EEG signals with robust performance. </br></br>

<a href='http://arxiv.org/pdf/2112.06209.pdf'>2112.06209</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.3339баллов, №900</br>
<b>Measuring Complexity of Learning Schemes Using Hessian-Schatten\n  Total-Variation</b></br>
Authors: , Aziznejad, Shayan, Campos, Joaquim, Unser, Michael</br>
  In this paper, we introduce the Hessian-Schatten total-variation (HTV) -- a novel seminorm that quantifies the total &quot;rugosity&quot; of multivariate functions. Our motivation for defining HTV is to assess the complexity of supervised learning schemes. We start by specifying the adequate matrix-valued Banach spaces that are equipped with suitable classes of mixed-norms. We then show that HTV is invariant to rotations, scalings, and translations. Additionally, its minimum value is achieved for linear mappings, supporting the common intuition that linear <font color="#be00be">regression</font> is the least complex learning model. Next, we present closed-form expressions for computing the HTV of two general classes of functions. The first one is the class of Sobolev functions with a certain degree of regularity, for which we show that HTV coincides with the Hessian-Schatten seminorm that is sometimes used as a regularizer for image reconstruction. The second one is the class of continuous and piecewise linear (CPWL) functions. In this case, we show that the HTV reflects the total change in slopes between linear regions that have a common facet. Hence, it can be viewed as a convex relaxation (l1-type) of the number of linear regions (l0-type) of CPWL mappings. Finally, we illustrate the use of our proposed seminorm with some concrete examples. </br></br>

<a href='http://arxiv.org/pdf/2112.06406.pdf'>2112.06406</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.3351баллов, №901</br>
<b>Hybrid Atlas Building with Deep Registration Priors</b></br>
Authors: , Wu, Nian, Wang, Jian, Zhang, Miaomiao, Zhang, Guixu, Peng, Yaxin, Shen, Chaomin</br>
  Registration-based atlas building often poses computational challenges in high-dimensional image spaces. In this paper, we introduce a novel hybrid atlas building algorithm that fast estimates atlas from large-scale image datasets with much reduced computational cost. In contrast to previous approaches that iteratively perform registration tasks between an estimated atlas and individual images, we propose to use learned priors of registration from pre-trained neural networks. This newly developed hybrid framework features several advantages of (i) providing an efficient way of atlas building without losing the quality of results, and (ii) offering flexibility in utilizing a wide variety of deep learning based registration methods. We demonstrate the effectiveness of this proposed model on 3D <font color="#00be00">brain</font> <font color="#be00be">magnetic resonance</font> imaging (MRI) scans. </br></br>

<a href='http://arxiv.org/pdf/2112.08909.pdf'>2112.08909</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3352баллов, №902</br>
<b>CodedPaddedFL and CodedSecAgg: Straggler Mitigation and Secure\n  Aggregation in <font color="#be00be">Federated</font> Learning</b></br>
Authors: , Schlegel, Reent, Kumar, Siddhartha, Rosnes, Eirik, Amat, Alexandre Graell i</br>
  We present two novel coded <font color="#be00be">federated</font> learning (FL) schemes for linear <font color="#be00be">regression</font> that mitigate the effect of straggling devices. The first scheme, CodedPaddedFL, mitigates the effect of straggling devices while retaining the <font color="#be00be">privacy</font> level of conventional FL. Particularly, it combines one-time padding for user data privacy with gradient codes to yield resiliency against straggling devices. To apply one-time padding to real data, our scheme exploits a fixed-point arithmetic representation of the data. For a scenario with 25 devices, CodedPaddedFL achieves a speed-up factor of 6.6 and 9.2 for an accuracy of 95\\% and 85\\% on the MMIST and Fashion-MNIST datasets, respectively, compared to conventional FL. Furthermore, it yields similar performance in terms of latency compared to a recently proposed scheme by Prakash \\emph{et al.} without the shortcoming of additional leakage of <font color="#be00be">private</font> data. The second scheme, CodedSecAgg, provides straggler resiliency and robustness against model inversion attacks and is based on Shamir\'s secret sharing. CodedSecAgg <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> secure aggregation schemes such as LightSecAgg by a speed-up factor of 6.6--14.6, depending on the number of colluding devices, on the MNIST dataset for a scenario with 120 devices, at the expense of a 30\\% increase in latency compared to CodedPaddedFL. </br></br>

<a href='http://arxiv.org/pdf/2112.07022.pdf'>2112.07022</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.3374баллов, №903</br>
<b>Learning Body-Aware 3D Shape Generative Models</b></br>
Authors: , Blinn, Bryce, Ding, Alexander, Ritchie, Daniel, Jones, R. Kenny, Sridhar, Srinath, Savva, Manolis</br>
  The shape of many objects in the built environment is dictated by their relationships to the human body: how will a person interact with this object? Existing data-driven generative models of 3D shapes produce plausible objects but do not reason about the relationship of those objects to the human body. In this paper, we learn body-aware generative models of 3D shapes. Specifically, we train generative models of chairs, an ubiquitous shape category, which can be conditioned on a given body shape or sitting pose. The body-shape-conditioned models produce chairs which will be comfortable for a person with the given body shape; the pose-conditioned models produce chairs which accommodate the given sitting pose. To train these models, we define a &quot;sitting pose matching&quot; metric and a novel &quot;sitting comfort&quot; metric. Calculating these metrics requires an expensive optimization to sit the body into the chair, which is too slow to be used as a loss function for training a generative model. Thus, we train neural networks to efficiently approximate these metrics. We use our approach to train three body-aware generative shape models: a structured part-based generator, a <font color="#be00be">point cloud</font> generator, and an implicit surface generator. In all cases, our approach produces models which adapt their output chair shapes to input human body specifications. </br></br>

<a href='http://arxiv.org/pdf/2112.05872.pdf'>2112.05872</a> &nbsp&nbsp (cs:ML, cs:CV) &nbsp&nbsp -0.3392баллов, №904</br>
<b>SLOSH: Set LOcality Sensitive Hashing via Sliced-Wasserstein Embeddings</b></br>
Authors: , Lu, Yuzhe, Liu, Xinran, Soltoggio, Andrea, Kolouri, Soheil</br>
  Learning from set-structured data is an essential problem with many applications in machine learning and computer vision. This paper focuses on non-parametric and data-independent learning from set-structured data using approximate <font color="#be00be">nearest neighbo</font>r (ANN) solutions, particularly locality-sensitive hashing. We consider the problem of set <font color="#be00be">retrieval</font> from an input set query. Such retrieval problem requires: 1) an efficient mechanism to calculate the distances/dissimilarities between sets, and 2) an appropriate data structure for fast nearest neighbor search. To that end, we propose Sliced-Wasserstein set embedding as a computationally efficient &quot;set-2-vector&quot; mechanism that enables downstream ANN, with <font color="#be00be">theor</font>etical guarantees. The set elements are treated as samples from an unknown underlying distribution, and the Sliced-Wasserstein distance is used to compare sets. We demonstrate the effectiveness of our algorithm, denoted as Set-LOcality Sensitive Hashing (SLOSH), on various set retrieval datasets and compare our proposed embedding with standard set embedding approaches, including Generalized Mean (GeM) embedding/pooling, Featurewise Sort Pooling (FSPool), and Covariance Pooling and show consistent improvement in retrieval results. The code for replicating our results is available here: \\href{<font color="#006400">http</font>s://<font color="#00be00">github</font>.com/mint-vu/SLOSH}{https://github.com/mint-vu/SLOSH}. </br></br>

<a href='http://arxiv.org/pdf/2112.07054.pdf'>2112.07054</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3399баллов, №905</br>
<b>Graph network for simultaneous learning of forward and inverse physics</b></br>
Authors: , Prakash, Sakthi Kumar Arul, Tucker, Conrad</br>
  In this work, we propose an end-to-end graph network that learns forward and inverse models of particle-based physics using <font color="#be00be">interpret</font>able inductive biases. Physics-informed neural networks are often engineered to solve specific problems through problem-specific regularization and loss functions. Such explicit learning biases the network to learn data specific patterns and may require a change in the loss function or neural network architecture hereby limiting their generalizabiliy. While recent studies have proposed graph networks to study forward dynamics, they rely on particle specific parameters such as mass, etc. to approximate the dynamics of the system. Our graph network is implicitly biased by learning to solve several tasks, thereby sharing representations between tasks in order to learn the forward dynamics as well as infer the probability distribution of unknown particle specific properties. We evaluate our approach on one-step next state prediction tasks across diverse datasets that feature different particle interactions. Our comparison against related data-driven physics learning approaches reveals that our model is able to predict the forward dynamics with at least an order of magnitude higher accuracy. We also show that our approach is able to recover multi-modal probability distributions of unknown physical parameters using orders of magnitude fewer samples. </br></br>

<a href='http://arxiv.org/pdf/2112.06433.pdf'>2112.06433</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.3421баллов, №906</br>
<b>Generate <font color="#be00be">Point Cloud</font>s with Multiscale Details from Graph-Represented\n  Structures</b></br>
Authors: , Yang, Ximing, Jin, Cheng</br>
  Generating <font color="#be00be">point cloud</font>s from structures is a highly valued method to control the generation of point clouds.One of the major problems in structure-based controllable point cloud generation is the lack of controllability to details, as details are missing in most existing representations of structures.It can be observed that definitions of details and structures are subjective.Details can be treated as structures on small scale.To represent structures in different scales at the same time, we present a graph-based representation of structures called the Multiscale Structure Graph(MSG).By treating details as small-scale structures, similar patterns of local structures can be found at different scales, places, densities, and angles.The knowledge learned from a pattern can be transferred to similar patterns in other scales.An encoding and generation mechanism, namely the Multiscale Structure-based Point Cloud Generator(MSPCG), for generating dense point clouds from the MSG is proposed, which can simultaneously learn local patterns with miscellaneous spatial properties.Our MSPCG also has great generalization ability and scalability.An MSPCG trained on the ShapeNet dataset can enable multi-scale edition on point clouds, generate point clouds for unseen categories, and generate indoor scenes from a given structure. The experimental results show that our method significantly <font color="#00be00">outperform</font>s baseline methods. </br></br>

<a href='http://arxiv.org/pdf/2112.05576.pdf'>2112.05576</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.3447баллов, №907</br>
<b>GPU-accelerated image alignment for <font color="#be00be">object detection</font> in industrial\n  applications</b></br>
Authors: , Le, Trung-Son, Lin, Chyi-Yeu</br>
  This research proposes a practical method for detecting featureless objects by using image alignment approach with a robust similarity measure in industrial applications. This similarity measure is robust against occlusion, illumination changes and background clutter. The performance of the proposed GPU (Graphics Processing Unit) accelerated algorithm is deemed successful in experiments of comparison between both CPU and GPU implementations </br></br>

<a href='http://arxiv.org/pdf/2112.06049.pdf'>2112.06049</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3464баллов, №908</br>
<b>Auto-Tag: Tagging-Data-By-Example in Data Lakes</b></br>
Authors: , He, Yeye, Song, Jie, Wang, Yue, Chaudhuri, Surajit, Anil, Vishal, Lassiter, Blake, Goland, Yaron, Malhotra, Gaurav</br>
  As data lakes become increasingly popular in large enterprises today, there is a growing need to tag or classify data assets (e.g., files and databases) in data lakes with additional metadata (e.g., semantic column-types), as the inferred metadata can enable a range of downstream applications like data governance (e.g., GDPR compliance), and dataset search. Given the sheer size of today\'s enterprise data lakes with petabytes of data and millions of data assets, it is imperative that data assets can be ``auto-tagged\'\', using <font color="#be00be">lightweight</font> inference algorithms and minimal user input. In this work, we develop Auto-Tag, a corpus-driven approach that automates data-tagging of \\textit{custom} data types in enterprise data lakes. Using Auto-Tag, users only need to provide \\textit{one} example column to demonstrate the desired data-type to tag. Leveraging an index structure built offline using a lightweight scan of the data lake, which is analogous to pre-training in machine learning, Auto-Tag can infer suitable data patterns to best ``describe\'\' the underlying ``domain\'\' of the given column at an interactive speed, which can then be used to tag additional data of the same ``type\'\' in data lakes. The Auto-Tag approach can adapt to custom data-types, and is shown to be both accurate and efficient. Part of Auto-Tag ships as a ``custom-classification\'\' feature in a cloud-based data governance and catalog solution \\textit{Azure Purview}. </br></br>

<a href='http://arxiv.org/pdf/2112.05752.pdf'>2112.05752</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.3465баллов, №909</br>
<b>Specificity-Preserving <font color="#be00be">Federated</font> Learning for MR Image Reconstruction</b></br>
Authors: , Feng, Chun-Mei, Yan, Yunlu, Fu, Huazhu, Xu, Yong, Shao, Ling</br>
  <font color="#be00be">Federated</font> learning (FL) can be used to improve data <font color="#be00be">privacy</font> and efficiency in <font color="#be00be">magnetic resonance</font> (MR) image reconstruction by enabling multiple institutions to collaborate without needing to aggregate local data. However, the domain shift caused by different MR imaging protocols can substantially degrade the performance of FL models. Recent FL techniques tend to solve this by enhancing the generalization of the global model, but they ignore the domain-specific features, which may contain important information about the device properties and be useful for local reconstruction. In this paper, we propose a specificity-preserving FL algorithm for MR image reconstruction (FedMRI). The core idea is to divide the MR reconstruction model into two parts: a globally shared encoder to obtain a generalized representation at the global level, and a client-specific decoder to preserve the domain-specific properties of each client, which is important for collaborative reconstruction when the clients have unique distribution. Moreover, to further boost the convergence of the globally shared encoder when a domain shift is present, a weighted contrastive regularization is introduced to directly correct any deviation between the client and server during optimization. Extensive experiments demonstrate that our FedMRI\'s reconstructed results are the closest to the ground-truth for multi-institutional data, and that it <font color="#00be00">outperform</font>s <font color="#00be00">state-of-the-art</font> FL methods. </br></br>

<a href='http://arxiv.org/pdf/2112.03478.pdf'>2112.03478</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.3469баллов, №910</br>
<b>Generative Adversarial Networks for Labeled Data Creation for Structural\n  Monitoring and Damage Detection</b></br>
Authors: , Luleci, Furkan, Catbas, F. Necati, Avci, Onur</br>
  There has been a drastic progression in the field of Data Science in the last few decades and other disciplines have been continuously benefitting from it. Structural Health Monitoring (SHM) is one of those fields that use Artificial Intelligence (AI) such as Machine Learning (ML) and Deep Learning (DL) algorithms for condition assessment of civil structures based on the collected data. The ML and DL methods require plenty of data for training procedures; however, in SHM, data collection from civil structures is very exhaustive; particularly getting useful data (damage associated data) can be very challenging. This paper uses 1-D Wasserstein Deep Convolutional Generative Adversarial Networks using Gradient Penalty (1-D WDCGAN-GP) for synthetic labeled vibration data generation. Then, implements structural damage detection on different levels of synthetically enhanced vibration datasets by using 1-D Deep Convolutional Neural Network (1-D DCNN). The damage detection results show that the 1-D WDCGAN-GP can be successfully utilized to tackle data scarcity in vibration-based damage <font color="#be00be">diagnos</font>tics of civil structures. Keywords: Structural Health Monitoring (SHM), Structural Damage Diagnostics, Structural Damage Detection, 1-D Deep Convolutional Neural Networks (1-D DCNN), 1-D Generative Adversarial Networks (1-D GAN), Deep Convolutional Generative Adversarial Networks (DCGAN), Wasserstein Generative Adversarial Networks with Gradient Penalty (WGAN-GP) </br></br>

<a href='http://arxiv.org/pdf/2112.08935.pdf'>2112.08935</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.3487баллов, №911</br>
<b>MVSS-Net: Multi-View Multi-Scale Supervised Networks for Image\n  Manipulation Detection</b></br>
Authors: , Dong, Chengbo, Chen, Xinru, Hu, Ruohan, Cao, Juan, Li, Xirong</br>
  The key research question for image manipulation detection is how to learn generalizable features that are sensitive to manipulations in novel data, whilst specific to prevent false alarms on authentic images. Current research emphasizes the sensitivity, with the specificity mostly ignored. In this paper we address both aspects by multi-view feature learning and multi-scale supervision. By exploiting noise distribution and boundary artifacts surrounding tampered regions, the former aims to learn semantic-agnostic and thus more generalizable features. The latter allows us to learn from authentic images which are nontrivial to be taken into account by the prior art that relies on a semantic <font color="#be00be">segmentation</font> loss. Our thoughts are realized by a new network which we term MVSS-Net and its enhanced version MVSS-Net++. Comprehensive experiments on six public benchmark datasets justify the viability of the MVSS-Net series for both pixel-level and image-level manipulation detection. </br></br>

<a href='http://arxiv.org/pdf/2112.08175.pdf'>2112.08175</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.3490баллов, №912</br>
<b>A Factorization Approach for Motor Imagery Classification</b></br>
Authors: , Lee, Byeong-Hoo, Cho, Jeong-Hyun, Kwon, Byung-Hee</br>
  <font color="#00be00">Brain</font>-computer interface uses brain signals to communicate with external devices without actual control. Many studies have been conducted to classify motor imagery based on machine learning. However, classifying imagery data with sparse spatial characteristics, such as single-arm motor imagery, remains a challenge. In this paper, we proposed a method to factorize<font color="#be00be"> EEG </font>signals into two groups to classify motor imagery even if spatial features are sparse. Based on adversarial learning, we focused on extracting common features of EEG signals which are robust to noise and extracting only signal features. In addition, class-specific features were extracted which are specialized for class classification. Finally, the proposed method classifies the classes by representing the features of the two groups as one embedding space. Through experiments, we confirmed the feasibility that extracting features into two groups is advantageous for datasets that contain sparse spatial features. </br></br>

<a href='http://arxiv.org/pdf/2112.05313.pdf'>2112.05313</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3501баллов, №913</br>
<b>Building Autocorrelation-Aware Representations for Fine-Scale\n  Spatiotemporal Prediction</b></br>
Authors: , Lin, Yijun, Chiang, Yao-Yi, Franklin, Meredith, Eckel, Sandrah P., Ambite, Jos&#xe9; Luis</br>
  Many scientific prediction problems have spatiotemporal data- and modeling-related challenges in handling complex variations in space and time using only sparse and unevenly distributed observations. This paper presents a novel deep learning architecture, Deep learning predictions for LocATion-dependent Time-sEries data (DeepLATTE), that explicitly incorporates <font color="#be00be">theor</font>ies of spatial statistics into neural networks to address these challenges. In addition to a feature selection module and a spatiotemporal learning module, DeepLATTE contains an autocorrelation-guided semi-supervised learning strategy to enforce both local autocorrelation patterns and global autocorrelation trends of the predictions in the learned spatiotemporal embedding space to be consistent with the observed data, overcoming the limitation of sparse and unevenly distributed observations. During the training process, both supervised and semi-supervised losses guide the updates of the entire network to: 1) prevent overfitting, 2) refine feature selection, 3) learn useful spatiotemporal representations, and 4) improve overall prediction. We conduct a demonstration of DeepLATTE using <font color="#00be00">publicly available</font> data for an important public health topic, air quality prediction, in a well-studied, complex physical environment - Los Angeles. The experiment demonstrates that the proposed approach provides accurate fine-spatial-scale air quality predictions and reveals the critical environmental factors affecting the results. </br></br>

<a href='http://arxiv.org/pdf/2112.05300.pdf'>2112.05300</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.3516баллов, №914</br>
<b>Representing 3D Shapes with Probabilistic Directed Distance Fields</b></br>
Authors: , Aumentado-Armstrong, Tristan, Tsogkas, Stavros, Dickinson, Sven, Jepson, Allan</br>
  Differentiable rendering is an essential operation in modern vision, allowing inverse graphics approaches to 3D understanding to be utilized in modern machine learning frameworks. Explicit shape representations (voxels, <font color="#be00be">point cloud</font>s, or meshes), while relatively easily rendered, often suffer from limited geometric fidelity or topological constraints. On the other hand, implicit representations (occupancy, distance, or radiance fields) preserve greater fidelity, but suffer from complex or inefficient rendering processes, limiting scalability. In this work, we endeavour to address both shortcomings with a novel shape representation that allows fast differentiable rendering within an implicit architecture. Building on implicit distance representations, we define Directed Distance Fields (DDFs), which map an oriented point (position and direction) to surface visibility and depth. Such a field can render a depth map with a single forward pass per pixel, enable differential surface geometry extraction (e.g., surface normals and curvatures) via network derivatives, be easily composed, and permit extraction of classical unsigned distance fields. Using probabilistic DDFs (PDDFs), we show how to model inherent discontinuities in the underlying field. Finally, we apply our method to fitting single shapes, unpaired 3D-aware generative image modelling, and single-image 3D reconstruction tasks, showcasing strong performance with simple architectural components via the versatility of our representation. </br></br>

<a href='http://arxiv.org/pdf/2112.06013.pdf'>2112.06013</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.3546баллов, №915</br>
<b>Efficient Document-level Event Extraction via Pseudo-Trigger-aware\n  Pruned Complete Graph</b></br>
Authors: , Zhu, Tong, Qu, Xiaoye, Chen, Wenliang, Wang, Zhefeng, Huai, Baoxing, Yuan, Nicholas Jing, Zhang, Min</br>
  There are two main challenges in document-level event extraction: 1) argument entities are scattered in different sentences, and 2) event triggers are often not available. To address these challenges, most previous studies mainly focus on building argument chains in an autoregressive way, which is inefficient in both training and inference. In contrast to the previous studies, we propose a fast and <font color="#be00be">lightweight</font> model named as PTPCG. We design a non-autoregressive decoding algorithm to perform event argument combination extraction on pruned complete graphs, which are constructed under the guidance of the automatically selected pseudo triggers. Compared to the previous systems, our system achieves <font color="#960096">competitive</font> results with lower resource consumption, taking only 3.6% GPU time (pfs-days) for training and up to 8.5 times faster for inference. Besides, our approach shows superior compatibility for the datasets with (or without) triggers and the pseudo triggers can be the supplements for annotated triggers to make further improvements. </br></br>

<a href='http://arxiv.org/pdf/2112.08196.pdf'>2112.08196</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3611баллов, №916</br>
<b>Generative Adversarial Networks for Data Generation in Structural Health\n  Monitoring</b></br>
Authors: , Luleci, Furkan, Catbas, F. Necati, Avci, Onur</br>
  Structural Health Monitoring (SHM) has been continuously benefiting from the advancements in the field of data science. Various types of Artificial Intelligence (AI) methods have been utilized for the assessment and evaluation of civil structures. In AI, Machine Learning (ML) and Deep Learning (DL) algorithms require plenty of datasets to train; particularly, the more data DL models are trained with, the better output it yields. Yet, in SHM applications, collecting data from civil structures through sensors is expensive and obtaining useful data (damage associated data) is challenging. In this paper, 1-D Wasserstein loss Deep Convolutional Generative Adversarial Networks using Gradient Penalty (1-D WDCGAN-GP) is utilized to generate damage associated vibration datasets that are similar to the input. For the purpose of vibration-based damage <font color="#be00be">diagnos</font>tics, a 1-D Deep Convolutional Neural Network (1-D DCNN) is built, trained, and tested on both real and generated datasets. The classification results from the 1-D DCNN on both datasets resulted to be very similar to each other. The presented work in this paper shows that for the cases of insufficient data in DL or ML-based damage diagnostics, 1-D WDCGAN-GP can successfully generate data for the model to be trained on. Keywords: 1-D Generative Adversarial Networks (GAN), Deep Convolutional Generative Adversarial Networks (DCGAN), Wasserstein Generative Adversarial Networks with Gradient Penalty (WGAN-GP), 1-D Convolutional Neural Networks (CNN), Structural Health Monitoring (SHM), Structural Damage Diagnostics, Structural Damage Detection </br></br>

<a href='http://arxiv.org/pdf/2112.08333.pdf'>2112.08333</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.3634баллов, №917</br>
<b>AllWOZ: Towards Multilingual Task-Oriented Dialog Systems for All</b></br>
Authors: , Zuo, Lei, Qian, Kun, Yang, Bowen, Yu, Zhou</br>
  A commonly observed problem of the <font color="#00be00">state-of-the-art</font> natural language technologies, such as Amazon Alexa and Apple Siri, is that their services do not extend to most developing countries\' citizens due to language barriers. Such populations suffer due to the lack of available resources in their languages to build NLP products. This paper presents AllWOZ, a multilingual multi-domain task-oriented <font color="#be00be">customer</font> service dialog dataset covering eight languages: English, Mandarin, Korean, <font color="#be00be">Vietnamese</font>, <font color="#be00be">Hindi</font>, French, Portuguese, and Thai. Furthermore, we create a benchmark for our multilingual dataset by applying mT5 with meta-learning. </br></br>

<a href='http://arxiv.org/pdf/2112.06223.pdf'>2112.06223</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.3707баллов, №918</br>
<b>ASCEND: A Spontaneous <font color="#be00be">Chinese</font>-English Dataset for Code-switching in\n  Multi-turn Conversation</b></br>
Authors: , Lovenia, Holy, Cahyawijaya, Samuel, Winata, Genta Indra, Xu, Peng, Yan, Xu, Liu, Zihan, Frieske, Rita, Yu, Tiezheng, Dai, Wenliang, Barezi, Elham J., Fung, Pascale</br>
  Code-switching is a speech phenomenon when a speaker switches language during a conversation. Despite the spontaneous nature of code-switching in conversational spoken language, most existing works collect code-switching data through read speech instead of spontaneous speech. ASCEND (A Spontaneous <font color="#be00be">Chinese</font>-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. We report ASCEND\'s design and procedure of collecting the speech data, including the annotations in this work. ASCEND includes 23 bilinguals that are fluent in both Chinese and English and consists of 9.23 hours clean speech corpus. </br></br>

<a href='http://arxiv.org/pdf/2111.15196.pdf'>2111.15196</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3739баллов, №919</br>
<b>PGNets: Planet mass prediction using convolutional neural networks for\n  radio continuum observations of protoplanetary disks</b></br>
Authors: , Zhang, Shangjia, Zhu, Zhaohuan, Kang, Mingon</br>
  We developed Convolutional Neural Networks (CNNs) to rapidly and directly infer the planet mass from radio dust continuum images. Substructures induced by young planets in protoplanetary disks can be used to infer the potential young planets\' properties. Hydrodynamical simulations have been used to study the relationships between the planet\'s properties and these disk features. However, these attempts either fine-tuned numerical simulations to fit one protoplanetary disk at a time, which was time-consuming, or azimuthally averaged simulation results to derive some linear relationships between the gap width/depth and the planet mass, which lost information on asymmetric features in disks. To cope with these disadvantages, we developed Planet Gap neural Networks (PGNets) to infer the planet mass from 2D images. We first fit the gridded data in Zhang et al. (2018) as a classification problem. Then, we quadrupled the data set by running additional simulations with near-randomly sampled parameters, and derived the planet mass and disk viscosity together as a <font color="#be00be">regression</font> problem. The classification approach can reach an accuracy of 92\\%, whereas the regression approach can reach 1$\\sigma$ as 0.16 dex for planet mass and 0.23 dex for disk viscosity. We can reproduce the degeneracy scaling $\\alpha$ $\\propto$ $M_p^3$ found in the linear fitting method, which means that the CNN method can even be used to find degeneracy relationship. The gradient-weighted class activation mapping effectively confirms that PGNets use proper disk features to constrain the planet mass. We provide programs for PGNets and the traditional fitting method from Zhang et al. (2018), and discuss each method\'s advantages and disadvantages. </br></br>

<a href='http://arxiv.org/pdf/2112.07963.pdf'>2112.07963</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.3777баллов, №920</br>
<b>Towards General and Efficient Active Learning</b></br>
Authors: , Xie, Yichen, Tomizuka, Masayoshi, Zhan, Wei</br>
  Active learning aims to select the most informative samples to exploit limited annotation budgets. Most existing work follows a cumbersome pipeline by repeating the time-consuming model training and batch data selection multiple times on each dataset separately. We challenge this status quo by proposing a novel general and efficient active learning (GEAL) method in this paper. Utilizing a <font color="#00be00">publicly available</font> model pre-trained on a large dataset, our method can conduct data selection processes on different datasets with a single-pass inference of the same model. To capture the subtle local information inside images, we propose knowledge clusters that are easily extracted from the intermediate features of the pre-trained network. Instead of the troublesome batch selection strategy, all data samples are selected in one go by performing K-Center-Greedy in the fine-grained knowledge cluster level. The entire procedure only requires single-pass model inference without training or supervision, making our method notably superior to prior arts in terms of time complexity by up to hundreds of times. Extensive experiments widely demonstrate the promising performance of our method on <font color="#be00be">object detection</font>, semantic <font color="#be00be">segmentation</font>, depth estimation, and image classification. </br></br>

<a href='http://arxiv.org/pdf/2112.08930.pdf'>2112.08930</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML, stat:ML) &nbsp&nbsp -0.3797баллов, №921</br>
<b>Intelli-Paint: Towards Developing Human-like Painting Agents</b></br>
Authors: , Singh, Jaskirat, Smith, Cameron, Echevarria, Jose, Zheng, Liang</br>
  The generation of well-designed artwork is often quite time-consuming and assumes a high degree of proficiency on part of the human painter. In order to facilitate the human painting process, substantial research efforts have been made on teaching machines how to &quot;paint like a human&quot;, and then using the trained agent as a painting assistant tool for human users. However, current research in this direction is often reliant on a progressive grid-based division strategy wherein the agent divides the overall image into successively finer grids, and then proceeds to paint each of them in parallel. This inevitably leads to artificial painting sequences which are not easily intelligible to human users. To address this, we propose a novel painting approach which learns to generate output canvases while exhibiting a more human-like painting <font color="#be00be">style</font>. The proposed painting pipeline Intelli-Paint consists of 1) a progressive layering strategy which allows the agent to first paint a natural background scene representation before adding in each of the foreground objects in a progressive fashion. 2) We also introduce a novel sequential brushstroke guidance strategy which helps the painting agent to shift its attention between different image regions in a semantic-aware manner. 3) Finally, we propose a brushstroke regularization strategy which allows for ~60-80% reduction in the total number of required brushstrokes without any perceivable differences in the quality of the generated canvases. Through both quantitative and qualitative results, we show that the resulting agents not only show enhanced efficiency in output canvas generation but also exhibit a more natural-looking painting style which would better assist human users express their ideas through digital artwork. </br></br>

<a href='http://arxiv.org/pdf/2112.07558.pdf'>2112.07558</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.3832баллов, №922</br>
<b>Multi-Modal Temporal Attention Models for Crop Mapping from Satellite\n  Time Series</b></br>
Authors: , Garnot, Vivien Sainte Fare, Landrieu, Loic, Chehata, Nesrine</br>
  Optical and radar satellite time series are synergetic: optical images contain rich spectral information, while C-band radar captures useful geometrical information and is immune to cloud cover. Motivated by the recent success of temporal attention-based methods across multiple crop mapping tasks, we propose to investigate how these models can be adapted to operate on several modalities. We implement and evaluate multiple fusion schemes, including a novel approach and simple adjustments to the training procedure, significantly improving performance and efficiency with little added complexity. We show that most fusion schemes have advantages and drawbacks, making them relevant for specific settings. We then evaluate the benefit of multimodality across several tasks: parcel classification, pixel-based <font color="#be00be">segmentation</font>, and panoptic parcel segmentation. We show that by leveraging both optical and radar time series, multimodal temporal attention-based models can outmatch single-modality models in terms of performance and resilience to cloud cover. To conduct these experiments, we augment the PASTIS dataset with spatially aligned radar image time series. The resulting dataset, PASTIS-R, constitutes the first large-scale, multimodal, and open-access satellite time series dataset with semantic and instance annotations. </br></br>

<a href='http://arxiv.org/pdf/2112.06377.pdf'>2112.06377</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.3836баллов, №923</br>
<b>Surfer100: Generating Surveys From Web Resources on Wikipedia-<font color="#be00be">style</font></b></br>
Authors: , Li, Irene, Fabbri, Alexander, Kawamura, Rina, Liu, Yixin, Tang, Xiangru, Tae, Jaesung, Shen, Chang, Ma, Sally, Mizutani, Tomoe, Radev, Dragomir</br>
  Fast-developing fields such as Artificial Intelligence (AI) often outpace the efforts of encyclopedic sources such as Wikipedia, which either do not completely cover recently-introduced topics or lack such content entirely. As a result, methods for automatically producing content are valuable tools to address this information overload. We show that recent advances in pretrained language modeling can be combined for a two-stage extractive and abstractive approach for Wikipedia lead paragraph generation. We extend this approach to generate longer Wikipedia-<font color="#be00be">style</font> summaries with sections and examine how such methods struggle in this application through detailed studies with 100 reference human-collected surveys. This is the first study on utilizing web resources for long Wikipedia-style summaries to the best of our knowledge. </br></br>

<a href='http://arxiv.org/pdf/2112.08185.pdf'>2112.08185</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.3838баллов, №924</br>
<b>Learning Cross-Lingual IR from an English Retriever</b></br>
Authors: , Li, Yulong, Franz, Martin, Sultan, Md Arafat, Iyer, Bhavani, Lee, Young-Suk, Sil, Avirup</br>
  We present a new cross-lingual information <font color="#be00be">retrieval</font> (CLIR) model trained using multi-stage knowledge distillation (KD). The teacher and the student are heterogeneous systems-the former is a pipeline that relies on machine translation and monolingual IR, while the latter executes a single CLIR operation. We show that the student can learn both multilingual representations and CLIR by optimizing two corresponding KD objectives. Learning multilingual representations from an English-only retriever is accomplished using a novel cross-lingual alignment algorithm that greedily re-positions the teacher tokens for alignment. Evaluation on the XOR-TyDi benchmark shows that the proposed model is far more effective than the existing approach of fine-tuning with cross-lingual labeled IR data, with a gain in accuracy of 25.4 Recall@5kt. </br></br>

<a href='http://arxiv.org/pdf/2112.07102.pdf'>2112.07102</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.3848баллов, №925</br>
<b>COVID-19 Pneumonia and Influenza Pneumonia Detection Using Convolutional\n  Neural Networks</b></br>
Authors: , Antonchuk, Julianna, Prescott, Benjamin, Melanchthon, Philip, Singh, Robin</br>
  In the research, we developed a computer vision solution to support <font color="#be00be">diagnos</font>tic radiology in differentiating between COVID-19 pneumonia, influenza virus pneumonia, and normal biomarkers. The chest radiograph appearance of COVID-19 pneumonia is thought to be nonspecific, having presented a challenge to identify an optimal architecture of a convolutional neural network (CNN) that would classify with a high sensitivity among the pulmonary inflammation features of COVID-19 and non-COVID-19 types of pneumonia. Rahman (2021) states that COVID-19 radiography images observe unavailability and quality issues impacting the diagnostic process and affecting the accuracy of the deep learning detection models. A significant scarcity of COVID-19 radiography images introduced an imbalance in data motivating us to use over-sampling techniques. In the study, we include an extensive set of X-ray imaging of human lungs (CXR) with COVID-19 pneumonia, influenza virus pneumonia, and normal biomarkers to achieve an extensible and accurate CNN model. In the experimentation phase of the research, we evaluated a variety of convolutional network architectures, selecting a sequential convolutional network with two traditional convolutional layers and two pooling layers with maximum function. In its classification performance, the best performing model demonstrated a validation accuracy of 93% and an F1 score of 0.95. We chose the Azure Machine Learning service to perform network experimentation and solution deployment. The auto-scaling compute clusters offered a significant time reduction in network training. We would like to see scientists across fields of artificial intelligence and human biology collaborating and expanding on the proposed solution to provide rapid and comprehensive diagnostics, effectively mitigating the spread of the virus </br></br>

<a href='http://arxiv.org/pdf/2112.06142.pdf'>2112.06142</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3858баллов, №926</br>
<b>Semi-supervised teacher-student deep neural network for materials\n  discovery</b></br>
Authors: , Gleaves, Daniel, Siriwardane, Edirisuriya M. Dilanga, Zhao, Yong, Fu, Nihang, Hu, Jianjun</br>
  Data driven generative machine learning models have recently emerged as one of the most promising approaches for new materials discovery. While the generator models can generate millions of candidates, it is critical to train fast and accurate machine learning models to filter out stable, synthesizable materials with desired properties. However, such efforts to build supervised <font color="#be00be">regression</font> or classification screening models have been severely hindered by the lack of unstable or unsynthesizable samples, which usually are not collected and deposited in materials databases such as ICSD and Materials Project (MP). At the same time, there are a significant amount of unlabelled data available in these databases. Here we propose a semi-supervised deep neural network (TSDNN) model for high-performance formation energy and synthesizability prediction, which is achieved via its unique teacher-student dual network architecture and its effective exploitation of the large amount of unlabeled data. For formation energy based stability screening, our semi-supervised classifier achieves an absolute 10.3\\% accuracy improvement compared to the baseline CGCNN regression model. For synthesizability prediction, our model significantly increases the baseline PU learning\'s true positive rate from 87.9\\% to 97.9\\% using 1/49 model parameters.   To further prove the effectiveness of our models, we combined our TSDNN-energy and TSDNN-synthesizability models with our CubicGAN generator to discover novel stable cubic structures. Out of 1000 recommended candidate samples by our models, 512 of them have negative formation energies as validated by our DFT formation energy calculations. Our experimental results show that our semi-supervised deep neural networks can significantly improve the screening accuracy in large-scale generative materials design. </br></br>

<a href='http://arxiv.org/pdf/2112.08831.pdf'>2112.08831</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.3913баллов, №927</br>
<b>Bridging between Cognitive Processing Signals and Linguistic Features\n  via a Unified Attentional Network</b></br>
Authors: , Ren, Yuqi, Xiong, Deyi</br>
  Cognitive processing signals can be used to improve natural language processing (NLP) tasks. However, it is not clear how these signals correlate with linguistic information. Bridging between human language processing and linguistic features has been widely studied in neurolinguistics, usually via single-variable controlled experiments with highly-controlled stimuli. Such methods not only compromises the authenticity of natural reading, but also are time-consuming and expensive. In this paper, we propose a data-driven method to investigate the relationship between cognitive processing signals and linguistic features. Specifically, we present a unified attentional framework that is composed of embedding, attention, encoding and predicting layers to selectively map cognitive processing signals to linguistic features. We define the mapping procedure as a bridging task and develop 12 bridging tasks for lexical, syntactic and semantic features. The proposed framework only requires cognitive processing signals recorded under natural reading as inputs, and can be used to detect a wide range of linguistic features with a single cognitive dataset. Observations from experiment results resonate with previous neuroscience findings. In addition to this, our experiments also reveal a number of interesting findings, such as the correlation between contextual eye-<font color="#be00be">tracking</font> features and tense of sentence. </br></br>

<a href='http://arxiv.org/pdf/2112.07893.pdf'>2112.07893</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.3949баллов, №928</br>
<b>Graph-based Ensemble Machine Learning for Student Performance Prediction</b></br>
Authors: , Wang, Yinkai, Ding, Aowei, Guan, Kaiyi, Wu, Shixi, Du, Yuanqi</br>
  Student performance prediction is a critical research problem to understand the students\' needs, present proper learning opportunities/resources, and develop the teaching quality. However, traditional machine learning methods fail to produce stable and accurate prediction results. In this paper, we propose a graph-based ensemble machine learning method that aims to improve the stability of single machine learning methods via the consensus of multiple methods. To be specific, we leverage both supervised prediction methods and unsupervised <font color="#be00be">clustering</font> methods, build an iterative approach that propagates in a bipartite graph as well as converges to more stable and accurate prediction results. Extensive experiments demonstrate the effectiveness of our proposed method in predicting more accurate student performance. Specifically, our model <font color="#00be00">outperform</font>s the best traditional machine learning algorithms by up to 14.8% in prediction accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.08068.pdf'>2112.08068</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.3972баллов, №929</br>
<b>Head Matters: Explainable Human-centered Trait Prediction from Head\n  Motion Dynamics</b></br>
Authors: , Madan, Surbhi, Gahalawat, Monika, Guha, Tanaya, Subramanian, Ramanathan</br>
  We demonstrate the utility of elementary head-motion units termed kinemes for behavioral analytics to predict personality and interview traits. Transforming head-motion patterns into a sequence of kinemes facilitates discovery of latent temporal signatures characterizing the targeted traits, thereby enabling both efficient and explainable trait prediction. Utilizing Kinemes and<font color="#be00be"> Facial </font>Action Coding System (FACS) features to predict (a) OCEAN personality traits on the First Impressions Candidate Screening videos, and (b) Interview traits on the MIT dataset, we note that: (1) A Long-Short Term Memory (LSTM) network trained with kineme sequences performs better than or similar to a Convolutional Neural Network (CNN) trained with facial images; (2) Accurate predictions and explanations are achieved on combining FACS action units (AUs) with kinemes, and (3) Prediction performance is affected by the time-length over which head and facial movements are observed. </br></br>

<a href='http://arxiv.org/pdf/2112.07844.pdf'>2112.07844</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4022баллов, №930</br>
<b>Fix your Models by Fixing your Datasets</b></br>
Authors: , Sanyal, Atindriyo, Chatterji, Vikram, Vyas, Nidhi, Epstein, Ben, Demir, Nikita, Corletti, Anthony</br>
  The quality of underlying training data is very crucial for building performant machine learning models with wider generalizabilty. However, current machine learning (ML) tools lack streamlined processes for improving the data quality. So, getting data quality insights and iteratively pruning the errors to obtain a dataset which is most representative of downstream use cases is still an ad-hoc manual process. Our work addresses this data tooling gap, required to build improved ML workflows purely through data-centric techniques. More specifically, we introduce a systematic framework for (1) finding noisy or mislabelled samples in the dataset and, (2) identifying the most informative samples, which when included in training would provide maximal model performance lift. We demonstrate the efficacy of our framework on public as well as <font color="#be00be">private</font> enterprise datasets of two Fortune 500 companies, and are confident this work will form the basis for ML teams to perform more intelligent data discovery and pruning. </br></br>

<a href='http://arxiv.org/pdf/2112.06401.pdf'>2112.06401</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.4036баллов, №931</br>
<b>Deep Attentional Guided Image Filtering</b></br>
Authors: , Zhong, Zhiwei, Liu, Xianming, Jiang, Junjun, Zhao, Debin, Ji, Xiangyang</br>
  Guided filter is a fundamental tool in computer vision and computer graphics which aims to transfer structure information from guidance image to target image. Most existing methods construct filter <font color="#be00be">kernel</font>s from the guidance itself without considering the mutual dependency between the guidance and the target. However, since there typically exist significantly different edges in the two images, simply transferring all structural information of the guidance to the target would result in various artifacts. To cope with this problem, we propose an effective framework named deep attentional guided image filtering, the filtering process of which can fully integrate the complementary information contained in both images. Specifically, we propose an attentional kernel learning module to generate dual sets of filter kernels from the guidance and the target, respectively, and then adaptively combine them by modeling the pixel-wise dependency between the two images. Meanwhile, we propose a multi-scale guided image filtering module to progressively generate the filtering result with the constructed kernels in a coarse-to-fine manner. Correspondingly, a multi-scale fusion strategy is introduced to reuse the intermediate results in the coarse-to-fine process. Extensive experiments show that the proposed framework compares favorably with the <font color="#00be00">state-of-the-art</font> methods in a wide range of guided image filtering applications, such as guided <font color="#be00be">super-resolution</font>, cross-modality restoration, texture removal, and semantic <font color="#be00be">segmentation</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.08778.pdf'>2112.08778</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.4060баллов, №932</br>
<b>Self-Supervised Learning for <font color="#be00be">speech recognition</font> with Intermediate layer\n  supervision</b></br>
Authors: , Wang, Chengyi, Wu, Yu, Chen, Sanyuan, Liu, Shujie, Li, Jinyu, Qian, Yao, Yang, Zhenglu</br>
  Recently, pioneer work finds that speech pre-trained models can solve full-stack speech processing tasks, because the model utilizes bottom layers to learn speaker-related information and top layers to encode content-related information. Since the network capacity is limited, we believe the <font color="#be00be">speech recognition</font> performance could be further improved if the model is dedicated to audio content information learning. To this end, we propose Intermediate Layer Supervision for Self-Supervised Learning (ILS-SSL), which forces the model to concentrate on content information as much as possible by adding an additional SSL loss on the intermediate layers. Experiments on LibriSpeech test-other set show that our method <font color="#00be00">outperform</font>s HuBERT significantly, which achieves a 23.5%/11.6% relative word error rate reduction in the w/o language model setting for base/large models. Detailed analysis shows the bottom layers of our model have a better correlation with phonetic units, which is consistent with our intuition and explains the success of our method for ASR. </br></br>

<a href='http://arxiv.org/pdf/2112.08357.pdf'>2112.08357</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.4074баллов, №933</br>
<b>Design Challenges for a Multi-Perspective Search Engine</b></br>
Authors: , Chen, Sihao, Liu, Siyi, Uyttendaele, Xander, Zhang, Yi, Bruno, William, Roth, Dan</br>
  Many users turn to document <font color="#be00be">retrieval</font> systems (e.g. search engines) to seek answers to controversial questions. Answering such user queries usually require identifying responses within web documents, and aggregating the responses based on their different perspectives.   Classical document retrieval systems fall short at delivering a set of direct and diverse responses to the users. Naturally, identifying such responses within a document is a natural language understanding task. In this paper, we examine the challenges of synthesizing such language understanding objectives with document retrieval, and study a new perspective-oriented document retrieval paradigm. We discuss and assess the inherent natural language understanding challenges in order to achieve the goal. Following the design challenges and principles, we demonstrate and evaluate a practical prototype pipeline system. We use the prototype system to conduct a user survey in order to assess the utility of our paradigm, as well as understanding the user information needs for controversial queries. </br></br>

<a href='http://arxiv.org/pdf/2112.05509.pdf'>2112.05509</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.4083баллов, №934</br>
<b>Music demixing with the sliCQ transform</b></br>
Authors: , Hanssian, Sevag</br>
 <font color="#be00be"> Music </font>source separation is the task of extracting an estimate of one or more isolated sources or instruments (for example, drums or vocals) from musical audio. The task of music demixing or unmixing considers the case where the musical audio is separated into an estimate of all of its constituent sources that can be summed back to the original mixture. The Music Demixing Challenge was created to inspire new demixing research. Open-Unmix (UMX), and the improved variant CrossNet-Open-Unmix (X-UMX), were included in the challenge as the baselines. Both models use the Short-Time Fourier Transform (STFT) as the representation of music signals. The time-frequency uncertainty principle states that the STFT of a signal cannot have maximal resolution in both time and frequency. The tradeoff in time-frequency resolution can significantly affect music demixing results. Our proposed adaptation of UMX replaced the STFT with the sliCQT, a time-frequency transform with varying time-frequency resolution. Unfortunately, our model xumx-sliCQ achieved lower demixing scores than UMX. </br></br>

<a href='http://arxiv.org/pdf/2112.08217.pdf'>2112.08217</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.4113баллов, №935</br>
<b>Probabilistic Forecasting with Conditional Generative Networks via\n  Scoring Rule Minimization</b></br>
Authors: , Pacchiardi, Lorenzo, Adewoyin, Rilwan, Dueben, Peter, Dutta, Ritabrata</br>
  Probabilistic forecasting consists of stating a probability distribution for a future outcome based on past observations. In meteorology, ensembles of physics-based numerical models are run to get such distribution. Usually, performance is evaluated with scoring rules, functions of the forecast distribution and the observed outcome. With some scoring rules, calibration and sharpness of the forecast can be assessed at the same time.   In deep learning, generative neural networks parametrize distributions on high-dimensional spaces and easily allow sampling by transforming draws from a latent variable. Conditional generative networks additionally constrain the distribution on an input variable. In this manuscript, we perform probabilistic forecasting with conditional generative networks trained to minimize scoring rule values. In contrast to Generative Adversarial Networks (GANs), no discriminator is required and training is stable. We perform experiments on two chaotic models and a global dataset of <font color="#be00be">weather</font> observations; results are satisfactory and better calibrated than what achieved by GANs. </br></br>

<a href='http://arxiv.org/pdf/2112.08532.pdf'>2112.08532</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.4127баллов, №936</br>
<b>Penn-Helsinki Parsed Corpus of Early Modern English: First <font color="#be00be">Parsing</font>\n  Results and Analysis</b></br>
Authors: , Kulick, Seth, Ryant, Neville, Santorini, Beatrice</br>
  We present the first <font color="#be00be">parsing</font> results on the Penn-Helsinki Parsed Corpus of Early Modern English (PPCEME), a 1.9 million word treebank that is an important resource for research in syntactic change. We describe key features of PPCEME that make it challenging for parsing, including a larger and more varied set of function tags than in the Penn Treebank. We present results for this corpus using a modified version of the Berkeley Neural <font color="#be00be">Parser</font> and the approach to function tag recovery of Gabbard et al (2006). Despite its simplicity, this approach works <font color="#00be00">surprisin</font>gly well, suggesting it is possible to recover the original structure with sufficient accuracy to support linguistic applications (e.g., searching for syntactic structures of interest). However, for a subset of function tags (e.g., the tag indicating direct speech), additional work is needed, and we discuss some further limits of this approach. The resulting parser will be used to parse Early English Books Online, a 1.1 billion word corpus whose utility for the study of syntactic change will be greatly increased with the addition of accurate parse trees. </br></br>

<a href='http://arxiv.org/pdf/2112.01939.pdf'>2112.01939</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4157баллов, №937</br>
<b>Fast Projected Newton-like Method for Precision Matrix Estimation with\n  Nonnegative Partial Correlations</b></br>
Authors: , Ying, Jiaxi, Cardoso, Jos&#xe9; Vin&#xed;cius de M., Cai, Jian-Feng, Palomar, Daniel P.</br>
  We study the problem of estimating precision matrices in multivariate <font color="#be00be">Gaussi</font>an distributions where all partial correlations are nonnegative, also known as multivariate totally positive of order two ($\\mathrm{MTP}_2$). Such models have received significant attention in recent years, primarily due to interesting properties, e.g., the maximum likelihood estimator exists with as few as two observations regardless of the underlying dimension. We formulate this problem as a weighted $\\ell_1$-norm regularized Gaussian maximum likelihood estimation under $\\mathrm{MTP}_2$ constraints. On this direction, we propose a novel projected Newton-like algorithm that incorporates a well-designed approximate Newton direction, which results in our algorithm having the same orders of computation and memory costs as those of first-order methods. We prove that the proposed projected Newton-like algorithm converges to the minimizer of the problem. We further show, both <font color="#be00be">theor</font>etically and experimentally, that the minimizer of our formulation using the weighted $\\ell_1$-norm is able to recover the support of the underlying precision matrix correctly without requiring the incoherence condition present in $\\ell_1$-norm based methods. Experiments involving synthetic and <font color="#009600">real-world</font> data demonstrate that our proposed algorithm is significantly more efficient, from a computational time perspective, than the <font color="#00be00">state-of-the-art</font> methods. Finally, we apply our method in <font color="#be00be">financ</font>ial time-series data, which are well-known for displaying positive dependencies, where we observe a significant performance in terms of modularity value on the learned financial networks. </br></br>

<a href='http://arxiv.org/pdf/2112.05335.pdf'>2112.05335</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.4262баллов, №938</br>
<b>Uncertainty, Edge, and Reverse-Attention Guided Generative Adversarial\n  Network for Automatic Building Detection in Remotely Sensed Images</b></br>
Authors: , Chattopadhyay, Somrita, Kak, Avinash C.</br>
  Despite recent advances in deep-learning based semantic <font color="#be00be">segmentation</font>, automatic building detection from remotely sensed imagery is still a challenging problem owing to large variability in the appearance of buildings across the globe. The errors occur mostly around the boundaries of the building footprints, in shadow areas, and when detecting buildings whose exterior surfaces have reflectivity properties that are very similar to those of the surrounding regions. To overcome these problems, we propose a generative adversarial network based segmentation framework with uncertainty attention unit and refinement module embedded in the generator. The refinement module, composed of edge and reverse attention units, is designed to refine the predicted building map. The edge attention enhances the boundary features to estimate building boundaries with greater precision, and the reverse attention allows the network to explore the features missing in the previously estimated regions. The uncertainty attention unit assists the network in resolving uncertainties in classification. As a measure of the power of our approach, as of December 4, 2021, it ranks at the second place on DeepGlobe\'s public leaderboard despite the fact that main focus of our approach -- refinement of the building edges -- does not align exactly with the metrics used for leaderboard rankings. Our overall F1-score on DeepGlobe\'s challenging dataset is 0.745. We also report improvements on the previous-best results for the challenging INRIA Validation Dataset for which our network achieves an overall IoU of 81.28% and an overall accuracy of 97.03%. Along the same lines, for the official INRIA Test Dataset, our network scores 77.86% and 96.41% in overall IoU and accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.07974.pdf'>2112.07974</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.4265баллов, №939</br>
<b>Detail-aware Deep Clothing Animations Infused with Multi-source\n  Attributes</b></br>
Authors: , Li, Tianxing, Shi, Rui, Kanai, Takashi</br>
  This paper presents a novel learning-based clothing deformation method to generate rich and reasonable detailed deformations for garments worn by bodies of various shapes in various animations. In contrast to existing learning-based methods, which require numerous trained models for different garment topologies or poses and are unable to easily realize rich details, we use a unified framework to produce high fidelity deformations efficiently and easily. To address the challenging issue of predicting deformations influenced by multi-source attributes, we propose three strategies from novel perspectives. Specifically, we first found that the fit between the garment and the body has an important impact on the degree of folds. We then designed an attribute <font color="#be00be">parser</font> to generate detail-aware encodings and infused them into the graph neural network, therefore enhancing the discrimination of details under diverse attributes. Furthermore, to achieve better convergence and avoid overly smooth deformations, we proposed output reconstruction to mitigate the complexity of the learning task. Experiment results show that our proposed deformation method achieves better performance over existing methods in terms of generalization ability and quality of details. </br></br>

<a href='http://arxiv.org/pdf/2112.08605.pdf'>2112.08605</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.4282баллов, №940</br>
<b>Frequency Spectrum Augmentation Consistency for Domain Adaptive Object\n  Detection</b></br>
Authors: , Liu, Rui, Han, Yahong, Wang, Yaowei, Tian, Qi</br>
  Domain adaptive <font color="#be00be">object detection</font> (DAOD) aims to improve the generalization ability of detectors when the training and test data are from different domains. Considering the significant domain gap, some typical methods, e.g., CycleGAN-based methods, adopt the intermediate domain to bridge the source and target domains progressively. However, the CycleGAN-based intermediate domain lacks the pix- or instance-level supervision for object detection, which leads to semantic differences. To address this problem, in this paper, we introduce a Frequency Spectrum Augmentation Consistency (FSAC) framework with four different low-frequency filter operations. In this way, we can obtain a series of augmented data as the intermediate domain. Concretely, we propose a two-stage optimization framework. In the first stage, we utilize all the original and augmented source data to train an object detector. In the second stage, augmented source and target data with pseudo labels are adopted to perform the self-training for prediction consistency. And a teacher model optimized using Mean Teacher is used to further revise the pseudo labels. In the experiment, we evaluate our method on the single- and compound- target DAOD separately, which demonstrate the effectiveness of our method. </br></br>

<a href='http://arxiv.org/pdf/2112.01730.pdf'>2112.01730</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.4345баллов, №941</br>
<b>Action Units That Constitute Trainable Micro-expressions (and A\n  Large-scale Synthetic Dataset)</b></br>
Authors: , Liu, Yuchi, Wang, Zhongdao, Gedeon, Tom, Zheng, Liang</br>
  Due to the expensive data collection process, micro-expression datasets are generally much smaller in scale than those in other computer vision fields, rendering large-scale training less stable and feasible. In this paper, we aim to develop a protocol to automatically synthesize micro-expression training data that 1) are on a large scale and 2) allow us to train recognition models with strong accuracy on <font color="#009600">real-world</font> test sets. Specifically, we discover three types of Action Units (AUs) that can well constitute trainable micro-expressions. These AUs come from real-world micro-expressions, early frames of macro-expressions, and the relationship between AUs and expression labels defined by human knowledge. With these AUs, our protocol then employs large numbers of<font color="#be00be"> face </font>images with various identities and an existing face generation method for micro-expression synthesis. Micro-expression recognition models are trained on the generated micro-expression datasets and evaluated on real-world test sets, where very <font color="#960096">competitive</font> and stable performance is obtained. The experimental results not only validate the effectiveness of these AUs and our dataset synthesis protocol but also reveal some critical properties of micro-expressions: they generalize across faces, are close to early-stage macro-expressions, and can be manually defined. </br></br>

<a href='http://arxiv.org/pdf/2112.07745.pdf'>2112.07745</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4354баллов, №942</br>
<b>Learning to track environment state via predictive autoencoding</b></br>
Authors: , Andrecki, Marian, Taylor, Nicholas K.</br>
  This work introduces a neural architecture for learning forward models of stochastic environments. The task is achieved solely through learning from temporal unstructured observations in the form of images. Once trained, the model allows for <font color="#be00be">tracking</font> of the environment state in the presence of noise or with new percepts arriving intermittently. Additionally, the state estimate can be propagated in observation-blind mode, thus allowing for long-term predictions. The network can output both expectation over future observations and samples from belief distribution. The resulting functionalities are similar to those of a Particle Filter (PF). The architecture is evaluated in an environment where we simulate objects moving. As the forward and sensor models are available, we implement a PF to gauge the quality of the models learnt from the data. </br></br>

<a href='http://arxiv.org/pdf/2112.06672.pdf'>2112.06672</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4401баллов, №943</br>
<b>Tree-Based Dynamic Classifier Chains</b></br>
Authors: , Menc&#xed;a, Eneldo Loza, Kulessa, Moritz, Bohlender, Simon, F&#xfc;rnkranz, Johannes</br>
  Classifier chains are an effective technique for modeling label dependencies in multi-label classification. However, the method requires a fixed, static order of the labels. While in <font color="#be00be">theor</font>y, any order is sufficient, in practice, this order has a substantial impact on the quality of the final prediction. Dynamic classifier chains denote the idea that for each instance to classify, the order in which the labels are predicted is dynamically chosen. The complexity of a naive implementation of such an approach is prohibitive, because it would require to train a sequence of classifiers for every possible permutation of the labels. To tackle this problem efficiently, we propose a new approach based on random decision trees which can dynamically select the label ordering for each prediction. We show empirically that a dynamic selection of the next label improves over the use of a static ordering under an otherwise unchanged random decision tree model. % and experimental environment. In addition, we also demonstrate an alternative approach based on extreme gradient boosted trees, which allows for a more target-oriented training of dynamic classifier chains. Our results show that this variant <font color="#00be00">outperform</font>s random decision trees and other tree-based multi-label classification methods. More importantly, the dynamic selection strategy allows to considerably speed up training and prediction. </br></br>

<a href='http://arxiv.org/pdf/2112.04889.pdf'>2112.04889</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.4423баллов, №944</br>
<b>Artificial Intelligence and Design of Experiments for Assessing Security\n  of Electricity Supply: A Review and Strategic Outlook</b></br>
Authors: , Priesmann, Jan, M&#xfc;nch, Justin, Ridha, Elias, Spiegel, Thomas, Reich, Marius, Adam, Mario, Nolting, Lars, Praktiknjo, Aaron</br>
  Assessing the effects of the energy transition and liberalization of energy <font color="#be00be">market</font>s on resource adequacy is an increasingly important and demanding task. The rising complexity in energy systems requires adequate methods for energy system modeling leading to increased computational requirements. Furthermore, with complexity, uncertainty increases likewise calling for probabilistic assessments and scenario analyses. To adequately and efficiently address these various requirements, new methods from the field of data science are needed to accelerate current methods. With our systematic literature review, we want to close the gap between the three disciplines (1) assessment of security of electricity supply, (2) artificial intelligence, and (3) design of experiments. For this, we conduct a large-scale quantitative review on selected fields of application and methods and make a synthesis that relates the different disciplines to each other. Among other findings, we identify metamodeling of complex security of electricity supply models using AI methods and applications of AI-based methods for forecasts of storage dispatch and (non-)availabilities as promising fields of application that have not sufficiently been covered, yet. We end with deriving a new methodological pipeline for adequately and efficiently addressing the present and upcoming challenges in the assessment of security of electricity supply. </br></br>

<a href='http://arxiv.org/pdf/2112.06721.pdf'>2112.06721</a> &nbsp&nbsp (cs:SD, cs:CL) &nbsp&nbsp -0.4437баллов, №945</br>
<b>PM-MMUT: Boosted Phone-mask Data Augmentation using Multi-modeing Unit\n  Training for Robust Uyghur E2E <font color="#be00be">Speech Recognition</font></b></br>
Authors: , Ma, Guodong, Hu, Pengfei, Yolwas, Nurmemet, Huang, Shen, Huang, Hao</br>
  Consonant and vowel reduction are often encountered in Uyghur speech, which might cause performance degradation in Uyghur automatic <font color="#be00be">speech recognition</font> (ASR). Our recently proposed learning strategy based on masking, Phone Masking Training (PMT), alleviates the impact of such phenomenon in Uyghur ASR. Although PMT achieves remarkably improvements, there still exists room for further gains due to the granularity mismatch between masking unit of PMT (phoneme) and modeling unit (word-piece). To boost the performance of PMT, we propose multi-modeling unit training (MMUT) architecture fusion with PMT (PM-MMUT). The idea of MMUT framework is to split the Encoder into two parts including acoustic feature sequences to phoneme-level representation (AF-to-PLR) and phoneme-level representation to word-piece-level representation (PLR-to-WPLR). It allows AF-to-PLR to be optimized by an intermediate phoneme-based CTC loss to learn the rich phoneme-level context information brought by PMT. Experi-mental results on Uyghur ASR show that the proposed approaches improve significantly, <font color="#00be00">outperform</font>ing the pure PMT (reduction WER from 24.0 to 23.7 on Read-Test and from 38.4 to 36.8 on Oral-Test respectively). We also conduct experiments on the 960-hour Librispeech benchmark using ESPnet1, which achieves about 10% relative WER reduction on all the test sets without LM fusion comparing with the latest official ESPnet1 pre-trained model. </br></br>

<a href='http://arxiv.org/pdf/2112.07850.pdf'>2112.07850</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.4451баллов, №946</br>
<b>HyObscure: Hybrid Obscuring for <font color="#be00be">Privacy</font>-Preserving Data Publishing</b></br>
Authors: , Han, Xiao, Yang, Yuncong, Wu, Junjie</br>
  Minimizing <font color="#be00be">privacy</font> leakage while ensuring data utility is a critical problem to data holders in a privacy-preserving data publishing task. Most prior research concerns only with one type of data and resorts to a single obscuring method, \\eg, obfuscation or generalization, to achieve a privacy-utility tradeoff, which is inadequate for protecting real-life heterogeneous data and is hard to defend ever-growing machine learning based inference attacks. This work takes a pilot study on privacy-preserving data publishing when both generalization and obfuscation operations are employed for heterogeneous data protection. To this end, we first propose novel measures for privacy and utility quantification and formulate the hybrid privacy-preserving data obscuring problem to account for the joint effect of generalization and obfuscation. We then design a novel hybrid protection mechanism called HyObscure, to cross-iteratively optimize the generalization and obfuscation operations for maximum privacy protection under a certain utility guarantee. The convergence of the iterative process and the privacy leakage bound of HyObscure are also provided in <font color="#be00be">theor</font>y. Extensive experiments demonstrate that HyObscure significantly <font color="#00be00">outperform</font>s a variety of <font color="#00be00">state-of-the-art</font> baseline methods when facing various inference attacks under different scenarios. HyObscure also scales linearly to the data size and behaves robustly with varying key parameters. </br></br>

<a href='http://arxiv.org/pdf/2112.06135.pdf'>2112.06135</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.4537баллов, №947</br>
<b>Communication-Efficient <font color="#be00be">Federated</font> Learning for Neural Machine\n  Translation</b></br>
Authors: , Roosta, Tanya, Passban, Peyman, Chadha, Ankit</br>
  Training neural machine translation (NMT) models in <font color="#be00be">federated</font> learning (FL) settings could be inefficient both computationally and communication-wise, due to the large size of translation engines as well as the multiple rounds of updates required to train clients and a central server. In this paper, we explore how to efficiently build NMT models in an FL setup by proposing a novel solution. In order to reduce the communication overhead, out of all neural layers we only exchange what we term &quot;Controller&quot; layers. Controllers are a small number of additional neural components connected to our pre-trained architectures. These new components are placed in between original layers. They act as liaisons to communicate with the central server and learn minimal information that is sufficient enough to update clients.   We evaluated the performance of our models on five datasets from different domains to translate from German into English. We noted that the models equipped with Controllers preform on par with those trained in a central and non-FL setting. In addition, we observed a substantial reduction in the communication traffic of the FL pipeline, which is a direct consequence of using Controllers. Based on our experiments, Controller-based models are ~6 times less expensive than their other peers. This reduction is significantly important when we consider the number of parameters in large models and it becomes even more critical when such parameters need to be exchanged for multiple rounds in FL settings. </br></br>

<a href='http://arxiv.org/pdf/2112.09045.pdf'>2112.09045</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.4541баллов, №948</br>
<b>The MVTec 3D-AD Dataset for Unsupervised 3D <font color="#be00be">Anomal</font>y Detection and\n  Localization</b></br>
Authors: , Bergmann, Paul, Jin, Xin, Sattlegger, David, Steger, Carsten</br>
  We introduce the first comprehensive 3D dataset for the task of unsupervised <font color="#be00be">anomal</font>y detection and localization. It is inspired by <font color="#009600">real-world</font> visual inspection scenarios in which a model has to detect various types of defects on manufactured products, even if it is trained only on anomaly-free data. There are defects that manifest themselves as anomalies in the geometric structure of an object. These cause significant deviations in a 3D representation of the data. We employed a high-resolution industrial 3D sensor to acquire depth scans of 10 different object categories. For all object categories, we present a training and validation set, each of which solely consists of scans of anomaly-free samples. The corresponding test sets contain samples showing various defects such as scratches, dents, holes, contaminations, or deformations. Precise ground-truth annotations are provided for every anomalous test sample. An initial benchmark of 3D anomaly detection methods on our dataset indicates a considerable room for improvement. </br></br>

<a href='http://arxiv.org/pdf/2112.05403.pdf'>2112.05403</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.4569баллов, №949</br>
<b>Computing Diverse Shortest Paths Efficiently: A <font color="#be00be">Theor</font>etical and\n  Experimental Study</b></br>
Authors: , Hanaka, Tesshu, Kobayashi, Yasuaki, Kurita, Kazuhiro, Lee, See Woo, Otachi, Yota</br>
  Finding diverse solutions in combinatorial problems recently has received considerable attention (Baste et al. 2020; Fomin et al. 2020; Hanaka et al. 2021). In this paper we study the following type of problems: given an integer $k$, the problem asks for $k$ solutions such that the sum of pairwise (weighted) Hamming distances between these solutions is maximized. Such solutions are called diverse solutions. We present a polynomial-time algorithm for finding diverse shortest $st$-paths in weighted directed graphs. Moreover, we study the diverse version of other classical combinatorial problems such as diverse weighted matroid bases, diverse weighted arborescences, and diverse bipartite matchings. We show that these problems can be solved in polynomial time as well. To evaluate the practical performance of our algorithm for finding diverse shortest $st$-paths, we conduct a computational experiment with synthetic and <font color="#009600">real-world</font> instances.The experiment shows that our algorithm successfully computes diverse solutions within reasonable computational time. </br></br>

<a href='http://arxiv.org/pdf/2112.06063.pdf'>2112.06063</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.4597баллов, №950</br>
<b>MedAttacker: Exploring Black-Box <font color="#be00be">Adversarial Att</font>acks on Risk Prediction\n  Models in Healthcare</b></br>
Authors: , Ye, Muchao, Luo, Junyu, Zheng, Guanjie, Xiao, Cao, Wang, Ting, Ma, Fenglong</br>
  Deep neural networks (DNNs) have been broadly adopted in health risk prediction to provide healthcare <font color="#be00be">diagnos</font>es and treatments. To evaluate their robustness, existing research conducts <font color="#be00be">adversarial att</font>acks in the white/gray-box setting where model parameters are accessible. However, a more realistic black-box adversarial attack is ignored even though most <font color="#009600">real-world</font> models are trained with <font color="#be00be">private</font> data and released as black-box services on the cloud. To fill this gap, we propose the first black-box adversarial attack method against health risk prediction models named MedAttacker to investigate their vulnerability. MedAttacker addresses the challenges brought by EHR data via two steps: <font color="#00be00">hierarchical</font> position selection which selects the attacked positions in a <font color="#00be00">reinforcement learning</font> (RL) framework and substitute selection which identifies substitute with a score-based principle. Particularly, by considering the temporal context inside EHRs, it initializes its RL position selection policy by using the contribution score of each visit and the saliency score of each code, which can be well integrated with the deterministic substitute selection process decided by the score changes. In experiments, MedAttacker consistently achieves the highest average success rate and even <font color="#00be00">outperform</font>s a recent white-box EHR adversarial attack technique in certain cases when attacking three advanced health risk prediction models in the black-box setting across multiple real-world datasets. In addition, based on the experiment results we include a discussion on defending EHR adversarial attacks. </br></br>

<a href='http://arxiv.org/pdf/2111.14709.pdf'>2111.14709</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.4605баллов, №951</br>
<b>Linguistic Knowledge in Data Augmentation for Natural Language\n  Processing: An Example on <font color="#be00be">Chinese</font> Question Matching</b></br>
Authors: , Wang, Zhengxiang</br>
  To investigate the role of linguistic knowledge in data augmentation (DA) for Natural Language Processing (NLP), particularly, whether more linguistic knowledge leads to a better DA approach, we designed two adapted DA programs and applied them to LCQMC (a Large-scale <font color="#be00be">Chinese</font> Question Matching Corpus) for a binary Chinese question matching classification task. The two DA programs produce augmented texts by five simple text editing operations (or DA techniques), largely irrespective of language generation rules, but one is enhanced with a pre-trained n-gram language model to fuse it with prior linguistic knowledge. We then trained four neural network models (BOW, CNN, LSTM-RNN, and GRU-RNN) and a pre-trained model (ERNIE-Gram) on the LCQMC train sets of varying size as well as the related augmented train sets produced by the two DA programs. The test set performances of the five classification models show that adding probabilistic linguistic knowledge as constrains does not make the base DA program better, since there are no significant performance differences between the models trained on the two types of augmented train sets, both when the five DA techniques are applied together or separately. Moreover, due to the inability of the five DA techniques to make strictly paraphrastic augmented texts, the results indicate the need of sufficient amounts of training examples for the classification models trained on them to mediate the negative impact of false matching augmented text pairs and improve performances, a limitation of random text editing perturbations used a DA approach. </br></br>

<a href='http://arxiv.org/pdf/2112.06327.pdf'>2112.06327</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.4610баллов, №952</br>
<b>Improving Code-switching Language Modeling with Artificially Generated\n  Texts using Cycle-consistent Adversarial Networks</b></br>
Authors: , Li, Chia-Yu, Vu, Ngoc Thang</br>
  This paper presents our latest effort on improving Code-switching language models that suffer from data scarcity. We investigate methods to augment Code-switching training text data by artificially generating them. Concretely, we propose a cycle-consistent adversarial networks based framework to transfer monolingual text into Code-switching text, considering Code-switching as a speaking <font color="#be00be">style</font>. Our experimental results on the SEAME corpus show that utilising artificially generated Code-switching text data improves consistently the language model as well as the automatic <font color="#be00be">speech recognition</font> performance. </br></br>

<a href='http://arxiv.org/pdf/2112.07391.pdf'>2112.07391</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.4615баллов, №953</br>
<b>TASSY -- A Text Annotation Survey System</b></br>
Authors: , Spinde, Timo, Sinha, Kanishka, Meuschke, Norman, Gipp, Bela</br>
  We present a free and open-source tool for creating web-based surveys that include text annotation tasks. Existing tools offer either text annotation or survey functionality but not both. Combining the two input types is particularly relevant for investigating a reader\'s perception of a text which also depends on the reader\'s background, such as age, gender, and education. Our tool caters primarily to the needs of researchers in the Library and Information Sciences, the Social Sciences, and the Humanities who apply Content Analysis to investigate, e.g., media bias, political communication, or <font color="#be00be">fake news</font>. </br></br>

<a href='http://arxiv.org/pdf/2111.14844.pdf'>2111.14844</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.4629баллов, №954</br>
<b>Evaluation of Machine Learning Techniques for Forecast Uncertainty\n  Quantification</b></br>
Authors: , Sacco, Maximiliano A., Ruiz, Juan J., Pulido, Manuel, Tandeo, Pierre</br>
  Producing an accurate <font color="#be00be">weather</font> forecast and a reliable quantification of its uncertainty is an open scientific challenge. Ensemble forecasting is, so far, the most successful approach to produce relevant forecasts along with an estimation of their uncertainty. The main limitations of ensemble forecasting are the high computational cost and the difficulty to capture and quantify different sources of uncertainty, particularly those associated with model errors. In this work proof-of-concept model experiments are conducted to examine the performance of ANNs trained to predict a corrected state of the system and the state uncertainty using only a single deterministic forecast as input. We compare different training strategies: one based on a direct training using the mean and spread of an ensemble forecast as target, the other ones rely on an indirect training strategy using a deterministic forecast as target in which the uncertainty is implicitly learned from the data. For the last approach two alternative loss functions are proposed and evaluated, one based on the data observation likelihood and the other one based on a local estimation of the error. The performance of the networks is examined at different lead times and in scenarios with and without model errors. Experiments using the Lorenz\'96 model show that the ANNs are able to emulate some of the properties of ensemble forecasts like the filtering of the most unpredictable modes and a state-dependent quantification of the forecast uncertainty. Moreover, ANNs provide a reliable estimation of the forecast uncertainty in the presence of model error. </br></br>

<a href='http://arxiv.org/pdf/2112.08903.pdf'>2112.08903</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.4645баллов, №955</br>
<b>Graph Structure Learning with Variational Information Bottleneck</b></br>
Authors: , Sun, Qingyun, Li, Jianxin, Peng, Hao, Wu, Jia, Fu, Xingcheng, Ji, Cheng, Yu, Philip S.</br>
  Graph Neural Networks (GNNs) have shown promising results on a broad spectrum of applications. Most empirical studies of GNNs directly take the observed graph as input, assuming the observed structure perfectly depicts the accurate and complete relations between nodes. However, graphs in the <font color="#009600">real world</font> are inevitably noisy or incomplete, which could even exacerbate the quality of graph representations. In this work, we propose a novel Variational Information Bottleneck guided Graph Structure Learning framework, namely VIB-GSL, in the perspective of information <font color="#be00be">theor</font>y. VIB-GSL advances the Information Bottleneck (IB) principle for graph structure learning, providing a more elegant and universal framework for mining underlying task-relevant relations. VIB-GSL learns an informative and compressive graph structure to distill the actionable information for specific downstream tasks. VIB-GSL deduces a variational approximation for irregular graph data to form a tractable IB objective function, which facilitates training stability. Extensive experimental results demonstrate that the superior effectiveness and robustness of VIB-GSL. </br></br>

<a href='http://arxiv.org/pdf/2112.05611.pdf'>2112.05611</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp -0.4653баллов, №956</br>
<b>Eigenspace Restructuring: a Principle of Space and Frequency in Neural\n  Networks</b></br>
Authors: , Xiao, Lechao</br>
  Understanding the fundamental principles behind the massive success of neural networks is one of the most important open questions in deep learning. However, due to the highly complex nature of the problem, progress has been relatively slow. In this note, through the lens of infinite-width networks, a.k.a. neural <font color="#be00be">kernel</font>s, we present one such principle resulting from <font color="#00be00">hierarchical</font> localities. It is well-known that the eigenstructure of infinite-width multilayer perceptrons (MLPs) depends solely on the concept frequency, which measures the order of interactions. We show that the topologies from deep convolutional networks (CNNs) restructure the associated eigenspaces into finer subspaces. In addition to frequency, the new structure also depends on the concept space, which measures the spatial distance among nonlinear interaction terms. The resulting fine-grained eigenstructure dramatically improves the network\'s learnability, empowering them to simultaneously model a much richer class of interactions, including Long-Range-Low-Frequency interactions, Short-Range-High-Frequency interactions, and various interpolations and extrapolations in-between. Additionally, model scaling can improve the resolutions of interpolations and extrapolations and, therefore, the network\'s learnability. Finally, we prove a sharp characterization of the generalization error for infinite-width CNNs of any depth in the high-dimensional setting. Two corollaries follow: (1) infinite-width deep CNNs can break the curse of dimensionality without losing their expressivity, and (2) scaling improves performance in both the finite and infinite data regimes. </br></br>

<a href='http://arxiv.org/pdf/2112.07622.pdf'>2112.07622</a> &nbsp&nbsp (cs:AI, cs:CL) &nbsp&nbsp -0.4658баллов, №957</br>
<b>ISEEQ: Information Seeking Question Generation using Dynamic\n  Meta-Information <font color="#be00be">Retrieval</font> and <font color="#960096">Knowledge Graph</font>s</b></br>
Authors: , Gaur, Manas, Gunaratna, Kalpa, Srinivasan, Vijay, Jin, Hongxia</br>
  Conversational Information Seeking (CIS) is a relatively new research area within conversational AI that attempts to seek information from end-users in order to understand and satisfy users\' needs. If realized, such a system has far-reaching benefits in the <font color="#009600">real world</font>; for example, a CIS system can assist <font color="#be00be">clinic</font>ians in pre-screening or triaging <font color="#be00be">patient</font>s in healthcare. A key open sub-problem in CIS that remains unaddressed in the literature is generating Information Seeking Questions (ISQs) based on a short initial query from the end-user. To address this open problem, we propose Information SEEking Question generator (ISEEQ), a novel approach for generating ISQs from just a short user query, given a large text corpus relevant to the user query. Firstly, ISEEQ uses a <font color="#960096">knowledge graph</font> to enrich the user query. Secondly, ISEEQ uses the knowledge-enriched query to retrieve relevant context passages to ask coherent ISQs adhering to a conceptual flow. Thirdly, ISEEQ introduces a new deep generative-adversarial <font color="#00be00">reinforcement learning</font>-based approach for generating ISQs. We show that ISEEQ can generate high-quality ISQs to promote the development of CIS agents. ISEEQ significantly <font color="#00be00">outperform</font>s comparable baselines on five ISQ evaluation metrics across four datasets having user queries from diverse domains. Further, we argue that ISEEQ is transferable across domains for generating ISQs, as it shows the acceptable performance when trained and tested on different pairs of domains. The qualitative human evaluation confirms ISEEQ-generated ISQs are comparable in quality to human-generated questions and outperform the best comparable baseline. </br></br>

<a href='http://arxiv.org/pdf/2112.07872.pdf'>2112.07872</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.4676баллов, №958</br>
<b>A Comparison of Robust Kalman Filters for Improving Wheel-Inertial\n  <font color="#be00be">Odometry</font> in Planetary Rovers</b></br>
Authors: , Das, Shounak, Kilic, Cagri, Watson, Ryan, Gross, Jason</br>
  This paper compares the performance of adaptive and robust Kalman filter algorithms in improving wheel-inertial <font color="#be00be">odometry</font> on low featured rough terrain. Approaches include classical adaptive and robust methods as well as variational methods, which are evaluated experimentally on a wheeled rover in terrain similar to what would be encountered in planetary exploration. Variational filters show improved solution accuracy compared to the classical adaptive filters and are able to handle erroneous wheel odometry measurements and keep good localization for longer distances without significant drift. We also show how varying the parameters affects localization performance. </br></br>

<a href='http://arxiv.org/pdf/2112.06307.pdf'>2112.06307</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.4708баллов, №959</br>
<b>Image-to-Height Domain Translation for Synthetic Aperture Sonar</b></br>
Authors: , Stewart, Dylan, Johnson, Shawn, Zare, Alina</br>
  Observations of seabed texture with synthetic aperture sonar are dependent upon several factors. In this work, we focus on collection geometry with respect to isotropic and anisotropic textures. The low grazing angle of the collection geometry, combined with orientation of the sonar path relative to anisotropic texture, poses a significant challenge for image-alignment and other multi-view scene understanding frameworks. We previously proposed using features captured from estimated seabed relief to improve scene understanding. While several methods have been developed to estimate seabed relief via intensity, no large-scale study exists in the literature. Furthermore, a dataset of coregistered seabed relief maps and sonar imagery is nonexistent to learn this domain translation. We address these problems by producing a large simulated dataset containing coregistered pairs of seabed relief and intensity maps from two unique sonar data simulation techniques. We apply three types of models, with varying complexity, to translate intensity imagery to seabed relief: a <font color="#be00be">Gaussi</font>an Markov Random Field approach (GMRF), a conditional Generative Adversarial Network (cGAN), and UNet architectures. Methods are compared in reference to the coregistered simulated datasets using L1 error. Additionally, predictions on simulated and real SAS imagery are shown. Finally, models are compared on two datasets of hand-aligned SAS imagery and evaluated in terms of L1 error across multiple aspects in comparison to using intensity. Our comprehensive experiments show that the proposed UNet architectures <font color="#00be00">outperform</font> the GMRF and pix2pix cGAN models on seabed relief estimation for simulated and real SAS imagery. </br></br>

<a href='http://arxiv.org/pdf/2112.08222.pdf'>2112.08222</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4727баллов, №960</br>
<b>Guaranteed Contraction Control in the Presence of Imperfectly Learned\n  Dynamics</b></br>
Authors: , Zhao, Pan, Guo, Ziyao, Cheng, Yikun, Gahlawat, Aditya, Hovakimyan, Naira</br>
  This paper presents an approach for trajectory-centric learning control based on contraction metrics and disturbance estimation for nonlinear systems subject to matched uncertainties. The approach allows for the use of a broad class of model learning tools including deep neural networks to learn uncertain dynamics while still providing guarantees of transient <font color="#be00be">tracking</font> performance throughout the learning phase, including the special case of no learning. Within the proposed approach, a disturbance estimation law is proposed to estimate the pointwise value of the uncertainty, with pre-computable estimation error bounds (EEBs). The learned dynamics, the estimated disturbances, and the EEBs are then incorporated in a robust Riemannian energy condition to compute the control law that guarantees exponential convergence of actual trajectories to desired ones throughout the learning phase, even when the learned model is poor. On the other hand, with improved accuracy, the learned model can be incorporated in a high-level planner to plan better trajectories with improved performance, e.g., lower energy consumption and shorter travel time. The proposed framework is validated on a planar quadrotor navigation example. </br></br>

<a href='http://arxiv.org/pdf/2112.08189.pdf'>2112.08189</a> &nbsp&nbsp (cs:CV, cs:RO) &nbsp&nbsp -0.4728баллов, №961</br>
<b>ST-MTL: Spatio-Temporal Multitask Learning Model to Predict Scanpath\n  While <font color="#be00be">Tracking</font> Instruments in Robotic Surgery</b></br>
Authors: , Islam, Mobarakol, VS, Vibashan, Lim, Chwee Ming, Ren, Hongliang</br>
  Representation learning of the task-oriented attention while <font color="#be00be">tracking</font> instrument holds vast potential in image-guided robotic surgery. Incorporating cognitive ability to automate the camera control enables the surgeon to concentrate more on dealing with surgical instruments. The objective is to reduce the operation time and facilitate the surgery for both surgeons and <font color="#be00be">patient</font>s. We propose an end-to-end trainable Spatio-Temporal Multi-Task Learning (ST-MTL) model with a shared encoder and spatio-temporal decoders for the real-time surgical instrument <font color="#be00be">segmentation</font> and task-oriented saliency detection. In the MTL model of shared parameters, optimizing multiple loss functions into a convergence point is still an open challenge. We tackle the problem with a novel asynchronous spatio-temporal optimization (ASTO) technique by calculating independent gradients for each decoder. We also design a <font color="#960096">competitive</font> squeeze and excitation unit by casting a skip connection that retains weak features, excites strong features, and performs dynamic spatial and channel-wise feature recalibration. To capture better long term spatio-temporal dependencies, we enhance the long-short term memory (LSTM) module by concatenating high-level encoder features of consecutive frames. We also introduce Sinkhorn regularized loss to enhance task-oriented saliency detection by preserving computational efficiency. We generate the task-aware saliency maps and scanpath of the instruments on the dataset of the MICCAI 2017 robotic instrument segmentation challenge. Compared to the <font color="#00be00">state-of-the-art</font> segmentation and saliency methods, our model <font color="#00be00">outperform</font>s most of the evaluation metrics and produces an outstanding performance in the challenge. </br></br>

<a href='http://arxiv.org/pdf/2112.08086.pdf'>2112.08086</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.4734баллов, №962</br>
<b>Photonic neuromorphic computing using vertical cavity semiconductor\n  lasers</b></br>
Authors: , Skalli, Anas, Robertson, Joshua, Owen-Newns, Dafydd, Hejda, Matej, Porte, Xavier, Reitzenstein, Stephan, Hurtado, Antonio, Brunner, D.</br>
  Photonic realizations of neural network computing hardware are a promising approach to enable future scalability of neuromorphic computing. In this review we provide an overview on vertical-cavity surface-emitting lasers (VCSELs) and how these high-performance electro-optical components either implement or are combined with additional photonic hardware to demonstrate points (i-iii). In the neurmorphic photonics\' context, VCSELs are of exceptional interest as they are compatible with CMOS fabrication, readily achieve 30\\% wall-plug efficiency and &gt;30~GHz modulation bandwidth and hence are highly energy efficient and ultra-fast. Crucially, they react highly nonlinear to optical injection as well as to electrical modulation, making them highly suitable as all-optical as well as electro-optical photonic neurons. Their optical cavities are wavelength-limited, and standard semiconductor growth and lithography enables non-classical cavity configurations and geometries. This enables excitable VCSELs (i.e. spiking VCSELs) to finely control their temporal and spatial coherence, to unlock Terahertz bandwidths through spin-flip effects, and even to leverage cavity quantum electrodynamics to further boost their efficiency. Finally, as VCSEL arrays they are compatible with standard 2D photonic integration, but their emission vertical to the substrate makes them ideally suited for scalable integrated networks leveraging 3D photonic waveguides. Here, we discuss the implementation of spatially as well as temporally multiplexed VCSEL neural networks and <font color="#be00be">reservoir</font>s, computation on the basis of excitable VCSELs as photonic spiking neurons, as well as concepts and advances in the fabrication of VCSELs and microlasers. </br></br>

<a href='http://arxiv.org/pdf/2112.07616.pdf'>2112.07616</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.4781баллов, №963</br>
<b>DiPS: Differentiable Policy for Sketching in Recommender Systems</b></br>
Authors: , Ghosh, Aritra, Mitra, Saayan, Lan, Andrew</br>
  In sequential recommender system applications, it is important to develop models that can capture users\' evolving interest over time to successfully recommend future items that they are likely to interact with. For users with long histories, typical models based on recurrent neural networks tend to forget important items in the distant past. Recent works have shown that storing a small sketch of past items can improve sequential <font color="#be00be">recommendat</font>ion tasks. However, these works all rely on static sketching policies, i.e., heuristics to select items to keep in the sketch, which are not necessarily optimal and cannot improve over time with more training data. In this paper, we propose a differentiable policy for sketching (DiPS), a framework that learns a data-driven sketching policy in an end-to-end manner together with the recommender system model to explicitly maximize recommendation quality in the future. We also propose an approximate estimator of the gradient for optimizing the sketching algorithm parameters that is computationally efficient. We verify the effectiveness of DiPS on <font color="#009600">real-world</font> datasets under various practical settings and show that it requires up to $50\\%$ fewer sketch items to reach the same predictive quality than existing sketching policies. </br></br>

<a href='http://arxiv.org/pdf/2112.06362.pdf'>2112.06362</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4786баллов, №964</br>
<b>Scheduling Servers with Stochastic Bilinear Rewards</b></br>
Authors: , Kim, Jung-hun, Vojnovic, Milan</br>
  In this paper we study a multi-class, multi-server queueing system with stochastic rewards of job-server assignments following a bilinear model in feature vectors representing jobs and servers. Our goal is regret minimization against an oracle policy that has a complete information about system parameters. We propose a scheduling algorithm that uses a linear <font color="#be00be">bandit</font> algorithm along with dynamic allocation of jobs to servers. For the baseline setting, in which mean job service times are identical for all jobs, we show that our algorithm has a sub-linear regret, as well as a sub-linear bound on the mean queue length, in the horizon time. We further show that similar bounds hold under more general assumptions, allowing for non-identical mean job service times for different job classes and a time-varying set of server classes. We also show that better regret and mean queue length bounds can be guaranteed by an algorithm having access to traffic intensities of job classes. We present results of numerical experiments demonstrating how regret and mean queue length of our algorithms depend on various system parameters and compare their performance against a previously proposed algorithm using synthetic randomly generated data and a <font color="#009600">real-world</font> cluster computing data trace. </br></br>

<a href='http://arxiv.org/pdf/2112.05666.pdf'>2112.05666</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.4839баллов, №965</br>
<b>An Ensemble 1D-CNN-LSTM-GRU Model with Data Augmentation for Speech\n  <font color="#be00be">Emotion</font> Recognition</b></br>
Authors: , Ahmed, Md. Rayhan, Islam, Salekul, D, Ph., Islam, A. K. M. Muzahidul, D, Ph., Shatabda, Swakkhar, D, Ph.</br>
  In this paper, we propose an ensemble of deep neural networks along with data augmentation (DA) learned using effective speech-based features to recognize <font color="#be00be">emotion</font>s from speech. Our ensemble model is built on three deep neural network-based models. These neural networks are built using the basic local feature acquiring blocks (LFAB) which are consecutive layers of dilated 1D Convolutional Neural networks followed by the max pooling and batch normalization layers. To acquire the long-term dependencies in speech signals further two variants are proposed by adding Gated Recurrent Unit (GRU) and Long Short Term Memory (LSTM) layers respectively. All three network models have consecutive fully connected layers before the final softmax layer for classification. The ensemble model uses a weighted average to provide the final classification. We have utilized five standard benchmark datasets: TESS, EMO-DB, RAVDESS, SAVEE, and CREMA-D for evaluation. We have performed DA by injecting Additive White <font color="#be00be">Gaussi</font>an Noise, pitch shifting, and stretching the signal level to generalize the models, and thus increasing the accuracy of the models and reducing the overfitting as well. We handcrafted five categories of features: Mel-frequency cepstral coefficients, Log Mel-Scaled Spectrogram, Zero-Crossing Rate, Chromagram, and statistical Root Mean Square Energy value from each audio sample. These features are used as the input to the LFAB blocks that further extract the hidden local features which are then fed to either fully connected layers or to LSTM or GRU based on the model type to acquire the additional long-term contextual representations. LFAB followed by GRU or LSTM results in better performance compared to the baseline model. The ensemble model achieves the <font color="#00be00">state-of-the-art</font> weighted average accuracy in all the datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.07877.pdf'>2112.07877</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.4851баллов, №966</br>
<b>Learning to Transpile AMR into SPARQL</b></br>
Authors: , Bornea, Mihaela, Astudillo, Ramon Fernandez, Naseem, Tahira, Mihindukulasooriya, Nandana, Abdelaziz, Ibrahim, Kapanipathi, Pavan, Florian, Radu, Roukos, Salim</br>
  We propose a transition-based system to transpile Abstract Meaning Representation (AMR) into SPARQL for Knowledge Base Question Answering (KBQA). This allows to delegate part of the abstraction problem to a strongly pre-trained semantic <font color="#be00be">parser</font>, while learning transpiling with small amount of paired data. We departure from recent work relating AMR and SPARQL constructs, but rather than applying a set of rules, we teach the BART model to selectively use these relations. Further, we avoid explicitly encoding AMR but rather encode the parser state in the attention mechanism of BART, following recent semantic <font color="#be00be">parsing</font> works. The resulting model is simple, provides supporting text for its decisions, and <font color="#00be00">outperform</font>s recent progress in AMR-based KBQA in LC-QuAD (F1 53.4), matching it in QALD (F1 30.8), while exploiting the same inductive biases. </br></br>

<a href='http://arxiv.org/pdf/2112.06053.pdf'>2112.06053</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4856баллов, №967</br>
<b>FedSoft: Soft Clustered <font color="#be00be">Federated</font> Learning with Proximal Local Updating</b></br>
Authors: , Ruan, Yichen, Joe-Wong, Carlee</br>
  Traditionally, clustered <font color="#be00be">federated</font> learning groups clients with the same data distribution into a cluster, so that every client is uniquely associated with one data distribution and helps train a model for this distribution. We relax this hard association assumption to soft clustered federated learning, which allows every local dataset to follow a mixture of multiple source distributions. We propose FedSoft, which trains both locally personalized models and high-quality cluster models in this setting. FedSoft limits client workload by using proximal updates to require the completion of only one optimization task from a subset of clients in every communication round. We show, analytically and empirically, that FedSoft effectively exploits similarities between the source distributions to learn personalized and cluster models that perform well. </br></br>

<a href='http://arxiv.org/pdf/2112.06643.pdf'>2112.06643</a> &nbsp&nbsp (cs:NE) &nbsp&nbsp -0.4866баллов, №968</br>
<b>On the Dynamics of Hopfield Neural Networks on Unit Quaternions</b></br>
Authors: , Valle, Marcos Eduardo, de Castro, Fidelis Zanetti</br>
  In this paper, we first address the dynamics of the elegant multi-valued quaternionic Hopfield neural network (MV-QHNN) proposed by Minemoto and collaborators. Contrary to what was expected, we show that the MV-QHNN, as well as one of its variation, does not always come to rest at an equilibrium state under the usual conditions. In fact, we provide simple examples in which the network yields a periodic sequence of quaternionic state vectors. Afterward, we turn our attention to the continuous-valued quaternionic Hopfield neural network (CV-QHNN), which can be derived from the MV-QHNN by means of a limit process. The CV-QHNN can be implemented more easily than the MV-QHNN model. Furthermore, the asynchronous CV-QHNN always settles down into an equilibrium state under the usual conditions. <font color="#be00be">Theor</font>etical issues are all illustrated by examples in this paper. </br></br>

<a href='http://arxiv.org/pdf/2112.06462.pdf'>2112.06462</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.4872баллов, №969</br>
<b>Predicting User Code-Switching Level from Sociological and Psychological\n  Profiles</b></br>
Authors: , Hamed, Injy, Bolock, Alia El, Rizk, Nader, Herbert, Cornelia, Abdennadher, Slim, Vu, Ngoc Thang</br>
  Multilingual speakers tend to alternate between languages within a conversation, a phenomenon referred to as &quot;code-switching&quot; (CS). CS is a complex phenomenon that not only encompasses linguistic challenges, but also contains a great deal of complexity in terms of its dynamic behaviour across speakers. This dynamic behaviour has been studied by sociologists and psychologists, identifying factors affecting CS. In this paper, we provide an empirical user study on Arabic-English CS, where we show the correlation between users\' CS frequency and character traits. We use machine learning (ML) to validate the findings, informing and confirming existing <font color="#be00be">theor</font>ies. The predictive models were able to predict users\' CS frequency with an accuracy higher than 55%, where travel experiences and personality traits played the biggest role in the modeling process. </br></br>

<a href='http://arxiv.org/pdf/2112.06412.pdf'>2112.06412</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.4875баллов, №970</br>
<b>A Survey of Toxic Comment Classification Methods</b></br>
Authors: , Wang, Kehan, Yang, Jiaxi, Wu, Hongjun</br>
  While in real life everyone behaves themselves at least to some extent, it is much more difficult to expect people to behave themselves on the internet, because there are few checks or consequences for posting something toxic to others. Yet, for people on the other side, toxic texts often lead to serious psychological consequences. Detecting such toxic texts is challenging. In this paper, we attempt to build a toxicity detector using machine learning methods including CNN, Naive <font color="#be00be">Bayes</font> model, as well as LSTM. While there has been numerous groundwork laid by others, we aim to build models that provide higher accuracy than the predecessors. We produced very high accuracy models using LSTM and CNN, and compared them to the go-to solutions in language processing, the Naive Bayes model. A word embedding approach is also applied to empower the accuracy of our models. </br></br>

<a href='http://arxiv.org/pdf/2112.06883.pdf'>2112.06883</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.4899баллов, №971</br>
<b>A Methodology for a Scalable, Collaborative, and Resource-Efficient\n  Platform to Facilitate Healthcare AI Research</b></br>
Authors: , Cohen, Raphael Y., Kovacheva, Vesela P.</br>
  Healthcare AI holds the potential to increase <font color="#be00be">patient</font> safety, augment efficiency and improve patient outcomes, yet research is often limited by data access, cohort curation, and tooling for analysis. Collection and translation of electronic health record data, live data, and real-time high resolution device data can be challenging and time-consuming. The development of <font color="#009600">real-world</font> AI tools requires overcoming challenges in data acquisition, scarce hospital resources and high needs for data governance. These bottlenecks may result in resource-heavy needs and long delays in research and development of AI systems. We present a system and methodology to accelerate data acquisition, dataset development and analysis, and AI model development. We created an interactive platform that relies on a scalable microservice backend. This system can ingest 15,000 patient records per hour, where each record represents thousands of multimodal measurements, text notes, and high resolution data. Collectively, these records can approach a terabyte of data. The system can further perform cohort generation and preliminary dataset analysis in 2-5 minutes. As a result, multiple users can collaborate simultaneously to iterate on datasets and models in real time. We anticipate that this approach will drive real-world AI model development, and, in the long run, meaningfully improve healthcare delivery. </br></br>

<a href='http://arxiv.org/pdf/2112.09068.pdf'>2112.09068</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4906баллов, №972</br>
<b>Estimation of Physical Activity Level and Ambient Condition Thresholds\n  for Respiratory Health using Smartphone Sensors</b></br>
Authors: , Uwaoma, Chinazunwa</br>
  While physical activity has been described as a primary prevention against chronic <font color="#be00be">diseas</font>es, strenuous physical exertion under adverse ambient conditions has also been reported as a major contributor to exacerbation of chronic respiratory conditions. Maintaining a balance by monitoring the type and the level of physical activities of affected individuals, could help in reducing the cost and burden of managing respiratory ailments. This paper explores the potentiality of motion sensors in Smartphones to estimate physical activity thresholds that could trigger symptoms of exercise induced respiratory conditions (EiRCs). The focus is on the extraction of measurements from the embedded motion sensors to determine the activity level and the type of activity that is tolerable to individuals respiratory health. The calculations are based on the correlation between Signal Magnitude Area (SMA) and Energy Expenditure (EE). We also consider the effect of changes in the ambient conditions like temperature and humidity, as contributing factors to respiratory distress during physical exercise. Real time data collected from healthy individuals were used to demonstrate the potentiality of a<font color="#960096"> mobile </font>phone as tool to regulate the level of physical activities of individuals with EiRCs. We describe a practical situation where the experimental outcomes can be applied to promote good respiratory health. </br></br>

<a href='http://arxiv.org/pdf/2112.06763.pdf'>2112.06763</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4906баллов, №973</br>
<b>A Homotopy Algorithm for Optimal Transport</b></br>
Authors: , Yousefzadeh, Roozbeh</br>
  The optimal transport problem has many applications in machine learning, physics, biology, <font color="#be00be">economic</font>s, etc. Although its goal is very clear and mathematically well-defined, finding its optimal solution can be challenging for large datasets in high-dimensional space. Here, we propose a homotopy algorithm that first transforms the problem into an easy form, by changing the target distribution. It then transforms the problem back to the original form through a series of iterations, tracing a path of solutions until it finds the optimal solution for the original problem. We define the homotopy path as a subspace rotation based on the orthogonal Procrustes problem, and then we discretize the homotopy path using eigenvalue decomposition of the rotation matrix. Our goal is to provide an algorithm with complexity bound $\\mathcal{O}(n^2 \\log(n))$, faster than the existing methods in the literature. </br></br>

<a href='http://arxiv.org/pdf/2112.08524.pdf'>2112.08524</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.4906баллов, №974</br>
<b>FLoRA: Single-shot Hyper-parameter Optimization for <font color="#be00be">Federated</font> Learning</b></br>
Authors: , Zhou, Yi, Ram, Parikshit, Salonidis, Theodoros, Baracaldo, Nathalie, Samulowitz, Horst, Ludwig, Heiko</br>
  We address the relatively unexplored problem of hyper-parameter optimization (HPO) for <font color="#be00be">federated</font> learning (FL-HPO). We introduce Federated Loss suRface Aggregation (FLoRA), the first FL-HPO solution framework that can address use cases of tabular data and gradient boosting training algorithms in addition to stochastic gradient descent/neural networks commonly addressed in the FL literature. The framework enables single-shot FL-HPO, by first identifying a good set of hyper-parameters that are used in a **single** FL training. Thus, it enables FL-HPO solutions with minimal additional communication overhead compared to FL training without HPO. Our empirical evaluation of FLoRA for Gradient Boosted Decision Trees on seven OpenML data sets demonstrates significant model accuracy improvements over the considered baseline, and robustness to increasing number of parties involved in FL-HPO training. </br></br>

<a href='http://arxiv.org/pdf/2112.06723.pdf'>2112.06723</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.4911баллов, №975</br>
<b>Understanding and Improving the Exemplar-based Generation for\n  Open-domain Conversation</b></br>
Authors: , Han, Seungju, Kim, Beomsu, Seo, Seokjun, Erdenee, Enkhbayar, Chang, Buru</br>
  Exemplar-based generative models for open-domain conversation produce responses based on the exemplars provided by the retriever, taking advantage of generative models and <font color="#be00be">retrieval</font> models. However, they often ignore the retrieved exemplars while generating responses or produce responses over-fitted to the retrieved exemplars. In this paper, we argue that these drawbacks are derived from the one-to-many problem of the open-domain conversation. When the retrieved exemplar is relevant to the given context yet significantly different from the gold response, the exemplar-based generative models are trained to ignore the exemplar since the exemplar is not helpful for generating the gold response. On the other hand, when the retrieved exemplar is lexically similar to the gold response, the generative models are trained to rely on the exemplar highly. Therefore, we propose a training method selecting exemplars that are semantically relevant to the gold response but lexically distanced from the gold response to mitigate the above disadvantages. In the training phase, our proposed training method first uses the gold response instead of dialogue context as a query to select exemplars that are semantically relevant to the gold response. And then, it eliminates the exemplars that lexically resemble the gold responses to alleviate the dependency of the generative models on that exemplars. The remaining exemplars could be irrelevant to the given context since they are searched depending on the gold response. Thus, our proposed training method further utilizes the relevance scores between the given context and the exemplars to penalize the irrelevant exemplars. Extensive experiments demonstrate that our proposed training method alleviates the drawbacks of the existing exemplar-based generative models and significantly improves the performance in terms of appropriateness and informativeness. </br></br>

<a href='http://arxiv.org/pdf/2112.07441.pdf'>2112.07441</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp -0.4939баллов, №976</br>
<b>An <font color="#be00be">Interpret</font>ive Constrained Linear Model for ResNet and MgNet</b></br>
Authors: , He, Juncai, Xu, Jinchao, Zhang, Lian, Zhu, Jianqing</br>
  We propose a constrained linear data-feature-mapping model as an <font color="#be00be">interpret</font>able mathematical model for image classification using a convolutional neural network (CNN). From this viewpoint, we establish detailed connections between the traditional iterative schemes for linear systems and the architectures of the basic blocks of ResNet- and MgNet-type models. Using these connections, we present some modified ResNet models that compared with the original models have fewer parameters and yet can produce more accurate results, thereby demonstrating the validity of this constrained learning data-feature-mapping assumption. Based on this assumption, we further propose a general data-feature iterative scheme to show the rationality of MgNet. We also provide a systematic numerical study on MgNet to show its success and advantages in image classification problems and demonstrate its advantages in comparison with established networks. </br></br>

<a href='http://arxiv.org/pdf/2112.08967.pdf'>2112.08967</a> &nbsp&nbsp (cs:ML, cs:RO) &nbsp&nbsp -0.5001баллов, №977</br>
<b>End-to-End Multi-Task Deep Learning and Model Based Control Algorithm\n  for Autonomous Driving</b></br>
Authors: , Lee, Der-Hau, Liu, Jinn-Liang</br>
  End-to-end driving with a deep learning neural network (DNN) has become a rapidly growing paradigm of autonomous driving in industry and academia. Yet safety measures and <font color="#be00be">interpret</font>ability still pose challenges to this paradigm. We propose an end-to-end driving algorithm that integrates multi-task DNN, path prediction, and control models in a pipeline of data flow from sensory devices through these models to driving decisions. It provides quantitative measures to evaluate the holistic, dynamic, and real-time performance of end-to-end driving systems, and thus allows to quantify their safety and interpretability. The DNN is a modified UNet, a well known encoder-decoder neural network of semantic <font color="#be00be">segmentation</font>. It consists of one segmentation, one <font color="#be00be">regression</font>, and two classification tasks for lane segmentation, path prediction, and vehicle controls. We present three variants of the modified UNet architecture having different complexities, compare them on different tasks in four static measures for both single and multi-task (MT) architectures, and then identify the best one by two additional dynamic measures in real-time simulation. We also propose a learning- and model-based longitudinal controller using model predictive control method. With the Stanley lateral controller, our results show that MTUNet <font color="#00be00">outperform</font>s an earlier modified UNet in terms of curvature and lateral offset estimation on curvy roads at normal speed, which has been tested in a real car driving on real roads. </br></br>

<a href='http://arxiv.org/pdf/2112.06569.pdf'>2112.06569</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.5004баллов, №978</br>
<b>Triangle Attack: A Query-efficient Decision-based <font color="#be00be">Adversarial Att</font>ack</b></br>
Authors: , Wang, Xiaosen, Zhang, Zeliang, Tong, Kangheng, Gong, Dihong, He, Kun, Li, Zhifeng, Liu, Wei</br>
  Decision-based attack poses a severe threat to <font color="#009600">real-world</font> applications since it regards the target model as a black box and only accesses the hard prediction label. Great efforts have been made recently to decrease the number of queries; however, existing decision-based attacks still require thousands of queries in order to generate good quality adversarial examples. In this work, we find that a benign sample, the current and the next adversarial examples could naturally construct a triangle in a subspace for any iterative attacks. Based on the law of sines, we propose a novel Triangle Attack (TA) to optimize the perturbation by utilizing the geometric information that the longer side is always opposite the larger angle in any triangle. However, directly applying such information on the input image is ineffective because it cannot thoroughly explore the neighborhood of the input sample in the high dimensional space. To address this issue, TA optimizes the perturbation in the low frequency space for effective dimensionality reduction owing to the generality of such geometric property. Extensive evaluations on the ImageNet dataset demonstrate that TA achieves a much higher attack success rate within 1,000 queries and needs a much less number of queries to achieve the same attack success rate under various perturbation budgets than existing decision-based attacks. With such high efficiency, we further demonstrate the applicability of TA on real-world API, i.e., Tencent Cloud API. </br></br>

<a href='http://arxiv.org/pdf/2112.06685.pdf'>2112.06685</a> &nbsp&nbsp (cs:CV, cs:ML, cs:NE) &nbsp&nbsp -0.5038баллов, №979</br>
<b>Quaternion-Valued Convolutional Neural Network Applied for Acute\n  Lymphoblastic Leukemia <font color="#be00be">Diagnos</font>is</b></br>
Authors: , Granero, Marco Aur&#xe9;lio, Hern&#xe1;ndez, Cristhian Xavier, Valle, Marcos Eduardo</br>
  The field of neural networks has seen significant advances in recent years with the development of deep and convolutional neural networks. Although many of the current works address real-valued models, recent studies reveal that neural networks with hypercomplex-valued parameters can better capture, generalize, and represent the complexity of multidimensional data. This paper explores the quaternion-valued convolutional neural network application for a pattern recognition task from <font color="#640064">medic</font>ine, namely, the <font color="#be00be">diagnos</font>is of acute lymphoblastic leukemia. Precisely, we compare the performance of real-valued and quaternion-valued convolutional neural networks to classify lymphoblasts from the peripheral blood smear microscopic images. The quaternion-valued convolutional neural network achieved better or similar performance than its corresponding real-valued network but using only 34% of its parameters. This result confirms that quaternion algebra allows capturing and extracting information from a color image with fewer parameters. </br></br>

<a href='http://arxiv.org/pdf/2112.08673.pdf'>2112.08673</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5058баллов, №980</br>
<b>Intelligent Bearing Fault <font color="#be00be">Diagnos</font>is Method Combining Mixed Input and\n  Hybrid CNN-MLP model</b></br>
Authors: , Sinitsin, V., Ibryaeva, O., Sakovskaya, V., Eremeeva, V.</br>
  Rolling bearings are one of the most widely used bearings in industrial machines. Deterioration in the condition of rolling bearings can result in the total failure of rotating machinery. AI-based methods are widely applied in the <font color="#be00be">diagnos</font>is of rolling bearings. Hybrid NN-based methods have been shown to achieve the best diagnosis results. Typically, raw data is generated from accelerometers mounted on the machine housing. However, the diagnostic utility of each signal is highly dependent on the location of the corresponding accelerometer. This paper proposes a novel hybrid CNN-MLP model-based diagnostic method which combines mixed input to perform rolling bearing diagnostics. The method successfully detects and localizes bearing defects using acceleration data from a shaft-mounted wireless acceleration sensor. The experimental results show that the hybrid model is superior to the CNN and MLP models operating separately, and can deliver a high detection accuracy of 99,6% for the bearing faults compared to 98% for CNN and 81% for MLP models. </br></br>

<a href='http://arxiv.org/pdf/2112.07624.pdf'>2112.07624</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.5081баллов, №981</br>
<b>Interaction-Aware Trajectory Prediction and Planning for Autonomous\n  Vehicles in Forced Merge Scenarios</b></br>
Authors: , Liu, Kaiwen, Li, Nan, Tseng, H. Eric, Kolmanovsky, Ilya, Girard, Anouck</br>
  Merging is, in general, a challenging task for both human drivers and autonomous vehicles, especially in dense traffic, because the merging vehicle typically needs to interact with other vehicles to identify or create a gap and safely merge into. In this paper, we consider the problem of autonomous vehicle control for forced merge scenarios. We propose a novel game-<font color="#be00be">theor</font>etic controller, called the Leader-Follower Game Controller (LFGC), in which the interactions between the autonomous ego vehicle and other vehicles with a priori uncertain driving intentions is modeled as a partially observable leader-follower game. The LFGC estimates the other vehicles\' intentions online based on observed trajectories, and then predicts their future trajectories and plans the ego vehicle\'s own trajectory using Model Predictive Control (MPC) to simultaneously achieve probabilistically guaranteed safety and merging objectives. To verify the performance of LFGC, we test it in simulations and with the NGSIM data, where the LFGC demonstrates a high success rate of 97.5% in merging. </br></br>

<a href='http://arxiv.org/pdf/2112.05745.pdf'>2112.05745</a> &nbsp&nbsp (cs:AI, cs:ML, cs:RO) &nbsp&nbsp -0.5096баллов, №982</br>
<b>A Simple and Efficient Sampling-based Algorithm for General Reachability\n  Analysis</b></br>
Authors: , Lew, Thomas, Janson, Lucas, Bonalli, Riccardo, Pavone, Marco</br>
  In this work, we analyze an efficient sampling-based algorithm for general-purpose reachability analysis, which remains a notoriously challenging problem with applications ranging from neural network verification to safety analysis of dynamical systems. By sampling inputs, evaluating their images in the true reachable set, and taking their $\\epsilon$-padded convex hull as a set estimator, this algorithm applies to general problem settings and is simple to implement. Our main contribution is the derivation of asymptotic and finite-sample accuracy guarantees using random set <font color="#be00be">theor</font>y. This analysis informs algorithmic design to obtain an $\\epsilon$-close reachable set approximation with high probability, provides insights into which reachability problems are most challenging, and motivates safety-critical applications of the technique. On a neural network verification task, we show that this approach is more accurate and significantly faster than prior work. Informed by our analysis, we also design a robust model predictive controller that we demonstrate in hardware experiments. </br></br>

<a href='http://arxiv.org/pdf/2112.06694.pdf'>2112.06694</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5096баллов, №983</br>
<b>Optimal Rate Adaption in <font color="#be00be">Federated</font> Learning with Compressed\n  Communications</b></br>
Authors: , Cui, Laizhong, Su, Xiaoxin, Zhou, Yipeng, Liu, Jiangchuan</br>
  <font color="#be00be">Federated</font> Learning (FL) incurs high communication overhead, which can be greatly alleviated by compression for model updates. Yet the tradeoff between compression and model accuracy in the networked environment remains unclear and, for simplicity, most implementations adopt a fixed compression rate only. In this paper, we for the first time systematically examine this tradeoff, identifying the influence of the compression error on the final model accuracy with respect to the learning rate. Specifically, we factor the compression error of each global iteration into the convergence rate analysis under both strongly convex and non-convex loss functions. We then present an adaptation framework to maximize the final model accuracy by strategically adjusting the compression rate in each iteration. We have discussed the key implementation issues of our framework in practical networks with representative compression algorithms. Experiments over the popular MNIST and CIFAR-10 datasets confirm that our solution effectively reduces network traffic yet maintains high model accuracy in FL. </br></br>

<a href='http://arxiv.org/pdf/2111.11297.pdf'>2111.11297</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5124баллов, №984</br>
<b>Teaching Humans When To Defer to a Classifier via Exemplars</b></br>
Authors: , Mozannar, Hussein, Satyanarayan, Arvind, Sontag, David</br>
  Expert decision makers are starting to rely on data-driven automated agents to assist them with various tasks. For this collaboration to perform properly, the human decision maker must have a mental model of when and when not to rely on the agent. In this work, we aim to ensure that human decision makers learn a valid mental model of the agent\'s strengths and weaknesses. To accomplish this goal, we propose an exemplar-based teaching strategy where humans solve the task with the help of the agent and try to formulate a set of guidelines of when and when not to defer. We present a novel parameterization of the human\'s mental model of the AI that applies a <font color="#be00be">nearest neighbo</font>r rule in local regions surrounding the teaching examples. Using this model, we derive a near-optimal strategy for selecting a representative teaching set. We validate the benefits of our teaching strategy on a multi-hop question answering task using crowd workers and find that when workers draw the right lessons from the teaching stage, their task performance improves, we furthermore validate our method on a set of synthetic experiments. </br></br>

<a href='http://arxiv.org/pdf/2112.07055.pdf'>2112.07055</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.5132баллов, №985</br>
<b>Language Models are not Models of Language</b></br>
Authors: , Veres, Csaba</br>
  Natural Language Processing (NLP) has become one of the leading application areas in the current Artificial Intelligence boom. Transfer learning has enabled large deep learning neural networks trained on the language modeling task to vastly improve performance in almost all language tasks. Interestingly, when the models are trained with data that includes software code, they demonstrate remarkable abilities in generating functioning computer code from natural language specifications. We argue that this creates a conundrum for claims that neural models provide an alternative <font color="#be00be">theor</font>y to generative phrase structure grammars in explaining how language works. Since the syntax of programming languages is determined by phrase structure grammars, successful neural models are apparently uninformative about the theoretical foundations of programming languages, and by extension, natural languages. We argue that the term language model is misleading because deep learning models are not theoretical models of language and propose the adoption of corpus model instead, which better reflects the genesis and contents of the model. </br></br>

<a href='http://arxiv.org/pdf/2112.06033.pdf'>2112.06033</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5169баллов, №986</br>
<b>Spatial Graph Convolutional Neural Network via Structured Subdomain\n  Adaptation and Domain Adversarial Learning for Bearing Fault <font color="#be00be">Diagnos</font>is</b></br>
Authors: , Ghorvei, Mohammadreza, Kavianpour, Mohammadreza, Beheshti, Mohammad TH, Ramezani, Amin</br>
  Unsupervised domain adaptation (UDA) has shown remarkable results in bearing fault <font color="#be00be">diagnos</font>is under changing working conditions in recent years. However, most UDA methods do not consider the geometric structure of the data. Furthermore, the global domain adaptation technique is commonly applied, which ignores the relation between subdomains. This paper addresses mentioned challenges by presenting the novel deep subdomain adaptation graph convolution neural network (DSAGCN), which has two key characteristics: First, graph convolution neural network (GCNN) is employed to model the structure of data. Second, adversarial domain adaptation and local maximum mean discrepancy (LMMD) methods are applied concurrently to align the subdomain\'s distribution and reduce structure discrepancy between relevant subdomains and global domains. CWRU and Paderborn bearing datasets are used to validate the DSAGCN method\'s efficiency and superiority between comparison models. The experimental results demonstrate the significance of aligning structured subdomains along with domain adaptation methods to obtain an accurate data-driven model in unsupervised fault diagnosis. </br></br>

<a href='http://arxiv.org/pdf/2112.05531.pdf'>2112.05531</a> &nbsp&nbsp (cs:NE) &nbsp&nbsp -0.5170баллов, №987</br>
<b>Global convergence of ResNets: From finite to infinite width using\n  linear parameterization</b></br>
Authors: , Barboni, Rapha&#xeb;l, Peyr&#xe9;, Gabriel, Vialard, Fran&#xe7;ois-Xavier</br>
  Overparametrization is a key factor in the absence of convexity to explain global convergence of gradient descent (GD) for neural networks. Beside the well studied lazy regime, infinite width (mean field) analysis has been developed for shallow networks, using on convex optimization technics. To bridge the gap between the lazy and mean field regimes, we study Residual Networks (ResNets) in which the residual block has linear parametrization while still being nonlinear. Such ResNets admit both infinite depth and width limits, encoding residual blocks in a Reproducing <font color="#be00be">Kernel</font> Hilbert Space (RKHS). In this limit, we prove a local Polyak-Lojasiewicz inequality. Thus, every critical point is a global minimizer and a local convergence result of GD holds, retrieving the lazy regime. In contrast with other mean-field studies, it applies to both parametric and non-parametric cases under an expressivity condition on the residuals. Our analysis leads to a practical and quantified recipe: starting from a universal RKHS, Random Fourier Features are applied to obtain a finite dimensional parameterization satisfying with high-probability our expressivity condition. </br></br>

<a href='http://arxiv.org/pdf/2112.05239.pdf'>2112.05239</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5175баллов, №988</br>
<b>On multivariate randomized classification trees: $l_0$-based sparsity,\n  VC~dimension and decomposition methods</b></br>
Authors: , Amaldi, Edoardo, Consolo, Antonio, Manno, Andrea</br>
  Decision trees are widely-used classification and <font color="#be00be">regression</font> models because of their <font color="#be00be">interpret</font>ability and good accuracy. Classical methods such as CART are based on greedy approaches but a growing attention has recently been devoted to optimal decision trees. We investigate the nonlinear continuous optimization formulation proposed in Blanquero et al. (EJOR, vol. 284, 2020; COR, vol. 132, 2021) for (sparse) optimal randomized classification trees. Sparsity is important not only for feature selection but also to improve interpretability. We first consider alternative methods to sparsify such trees based on concave approximations of the $l_{0}$ ``norm&quot;. Promising results are obtained on 24 datasets in comparison with $l_1$ and $l_{\\infty}$ regularizations. Then, we derive bounds on the VC dimension of multivariate randomized classification trees. Finally, since training is computationally challenging for large datasets, we propose a general decomposition scheme and an efficient version of it. Experiments on larger datasets show that the proposed decomposition method is able to significantly reduce the training times without compromising the accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.08918.pdf'>2112.08918</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.5211баллов, №989</br>
<b>Khmer Word Search: Challenges, Solutions, and Semantic-Aware Search</b></br>
Authors: , Buoy, Rina, Taing, Nguonly, Chenda, Sovisal</br>
  Search is one of the key functionalities in digital platforms and applications such as an electronic dictionary, a search engine, and an <font color="#be00be">e-commerce</font> platform. While the search function in some languages is trivial, Khmer word search is challenging given its complex writing system. Multiple orders of characters and different spelling realizations of words impose a constraint on Khmer word search functionality. Additionally, spelling mistakes are common since robust spellcheckers are not commonly available across the input device platforms. These challenges hinder the use of Khmer language in search-embedded applications. Moreover, due to the absence of WordNet-like lexical databases for Khmer language, it is impossible to establish semantic relation between words, enabling semantic search. In this paper, we propose a set of robust solutions to the above challenges associated with Khmer word search. The proposed solutions include character order normalization, grapheme and phoneme-based spellcheckers, and Khmer word semantic model. The semantic model is based on the word embedding model that is trained on a 30-million-word corpus and is used to capture the semantic similarities between words. </br></br>

<a href='http://arxiv.org/pdf/2112.05753.pdf'>2112.05753</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5228баллов, №990</br>
<b>Using Machine Learning to Predict Air Quality Index in New Delhi</b></br>
Authors: , Bhattacharya, Samayan, Shahnawaz, Sk</br>
  Air quality has a significant impact on human health. Degradation in air quality leads to a wide range of health issues, especially in children. The ability to predict air quality enables the government and other concerned organizations to take necessary steps to shield the most vulnerable, from being exposed to the air with hazardous quality. Traditional approaches to this task have very limited success because of a lack of access of such methods to sufficient longitudinal data. In this paper, we use a Support Vector <font color="#be00be">Regression</font> (SVR) model to forecast the levels of various pollutants and the air quality index, using archive pollution data made <font color="#00be00">publicly available</font> by Central Pollution Control Board and the US Embassy in New Delhi. Among the tested methods, a Radial Basis Function (RBF) <font color="#be00be">kernel</font> produced the best results with SVR. According to our experiments, using the whole range of available variables produced better results than using features selected by principal component analysis. The model predicts levels of various pollutants, like, sulfur dioxide, carbon monoxide, nitrogen dioxide, particulate matter 2.5, and ground-level ozone, as well as the Air Quality Index (AQI), at an accuracy of 93.4 percent. </br></br>

<a href='http://arxiv.org/pdf/2112.08845.pdf'>2112.08845</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5264баллов, №991</br>
<b>Multiple Instance Learning for <font color="#00be00">Brain</font> Tumor Detection from Magnetic\n  Resonance Spectroscopy Data</b></br>
Authors: , Lu, Diyuan, Kurz, Gerhard, Polomac, Nenad, Gacheva, Iskra, Hattingen, Elke, Triesch, Jochen</br>
  We apply deep learning (DL) on <font color="#be00be">Magnetic resonance</font> spectroscopy (MRS) data for the task of <font color="#00be00">brain</font> tumor detection. <font color="#640064">Medic</font>al applications often suffer from data scarcity and corruption by noise. Both of these problems are prominent in our data set. Furthermore, a varying number of spectra are available for the different <font color="#be00be">patient</font>s. We address these issues by considering the task as a multiple instance learning (MIL) problem. Specifically, we aggregate multiple spectra from the same patient into a &quot;bag&quot; for classification and apply data augmentation techniques. To achieve the permutation invariance during the process of bagging, we proposed two approaches: (1) to apply min-, max-, and average-pooling on the features of all samples in one bag and (2) to apply an attention mechanism. We tested these two approaches on multiple neural network architectures. We demonstrate that classification performance is significantly improved when training on multiple instances rather than single spectra. We propose a simple oversampling data augmentation method and show that it could further improve the performance. Finally, we demonstrate that our proposed model <font color="#00be00">outperform</font>s manual classification by neuroradiologists according to most performance metrics. </br></br>

<a href='http://arxiv.org/pdf/2112.05826.pdf'>2112.05826</a> &nbsp&nbsp (cs:CL, cs:AI, cs:ML) &nbsp&nbsp -0.5294баллов, №992</br>
<b>Sequence-level self-learning with multiple hypotheses</b></br>
Authors: , Kumatani, Kenichi, Dimitriadis, Dimitrios, Gaur, Yashesh, Gmyr, Robert, Eskimez, Sefik Emre, Li, Jinyu, Zeng, Michael</br>
  In this work, we develop new self-learning techniques with an attention-based sequence-to-sequence (seq2seq) model for automatic <font color="#be00be">speech recognition</font> (ASR). For untranscribed speech data, the hypothesis from an ASR system must be used as a label. However, the imperfect ASR result makes unsupervised learning difficult to consistently improve recognition performance especially in the case that multiple powerful teacher models are unavailable. In contrast to conventional unsupervised learning approaches, we adopt the \\emph{multi-task learning} (MTL) framework where the $n$-th best ASR hypothesis is used as the label of each task. The seq2seq network is updated through the MTL framework so as to find the common representation that can cover multiple hypotheses. By doing so, the effect of the \\emph{hard-decision} errors can be alleviated.   We first demonstrate the effectiveness of our self-learning methods through ASR experiments in an accent adaptation task between the US and British English speech. Our experiment results show that our method can reduce the WER on the British speech data from 14.55\\% to 10.36\\% compared to the baseline model trained with the US English data only. Moreover, we investigate the effect of our proposed methods in a <font color="#be00be">federated</font> learning scenario. </br></br>

<a href='http://arxiv.org/pdf/2112.08440.pdf'>2112.08440</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5321баллов, №993</br>
<b><font color="#be00be">Climate</font>-Invariant Machine Learning</b></br>
Authors: , Beucler, Tom, Pritchard, Michael, Yuval, Janni, Gupta, Ankitesh, Peng, Liran, Rasp, Stephan, Ahmed, Fiaz, O\'Gorman, Paul A., Neelin, J. David, Lutsko, Nicholas J., Gentine, Pierre</br>
  Data-driven algorithms, in particular neural networks, can emulate the effects of unresolved processes in coarse-resolution <font color="#be00be">climate</font> models when trained on high-resolution simulation data; however, they often make large generalization errors when evaluated in conditions they were not trained on. Here, we propose to physically rescale the inputs and outputs of machine learning algorithms to help them generalize to unseen climates. Applied to offline parameterizations of subgrid-scale thermodynamics in three distinct climate models, we show that rescaled or &quot;climate-invariant&quot; neural networks make accurate predictions in test climates that are 4K and 8K warmer than their training climates. Additionally, &quot;climate-invariant&quot; neural nets facilitate generalization between Aquaplanet and Earth-like simulations. Through visualization and attribution methods, we show that compared to standard machine learning models, &quot;climate-invariant&quot; algorithms learn more local and robust relations between storm-scale convection, radiation, and their synoptic thermodynamic environment. Overall, these results suggest that explicitly incorporating physical knowledge into data-driven models of Earth system processes can improve their consistency and ability to generalize across climate regimes. </br></br>

<a href='http://arxiv.org/pdf/2112.05644.pdf'>2112.05644</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.5352баллов, №994</br>
<b>Roominoes: Generating Novel 3D Floor Plans From Existing 3D Rooms</b></br>
Authors: , Wang, Kai, Xu, Xianghao, Lei, Leon, Ling, Selena, Lindsay, Natalie, Chang, Angel X., Savva, Manolis, Ritchie, Daniel</br>
  Realistic 3D indoor scene datasets have enabled significant recent progress in computer vision, scene understanding, autonomous navigation, and 3D reconstruction. But the scale, diversity, and customizability of existing datasets is limited, and it is time-consuming and expensive to scan and annotate more. Fortunately, combinatorics is on our side: there are enough individual rooms in existing 3D scene datasets, if there was but a way to recombine them into new layouts. In this paper, we propose the task of generating novel 3D floor plans from existing 3D rooms. We identify three sub-tasks of this problem: generation of 2D layout, <font color="#be00be">retrieval</font> of compatible 3D rooms, and deformation of 3D rooms to fit the layout. We then discuss different strategies for solving the problem, and design two representative pipelines: one uses available 2D floor plans to guide selection and deformation of 3D rooms; the other learns to retrieve a set of compatible 3D rooms and combine them into novel layouts. We design a set of metrics that evaluate the generated results with respect to each of the three subtasks and show that different methods trade off performance on these subtasks. Finally, we survey downstream tasks that benefit from generated 3D scenes and discuss strategies in selecting the methods most appropriate for the demands of these tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.06345.pdf'>2112.06345</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.5426баллов, №995</br>
<b>A Survey on Societal Event Forecasting with Deep Learning</b></br>
Authors: , Deng, Songgaojun, Ning, Yue</br>
  Population-level societal events, such as civil unrest and crime, often have a significant impact on our daily life. Forecasting such events is of great importance for decision-making and resource allocation. Event prediction has traditionally been challenging due to the lack of knowledge regarding the true causes and underlying mechanisms of event occurrence. In recent years, research on event forecasting has made significant progress due to two main reasons: (1) the development of machine learning and deep learning algorithms and (2) the accessibility of public data such as social media, news sources, blogs, <font color="#be00be">economic</font> indicators, and other meta-data sources. The explosive growth of data and the remarkable advancement in software/hardware technologies have led to applications of deep learning techniques in societal event studies. This paper is dedicated to providing a systematic and comprehensive overview of deep learning technologies for societal event predictions. We focus on two domains of societal events: \\textit{civil unrest} and \\textit{crime}. We first introduce how event forecasting problems are formulated as a machine learning prediction task. Then, we summarize data resources, traditional methods, and recent development of deep learning models for these problems. Finally, we discuss the challenges in societal event forecasting and put forward some promising directions for future research. </br></br>

<a href='http://arxiv.org/pdf/2112.06657.pdf'>2112.06657</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5447баллов, №996</br>
<b>You Can Wash Better: Daily Handwashing Assessment with Smartwatches</b></br>
Authors: , Wang, Fei, Wu, Xilei, Wang, Xin, Chi, Jianlei, Shi, Jingang, Huang, Dong</br>
  We propose UWash, an intelligent solution upon smartwatches, to assess handwashing for the purpose of raising users\' awareness and cultivating habits in high-quality handwashing. UWash can identify the onset/offset of handwashing, measure the duration of each gesture, and score each gesture as well as the entire procedure in accordance with the WHO guidelines. Technically, we address the task of handwashing assessment as the semantic <font color="#be00be">segmentation</font> problem in computer vision, and propose a <font color="#be00be">lightweight</font> UNet-like network, only 496KBits, to achieve it effectively. Experiments over 51 subjects show that UWash achieves the accuracy of 92.27\\% on sample-wise handwashing gesture recognition, $&lt;$0.5 \\textit{seconds} error in onset/offset detection, and $&lt;$5 out of 100 \\textit{points} error in scoring in the user-dependent setting, while remains promising in the cross-user evaluation and in the cross-user-cross-location evaluation. </br></br>

<a href='http://arxiv.org/pdf/2112.01039.pdf'>2112.01039</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.5497баллов, №997</br>
<b>How global observation works in <font color="#be00be">Federated</font> Learning: Integrating vertical\n  training into Horizontal Federated Learning</b></br>
Authors: , Wan, Shuo, Lu, Jiaxun, Fan, Pingyi, Shao, Yunfeng, Peng, Chenghui, Letaief, Khaled B.</br>
  <font color="#be00be">Federated</font> learning (FL) has recently emerged as a transformative paradigm that jointly train a model with distributed data sets in IoT while avoiding the need for central data collection. Due to the limited observation range, such data sets can only reflect local information, which limits the quality of trained models. In practice, the global information and local observations would require a joint consideration for learning to make a reasonable policy. However, in horizontal FL, the central agency only acts as a model aggregator without utilizing its global observation to further improve the model. This could significantly degrade the performance in some missions such as traffic flow prediction in network systems, where the global information may enhance the accuracy. Meanwhile, the global feature may not be directly transmitted to agents for data security. How to utilize the global observation residing in the central agency while protecting its safety thus rises up as an important problem in FL. In this paper, we develop a vertical-horizontal federated learning (VHFL) process, where the global feature is shared with the agents in a procedure similar to that of vertical FL without any extra communication rounds. By considering the delay and packet loss, we will analyze VHFL convergence and validate its performance by experiments. It is shown that the proposed VHFL could enhance the accuracy compared with horizontal FL while still protecting the security of global data. </br></br>

<a href='http://arxiv.org/pdf/2112.08538.pdf'>2112.08538</a> &nbsp&nbsp (cs:ML, cs:CV) &nbsp&nbsp -0.5509баллов, №998</br>
<b>Visualizing the Loss Landscape of Winning Lottery Tickets</b></br>
Authors: , Bain, Robert</br>
  The underlying loss landscapes of deep neural networks have a great impact on their training, but they have mainly been studied <font color="#be00be">theor</font>etically due to computational constraints. This work vastly reduces the time required to compute such loss landscapes, and uses them to study winning lottery tickets found via iterative magnitude pruning. We also share results that contradict previously claimed correlations between certain loss landscape projection methods and model trainability and generalization error. </br></br>

<a href='http://arxiv.org/pdf/2112.08736.pdf'>2112.08736</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.5520баллов, №999</br>
<b>Learning to Minimize Cost-to-Serve for Multi-Node Multi-Product Order\n  Fulfilment in Electronic Commerce</b></br>
Authors: , Pathakota, Pranavi, Zaid, Kunwar, Dhara, Anulekha, Meisheri, Hardik, Souza, Shaun D, Shah, Dheeraj, Khadilkar, Harshad</br>
  We describe a novel decision-making problem developed in response to the demands of retail electronic commerce (<font color="#be00be">e-commerce</font>). While working with logistics and retail industry business collaborators, we found that the cost of delivery of products from the most opportune node in the supply chain (a quantity called the cost-to-serve or CTS) is a key challenge. The large scale, high stochasticity, and large geographical spread of e-commerce supply chains make this setting ideal for a carefully designed data-driven decision-making algorithm. In this preliminary work, we focus on the specific subproblem of delivering multiple products in arbitrary quantities from any warehouse to multiple <font color="#be00be">customer</font>s in each time period. We compare the relative performance and computational efficiency of several baselines, including heuristics and mixed-integer linear programming. We show that a <font color="#00be00">reinforcement learning</font> based algorithm is <font color="#960096">competitive</font> with these policies, with the potential of efficient scale-up in the <font color="#009600">real world</font>. </br></br>

<a href='http://arxiv.org/pdf/2111.06908.pdf'>2111.06908</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.5615баллов, №1000</br>
<b>Explainable AI for Psychological Profiling from Digital Footprints: A\n  Case Study of Big Five Personality Predictions from Spending Data</b></br>
Authors: , Ramon, Yanou, Matz, Sandra C., Farrokhnia, R. A., Martens, David</br>
  Every step we take in the digital world leaves behind a record of our behavior; a digital footprint. Research has suggested that algorithms can translate these digital footprints into accurate estimates of psychological characteristics, including personality traits, mental health or intelligence. The mechanisms by which AI generates these insights, however, often remain opaque. In this paper, we show how Explainable AI (XAI) can help domain experts and data subjects validate, question, and improve models that classify psychological traits from digital footprints. We elaborate on two popular XAI methods (rule extraction and counterfactual explanations) in the context of Big Five personality predictions (traits and facets) from <font color="#be00be">financ</font>ial transactions data (N = 6,408). First, we demonstrate how global rule extraction sheds light on the spending patterns identified by the model as most predictive for personality, and discuss how these rules can be used to explain, validate, and improve the model. Second, we implement local rule extraction to show that individuals are assigned to personality classes because of their unique financial behavior, and that there exists a positive link between the model\'s prediction confidence and the number of features that contributed to the prediction. Our experiments highlight the importance of both global and local XAI methods. By better understanding how predictive models work in general as well as how they derive an outcome for a particular person, XAI promotes accountability in a world in which AI impacts the lives of billions of people around the world. </br></br>

<a href='http://arxiv.org/pdf/2112.07241.pdf'>2112.07241</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.5662баллов, №1001</br>
<b>Static-Dynamic Co-Teaching for Class-Incremental 3D <font color="#be00be">Object Detection</font></b></br>
Authors: , Zhao, Na, Lee, Gim Hee</br>
  Deep learning-based approaches have shown remarkable performance in the 3D <font color="#be00be">object detection</font> task. However, they suffer from a catastrophic performance drop on the originally trained classes when incrementally learning new classes without revisiting the old data. This &quot;catastrophic forgetting&quot; phenomenon impedes the deployment of 3D object detection approaches in <font color="#009600">real-world</font> scenarios, where continuous learning systems are needed. In this paper, we study the unexplored yet important class-incremental 3D object detection problem and present the first solution - SDCoT, a novel static-dynamic co-teaching method. Our SDCoT alleviates the catastrophic forgetting of old classes via a static teacher, which provides pseudo annotations for old classes in the new samples and regularizes the current model by extracting previous knowledge with a distillation loss. At the same time, SDCoT consistently learns the underlying knowledge from new data via a dynamic teacher. We conduct extensive experiments on two benchmark datasets and demonstrate the superior performance of our SDCoT over baseline approaches in several incremental learning scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.08268.pdf'>2112.08268</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.5704баллов, №1002</br>
<b>Prescriptive Machine Learning for Automated Decision Making: Challenges\n  and Opportunities</b></br>
Authors: , H&#xfc;llermeier, Eyke</br>
  Recent applications of machine learning (ML) reveal a noticeable shift from its use for predictive modeling in the sense of a data-driven construction of models mainly used for the purpose of prediction (of ground-truth facts) to its use for prescriptive modeling. What is meant by this is the task of learning a model that stipulates appropriate decisions about the right course of action in <font color="#009600">real-world</font> scenarios: Which <font color="#640064">medic</font>al therapy should be applied? Should this person be hired for the job? As argued in this article, prescriptive modeling comes with new technical conditions for learning and new demands regarding reliability, responsibility, and the ethics of decision making. Therefore, to support the data-driven design of decision-making agents that act in a rational but at the same time responsible manner, a rigorous methodological foundation of prescriptive ML is needed. The purpose of this short paper is to elaborate on specific characteristics of prescriptive ML and to highlight some key challenges it implies. Besides, drawing connections to other branches of contemporary AI research, the grounding of prescriptive ML in a (generalized) decision-<font color="#be00be">theor</font>etic framework is advocated. </br></br>

<a href='http://arxiv.org/pdf/2112.06735.pdf'>2112.06735</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5747баллов, №1003</br>
<b>Unsupervised machine learning approaches to the $q$-state Potts model</b></br>
Authors: , Tirelli, Andrea, Carvalho, Danyella O., Oliveira, Lucas A., Lima, J. P., Costa, Natanael C., Santos, Raimundo R. dos</br>
  In this paper with study phase transitions of the $q$-state Potts model, through a number of unsupervised machine learning techniques, namely Principal Component Analysis (PCA), $k$-means <font color="#be00be">clustering</font>, Uniform Manifold Approximation and Projection (UMAP), and Topological Data Analysis (TDA). Even though in all cases we are able to retrieve the correct critical temperatures $T_c(q)$, for $q = 3, 4$ and $5$, results show that non-linear methods as UMAP and TDA are less dependent on finite size effects, while still being able to distinguish between first and second order phase transitions. This study may be considered as a benchmark for the use of different unsupervised machine learning algorithms in the investigation of phase transitions. </br></br>

<a href='http://arxiv.org/pdf/2112.08136.pdf'>2112.08136</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.5756баллов, №1004</br>
<b>Characterizing the Program Expressive Power of Existential Rule\n  Languages</b></br>
Authors: , Zhang, Heng</br>
  Existential rule languages are a family of ontology languages that have been widely used in ontology-mediated query answering (OMQA). However, for most of them, the expressive power of representing domain knowledge for OMQA, known as the program expressive power, is not well-understood yet. In this paper, we establish a number of novel characterizations for the program expressive power of several important existential rule languages, including tuple-generating dependencies (TGDs), linear TGDs, as well as disjunctive TGDs. The characterizations employ natural model-<font color="#be00be">theor</font>etic properties, and automata-theoretic properties sometimes, which thus provide powerful tools for identifying the definability of domain knowledge for OMQA in these languages. </br></br>

<a href='http://arxiv.org/pdf/2112.05742.pdf'>2112.05742</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.5760баллов, №1005</br>
<b>A Puzzle-Based Dataset for Natural Language Inference</b></br>
Authors: , Szomiu, Roxana, Groza, Adrian</br>
  We provide here a dataset for tasks related to natural language understanding and natural language inference. The dataset contains logical puzzles in natural language from three domains: comparing puzzles, knighs and knaves, and zebra puzzles. Each puzzle is associated with the entire set of atomic questions that can be generated based on the relations and individuals occurring in the text. For each question we provide the correct answer: entailment, contradiction or ambiguity. The answer\'s correctness is verified against <font color="#be00be">theor</font>em provers. Good puzzles have two properties: (i) each piece of information is necessary and (ii) no unnecessary information is provided. These properties make puzzles interesting candidates for machine comprehension tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.08940.pdf'>2112.08940</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5765баллов, №1006</br>
<b>Challenges and Solutions to Build a Data Pipeline to Identify <font color="#be00be">Anomal</font>ies\n  in Enterprise System Performance</b></br>
Authors: , Huang, Xiaobo, Banerjee, Amitabha, Chen, Chien-Chia, Huang, Chengzhi, Chuang, Tzu Yi, Srivastava, Abhishek, Cheveresan, Razvan</br>
  We discuss how VMware is solving the following challenges to harness data to operate our ML-based <font color="#be00be">anomal</font>y detection system to detect performance issues in our Software Defined Data Center (SDDC) enterprise deployments: (i) label scarcity and label bias due to heavy dependency on unscalable human annotators, and (ii) data drifts due to ever-changing workload patterns, software stack and underlying hardware. Our anomaly detection system has been deployed in production for many years and has successfully detected numerous major performance issues. We demonstrate that by addressing these data challenges, we not only improve the accuracy of our performance anomaly detection model by 30%, but also ensure that the model performance to never degrade over time. </br></br>

<a href='http://arxiv.org/pdf/2112.07969.pdf'>2112.07969</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.5772баллов, №1007</br>
<b>Predicting Media Memorability: Comparing Visual, Textual and Auditory\n  Features</b></br>
Authors: , Sweeney, Lorin, Healy, Graham, Smeaton, Alan F.</br>
  This paper describes our approach to the Predicting Media Memorability task in MediaEval 2021, which aims to address the question of media memorability by setting the task of automatically predicting video memorability. This year we tackle the task from a comparative standpoint, looking to gain deeper insights into each of three explored modalities, and using our results from last year\'s submission (2020) as a point of reference. Our best performing short-term memorability model (0.132) tested on the TRECVid2019 dataset -- just like last year -- was a frame based CNN that was not trained on any TRECVid data, and our best short-term memorability model (0.524) tested on the Memento10k dataset, was a <font color="#be00be">Bayes</font>ian Ride Regressor fit with DenseNet121 visual features. </br></br>

<a href='http://arxiv.org/pdf/2112.07214.pdf'>2112.07214</a> &nbsp&nbsp (cs:SD, cs:CV) &nbsp&nbsp -0.5776баллов, №1008</br>
<b>Noise Reduction and Driving Event Extraction Method for Performance\n  Improvement on Driving Noise-based Surface <font color="#be00be">Anomal</font>y Detection</b></br>
Authors: , Park, YeongHyeon, Lee, JoonSung, Kim, Myung Jin, Park, Wonseok</br>
  Foreign substances on the road surface, such as rainwater or black ice, reduce the friction between the tire and the surface. The above situation will reduce the braking performance and make difficult to control the vehicle body posture. In that case, there is a possibility of property damage at least. In the worst case, personal damage will be occured. To avoid this problem, a road <font color="#be00be">anomal</font>y detection model is proposed based on vehicle driving noise. However, the prior proposal does not consider the extra noise, mixed with driving noise, and skipping calculations for moments without vehicle driving. In this paper, we propose a simple driving event extraction method and noise reduction method for improving computational efficiency and anomaly detection performance. </br></br>

<a href='http://arxiv.org/pdf/2112.07356.pdf'>2112.07356</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.5788баллов, №1009</br>
<b>Technical Language Supervision for Intelligent Fault <font color="#be00be">Diagnos</font>is in\n  Process Industry</b></br>
Authors: , L&#xf6;wenmark, Karl, Taal, Cees, Schnabel, Stephan, Liwicki, Marcus, Sandin, Fredrik</br>
  In the process industry, condition monitoring systems with automated fault <font color="#be00be">diagnos</font>is methods assisthuman experts and thereby improve maintenance efficiency, process sustainability, and workplace safety.Improving the automated fault diagnosis methods using data and machine learning-based models is a centralaspect of intelligent fault diagnosis (IFD). A major challenge in IFD is to develop realistic datasets withaccurate labels needed to train and validate models, and to transfer models trained with labeled lab datato heterogeneous process industry environments. However, fault descriptions and work-orders written bydomain experts are increasingly digitized in modern condition monitoring systems, for example in the contextof rotating equipment monitoring. Thus, domain-specific knowledge about fault characteristics and severitiesexists as technical language annotations in industrial datasets. Furthermore, recent advances in naturallanguage processing enable weakly supervised model optimization using natural language annotations, mostnotably in the form ofnatural language supervision(NLS). This creates a timely opportunity to developtechnical language supervision(TLS) solutions for IFD systems grounded in industrial data, for exampleas a complement to pre-training with lab data to address problems like overfitting and inaccurate out-of-sample generalisation. We surveyed the literature and identify a considerable improvement in the maturityof NLS over the last two years, facilitating applications beyond natural language; a rapid development ofweak supervision methods; and transfer learning as a current trend in IFD which can benefit from thesedevelopments. Finally, we describe a framework for integration of TLS in IFD which is inspired by recentNLS innovations. </br></br>

<a href='http://arxiv.org/pdf/2112.08928.pdf'>2112.08928</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.5793баллов, №1010</br>
<b>A Superconducting Nanowire-based Architecture for Neuromorphic Computing</b></br>
Authors: , Lombo, Andres E., Lares, Jesus E., Castellani, Matteo, Chou, Chi-Ning, Lynch, Nancy, Berggren, Karl K.</br>
  Neuromorphic computing is poised to further the success of software-based neural networks by utilizing improved customized hardware. However, the translation of neuromorphic algorithms to hardware specifications is a problem that has been seldom explored. Building superconducting neuromorphic systems requires extensive expertise in both superconducting physics and <font color="#be00be">theor</font>etical neuroscience. In this work, we aim to bridge this gap by presenting a tool and methodology to translate algorithmic parameters into circuit specifications. We first show the correspondence between theoretical neuroscience models and the dynamics of our circuit topologies. We then apply this tool to solve linear systems by implementing a spiking neural network with our superconducting nanowire-based hardware. </br></br>

<a href='http://arxiv.org/pdf/2112.08703.pdf'>2112.08703</a> &nbsp&nbsp (cs:ET) &nbsp&nbsp -0.5796баллов, №1011</br>
<b>ADEPT: Automatic Differentiable DEsign of Photonic Tensor Cores</b></br>
Authors: , Gu, Jiaqi, Zhu, Hanqing, Feng, Chenghao, Jiang, Zixuan, Liu, Mingjie, Zhang, Shuhan, Chen, Ray T., Pan, David Z.</br>
  Photonic tensor cores (PTCs) are essential building blocks for optical artificial intelligence (AI) accelerators based on programmable photonic integrated circuits. PTCs can achieve ultra-fast and efficient tensor operations for neural network (NN) acceleration. Current PTC designs are either manually constructed or based on matrix decomposition <font color="#be00be">theor</font>y, which lacks the adaptability to meet various hardware constraints and device specifications. To our best knowledge, automatic PTC design methodology is still unexplored. It will be promising to move beyond the manual design paradigm and &quot;nurture&quot; photonic neurocomputing with AI and design automation. Therefore, in this work, for the first time, we propose a fully differentiable framework, dubbed ADEPT, that can efficiently search PTC designs adaptive to various circuit footprint constraints and foundry PDKs. Extensive experiments show superior flexibility and effectiveness of the proposed ADEPT framework to explore a large PTC design space. On various NN models and benchmarks, our searched PTC topology <font color="#00be00">outperform</font>s prior manually-designed structures with <font color="#960096">competitive</font> matrix representability, 2x-30x higher footprint compactness, and better noise robustness, demonstrating a new paradigm in photonic neural chip design. </br></br>

<a href='http://arxiv.org/pdf/2112.06704.pdf'>2112.06704</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5801баллов, №1012</br>
<b>Land use identification through social network interaction</b></br>
Authors: , Pauca-Quispe, Diana C., Butron-Revilla, Cinthya, Suarez-Lopez, Ernesto, Aranibar-Tila, Karla, Aguilar-Ruiz, Jesus S.</br>
  The Internet generates large volumes of data at a high rate, in particular, posts on social networks. Although social network data has numerous semantic adulterations, and is not intended to be a source of geo-spatial information, in the text of posts we find pieces of important information about how people relate to their environment, which can be used to identify interesting aspects of how human beings interact with portions of land based on their activities. This research proposes a methodology for the identification of land uses using Natural Language Processing (NLP) from the contents of the popular social network Twitter. It will be approached by identifying keywords with linguistic patterns from the text, and the geographical coordinates associated with the publication. Context-specific innovations are introduced to deal with data across South America and, in particular, in the city of Arequipa, Peru. The objective is to identify the five main land uses: residential, commercial, institutional-governmental, industrial-offices and unbuilt land. Within the framework of urban planning and sustainable urban management, the methodology contributes to the optimization of the identification techniques applied for the updating of land use cadastres, since the results achieved an accuracy of about 90%, which motivates its application in the real context. In addition, it would allow the identification of land use categories at a more detailed level, in situations such as a complex/mixed distribution building based on the amount of data collected. Finally, the methodology makes land use information available in a more up-to-date fashion and, above all, avoids the high <font color="#be00be">economic</font> cost of the non-automatic production of land use maps for cities, mostly in developing countries. </br></br>

<a href='http://arxiv.org/pdf/2112.05261.pdf'>2112.05261</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5803баллов, №1013</br>
<b>Equivariant Quantum Graph Circuits</b></br>
Authors: , Mernyei, P&#xe9;ter, Meichanetzidis, Konstantinos, Ceylan, &#x130;smail &#x130;lkan</br>
  We investigate quantum circuits for graph representation learning, and propose equivariant quantum graph circuits (EQGCs), as a class of parameterized quantum circuits with strong relational inductive bias for learning over graph-structured data. Conceptually, EQGCs serve as a unifying framework for quantum graph representation learning, allowing us to define several interesting subclasses subsuming existing proposals. In terms of the representation power, we prove that the subclasses of interest are universal approximators for functions over the bounded graph domain, and provide experimental evidence. Our <font color="#be00be">theor</font>etical perspective on quantum graph machine learning methods opens many directions for further work, and could lead to models with capabilities beyond those of classical approaches. </br></br>

<a href='http://arxiv.org/pdf/2112.05321.pdf'>2112.05321</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5842баллов, №1014</br>
<b>PMFL: Partial Meta-<font color="#be00be">Federated</font> Learning for heterogeneous tasks and its\n  applications on <font color="#009600">real-world</font> <font color="#640064">medic</font>al records</b></br>
Authors: , Zhang, Tianyi, Zhang, Shirui, Chen, Ziwei, Liu, Dianbo</br>
  <font color="#be00be">Federated</font> machine learning is a versatile and flexible tool to utilize distributed data from different sources, especially when communication technology develops rapidly and an unprecedented amount of data could be collected on<font color="#960096"> mobile </font>devices nowadays. Federated learning method exploits not only the data but the computational power of all devices in the network to achieve more efficient model training. Nevertheless, while most traditional federated learning methods work well for homogeneous data and tasks, adapting the method to a different heterogeneous data and task distribution is challenging. This limitation has constrained the applications of federated learning in <font color="#009600">real-world</font> contexts, especially in healthcare settings. Inspired by the fundamental idea of meta-learning, in this study we propose a new algorithm, which is an integration of federated learning and meta-learning, to tackle this issue. In addition, owing to the advantage of transfer learning for model generalization, we further improve our algorithm by introducing partial parameter sharing. We name this method partial meta-federated learning (PMFL). Finally, we apply the algorithms to two <font color="#640064">medic</font>al datasets. We show that our algorithm could obtain the fastest training speed and achieve the best performance when dealing with heterogeneous medical datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.08770.pdf'>2112.08770</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.5851баллов, №1015</br>
<b>A Proposition-Level <font color="#be00be">Clustering</font> Approach for Multi-Document <font color="#be00be">Summarization</font></b></br>
Authors: , Ernst, Ori, Caciularu, Avi, Shapira, Ori, Pasunuru, Ramakanth, Bansal, Mohit, Goldberger, Jacob, Dagan, Ido</br>
  Text <font color="#be00be">clustering</font> methods were traditionally incorporated into multi-document <font color="#be00be">summarization</font> (MDS) as a means for coping with considerable information repetition. Clusters were leveraged to indicate information saliency and to avoid redundancy. These methods focused on clustering sentences, even though closely related sentences also usually contain non-aligning information. In this work, we revisit the clustering approach, grouping together propositions for more precise information alignment. Specifically, our method detects salient propositions, clusters them into paraphrastic clusters, and generates a representative sentence for each cluster by fusing its propositions. Our summarization method improves over the previous <font color="#00be00">state-of-the-art</font> MDS method in the DUC 2004 and TAC 2011 datasets, both in automatic ROUGE scores and human preference. </br></br>

<a href='http://arxiv.org/pdf/2112.08027.pdf'>2112.08027</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.5865баллов, №1016</br>
<b>Speech frame implementation for speech analysis and recognition</b></br>
Authors: , Konev, A. A., Khlebnikov, V. S., Yakimuk, A. Yu.</br>
  Distinctive features of the created speech frame are: the ability to take into account the <font color="#be00be">emotion</font>al state of the speaker, sup-port for working with <font color="#be00be">diseas</font>es of the speech-forming tract of speakers and the presence of manual <font color="#be00be">segmentation</font> of a num-ber of speech signals. In addition, the system is focused on <font color="#00be00">Russia</font>n-language speech material, unlike most analogs. </br></br>

<a href='http://arxiv.org/pdf/2112.05488.pdf'>2112.05488</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.5894баллов, №1017</br>
<b>DronePose: The identification, <font color="#be00be">segmentation</font>, and orientation detection\n  of drones via neural networks</b></br>
Authors: , Scholes, Stirling, Ruget, Alice, Mora-Martin, German, Zhu, Feng, Gyongy, Istvan, Leach, Jonathan</br>
  The growing ubiquity of drones has raised concerns over the ability of traditional air-space monitoring technologies to accurately characterise such vehicles. Here, we present a CNN using a decision tree and ensemble structure to fully characterise drones in flight. Our system determines the drone type, orientation (in terms of pitch, roll, and yaw), and performs <font color="#be00be">segmentation</font> to classify different body parts (engines, body, and camera). We also provide a computer model for the rapid generation of large quantities of accurately labelled photo-realistic training data and demonstrate that this data is of sufficient fidelity to allow the system to accurately characterise real drones in flight. Our network will provide a valuable tool in the image processing chain where it may build upon existing drone detection technologies to provide complete drone characterisation over wide areas. </br></br>

<a href='http://arxiv.org/pdf/2112.06986.pdf'>2112.06986</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5928баллов, №1018</br>
<b>On The Reliability Of Machine Learning Applications In Manufacturing\n  Environments</b></br>
Authors: , Jourdan, Nicolas, Sen, Sagar, Husom, Erik Johannes, Garcia-Ceja, Enrique, Biegel, Tobias, Metternich, Joachim</br>
  The increasing deployment of advanced digital technologies such as Internet of Things (IoT) devices and Cyber-Physical Systems (CPS) in industrial environments is enabling the productive use of machine learning (ML) algorithms in the manufacturing domain. As ML applications transcend from research to productive use in <font color="#009600">real-world</font> industrial environments, the question of reliability arises. Since the majority of ML models are trained and evaluated on static datasets, continuous online monitoring of their performance is required to build reliable systems. Furthermore, concept and sensor drift can lead to degrading accuracy of the algorithm over time, thus compromising safety, acceptance and <font color="#be00be">economic</font>s if undetected and not properly addressed. In this work, we exemplarily highlight the severity of the issue on a <font color="#00be00">publicly available</font> industrial dataset which was recorded over the course of 36 months and explain possible sources of drift. We assess the robustness of ML algorithms commonly used in manufacturing and show, that the accuracy strongly declines with increasing drift for all tested algorithms. We further investigate how uncertainty estimation may be leveraged for online performance estimation as well as drift detection as a first step towards continually learning applications. The results indicate, that ensemble algorithms like <font color="#be00be">random forest</font>s show the least decay of confidence calibration under drift. </br></br>

<a href='http://arxiv.org/pdf/2112.07589.pdf'>2112.07589</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.5935баллов, №1019</br>
<b>Mitigating Channel-wise Noise for Single Image Super Resolution</b></br>
Authors: , Mandal, Srimanta, Purohit, Kuldeep, Rajagopalan, A. N.</br>
  In practice, images can contain different amounts of noise for different color channels, which is not acknowledged by existing <font color="#be00be">super-resolution</font> approaches. In this paper, we propose to super-resolve noisy color images by considering the color channels jointly. Noise statistics are blindly estimated from the input low-resolution image and are used to assign different weights to different color channels in the data cost. Implicit low-rank structure of visual data is enforced via nuclear norm minimization in association with adaptive weights, which is added as a regularization term to the cost. Additionally, multi-scale details of the image are added to the model through another regularization term that involves projection onto PCA basis, which is constructed using similar patches extracted across different scales of the input image. The results demonstrate the super-resolving capability of the approach in real scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.06868.pdf'>2112.06868</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.5938баллов, №1020</br>
<b>Variational autoencoders in the presence of low-dimensional data:\n  landscape and implicit bias</b></br>
Authors: , Koehler, Frederic, Mehta, Viraj, Risteski, Andrej, Zhou, Chenghui</br>
  Variational Autoencoders (VAEs) are one of the most commonly used generative models, particularly for image data. A prominent difficulty in training VAEs is data that is supported on a lower dimensional manifold. Recent work by Dai and Wipf (2019) suggests that on low-dimensional data, the generator will converge to a solution with 0 variance which is correctly supported on the ground truth manifold.   In this paper, via a combination of <font color="#be00be">theor</font>etical and empirical results, we show that the story is more subtle. Precisely, we show that for linear encoders/decoders, the story is mostly true and VAE training does recover a generator with support equal to the ground truth manifold, but this is due to the implicit bias of gradient descent rather than merely the VAE loss itself.   In the nonlinear case, we show that the VAE training frequently learns a higher-dimensional manifold which is a superset of the ground truth manifold. </br></br>

<a href='http://arxiv.org/pdf/2112.08676.pdf'>2112.08676</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5942баллов, №1021</br>
<b>Machine Learning-Accelerated Computational Solid Mechanics: Application\n  to Linear Elasticity</b></br>
Authors: , Arora, Rajat</br>
  This work presents a novel physics-informed deep learning based <font color="#be00be">super-resolution</font> framework to reconstruct high-resolution deformation fields from low-resolution counterparts, obtained from coarse mesh simulations or experiments. We leverage the governing equations and boundary conditions of the physical system to train the model without using any high-resolution labeled data. The proposed approach is applied to obtain the super-resolved deformation fields from the low-resolution stress and displacement fields obtained by running simulations on a coarse mesh for a body undergoing linear elastic deformation. We demonstrate that the super-resolved fields match the accuracy of an advanced numerical solver running at 400 times the coarse mesh resolution, while simultaneously satisfying the governing laws. A brief evaluation study comparing the performance of two deep learning based super-resolution architectures is also presented. </br></br>

<a href='http://arxiv.org/pdf/2112.07897.pdf'>2112.07897</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.5951баллов, №1022</br>
<b>Learning Graph Partitions</b></br>
Authors: , Mukherjee, Sayan</br>
  Given a partition of a graph into connected components, the membership oracle asserts whether any two vertices of the graph lie in the same component or not. We prove that for $n\\ge k\\ge 2$, learning the components of an $n$-vertex hidden graph with $k$ components requires at least $\\frac{1}{2}(n-k)(k-1)$ membership queries. This proves the optimality of the $O(nk)$ algorithm proposed by Reyzin and Srivastava (2007) for this problem, improving on the best known information-<font color="#be00be">theor</font>etic bound of $\\Omega(n\\log k)$ queries. Further, we construct an oracle that can learn the number of components of $G$ in asymptotically fewer queries than learning the full partition, thus answering another question posed by the same authors. Lastly, we introduce a more applicable version of this oracle, and prove asymptotically tight bounds of $\\widetilde\\Theta(m)$ queries for both learning and verifying an $m$-edge hidden graph $G$ using this oracle. </br></br>

<a href='http://arxiv.org/pdf/2111.11397.pdf'>2111.11397</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.5977баллов, №1023</br>
<b>Solar Potential Assessment using Multi-Class Buildings <font color="#be00be">Segmentation</font> from\n  Aerial Images</b></br>
Authors: , Nasrallah, Hasan, Samhat, Abed Ellatif, Faour, Ghaleb, Shi, Yilei, Ghandour, Ali J.</br>
  Semantic <font color="#be00be">Segmentation</font> of buildings present in satellite images using encoder-decoder like convolutional neural networks is being achieved with relatively high pixel-wise metric scores. In this paper, we aim to exploit the power of fully convolutional neural networks for an instance segmentation task using extra added classes to the output along with the watershed processing technique to leverage better object-wise metric results. We also show that CutMix mixed data augmentations and the One-Cycle learning rate policy are greater regularization methods to achieve a better fit on the training data and increase performance. Furthermore, Mixed Precision Training provided more flexibility to experiment with bigger networks and batches while maintaining stability and convergence during training. We compare and show the effect of these additional changes throughout our whole pipeline to finally provide a set a tuned hyper-parameters that are proven to perform better. </br></br>

<a href='http://arxiv.org/pdf/2112.06120.pdf'>2112.06120</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.5990баллов, №1024</br>
<b>Sidewalk Measurements from Satellite Images: Preliminary Findings</b></br>
Authors: , Hosseini, Maryam, Araujo, Iago B., Yazdanpanah, Hamed, Tokuda, Eric K., Miranda, Fabio, Silva, Claudio T., Cesar Jr, Roberto M.</br>
  Large-scale analysis of <font color="#be00be">pedestrian</font> infrastructures, particularly sidewalks, is critical to human-centric urban planning and design. Benefiting from the rich data set of planimetric features and high-resolution orthoimages provided through the New York City Open Data portal, we train a computer vision model to detect sidewalks, roads, and buildings from remote-sensing imagery and achieve 83% mIoU over held-out test set. We apply shape analysis techniques to study different attributes of the extracted sidewalks. More specifically, we do a tile-wise analysis of the width, angle, and curvature of sidewalks, which aside from their general impacts on walkability and accessibility of urban areas, are known to have significant roles in the mobility of wheelchair users. The preliminary results are promising, glimpsing the potential of the proposed approach to be adopted in different cities, enabling researchers and practitioners to have a more vivid picture of the pedestrian realm. </br></br>

<a href='http://arxiv.org/pdf/2111.14733.pdf'>2111.14733</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.5992баллов, №1025</br>
<b>Crime Prediction with Graph Neural Networks and Multivariate Normal\n  Distributions</b></br>
Authors: , Tekin, Selim Furkan, Kozat, Suleyman Serdar</br>
  Existing approaches to the crime prediction problem are unsuccessful in expressing the details since they assign the probability values to large regions. This paper introduces a new architecture with the graph convolutional networks (GCN) and multivariate <font color="#be00be">Gaussi</font>an distributions to perform high-resolution forecasting that applies to any spatiotemporal data. We tackle the sparsity problem in high resolution by leveraging the flexible structure of GCNs and providing a subdivision algorithm. We build our model with Graph Convolutional Gated Recurrent Units (Graph-ConvGRU) to learn spatial, temporal, and categorical relations. In each node of the graph, we learn a multivariate probability distribution from the extracted features of GCNs. We perform experiments on real-life and synthetic datasets, and our model obtains the best validation and the best test score among the baseline models with significant improvements. We show that our model is not only generative but also precise. </br></br>

<a href='http://arxiv.org/pdf/2112.01589.pdf'>2112.01589</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.5992баллов, №1026</br>
<b>InfoLM: A New Metric to Evaluate <font color="#be00be">Summarization</font> &amp; Data2Text Generation</b></br>
Authors: , Colombo, Pierre, Clavel, Chloe, Piantanida, Pablo</br>
  Assessing the quality of natural language generation systems through human annotation is very expensive. Additionally, human annotation campaigns are time-consuming and include non-reusable human labour. In practice, researchers rely on automatic metrics as a proxy of quality. In the last decade, many string-based metrics (e.g., BLEU) have been introduced. However, such metrics usually rely on exact matches and thus, do not robustly handle synonyms. In this paper, we introduce InfoLM a family of untrained metrics that can be viewed as a string-based metric that addresses the aforementioned flaws thanks to a pre-trained masked language model. This family of metrics also makes use of information measures allowing the adaptation of InfoLM to various evaluation criteria. Using direct assessment, we demonstrate that InfoLM achieves statistically significant improvement and over $10$ points of correlation gains in many configurations on both <font color="#be00be">summarization</font> and data2text generation. </br></br>

<a href='http://arxiv.org/pdf/2112.05416.pdf'>2112.05416</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.5993баллов, №1027</br>
<b>Optimizing Edge Detection for Image <font color="#be00be">Segmentation</font> with Multicut Penalties</b></br>
Authors: , Jung, Steffen, Ziegler, Sebastian, Kardoost, Amirhossein, Keuper, Margret</br>
  The Minimum Cost Multicut Problem (MP) is a popular way for obtaining a graph decomposition by optimizing binary edge labels over edge costs. While the formulation of a MP from independently estimated costs per edge is highly flexible and intuitive, solving the MP is NP-hard and time-expensive. As a remedy, recent work proposed to predict edge probabilities with awareness to potential conflicts by incorporating cycle constraints in the prediction process. We argue that such formulation, while providing a first step towards end-to-end learnable edge weights, is suboptimal, since it is built upon a loose relaxation of the MP. We therefore propose an adaptive CRF that allows to progressively consider more violated constraints and, in consequence, to issue solutions with higher validity. Experiments on the BSDS500 benchmark for natural image <font color="#be00be">segmentation</font> as well as on electron microscopic recordings show that our approach yields more precise edge detection and image segmentation. </br></br>

<a href='http://arxiv.org/pdf/2112.08609.pdf'>2112.08609</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.6001баллов, №1028</br>
<b>DuQM: A <font color="#be00be">Chinese</font> Dataset of Linguistically Perturbed Natural Questions\n  for Evaluating the Robustness of Question Matching Models</b></br>
Authors: , Zhu, Hongyu, Chen, Yan, Yan, Jing, Liu, Jing, Hong, Yu, Chen, Ying, Wu, Hua, Wang, Haifeng</br>
  In this paper, we focus on studying robustness evaluation of <font color="#be00be">Chinese</font> question matching. Most of the previous work on analyzing robustness issue focus on just one or a few types of artificial adversarial examples. Instead, we argue that it is necessary to formulate a comprehensive evaluation about the linguistic capabilities of models on natural texts. For this purpose, we create a Chinese dataset namely DuQM which contains natural questions with linguistic perturbations to evaluate the robustness of question matching models. DuQM contains 3 categories and 13 subcategories with 32 linguistic perturbations. The extensive experiments demonstrate that DuQM has a better ability to distinguish different models. Importantly, the detailed breakdown of evaluation by linguistic phenomenon in DuQM helps us easily <font color="#be00be">diagnos</font>e the strength and weakness of different models. Additionally, our experiment results show that the effect of artificial adversarial examples does not work on the natural texts. </br></br>

<a href='http://arxiv.org/pdf/2112.06761.pdf'>2112.06761</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.6013баллов, №1029</br>
<b>RSV: Robotic Sonography for Thyroid Volumetry</b></br>
Authors: , Zielke, John, Eilers, Christine, Busam, Benjamin, Weber, Wolfgang, Navab, Nassir, Wendler, Thomas</br>
  In nuclear <font color="#640064">medic</font>ine, radioiodine therapy is prescribed to treat <font color="#be00be">diseas</font>es like hyperthyroidism. The calculation of the prescribed dose depends, amongst other factors, on the thyroid volume. This is currently estimated using conventional 2D ultrasound imaging. However, this modality is inherently user-dependant, resulting in high variability in volume estimations. To increase reproducibility and consistency, we uniquely combine a neural network-based <font color="#be00be">segmentation</font> with an automatic robotic ultrasound scanning for thyroid volumetry. The robotic acquisition is achieved by using a 6 DOF robotic arm with an attached ultrasound probe. Its movement is based on an online segmentation of each thyroid lobe and the appearance of the US image. During post-processing, the US images are segmented to obtain a volume estimation. In an ablation study, we demonstrated the superiority of the motion guidance algorithms for the robot arm movement compared to a naive linear motion, executed by the robot in terms of volumetric accuracy. In a user study on a phantom, we compared conventional 2D ultrasound measurements with our robotic system. The mean volume measurement error of ultrasound expert users could be significantly decreased from 20.85+/-16.10% to only 8.23+/-3.10% compared to the ground truth. This tendency was observed even more in non-expert users where the mean error improvement with the robotic system was measured to be as high as $85\\%$ which clearly shows the advantages of the robotic support. </br></br>

<a href='http://arxiv.org/pdf/2112.05235.pdf'>2112.05235</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.6025баллов, №1030</br>
<b>The Fundamental Limits of Interval Arithmetic for Neural Networks</b></br>
Authors: , Mirman, Matthew, Baader, Maximilian, Vechev, Martin</br>
  Interval analysis (or interval bound propagation, IBP) is a popular technique for verifying and training provably robust deep neural networks, a fundamental challenge in the area of reliable machine learning. However, despite substantial efforts, progress on addressing this key challenge has stagnated, calling into question whether interval arithmetic is a viable path forward.   In this paper we present two fundamental results on the limitations of interval arithmetic for analyzing neural networks. Our main impossibility <font color="#be00be">theor</font>em states that for any neural network classifying just three points, there is a valid specification over these points that interval analysis can not prove. Further, in the restricted case of one-hidden-layer neural networks we show a stronger impossibility result: given any radius $\\alpha &lt; 1$, there is a set of $O(\\alpha^{-1})$ points with robust radius $\\alpha$, separated by distance $2$, that no one-hidden-layer network can be proven to classify robustly via interval analysis. </br></br>

<a href='http://arxiv.org/pdf/2112.08539.pdf'>2112.08539</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.6028баллов, №1031</br>
<b>Implicit Neural Representations for Deconvolving SAS Images</b></br>
Authors: , Reed, Albert, Blanford, Thomas, Brown, Daniel C., Jayasuriya, Suren</br>
  Synthetic aperture sonar (SAS) image resolution is constrained by waveform bandwidth and array geometry. Specifically, the waveform bandwidth determines a point spread function (PSF) that blurs the locations of point scatterers in the scene. In <font color="#be00be">theor</font>y, deconvolving the reconstructed SAS image with the scene PSF restores the original distribution of scatterers and yields sharper reconstructions. However, deconvolution is an ill-posed operation that is highly sensitive to noise. In this work, we leverage implicit neural representations (INRs), shown to be strong priors for the natural image space, to deconvolve SAS images. Importantly, our method does not require training data, as we perform our deconvolution through an analysis-bysynthesis optimization in a self-supervised fashion. We validate our method on simulated SAS data created with a point scattering model and real data captured with an in-air circular SAS. This work is an important first step towards applying neural networks for SAS image deconvolution. </br></br>

<a href='http://arxiv.org/pdf/2112.08572.pdf'>2112.08572</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6029баллов, №1032</br>
<b>Predictive Price-Performance Optimization for Serverless Query\n  Processing</b></br>
Authors: , Sen, Rathijit, Roy, Abhishek, Jindal, Alekh</br>
  We present an efficient, parametric modeling framework for predictive resource allocations, focusing on the amount of computational resources, that can optimize for a range of price-performance objectives for data analytics in serverless query processing settings. We discuss and evaluate in depth how our system, AutoExecutor, can use this framework to automatically select near-optimal executor and core counts for Spark <font color="#be00be">SQL</font> queries running on Azure Synapse. Our techniques improve upon Spark\'s in-built, reactive, dynamic executor allocation capabilities by substantially reducing the total executors allocated and executor occupancy while running queries, thereby freeing up executors that can potentially be used by other concurrent queries or in reducing the overall cluster provisioning needs. In contrast with post-execution analysis tools such as Sparklens, we predict resource allocations for queries before executing them and can also account for changes in input data sizes for predicting the desired allocations. </br></br>

<a href='http://arxiv.org/pdf/2112.06431.pdf'>2112.06431</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp -0.6030баллов, №1033</br>
<b>GM Score: Incorporating inter-class and intra-class generator diversity,\n  discriminability of disentangled representation, and sample fidelity for\n  evaluating GANs</b></br>
Authors: , GM, Harshvardhan, Sahu, Aanchal, Gourisaria, Mahendra Kumar</br>
  While generative adversarial networks (GAN) are popular for their higher sample quality as opposed to other generative models like the variational autoencoders (VAE) and <font color="#be00be">Boltzmann</font> machines, they suffer from the same difficulty of the evaluation of generated samples. Various aspects must be kept in mind, such as the quality of generated samples, the diversity of classes (within a class and among classes), the use of disentangled latent spaces, agreement of said evaluation metric with human perception, etc. In this paper, we propose a new score, namely, GM Score, which takes into various factors such as sample quality, disentangled representation, intra-class and inter-class diversity, and other metrics such as precision, recall, and F1 score are employed for discriminability of latent space of deep belief network (DBN) and restricted Boltzmann machine (RBM). The evaluation is done for different GANs (GAN, DCGAN, BiGAN, CGAN, CoupledGAN, LSGAN, SGAN, WGAN, and WGAN Improved) trained on the benchmark MNIST dataset. </br></br>

<a href='http://arxiv.org/pdf/2112.06532.pdf'>2112.06532</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6055баллов, №1034</br>
<b>A Complete Characterisation of ReLU-Invariant Distributions</b></br>
Authors: , Macdonald, Jan, W&#xe4;ldchen, Stephan</br>
  We give a complete characterisation of families of probability distributions that are invariant under the action of ReLU neural network layers. The need for such families arises during the training of <font color="#be00be">Bayes</font>ian networks or the analysis of trained neural networks, e.g., in the context of uncertainty quantification (UQ) or explainable artificial intelligence (XAI). We prove that no invariant parametrised family of distributions can exist unless at least one of the following three restrictions holds: First, the network layers have a width of one, which is unreasonable for practical neural networks. Second, the probability measures in the family have finite support, which basically amounts to sampling distributions. Third, the parametrisation of the family is not locally Lipschitz continuous, which excludes all computationally feasible families. Finally, we show that these restrictions are individually necessary. For each of the three cases we can construct an invariant family exploiting exactly one of the restrictions but not the other two. </br></br>

<a href='http://arxiv.org/pdf/2112.08906.pdf'>2112.08906</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.6056баллов, №1035</br>
<b>On the Uncertain Single-View Depths in Endoscopies</b></br>
Authors: , Rodr&#xed;guez-Puigvert, Javier, Recasens, David, Civera, Javier, Mart&#xed;nez-Cant&#xed;n, Rub&#xe9;n</br>
  Estimating depth from endoscopic images is a pre-requisite for a wide set of AI-assisted technologies, namely accurate localization, measurement of tumors, or identification of non-inspected areas. As the domain specificity of colonoscopies -- a deformable low-texture environment with fluids, poor lighting conditions and abrupt sensor motions -- pose challenges to multi-view approaches, single-view depth learning stands out as a promising line of research. In this paper, we explore for the first time <font color="#be00be">Bayes</font>ian deep networks for single-view depth estimation in colonoscopies. Their uncertainty quantification offers great potential for such a critical application area. Our specific contribution is two-fold: 1) an exhaustive analysis of Bayesian deep networks for depth estimation in three different datasets, highlighting challenges and conclusions regarding synthetic-to-real domain changes and supervised vs. self-supervised methods; and 2) a novel teacher-student approach to deep depth learning that takes into account the teacher uncertainty. </br></br>

<a href='http://arxiv.org/pdf/2112.08836.pdf'>2112.08836</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6062баллов, №1036</br>
<b>Imbalanced Sample Generation and Evaluation for Power System Transient\n  Stability Using CTGAN</b></br>
Authors: , Han, Gengshi, Liu, Shunyu, Chen, Kaixuan, Yu, Na, Feng, Zunlei, Song, Mingli</br>
  Although deep learning has achieved impressive advances in transient stability assessment of power systems, the insufficient and imbalanced samples still trap the training effect of the data-driven methods. This paper proposes a controllable sample generation framework based on Conditional Tabular Generative Adversarial Network (CTGAN) to generate specified transient stability samples. To fit the complex feature distribution of the transient stability samples, the proposed framework firstly models the samples as tabular data and uses <font color="#be00be">Gaussi</font>an mixture models to normalize the tabular data. Then we transform multiple conditions into a single conditional vector to enable multi-conditional generation. Furthermore, this paper introduces three evaluation metrics to verify the quality of generated samples based on the proposed framework. Experimental results on the IEEE 39-bus system show that the proposed framework effectively balances the transient stability samples and significantly improves the performance of transient stability assessment models. </br></br>

<a href='http://arxiv.org/pdf/2112.07163.pdf'>2112.07163</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6067баллов, №1037</br>
<b>Minimization of Stochastic First-order Oracle Complexity of Adaptive\n  Methods for Nonconvex Optimization</b></br>
Authors: , Iiduka, Hideaki</br>
  Numerical evaluations have definitively shown that, for deep learning optimizers such as stochastic gradient descent, momentum, and adaptive methods, the number of steps needed to train a deep neural network halves for each doubling of the batch size and that there is a region of diminishing returns beyond the critical batch size. In this paper, we determine the actual critical batch size by using the global minimizer of the stochastic first-order oracle (SFO) complexity of the optimizer. To prove the existence of the actual critical batch size, we set the lower and upper bounds of the SFO complexity and prove that there exist critical batch sizes in the sense of minimizing the lower and upper bounds. This proof implies that, if the SFO complexity fits the lower and upper bounds, then the existence of these critical batch sizes demonstrates the existence of the actual critical batch size. We also discuss the conditions needed for the SFO complexity to fit the lower and upper bounds and provide numerical results that support our <font color="#be00be">theor</font>etical results. </br></br>

<a href='http://arxiv.org/pdf/2112.07353.pdf'>2112.07353</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6142баллов, №1038</br>
<b>Machine Learning-based Prediction of Porosity for Concrete Containing\n  Supplementary Cementitious Materials</b></br>
Authors: , Cao, Chong</br>
  Porosity has been identified as the key indicator of the durability properties of concrete exposed to aggressive environments. This paper applies ensemble learning to predict porosity of high-performance concrete containing supplementary cementitious materials. The concrete samples utilized in this study are characterized by eight composition features including w/b ratio, binder content, fly ash, GGBS, superplasticizer, coarse/fine aggregate ratio, curing condition and curing days. The assembled database consists of 240 data records, featuring 74 unique concrete mixture designs. The proposed machine learning algorithms are trained on 180 observations (75%) chosen randomly from the data set and then tested on the remaining 60 observations (25%). The numerical experiments suggest that the <font color="#be00be">regression</font> tree ensembles can accurately predict the porosity of concrete from its mixture compositions. Gradient boosting trees generally <font color="#00be00">outperform</font>s <font color="#be00be">random forest</font>s in terms of prediction accuracy. For random forests, the out-of-bag error based hyperparameter tuning strategy is found to be much more efficient than k-Fold Cross-Validation. </br></br>

<a href='http://arxiv.org/pdf/2112.07467.pdf'>2112.07467</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.6160баллов, №1039</br>
<b>AI Ethics Principles in Practice: Perspectives of Designers and\n  Developers</b></br>
Authors: , Sanderson, Conrad, Douglas, David, Lu, Qinghua, Schleiger, Emma, Whittle, Jon, Lacey, Justine, Newnham, Glenn, Hajkowicz, Stefan, Robinson, Cathy, Hansen, David</br>
  As consensus across the various published AI ethics principles is approached, a gap remains between high-level principles and practical techniques that can be readily adopted to design and develop responsible AI systems. We examine the practices and experiences of researchers and engineers from Australia\'s national scientific research agency (CSIRO), who are involved in designing and developing AI systems for a range of purposes. Semi-structured interviews were used to examine how the practices of the participants relate to and align with a set of high-level AI ethics principles that are proposed by the Australian Government. The principles comprise: <font color="#be00be">Privacy</font> Protection &amp; Security, Reliability &amp; Safety, Transparency &amp; Explainability, Fairness, Contestability, Accountability, Human-centred Values, and Human, Social &amp; Environmental Wellbeing. The insights of the researchers and engineers as well as the challenges that arose for them in the practical application of the principles are examined. Finally, a set of organisational responses are provided to support the implementation of high-level AI ethics principles into practice. </br></br>

<a href='http://arxiv.org/pdf/2112.05929.pdf'>2112.05929</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.6187баллов, №1040</br>
<b>Server-Side Local Gradient Averaging and Learning Rate Acceleration for\n  Scalable Split Learning</b></br>
Authors: , Pal, Shraman, Uniyal, Mansi, Park, Jihong, Vepakomma, Praneeth, Raskar, Ramesh, Bennis, Mehdi, Jeon, Moongu, Choi, Jinho</br>
  In recent years, there have been great advances in the field of decentralized learning with <font color="#be00be">private</font> data. <font color="#be00be">Federated</font> learning (FL) and split learning (SL) are two spearheads possessing their pros and cons, and are suited for many user clients and large models, respectively. To enjoy both benefits, hybrid approaches such as SplitFed have emerged of late, yet their fundamentals have still been illusive. In this work, we first identify the fundamental bottlenecks of SL, and thereby propose a scalable SL framework, coined SGLR. The server under SGLR broadcasts a common gradient averaged at the split-layer, emulating FL without any additional communication across clients as opposed to SplitFed. Meanwhile, SGLR splits the learning rate into its server-side and client-side rates, and separately adjusts them to support many clients in parallel. Simulation results corroborate that SGLR achieves higher accuracy than other baseline SL methods including SplitFed, which is even on par with FL consuming higher energy and communication costs. As a secondary result, we observe greater reduction in leakage of sensitive information via mutual information using SLGR over the baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.06511.pdf'>2112.06511</a> &nbsp&nbsp (cs:ML, cs:AI, cs:CV) &nbsp&nbsp -0.6208баллов, №1041</br>
<b>Ex-Model: Continual Learning from a Stream of Trained Models</b></br>
Authors: , Carta, Antonio, Cossu, Andrea, Lomonaco, Vincenzo, Bacciu, Davide</br>
  Learning continually from non-stationary data streams is a challenging research topic of growing popularity in the last few years. Being able to learn, adapt, and generalize continually in an efficient, effective, and scalable way is fundamental for a sustainable development of Artificial Intelligent systems. However, an agent-centric view of continual learning requires learning directly from raw data, which limits the interaction between independent agents, the efficiency, and the <font color="#be00be">privacy</font> of current approaches. Instead, we argue that continual learning systems should exploit the availability of compressed information in the form of trained models. In this paper, we introduce and formalize a new paradigm named &quot;Ex-Model Continual Learning&quot; (ExML), where an agent learns from a sequence of previously trained models instead of raw data. We further contribute with three ex-model continual learning algorithms and an empirical setting comprising three datasets (MNIST, CIFAR-10 and CORe50), and eight scenarios, where the proposed algorithms are extensively tested. Finally, we highlight the peculiarities of the ex-model paradigm and we point out interesting future research directions. </br></br>

<a href='http://arxiv.org/pdf/2112.08391.pdf'>2112.08391</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6210баллов, №1042</br>
<b>Breeding realistic D-brane models</b></br>
Authors: , Loges, Gregory J., Shiu, Gary</br>
  Intersecting branes provide a useful mechanism to construct particle physics models from string <font color="#be00be">theor</font>y with a wide variety of desirable characteristics. The landscape of such models can be enormous, and navigating towards regions which are most phenomenologically interesting is potentially challenging. Machine learning techniques can be used to efficiently construct large numbers of consistent and phenomenologically desirable models. In this work we phrase the problem of finding consistent intersecting D-brane models in terms of genetic algorithms, which mimic natural selection to evolve a population collectively towards optimal solutions. For a four-dimensional ${\\cal N}=1$ supersymmetric type IIA orientifold with intersecting D6-branes, we demonstrate that $\\mathcal{O}(10^6)$ unique, fully consistent models can be easily constructed, and, by a judicious choice of search environment and hyper-parameters, $\\mathcal{O}(30\\%)$ of the found models contain the desired Standard Model gauge group factor. Having a sizable sample allows us to draw some preliminary landscape statistics of intersecting brane models both with and without the restriction of having the Standard Model gauge factor. </br></br>

<a href='http://arxiv.org/pdf/2112.08250.pdf'>2112.08250</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6239баллов, №1043</br>
<b>Predicting the utility of search spaces for black-box optimization:a\n  simple, budget-aware approach</b></br>
Authors: , Ariafar, Setareh, Gilmer, Justin, Nado, Zack, Snoek, Jasper, Jenatton, Rodolphe, Dahl, George E.</br>
  Black box optimization requires specifying a search space to explore for solutions, e.g. a d-dimensional compact space, and this choice is critical for getting the best results at a reasonable budget. Unfortunately, determining a high quality search space can be challenging in many applications. For example, when tuning hyperparameters for machine learning pipelines on a new problem given a limited budget, one must strike a balance between excluding potentially promising regions and keeping the search space small enough to be tractable. The goal of this work is to motivate -- through example applications in tuning deep neural networks -- the problem of predicting the quality of search spaces conditioned on budgets, as well as to provide a simple scoring method based on a utility function applied to a probabilistic response surface model, similar to <font color="#be00be">Bayes</font>ian optimization. We show that the method we present can compute meaningful budget-conditional scores in a variety of situations. We also provide experimental evidence that accurate scores can be useful in constructing and pruning search spaces. Ultimately, we believe scoring search spaces should become standard practice in the experimental workflow for deep learning. </br></br>

<a href='http://arxiv.org/pdf/2112.02719.pdf'>2112.02719</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.6247баллов, №1044</br>
<b>A Survey on Deep learning based Document Image Enhancement</b></br>
Authors: , Anvari, Zahra, Athitsos, Vassilis</br>
  Digitized documents such as scientific articles, tax forms, invoices, contract papers, historic texts are widely used nowadays. These document images could be degraded or damaged due to various reasons including poor lighting conditions, shadow, distortions like noise and blur, aging, ink stain, bleed-through, watermark, stamp, etc. Document image enhancement plays a crucial role as a pre-processing step in many automated document analysis and recognition tasks in particular when those tasks are dealing with degraded documents. With recent advances in deep learning, many methods are proposed to enhance the quality of these document images. In this paper, we review deep learning-based methods, datasets, and metrics for six main document image enhancement tasks, including binarization, <font color="#be00be">deblur</font>ing, denoising, defading, watermark removal, and shadow removal. We summarize the recent works for each task and discuss their features, challenges, and limitations. We introduce multiple document image enhancement tasks that have received little to no attention, including over and under exposure correction, super resolution, and bleed-through removal. We identify several promising research directions and opportunities for future research. </br></br>

<a href='http://arxiv.org/pdf/2112.08281.pdf'>2112.08281</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.6248баллов, №1045</br>
<b>Detecting Object States vs Detecting Objects: A New Dataset and a\n  Quantitative Experimental Study</b></br>
Authors: , Gouidis, Filippos, Patkos, Theodoris, Argyros, Antonis, Plexousakis, Dimitris</br>
  The detection of object states in images (State Detection - SD) is a problem of both <font color="#be00be">theor</font>etical and practical importance and it is tightly interwoven with other important computer vision problems, such as action recognition and affordance detection. It is also highly relevant to any entity that needs to reason and act in dynamic domains, such as robotic systems and intelligent agents. Despite its importance, up to now, the research on this problem has been limited. In this paper, we attempt a systematic study of the SD problem. First, we introduce the Object State Detection Dataset (OSDD), a new <font color="#00be00">publicly available</font> dataset consisting of more than 19,000 annotations for 18 object categories and 9 state classes. Second, using a standard deep learning framework used for <font color="#be00be">Object Detection</font> (OD), we conduct a number of appropriately designed experiments, towards an in-depth study of the behavior of the SD problem. This study enables the setup of a baseline on the performance of SD, as well as its relative performance in comparison to OD, in a variety of scenarios. Overall, the experimental outcomes confirm that SD is harder than OD and that tailored SD methods need to be developed for addressing effectively this significant problem. </br></br>

<a href='http://arxiv.org/pdf/2112.03214.pdf'>2112.03214</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.6253баллов, №1046</br>
<b>Piano Timbre Development Analysis using Machine Learning</b></br>
Authors: , Plath, Niko, Bader, Rolf</br>
  A data set of recorded single played tones of a concert grand piano is investigated using Machine Learning (ML) on psychoacoustic timbre features. The examined instrument has been recorded at two stages: firstly right after manufacture and secondly after being played in a concert hall for one year. A previous study [Plath2019] revealed that listeners clearly distinguished both stages but no clear correlation with acoustics, signal processing tools or verbalizations of perceived differences could be found. Using a Self-Organizing Map (SOM), training single as well as double feature sets, it can be shown that spectral flux is able to perfectly cluster the two stages. Sound Pressure Level (SPL), roughness, and fractal correlation dimension (as a measure for initial transient chaoticity) are furthermore able to order the keys with respect to high and low notes. Combining spectral flux with the three other features in double-feature training sets maintains stage <font color="#be00be">clustering</font> only for SPL and fractal dimension, showing sub-clusters for both stages. These sub-clusters point to a homogenization of SPL for stage 2 with respect to stage 1 and a pronounced ordering and sub-clustering of key regions with respect to initial transient chaoticity. </br></br>

<a href='http://arxiv.org/pdf/2112.07110.pdf'>2112.07110</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.6258баллов, №1047</br>
<b>Non Asymptotic Bounds for Optimization via Online Multiplicative\n  Stochastic Gradient Descent</b></br>
Authors: , Bhattacharya, Riddhiman</br>
  The gradient noise of Stochastic Gradient Descent (SGD) is considered to play a key role in its properties (e.g. escaping low potential points and regularization). Past research has indicated that the covariance of the SGD error done via minibatching plays a critical role in determining its regularization and escape from low potential points. It is however not much explored how much the distribution of the error influences the behavior of the algorithm. Motivated by some new research in this area, we prove universality results by showing that noise classes that have the same mean and covariance structure of SGD via minibatching have similar properties. We mainly consider the Multiplicative Stochastic Gradient Descent (M-SGD) algorithm as introduced by Wu et al., which has a much more general noise class than the SGD algorithm done via minibatching. We establish nonasymptotic bounds for the M-SGD algorithm mainly with respect to the Stochastic Differential Equation corresponding to SGD via minibatching. We also show that the M-SGD error is approximately a scaled <font color="#be00be">Gaussi</font>an distribution with mean $0$ at any fixed point of the M-SGD algorithm. We also establish bounds for the convergence of the M-SGD algorithm in the strongly convex regime. </br></br>

<a href='http://arxiv.org/pdf/2112.07615.pdf'>2112.07615</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.6287баллов, №1048</br>
<b>Cold Item Integration in Deep Hybrid Recommenders via Tunable Stochastic\n  Gates</b></br>
Authors: , Barkan, Oren, Hirsch, Roy, Katz, Ori, Caciularu, Avi, Weill, Jonathan, Koenigstein, Noam</br>
  A major challenge in collaborative filtering methods is how to produce <font color="#be00be">recommendat</font>ions for cold items (items with no ratings), or integrate cold item into an existing catalog. Over the years, a variety of hybrid recommendation models have been proposed to address this problem by utilizing items\' metadata and content along with their ratings or usage patterns. In this work, we wish to revisit the cold start problem in order to draw attention to an overlooked challenge: the ability to integrate and balance between (regular) warm items and completely cold items. In this case, two different challenges arise: (1) preserving high quality performance on warm items, while (2) learning to promote cold items to relevant users. First, we show that these two objectives are in fact conflicting, and the balance between them depends on the business needs and the application at hand. Next, we propose a novel hybrid recommendation algorithm that bridges these two conflicting objectives and enables a harmonized balance between preserving high accuracy for warm items while effectively promoting completely cold items. We demonstrate the effectiveness of the proposed algorithm on movies, apps, and articles recommendations, and provide an empirical analysis of the cold-warm trade-off. </br></br>

<a href='http://arxiv.org/pdf/2112.05909.pdf'>2112.05909</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.6310баллов, №1049</br>
<b>Neural Attention Models in Deep Learning: Survey and Taxonomy</b></br>
Authors: , Santana, Alana, Colombini, Esther</br>
  Attention is a state of arousal capable of dealing with limited processing bottlenecks in human beings by focusing selectively on one piece of information while ignoring other perceptible information. For decades, concepts and functions of attention have been studied in philosophy, psychology, neuroscience, and computing. Currently, this property has been widely explored in deep neural networks. Many different neural attention models are now available and have been a very active research area over the past six years. From the <font color="#be00be">theor</font>etical standpoint of attention, this survey provides a critical analysis of major neural attention models. Here we propose a taxonomy that corroborates with theoretical aspects that predate Deep Learning. Our taxonomy provides an organizational structure that asks new questions and structures the understanding of existing attentional mechanisms. In particular, 17 criteria derived from psychology and neuroscience classic studies are formulated for qualitative comparison and critical analysis on the 51 main models found on a set of more than 650 papers analyzed. Also, we highlight several theoretical issues that have not yet been explored, including discussions about biological plausibility, highlight current research trends, and provide insights for the future. </br></br>

<a href='http://arxiv.org/pdf/2112.05559.pdf'>2112.05559</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6316баллов, №1050</br>
<b>Collaborative Learning over Wireless Networks: An Introductory Overview</b></br>
Authors: , Ozfatura, Emre, Gunduz, Deniz, Poor, H. Vincent</br>
  In this chapter, we will mainly focus on collaborative training across wireless devices. Training a ML model is equivalent to solving an optimization problem, and many distributed optimization algorithms have been developed over the last decades. These distributed ML algorithms provide data locality; that is, a joint model can be trained collaboratively while the data available at each participating device remains local. This addresses, to some extend, the <font color="#be00be">privacy</font> concern. They also provide computational scalability as they allow exploiting computational resources distributed across many edge devices. However, in practice, this does not directly lead to a linear gain in the overall learning speed with the number of devices. This is partly due to the communication bottleneck limiting the overall computation speed. Additionally, wireless devices are highly heterogeneous in their computational capabilities, and both their computation speed and communication rate can be highly time-varying due to physical factors. Therefore, distributed learning algorithms, particularly those to be implemented at the wireless network edge, must be carefully designed taking into account the impact of time-varying communication network as well as the heterogeneous and stochastic computation capabilities of devices. </br></br>

<a href='http://arxiv.org/pdf/2112.08033.pdf'>2112.08033</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.6344баллов, №1051</br>
<b><font color="#be00be">Named entity</font> recognition architecture combining contextual and global\n  features</b></br>
Authors: , Hanh, Tran Thi Hong, Doucet, Antoine, Sidere, Nicolas, Moreno, Jose G., Pollak, Senja</br>
  <font color="#be00be">Named entity</font> recognition (NER) is an information extraction technique that aims to locate and classify named entities (e.g., organizations, locations,...) within a document into predefined categories. Correctly identifying these phrases plays a significant role in simplifying information access. However, it remains a difficult task because named entities (NEs) have multiple forms and they are context-dependent. While the context can be represented by contextual features, global relations are often misrepresented by those models. In this paper, we propose the combination of contextual features from XLNet and global features from Graph Convolution Network (GCN) to enhance<font color="#be00be"> NER </font>performance. Experiments over a widely-used dataset, CoNLL 2003, show the benefits of our strategy, with results <font color="#960096">competitive</font> with the <font color="#00be00">state of the art</font> (SOTA). </br></br>

<a href='http://arxiv.org/pdf/2112.04660.pdf'>2112.04660</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6350баллов, №1052</br>
<b>A Fully Single Loop Algorithm for Bilevel Optimization without Hessian\n  Inverse</b></br>
Authors: , Li, Junyi, Gu, Bin, Huang, Heng</br>
  In this paper, we propose a new Hessian inverse free Fully Single Loop Algorithm (FSLA) for bilevel optimization problems. Classic algorithms for bilevel optimization admit a double loop structure which is computationally expensive. Recently, several single loop algorithms have been proposed with optimizing the inner and outer variable alternatively. However, these algorithms not yet achieve fully single loop. As they overlook the loop needed to evaluate the hyper-gradient for a given inner and outer state. In order to develop a fully single loop algorithm, we first study the structure of the hyper-gradient and identify a general approximation formulation of hyper-gradient computation that encompasses several previous common approaches, e.g. back-propagation through time, conjugate gradient, \\emph{etc.} Based on this formulation, we introduce a new state variable to maintain the historical hyper-gradient information. Combining our new formulation with the alternative update of the inner and outer variables, we propose an efficient fully single loop algorithm. We <font color="#be00be">theor</font>etically show that the error generated by the new state can be bounded and our algorithm converges with the rate of $O(\\epsilon^{-2})$. Finally, we verify the efficacy our algorithm empirically through multiple bilevel optimization based machine learning tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.04752.pdf'>2112.04752</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.6354баллов, №1053</br>
<b>Modelling Lips-State Detection Using CNN for Non-Verbal Communications</b></br>
Authors: , Ishmam, Abtahi, Hasan, Mahmudul, Onim, Md. Saif Hassan, Roy, Koushik, Akif, Md. Akiful Haque, Nyeem, Hossain</br>
  Vision-based deep learning models can be promising for speech-and-hearing-impaired and secret communications. While such non-verbal communications are primarily investigated with hand-gestures and<font color="#be00be"> facial </font>expressions, no research endeavour is tracked so far for the lips state (i.e., open/close)-based <font color="#be00be">interpret</font>ation/translation system. In support of this development, this paper reports two new Convolutional Neural Network (CNN) models for lips state detection. Building upon two prominent lips landmark detectors, DLIB and MediaPipe, we simplify lips-state model with a set of six key landmarks, and use their distances for the lips state classification. Thereby, both the models are developed to count the opening and closing of lips and thus, they can classify a symbol with the total count. Varying frame-rates, lips-movements and face-angles are investigated to determine the effectiveness of the models. Our early experimental results demonstrate that the model with DLIB is relatively slower in terms of an average of 6 frames per second (FPS) and higher average detection accuracy of 95.25%. In contrast, the model with MediaPipe offers faster landmark detection capability with an average FPS of 20 and detection accuracy of 94.4%. Both models thus could effectively interpret the lips state for non-verbal semantics into a natural language. </br></br>

<a href='http://arxiv.org/pdf/2111.15317.pdf'>2111.15317</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6360баллов, №1054</br>
<b>AutoDrop: Training Deep Learning Models with Automatic Learning Rate\n  Drop</b></br>
Authors: , Teng, Yunfei, Wang, Jing, Choromanska, Anna</br>
  Modern deep learning (DL) architectures are trained using variants of the SGD algorithm that is run with a $\\textit{manually}$ defined learning rate schedule, i.e., the learning rate is dropped at the pre-defined epochs, typically when the training loss is expected to saturate. In this paper we develop an algorithm that realizes the learning rate drop $\\textit{automatically}$. The proposed method, that we refer to as AutoDrop, is motivated by the observation that the angular velocity of the model parameters, i.e., the velocity of the changes of the convergence direction, for a fixed learning rate initially increases rapidly and then progresses towards soft saturation. At saturation the optimizer slows down thus the angular velocity saturation is a good indicator for dropping the learning rate. After the drop, the angular velocity &quot;resets&quot; and follows the previously described pattern - it increases again until saturation. We show that our method improves over SOTA training approaches: it accelerates the training of DL models and leads to a better generalization. We also show that our method does not require any extra hyperparameter tuning. AutoDrop is furthermore extremely simple to implement and computationally cheap. Finally, we develop a <font color="#be00be">theor</font>etical framework for analyzing our algorithm and provide convergence guarantees. </br></br>

<a href='http://arxiv.org/pdf/2112.07787.pdf'>2112.07787</a> &nbsp&nbsp (cs:CV, cs:RO) &nbsp&nbsp -0.6373баллов, №1055</br>
<b>Revisiting 3D <font color="#be00be">Object Detection</font> From an Egocentric Perspective</b></br>
Authors: , Deng, Boyang, Qi, Charles R., Najibi, Mahyar, Funkhouser, Thomas, Zhou, Yin, Anguelov, Dragomir</br>
  3D <font color="#be00be">object detection</font> is a key module for safety-critical robotics applications such as autonomous driving. For these applications, we care most about how the detections affect the ego-agent\'s behavior and safety (the egocentric perspective). Intuitively, we seek more accurate descriptions of object geometry when it\'s more likely to interfere with the ego-agent\'s motion trajectory. However, current detection metrics, based on box Intersection-over-Union (IoU), are object-centric and aren\'t designed to capture the spatio-temporal relationship between objects and the ego-agent. To address this issue, we propose a new egocentric measure to evaluate 3D object detection, namely Support Distance Error (SDE). Our analysis based on SDE reveals that the egocentric detection quality is bounded by the coarse geometry of the bounding boxes. Given the insight that SDE would benefit from more accurate geometry descriptions, we propose to represent objects as amodal contours, specifically amodal star-shaped polygons, and devise a simple model, StarPoly, to predict such contours. Our experiments on the large-scale Waymo Open Dataset show that SDE better reflects the impact of detection quality on the ego-agent\'s safety compared to IoU; and the estimated contours from StarPoly consistently improve the egocentric detection quality over recent 3D object detectors. </br></br>

<a href='http://arxiv.org/pdf/2112.05911.pdf'>2112.05911</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6420баллов, №1056</br>
<b>Learning Contraction Policies from Offline Data</b></br>
Authors: , Rezazadeh, Navid, Kolarich, Maxwell, Kia, Solmaz S., Mehr, Negar</br>
  This paper proposes a data-driven method for learning convergent control policies from offline data using Contraction <font color="#be00be">theor</font>y. Contraction theory enables constructing a policy that makes the closed-loop system trajectories inherently convergent towards a unique trajectory. At the technical level, identifying the contraction metric, which is the distance metric with respect to which a robot\'s trajectories exhibit contraction is often non-trivial. We propose to jointly learn the control policy and its corresponding contraction metric while enforcing contraction. To achieve this, we learn an implicit dynamics model of the robotic system from an offline data set consisting of the robot\'s state and input trajectories. Using this learned dynamics model, we propose a data augmentation algorithm for learning contraction policies. We randomly generate samples in the state-space and propagate them forward in time through the learned dynamics model to generate auxiliary sample trajectories. We then learn both the control policy and the contraction metric such that the distance between the trajectories from the offline data set and our generated auxiliary sample trajectories decreases over time. We evaluate the performance of our proposed framework on simulated robotic goal-reaching tasks and demonstrate that enforcing contraction results in faster convergence and greater robustness of the learned policy. </br></br>

<a href='http://arxiv.org/pdf/2112.06029.pdf'>2112.06029</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.6440баллов, №1057</br>
<b>On Automatic Data Augmentation for 3D <font color="#be00be">Point Cloud</font> Classification</b></br>
Authors: , Zhang, Wanyue, Xu, Xun, Liu, Fayao, Foo, Chuan-Sheng</br>
  Data augmentation is an important technique to reduce overfitting and improve learning performance, but existing works on data augmentation for 3D <font color="#be00be">point cloud</font> data are based on heuristics. In this work, we instead propose to automatically learn a data augmentation strategy using bilevel optimization. An augmentor is designed in a similar fashion to a conditional generator and is optimized by minimizing a base model\'s loss on a validation set when the augmented input is used for training the model. This formulation provides a more principled way to learn data augmentation on 3D point clouds. We evaluate our approach on standard point cloud classification tasks and a more challenging setting with pose misalignment between training and validation/test sets. The proposed strategy achieves <font color="#960096">competitive</font> performance on both tasks and we provide further insight into the augmentor\'s ability to learn the validation set distribution. </br></br>

<a href='http://arxiv.org/pdf/2112.08713.pdf'>2112.08713</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.6471баллов, №1058</br>
<b>CONFIT: Toward Faithful Dialogue <font color="#be00be">Summarization</font> with\n  Linguistically-Informed Contrastive Fine-tuning</b></br>
Authors: , Tang, Xiangru, Nair, Arjun, Wang, Borui, Wang, Bingyao, Desai, Jai, Wade, Aaron, Li, Haoran, Celikyilmaz, Asli, Mehdad, Yashar, Radev, Dragomir</br>
  Factual inconsistencies in generated summaries severely limit the practical applications of abstractive dialogue <font color="#be00be">summarization</font>. Although significant progress has been achieved by using pre-trained models, substantial amounts of hallucinated content are found during the human evaluation. Pre-trained models are most commonly fine-tuned with cross-entropy loss for text summarization, which may not be an optimal strategy. In this work, we provide a typology of factual errors with annotation data to highlight the types of errors and move away from a binary understanding of factuality. We further propose a training strategy that improves the factual consistency and overall quality of summaries via a novel contrastive fine-tuning, called ConFiT. Based on our linguistically-informed typology of errors, we design different modular objectives that each target a specific type. Specifically, we utilize hard negative samples with errors to reduce the generation of factual inconsistency. In order to capture the key information between speakers, we also design a dialogue-specific loss. Using human evaluation and automatic faithfulness metrics, we show that our model significantly reduces all kinds of factual errors on the dialogue summarization, SAMSum corpus. Moreover, our model could be generalized to the meeting summarization, AMI corpus, and it produces significantly higher scores than most of the baselines on both datasets regarding word-overlap metrics. </br></br>

<a href='http://arxiv.org/pdf/2112.04953.pdf'>2112.04953</a> &nbsp&nbsp (cs:AI, cs:ML, stat:ML) &nbsp&nbsp -0.6472баллов, №1059</br>
<b>Machine Learning for Utility Prediction in Argument-Based Computational\n  Persuasion</b></br>
Authors: , Donadello, Ivan, Hunter, Anthony, Teso, Stefano, Dragoni, Mauro</br>
  Automated persuasion systems (APS) aim to persuade a user to believe something by entering into a dialogue in which arguments and counterarguments are exchanged. To maximize the probability that an APS is successful in persuading a user, it can identify a global policy that will allow it to select the best arguments it presents at each stage of the dialogue whatever arguments the user presents. However, in real applications, such as for healthcare, it is unlikely the utility of the outcome of the dialogue will be the same, or the exact opposite, for the APS and user. In order to deal with this situation, games in extended form have been harnessed for argumentation in Bi-party Decision <font color="#be00be">Theor</font>y. This opens new problems that we address in this paper: (1) How can we use Machine Learning (ML) methods to predict utility functions for different subpopulations of users? and (2) How can we identify for a new user the best utility function from amongst those that we have learned? To this extent, we develop two ML methods, EAI and EDS, that leverage information coming from the users to predict their utilities. EAI is restricted to a fixed amount of information, whereas EDS can choose the information that best detects the subpopulations of a user. We evaluate EAI and EDS in a simulation setting and in a realistic case study concerning healthy eating habits. Results are promising in both cases, but EDS is more effective at predicting useful utility functions. </br></br>

<a href='http://arxiv.org/pdf/2112.08304.pdf'>2112.08304</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6550баллов, №1060</br>
<b>On the Convergence and Robustness of Adversarial Training</b></br>
Authors: , Wang, Yisen, Ma, Xingjun, Bailey, James, Yi, Jinfeng, Zhou, Bowen, Gu, Quanquan</br>
  Improving the robustness of deep neural networks (DNNs) to adversarial examples is an important yet challenging problem for secure deep learning. Across existing defense techniques, adversarial training with Projected Gradient Decent (PGD) is amongst the most effective. Adversarial training solves a min-max optimization problem, with the \\textit{inner maximization} generating adversarial examples by maximizing the classification loss, and the \\textit{outer minimization} finding model parameters by minimizing the loss on adversarial examples generated from the inner maximization. A criterion that measures how well the inner maximization is solved is therefore crucial for adversarial training. In this paper, we propose such a criterion, namely First-Order Stationary Condition for constrained optimization (FOSC), to quantitatively evaluate the convergence quality of adversarial examples found in the inner maximization. With FOSC, we find that to ensure better robustness, it is essential to use adversarial examples with better convergence quality at the \\textit{later stages} of training. Yet at the early stages, high convergence quality adversarial examples are not necessary and may even lead to poor robustness. Based on these observations, we propose a \\textit{dynamic} training strategy to gradually increase the convergence quality of the generated adversarial examples, which significantly improves the robustness of adversarial training. Our <font color="#be00be">theor</font>etical and empirical results show the effectiveness of the proposed method. </br></br>

<a href='http://arxiv.org/pdf/2112.05686.pdf'>2112.05686</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.6579баллов, №1061</br>
<b>Learning-based personal <font color="#be00be">speech enhancement</font> for teleconferencing by\n  exploiting spatial-spectral features</b></br>
Authors: , Hsu, Yicheng, Lee, Yonghan, Bai, Mingsian R.</br>
  Teleconferencing is becoming essential during the COVID-19 pandemic. However, in <font color="#009600">real-world</font> applications, speech quality can deteriorate due to, for example, background interference, noise, or <font color="#be00be">reverberat</font>ion. To solve this problem, target speech extraction from the mixture signals can be performed with the aid of the user\'s vocal features. Various features are accounted for in this study\'s proposed system, including speaker embeddings derived from user enrollment and a novel long-short-term spatial coherence (LSTSC) feature to the target speaker activity. As a learning-based approach, a target speech sifting network was employed to extract the target speech signal. The network trained with LSTSC in the proposed approach is robust to microphone array geometries and the number of microphones. Furthermore, the proposed enhancement system was compared with a baseline system with speaker embeddings and interchannel phase difference. The results demonstrated the superior performance of the proposed system over the baseline in enhancement performance and robustness. </br></br>

<a href='http://arxiv.org/pdf/2112.05958.pdf'>2112.05958</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.6608баллов, №1062</br>
<b>You Only Need End-to-End Training for Long-Tailed Recognition</b></br>
Authors: , Zhang, Zhiwei</br>
  The generalization gap on the long-tailed data sets is largely owing to most categories only occupying a few training samples. Decoupled training achieves better performance by training backbone and classifier separately. What causes the poorer performance of end-to-end model training (e.g., logits margin-based methods)? In this work, we identify a key factor that affects the learning of the classifier: the channel-correlated features with low entropy before inputting into the classifier. From the perspective of information <font color="#be00be">theor</font>y, we analyze why cross-entropy loss tends to produce highly correlated features on the imbalanced data. In addition, we theoretically analyze and prove its impacts on the gradients of classifier weights, the condition number of Hessian, and logits margin-based approach. Therefore, we firstly propose to use Channel Whitening to decorrelate (&quot;scatter&quot;) the classifier\'s inputs for decoupling the weight update and reshaping the skewed decision boundary, which achieves satisfactory results combined with logits margin-based method. However, when the number of minor classes are large, batch imbalance and more participation in training cause over-fitting of the major classes. We also propose two novel modules, Block-based Relatively Balanced Batch Sampler (B3RS) and Batch Embedded Training (BET) to solve the above problems, which makes the end-to-end training achieve even better performance than decoupled training. Experimental results on the long-tailed classification benchmarks, CIFAR-LT and ImageNet-LT, demonstrate the effectiveness of our method. </br></br>

<a href='http://arxiv.org/pdf/2112.06323.pdf'>2112.06323</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.6609баллов, №1063</br>
<b>Interpolated Joint Space Adversarial Training for Robust and\n  Generalizable Defenses</b></br>
Authors: , Lau, Chun Pong, Liu, Jiang, Souri, Hossein, Lin, Wei-An, Feizi, Soheil, Chellappa, Rama</br>
  Adversarial training (AT) is considered to be one of the most reliable defenses against <font color="#be00be">adversarial att</font>acks. However, models trained with AT sacrifice standard accuracy and do not generalize well to novel attacks. Recent works show generalization improvement with adversarial samples under novel threat models such as on-manifold threat model or neural perceptual threat model. However, the former requires exact manifold information while the latter requires algorithm relaxation. Motivated by these considerations, we exploit the underlying manifold information with Normalizing Flow, ensuring that exact manifold assumption holds. Moreover, we propose a novel threat model called Joint Space Threat Model (JSTM), which can serve as a special case of the neural perceptual threat model that does not require additional relaxation to craft the corresponding adversarial attacks. Under JSTM, we develop novel adversarial attacks and defenses. The mixup strategy improves the standard accuracy of neural networks but sacrifices robustness when combined with AT. To tackle this issue, we propose the Robust Mixup strategy in which we maximize the adversity of the interpolated images and gain robustness and prevent overfitting. Our experiments show that Interpolated Joint Space Adversarial Training (IJSAT) achieves good performance in standard accuracy, robustness, and generalization in CIFAR-10/100, OM-ImageNet, and CIFAR-10-C datasets. IJSAT is also flexible and can be used as a data augmentation method to improve standard accuracy and combine with many existing AT approaches to improve robustness. </br></br>

<a href='http://arxiv.org/pdf/2111.13955.pdf'>2111.13955</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6641баллов, №1064</br>
<b>A Recommender System-Inspired Cloud Data Filling Scheme for\n  Satellite-based Coastal Observation</b></br>
Authors: , Wang, Ruo-Qian</br>
  Filling missing data in cloud-covered areas of satellite imaging is an important task to improve data quantity and quality for enhanced earth observation. Traditional cloud filling studies focused on continuous numerical data such as temperature and cyanobacterial concentration in the open ocean. Cloud data filling issues in coastal imaging is far less studied because of the complex landscape. Inspired by the success of data imputation methods in recommender systems that are designed for online shopping, the present study explored their application to satellite cloud data filling tasks. A numerical experiment was designed and conducted for a LandSat dataset with a range of synthetic cloud covers to examine the performance of different data filling schemes. The recommender system-inspired matrix factorization algorithm called Funk-SVD showed superior performance in computational accuracy and efficiency for the task of recovering landscape types in a complex coastal area than the traditional data filling scheme of DINEOF (Data Interpolating Empirical Orthogonal Functions) and the deep learning method of Datawig. The new method achieved the best filling accuracy and reached a speed comparable to DINEOF and much faster than deep learning. A <font color="#be00be">theor</font>etical framework was created to analyze the error propagation in DINEOF and found the algorithm needs to be modified to converge to the ground truth. The present study showed that Funk-SVD has great potential to enhance cloud data filling performance and connects the fields of recommender systems and cloud filling to promote the improvement and sharing of useful algorithms. </br></br>

<a href='http://arxiv.org/pdf/2112.05456.pdf'>2112.05456</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.6650баллов, №1065</br>
<b>Camera Condition Monitoring and Readjustment by means of Noise and Blur</b></br>
Authors: , Wischow, Maik, Gallego, Guillermo, Ernst, Ines, B&#xf6;rner, Anko</br>
  Autonomous vehicles and robots require increasingly more robustness and reliability to meet the demands of modern tasks. These requirements specially apply to cameras because they are the predominant sensors to acquire information about the environment and support actions. A camera must maintain proper functionality and take automatic countermeasures if necessary. However, there is little work that examines the practical use of a general condition monitoring approach for cameras and designs countermeasures in the context of an envisaged high-level application. We propose a generic and <font color="#be00be">interpret</font>able self-health-maintenance framework for cameras based on data- and physically-grounded models. To this end, we determine two reliable, real-time capable estimators for typical image effects of a camera in poor condition (defocus blur, motion blur, different noise phenomena and most common combinations) by comparing traditional and retrained machine learning-based approaches in extensive experiments. Furthermore, we demonstrate how one can adjust the camera parameters (e.g., exposure time and ISO gain) to achieve optimal whole-system capability based on experimental (non-linear and non-monotonic) input-output performance curves, using <font color="#be00be">object detection</font>, motion blur and sensor noise as examples. Our framework not only provides a practical ready-to-use solution to evaluate and maintain the health of cameras, but can also serve as a basis for extensions to tackle more sophisticated problems that combine additional data sources (e.g., sensor or environment parameters) empirically in order to attain fully reliable and robust machines. </br></br>

<a href='http://arxiv.org/pdf/2112.08458.pdf'>2112.08458</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6670баллов, №1066</br>
<b>Leveraging the structure of dynamical systems for data-driven modeling</b></br>
Authors: , Bucci, Alessandro, Semeraro, Onofrio, Allauzen, Alexandre, Chibbaro, Sergio, Mathelin, Lionel</br>
  The reliable prediction of the temporal behavior of complex systems is required in numerous scientific fields. This strong interest is however hindered by modeling issues: often, the governing equations describing the physics of the system under consideration are not accessible or, when known, their solution might require a computational time incompatible with the prediction time constraints.   Nowadays, approximating complex systems at hand in a generic functional format and informing it ex nihilo from available observations has become a common practice, as illustrated by the enormous amount of scientific work appeared in the last years. Numerous successful examples based on deep neural networks are already available, although generalizability of the models and margins of guarantee are often overlooked. Here, we consider Long-Short Term Memory neural networks and thoroughly investigate the impact of the training set and its structure on the quality of the long-term prediction. Leveraging ergodic <font color="#be00be">theor</font>y, we analyze the amount of data sufficient for a priori guaranteeing a faithful model of the physical system.   We show how an informed design of the training set, based on invariants of the system and the structure of the underlying attractor, significantly improves the resulting models, opening up avenues for research within the context of active learning. Further, the non-trivial effects of the memory initializations when relying on memory-capable models will be illustrated. Our findings provide evidence-based good-practice on the amount and the choice of data required for an effective data-driven modeling of any complex dynamical system. </br></br>

<a href='http://arxiv.org/pdf/2111.07380.pdf'>2111.07380</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6690баллов, №1067</br>
<b>Eluding Secure Aggregation in <font color="#be00be">Federated</font> Learning via Model Inconsistency</b></br>
Authors: , Pasquini, Dario, Francati, Danilo, Ateniese, Giuseppe</br>
  Secure aggregation is a cryptographic protocol that securely computes the aggregation of its inputs. It is pivotal in keeping model updates <font color="#be00be">private</font> in <font color="#be00be">federated</font> learning. Indeed, the use of secure aggregation prevents the server from learning the value and the source of the individual model updates provided by the users, hampering inference and data attribution attacks.   In this work, we show that a malicious server can easily elude secure aggregation as if the latter were not in place. We devise two different attacks capable of inferring information on individual private training datasets, independently of the number of users participating in the secure aggregation. This makes them concrete threats in large-scale, <font color="#009600">real-world</font> federated learning applications.   The attacks are generic and do not target any specific secure aggregation protocol. They are equally effective even if the secure aggregation protocol is replaced by its ideal functionality that provides the perfect level of security. Our work demonstrates that secure aggregation has been incorrectly combined with federated learning and that current implementations offer only a &quot;false sense of security\'\'. </br></br>

<a href='http://arxiv.org/pdf/2111.06679.pdf'>2111.06679</a> &nbsp&nbsp (cs:ML, cs:AI, cs:NE) &nbsp&nbsp -0.6705баллов, №1068</br>
<b>deepstruct -- linking deep learning and graph <font color="#be00be">theor</font>y</b></br>
Authors: , Stier, Julian, Granitzer, Michael</br>
  deepstruct connects deep learning models and graph <font color="#be00be">theor</font>y such that different graph structures can be imposed on neural networks or graph structures can be extracted from trained neural network models. For this, deepstruct provides deep neural network models with different restrictions which can be created based on an initial graph. Further, tools to extract graph structures from trained models are available. This step of extracting graphs can be computationally expensive even for models of just a few dozen thousand parameters and poses a challenging problem. deepstruct supports research in pruning, neural <font color="#00be00">architecture search</font>, automated network design and structure analysis of neural networks. </br></br>

<a href='http://arxiv.org/pdf/2112.06651.pdf'>2112.06651</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.6705баллов, №1069</br>
<b>Accoustate: Auto-annotation of IMU-generated Activity Signatures under\n  Smart Infrastructure</b></br>
Authors: , Chatterjee, Soumyajit, Singh, Arun, Mitra, Bivas, Chakraborty, Sandip</br>
  Human activities within smart infrastructures generate a vast amount of IMU data from the wearables worn by individuals. Many existing studies rely on such sensory data for human activity recognition (HAR); however, one of the major bottlenecks is their reliance on pre-annotated or labeled data. Manual human-driven annotations are neither scalable nor efficient, whereas existing auto-annotation techniques heavily depend on video signatures. Still, video-based auto-annotation needs high computation resources and has <font color="#be00be">privacy</font> concerns when the data from a personal space, like a smart-home, is transferred to the cloud. This paper exploits the acoustic signatures generated from human activities to label the wearables\' IMU data at the edge, thus mitigating resource requirement and data privacy concerns. We utilize acoustic-based pre-trained HAR models for cross-modal labeling of the IMU data even when two individuals perform simultaneous but different activities under the same environmental context. We observe that non-overlapping acoustic gaps exist with a high probability during the simultaneous activities performed by two individuals in the environment\'s acoustic context, which helps us resolve the overlapping activity signatures to label them individually. A principled evaluation of the proposed approach on two real-life in-house datasets further augmented to create a dual occupant setup, shows that the framework can correctly annotate a significant volume of unlabeled IMU data from both individuals with an accuracy of $\\mathbf{82.59\\%}$ ($\\mathbf{\\pm 17.94\\%}$) and $\\mathbf{98.32\\%}$ ($\\mathbf{\\pm 3.68\\%}$), respectively, for a workshop and a kitchen environment. </br></br>

<a href='http://arxiv.org/pdf/2112.06823.pdf'>2112.06823</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.6715баллов, №1070</br>
<b>Multi-Asset Spot and Option <font color="#be00be">Market</font> Simulation</b></br>
Authors: , Wiese, Magnus, Wood, Ben, Pachoud, Alexandre, Korn, Ralf, Buehler, Hans, Murray, Phillip, Bai, Lianjun</br>
  We construct realistic spot and equity option <font color="#be00be">market</font> simulators for a single underlying on the basis of normalizing flows. We address the high-dimensionality of market observed call prices through an arbitrage-free autoencoder that approximates efficient low-dimensional representations of the prices while maintaining no static arbitrage in the reconstructed surface. Given a multi-asset universe, we leverage the conditional invertibility property of normalizing flows and introduce a scalable method to calibrate the joint distribution of a set of independent simulators while preserving the dynamics of each simulator. Empirical results highlight the goodness of the calibrated simulators and their fidelity. </br></br>

<a href='http://arxiv.org/pdf/2112.06522.pdf'>2112.06522</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.6717баллов, №1071</br>
<b>Anatomizing Bias in<font color="#be00be"> Facial </font>Analysis</b></br>
Authors: , Singh, Richa, Majumdar, Puspita, Mittal, Surbhi, Vatsa, Mayank</br>
  Existing<font color="#be00be"> facial </font>analysis systems have been shown to yield biased results against certain demographic subgroups. Due to its impact on society, it has become imperative to ensure that these systems do not discriminate based on gender, identity, or skin tone of individuals. This has led to research in the identification and mitigation of bias in AI systems. In this paper, we encapsulate bias detection/estimation and mitigation algorithms for facial analysis. Our main contributions include a systematic review of algorithms proposed for understanding bias, along with a taxonomy and extensive overview of existing bias mitigation algorithms. We also discuss open challenges in the field of biased facial analysis. </br></br>

<a href='http://arxiv.org/pdf/2112.07611.pdf'>2112.07611</a> &nbsp&nbsp (cs:AI, cs:ML, stat:ML) &nbsp&nbsp -0.6723баллов, №1072</br>
<b>Speeding up Learning Quantum States through Group Equivariant\n  Convolutional Quantum Ans{\\&quot;a}tze</b></br>
Authors: , Zheng, Han, Li, Zimu, Liu, Junyu, Strelchuk, Sergii, Kondor, Risi</br>
  We develop a <font color="#be00be">theor</font>etical framework for $S_n$-equivariant quantum convolutional circuits, building on and significantly generalizing Jordan\'s Permutational Quantum Computing (PQC) formalism. We show that quantum circuits are a natural choice for Fourier space neural architectures affording a super-exponential speedup in computing the matrix elements of $S_n$-Fourier coefficients compared to the best known classical Fast Fourier Transform (FFT) over the symmetric group. In particular, we utilize the Okounkov-Vershik approach to prove Harrow\'s statement (Ph.D. Thesis 2005 p.160) on the equivalence between $\\operatorname{SU}(d)$- and $S_n$-irrep bases and to establish the $S_n$-equivariant Convolutional Quantum Alternating Ans{\\&quot;a}tze ($S_n$-CQA) using Young-Jucys-Murphy (YJM) elements. We prove that $S_n$-CQA are dense, thus expressible within each $S_n$-irrep block, which may serve as a universal model for potential future quantum machine learning and optimization applications. Our method provides another way to prove the universality of Quantum Approximate Optimization Algorithm (QAOA), from the representation-theoretical point of view. Our framework can be naturally applied to a wide array of problems with global $\\operatorname{SU}(d)$ symmetry. We present numerical simulations to showcase the effectiveness of the ans{\\&quot;a}tze to find the sign structure of the ground state of the $J_1$--$J_2$ antiferromagnetic Heisenberg model on the rectangular and Kagome lattices. Our work identifies quantum advantage for a specific machine learning problem, and provides the first application of the celebrated Okounkov-Vershik\'s representation theory to machine learning and quantum physics. </br></br>

<a href='http://arxiv.org/pdf/2112.08740.pdf'>2112.08740</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.6729баллов, №1073</br>
<b>Feature Erasing and Diffusion Network for Occluded Person\n  <font color="#be00be">Re-Identification</font></b></br>
Authors: , Wang, Zhikang, Zhu, Feng, Tang, Shixiang, Zhao, Rui, He, Lihuo, Song, Jiangning</br>
  Occluded person <font color="#be00be">re-identification</font> (ReID) aims at matching occluded person images to holistic ones across different camera views. Target <font color="#be00be">Pedestrian</font>s (TP) are usually disturbed by Non-Pedestrian Occlusions (NPO) and NonTarget Pedestrians (NTP). Previous methods mainly focus on increasing model\'s robustness against NPO while ignoring feature contamination from NTP. In this paper, we propose a novel Feature Erasing and Diffusion Network (FED) to simultaneously handle NPO and NTP. Specifically, NPO features are eliminated by our proposed Occlusion Erasing Module (OEM), aided by the NPO augmentation strategy which simulates NPO on holistic pedestrian images and generates precise occlusion masks. Subsequently, we Subsequently, we diffuse the pedestrian representations with other memorized features to synthesize NTP characteristics in the feature space which is achieved by a novel Feature Diffusion Module (FDM) through a learnable cross attention mechanism. With the guidance of the occlusion scores from OEM, the feature diffusion process is mainly conducted on visible body parts, which guarantees the quality of the synthesized NTP characteristics. By jointly optimizing OEM and FDM in our proposed FED network, we can greatly improve the model\'s perception ability towards TP and alleviate the influence of NPO and NTP. Furthermore, the proposed FDM only works as an auxiliary module for training and will be discarded in the inference phase, thus introducing little inference computational overhead. Experiments on occluded and holistic person ReID benchmarks demonstrate the superiority of FED over <font color="#00be00">state-of-the-art</font>s, where FED achieves 86.3% Rank-1 accuracy on Occluded-REID, surpassing others by at least 4.7%. </br></br>

<a href='http://arxiv.org/pdf/2112.02222.pdf'>2112.02222</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.6767баллов, №1074</br>
<b>Predicting Axillary Lymph Node Metastasis in Early Breast <font color="#be00be">Cancer</font> Using\n  Deep Learning on Primary Tumor Biopsy Slides</b></br>
Authors: , Xu, Feng, Zhu, Chuang, Tang, Wenqi, Wang, Ying, Zhang, Yu, Li, Jie, Jiang, Hongchuan, Shi, Zhongyue, Liu, Jun, Jin, Mulan</br>
  Objectives: To develop and validate a deep learning (DL)-based primary tumor biopsy signature for predicting axillary lymph node (ALN) metastasis preoperatively in early breast <font color="#be00be">cancer</font> (EBC) <font color="#be00be">patient</font>s with <font color="#be00be">clinic</font>ally negative ALN.   Methods: A total of 1,058 EBC patients with <font color="#be00be">patholog</font>ically confirmed ALN status were enrolled from May 2010 to August 2020. A DL core-needle biopsy (DL-CNB) model was built on the attention-based multiple instance-learning (AMIL) framework to predict ALN status utilizing the DL features, which were extracted from the cancer areas of digitized whole-slide images (WSIs) of breast CNB specimens annotated by two pathologists. Accuracy, sensitivity, specificity, receiver operating characteristic (ROC) curves, and areas under the ROC curve (AUCs) were analyzed to evaluate our model.   Results: The best-performing DL-CNB model with VGG16_BN as the feature extractor achieved an AUC of 0.816 (95% confidence interval (CI): 0.758, 0.865) in predicting positive ALN metastasis in the independent test cohort. Furthermore, our model incorporating the clinical data, which was called DL-CNB+C, yielded the best accuracy of 0.831 (95%CI: 0.775, 0.878), especially for patients younger than 50 years (AUC: 0.918, 95%CI: 0.825, 0.971). The <font color="#be00be">interpret</font>ation of DL-CNB model showed that the top signatures most predictive of ALN metastasis were characterized by the nucleus features including density ($p$ = 0.015), circumference ($p$ = 0.009), circularity ($p$ = 0.010), and orientation ($p$ = 0.012).   Conclusion: Our study provides a novel DL-based biomarker on primary tumor CNB slides to predict the metastatic status of ALN preoperatively for patients with EBC. The codes and dataset are available at <font color="#006400">http</font>s://<font color="#00be00">github</font>.com/bupt-ai-cz/BALNMP </br></br>

<a href='http://arxiv.org/pdf/2112.06543.pdf'>2112.06543</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6791баллов, №1075</br>
<b>Efficient spatio-temporal <font color="#be00be">weather</font> forecasting using U-Net</b></br>
Authors: , Punjabi, Akshay, Ayala, Pablo Izquierdo</br>
  <font color="#be00be">Weather</font> forecast plays an essential role in multiple aspects of the daily life of human beings. Currently, physics based numerical weather prediction is used to predict the weather and requires enormous amount of computational resources. In recent years, deep learning based models have seen wide success in many weather-prediction related tasks. In this paper we describe our experiments for the Weather4cast 2021 Challenge, where 8 hours of spatio-temporal weather data is predicted based on an initial one hour of spatio-temporal data. We focus on SmaAt-UNet, an efficient U-Net based autoencoder. With this model we achieve competent results whilst maintaining low computational resources. Furthermore, several approaches and possible future work is discussed at the end of the paper. </br></br>

<a href='http://arxiv.org/pdf/2112.06388.pdf'>2112.06388</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.6838баллов, №1076</br>
<b>A Cluster-Based Weighted Feature Similarity Moving Target <font color="#be00be">Tracking</font>\n  Algorithm for Automotive FMCW Radar</b></br>
Authors: , Chen, Rongqian, Zou, Yingquan, Gao, Anyong, Chen, Leshi</br>
  We studied a target <font color="#be00be">tracking</font> algorithm based on millimeter-wave (MMW) radar in an autonomous driving environment. Aiming at the cluster matching in the target tracking stage, a new weighted feature similarity algorithm is proposed, which increases the matching rate of the same target in adjacent frames under strong environmental noise and multiple interference targets. For autonomous driving scenarios, we constructed a method that uses its motion parameters to extract and correct the trajectory of a moving target, which solves the problem of moving target detection and trajectory correction during vehicle movement. Finally, the feasibility of the proposed method was verified by a series of experiments in autonomous driving environments. The results verify the high recognition accuracy and low positional error of the method. </br></br>

<a href='http://arxiv.org/pdf/2112.08835.pdf'>2112.08835</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.6870баллов, №1077</br>
<b>Self-supervised Enhancement of Latent Discovery in GANs</b></br>
Authors: , Sreelatha, Silpa Vadakkeeveetil, Kappiyath, Adarsh, Sumitra, S</br>
  Several methods for discovering <font color="#be00be">interpret</font>able directions in the latent space of pre-trained GANs have been proposed. Latent semantics discovered by unsupervised methods are relatively less disentangled than supervised methods since they do not use pre-trained attribute classifiers. We propose Scale Ranking Estimator (SRE), which is trained using self-supervision. SRE enhances the disentanglement in directions obtained by existing unsupervised disentanglement techniques. These directions are updated to preserve the ordering of variation within each direction in latent space. Qualitative and quantitative evaluation of the discovered directions demonstrates that our proposed method significantly improves disentanglement in various datasets. We also show that the learned SRE can be used to perform Attribute-based image <font color="#be00be">retrieval</font> task without further training. </br></br>

<a href='http://arxiv.org/pdf/2112.08414.pdf'>2112.08414</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.6884баллов, №1078</br>
<b>DSGPT: Domain-Specific Generative Pre-Training of <font color="#00be00">Transformer</font>s for Text\n  Generation in <font color="#be00be">E-commerce</font> Title and Review <font color="#be00be">Summarization</font></b></br>
Authors: , Zhang, Xueying, Jiang, Yunjiang, Shang, Yue, Cheng, Zhaomeng, Zhang, Chi, Fan, Xiaochuan, Xiao, Yun, Long, Bo</br>
  We propose a novel domain-specific generative pre-training (DS-GPT) method for text generation and apply it to the product titleand review <font color="#be00be">summarization</font> problems on <font color="#be00be">E-commerce</font><font color="#960096"> mobile </font>display.First, we adopt a decoder-only <font color="#00be00">transformer</font> architecture, which fitswell for fine-tuning tasks by combining input and output all to-gether. Second, we demonstrate utilizing only small amount of pre-training data in related domains is powerful. Pre-training a languagemodel from a general corpus such as Wikipedia or the CommonCrawl requires tremendous time and resource commitment, andcan be wasteful if the downstream tasks are limited in variety. OurDSGPT is pre-trained on a limited dataset, the <font color="#be00be">Chinese</font> short textsummarization dataset (LCSTS). Third, our model does not requireproduct-related human-labeled data. For title summarization task,the state of art explicitly uses additional background knowledgein training and predicting stages. In contrast, our model implic-itly captures this knowledge and achieves significant improvementover other methods, after fine-tuning on the public Taobao.comdataset. For review summarization task, we utilize JD.com in-housedataset, and observe similar improvement over standard machinetranslation methods which lack the flexibility of fine-tuning. Ourproposed work can be simply extended to other domains for a widerange of text generation tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.08513.pdf'>2112.08513</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.6893баллов, №1079</br>
<b>DocAMR: Multi-Sentence AMR Representation and Evaluation</b></br>
Authors: , Naseem, Tahira, Blodgett, Austin, Kumaravel, Sadhana, O\'Gorman, Tim, Lee, Young-Suk, Flanigan, Jeffrey, Astudillo, Ram&#xf3;n Fernandez, Florian, Radu, Roukos, Salim, Schneider, Nathan</br>
  Despite extensive research on <font color="#be00be">parsing</font> of English sentences into Abstraction Meaning Representation (AMR) graphs, which are compared to gold graphs via the Smatch metric, full-document parsing into a unified graph representation lacks well-defined representation and evaluation. Taking advantage of a super-sentential level of coreference annotation from previous work, we introduce a simple algorithm for deriving a unified graph representation, avoiding the pitfalls of information loss from over-merging and lack of coherence from under-merging. Next, we describe improvements to the Smatch metric to make it tractable for comparing document-level graphs, and use it to re-evaluate the best published document-level AMR <font color="#be00be">parser</font>. We also present a pipeline approach combining the top performing AMR parser and coreference resolution systems, providing a strong baseline for future research. </br></br>

<a href='http://arxiv.org/pdf/2112.06567.pdf'>2112.06567</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.6910баллов, №1080</br>
<b>Implications of Topological Imbalance for Representation Learning on\n  Bio<font color="#640064">medic</font>al <font color="#960096">Knowledge Graph</font>s</b></br>
Authors: , Bonner, Stephen, Kirik, Ufuk, Engkvist, Ola, Tang, Jian, Barrett, Ian P</br>
  Improving on the standard of care for <font color="#be00be">diseas</font>es is predicated on better treatments, which in turn relies on finding and developing new <font color="#00be00">drug</font>s. However, drug discovery is a complex and costly process. Adoption of methods from machine learning has given rise to creation of drug discovery <font color="#960096">knowledge graph</font>s which utilize the inherent interconnected nature of the domain. Graph-based data modelling, combined with knowledge graph embeddings provide a more intuitive representation of the domain and are suitable for inference tasks such as predicting missing links. One such example would be producing ranked lists of likely associated genes for a given disease, often referred to as target discovery. It is thus critical that these predictions are not only pertinent but also biologically meaningful. However, knowledge graphs can be biased either directly due to the underlying data sources that are integrated or due to modeling choices in the construction of the graph, one consequence of which is that certain entities can get topologically overrepresented. We show how knowledge graph embedding models can be affected by this structural imbalance, resulting in densely connected entities being highly ranked no matter the context. We provide support for this observation across different datasets, models and predictive tasks. Further, we show how the graph topology can be perturbed to artificially alter the rank of a gene via random, biologically meaningless information. This suggests that such models can be more influenced by the frequency of entities rather than biological information encoded in the relations, creating issues when entity frequency is not a true reflection of underlying data. Our results highlight the importance of data modeling choices and emphasizes the need for practitioners to be mindful of these issues when <font color="#be00be">interpret</font>ing model outputs and during knowledge graph composition. </br></br>

<a href='http://arxiv.org/pdf/2112.06007.pdf'>2112.06007</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.6918баллов, №1081</br>
<b>Determinantal point processes based on orthogonal polynomials for\n  sampling minibatches in SGD</b></br>
Authors: , Bardenet, Remi, Ghosh, Subhro, Lin, Meixia</br>
  Stochastic gradient descent (SGD) is a cornerstone of machine learning. When the number N of data items is large, SGD relies on constructing an unbiased estimator of the gradient of the empirical risk using a small subset of the original dataset, called a minibatch. Default minibatch construction involves uniformly sampling a subset of the desired size, but alternatives have been explored for variance reduction. In particular, experimental evidence suggests drawing minibatches from determinantal point processes (DPPs), distributions over minibatches that favour diversity among selected items. However, like in recent work on DPPs for coresets, providing a systematic and principled understanding of how and why DPPs help has been difficult. In this work, we contribute an orthogonal polynomial-based DPP paradigm for minibatch sampling in SGD. Our approach leverages the specific data distribution at hand, which endows it with greater sensitivity and power over existing data-agnostic methods. We substantiate our method via a detailed <font color="#be00be">theor</font>etical analysis of its convergence properties, interweaving between the discrete data set and the underlying continuous domain. In particular, we show how specific DPPs and a string of controlled approximations can lead to gradient estimators with a variance that decays faster with the batchsize than under uniform sampling. Coupled with existing finite-time guarantees for SGD on convex objectives, this entails that, DPP minibatches lead to a smaller bound on the mean square approximation error than uniform minibatches. Moreover, our estimators are amenable to a recent algorithm that directly samples linear statistics of DPPs (i.e., the gradient estimator) without sampling the underlying DPP (i.e., the minibatch), thereby reducing computational overhead. We provide detailed synthetic as well as real data experiments to substantiate our theoretical claims. </br></br>

<a href='http://arxiv.org/pdf/2112.08806.pdf'>2112.08806</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.6924баллов, №1082</br>
<b>Dataset correlation inference attacks against machine learning models</b></br>
Authors: , Cre&#x163;u, Ana-Maria, Gu&#xe9;pin, Florent, de Montjoye, Yves-Alexandre</br>
  Machine learning models are increasingly used by businesses and organizations around the world to automate tasks and decision-making. Trained on potentially sensitive datasets, machine learning models have been shown to leak information about individuals in the dataset as well as global dataset information. We here take research in dataset property inference attacks one step further by proposing a new attack against ML models: a dataset correlation inference attack, where an attacker\'s goal is to infer the correlation between input variables of a model. We first show that an attacker can exploit the spherical parametrization of correlation matrices, to make an informed guess. This means that using only the correlation between the input variables and the target variable, an attacker can infer the correlation between two input variables much better than a random guess baseline. We propose a second attack which exploits the access to a machine learning model using shadow modeling to refine the guess. Our attack uses <font color="#be00be">Gaussi</font>an copula-based generative modeling to generate synthetic datasets with a wide variety of correlations in order to train a meta-model for the correlation inference task. We evaluate our attack against Logistic <font color="#be00be">Regression</font> and Multi-layer perceptron models and show it to <font color="#00be00">outperform</font> the model-less attack. Our results show that the accuracy of the second, machine learning-based attack decreases with the number of variables and converges towards the accuracy of the model-less attack. However, correlations between input variables which are highly correlated with the target variable are more vulnerable regardless of the number of variables. Our work bridges the gap between what can be considered a global leakage about the training dataset and individual-level leakages. When coupled with marginal leakage attacks,it might also constitute a first step towards dataset reconstruction. </br></br>

<a href='http://arxiv.org/pdf/2112.08692.pdf'>2112.08692</a> &nbsp&nbsp (cs:CV, cs:CL, cs:ML) &nbsp&nbsp -0.6926баллов, №1083</br>
<b>Lacuna Reconstruction: Self-supervised Pre-training for <font color="#be00be">Low-Resource</font>\n  Historical Document Transcription</b></br>
Authors: , Vogler, Nikolai, Allen, Jonathan Parkes, Miller, Matthew Thomas, Berg-Kirkpatrick, Taylor</br>
  We present a self-supervised pre-training approach for learning rich visual language representations for both handwritten and printed historical document transcription. After supervised fine-tuning of our pre-trained encoder representations for <font color="#be00be">low-resource</font> document transcription on two languages, (1) a heterogeneous set of handwritten Islamicate manuscript images and (2) early modern English printed documents, we show a meaningful improvement in recognition accuracy over the same supervised model trained from scratch with as few as 30 line image transcriptions for training. Our masked language model-<font color="#be00be">style</font> pre-training strategy, where the model is trained to be able to identify the true masked visual representation from distractors sampled from within the same line, encourages learning robust contextualized language representations invariant to scribal writing style and printing noise present across documents. </br></br>

<a href='http://arxiv.org/pdf/2112.08363.pdf'>2112.08363</a> &nbsp&nbsp (cs:ML, cs:CV) &nbsp&nbsp -0.6945баллов, №1084</br>
<b>Performance or Trust? Why Not Both. Deep AUC Maximization with\n  Self-Supervised Learning for COVID-19 Chest X-ray Classifications</b></br>
Authors: , He, Siyuan, Xi, Pengcheng, Ebadi, Ashkan, Tremblay, Stephane, Wong, Alexander</br>
  Effective representation learning is the key in improving model performance for <font color="#640064">medic</font>al image analysis. In training deep learning models, a compromise often must be made between performance and trust, both of which are essential for medical applications. Moreover, models optimized with cross-entropy loss tend to suffer from unwarranted overconfidence in the majority class and over-cautiousness in the minority class. In this work, we integrate a new surrogate loss with self-supervised learning for computer-aided screening of COVID-19 <font color="#be00be">patient</font>s using radiography images. In addition, we adopt a new quantification score to measure a model\'s trustworthiness. Ablation study is conducted for both the performance and the trust on feature learning methods and loss functions. Comparisons show that leveraging the new surrogate loss on self-supervised models can produce label-efficient networks that are both high-performing and trustworthy. </br></br>

<a href='http://arxiv.org/pdf/2112.07208.pdf'>2112.07208</a> &nbsp&nbsp (cs:NE) &nbsp&nbsp -0.6948баллов, №1085</br>
<b><font color="#be00be">Interpret</font>able Convolutional Neural Networks for Subject-Independent\n  Motor Imagery Classification</b></br>
Authors: , Bang, Ji-Seon, Lee, Seong-Whan</br>
  Deep learning frameworks have become increasingly popular in <font color="#00be00">brain</font> computer interface (BCI) study thanks to their outstanding performance. However, in terms of the classification model alone, they are treated as black box as they do not provide any information on what led them to reach a particular decision. In other words, we cannot convince whether the high performance was aroused by the neuro-physiological factors or simply noise. Because of this disadvantage, it is difficult to ensure adequate reliability compared to their high performance. In this study, we propose an explainable deep learning model for BCI. Specifically, we aim to classify<font color="#be00be"> EEG </font>signal which is obtained from the motor-imagery (MI) task. In addition, we adopted layer-wise relevance propagation (LRP) to the model to <font color="#be00be">interpret</font> the reason that the model derived certain classification output. We visualized the heatmap which indicates the output of the LRP in form of topography to certify neuro-physiological factors. Furthermore, we classified EEG with the subject-independent manner to learn robust and generalized EEG features by avoiding subject dependency. The methodology also provides the advantage of avoiding the expense of building training data for each subject. With our proposed model, we obtained generalized heatmap patterns for all subjects. As a result, we can conclude that our proposed model provides neuro-physiologically reliable interpretation. </br></br>

<a href='http://arxiv.org/pdf/2112.08735.pdf'>2112.08735</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.6984баллов, №1086</br>
<b>Pay More Attention to History: A Context Modeling Strategy for\n  Conversational Text-to-<font color="#be00be">SQL</font></b></br>
Authors: , Li, Yuntao, Zhang, Hanchu, Li, Yutian, Wang, Sirui, Wu, Wei, Zhang, Yan</br>
  Conversational text-to-<font color="#be00be">SQL</font> aims at converting multi-turn natural language queries into their corresponding SQL representations. One of the most intractable problem of conversational text-to-SQL is modeling the semantics of multi-turn queries and gathering proper information required for the current query. This paper shows that explicit modeling the semantic changes by adding each turn and the <font color="#be00be">summarization</font> of the whole context can bring better performance on converting conversational queries into SQLs. In particular, we propose two conversational modeling tasks in both turn grain and conversation grain. These two tasks simply work as auxiliary training tasks to help with multi-turn conversational semantic <font color="#be00be">parsing</font>. We conducted empirical studies and achieve new <font color="#00be00">state-of-the-art</font> results on large-scale open-domain conversational text-to-SQL dataset. The results demonstrate that the proposed mechanism significantly improves the performance of multi-turn semantic parsing. </br></br>

<a href='http://arxiv.org/pdf/2111.13657.pdf'>2111.13657</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp -0.6985баллов, №1087</br>
<b>Amazon SageMaker Model Monitor: A System for Real-Time Insights into\n  Deployed Machine Learning Models</b></br>
Authors: , Nigenda, David, Karnin, Zohar, Zafar, Muhammad Bilal, Ramesha, Raghu, Tan, Alan, Donini, Michele, Kenthapadi, Krishnaram</br>
  With the increasing adoption of machine learning (ML) models and systems in high-stakes settings across different industries, guaranteeing a model\'s performance after deployment has become crucial. Monitoring models in production is a critical aspect of ensuring their continued performance and reliability. We present Amazon SageMaker Model Monitor, a fully managed service that continuously monitors the quality of machine learning models hosted on Amazon SageMaker. Our system automatically detects data, concept, bias, and feature attribution drift in models in real-time and provides alerts so that model owners can take corrective actions and thereby maintain high quality models. We describe the key requirements obtained from <font color="#be00be">customer</font>s, system design and architecture, and methodology for detecting different types of drift. Further, we provide quantitative evaluations followed by use cases, insights, and lessons learned from more than 1.5 years of production deployment. </br></br>

<a href='http://arxiv.org/pdf/2112.09051.pdf'>2112.09051</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.7005баллов, №1088</br>
<b>Simultaneous Multivariate Forecast of Space <font color="#be00be">Weather</font> Indices using Deep\n  Neural Network Ensembles</b></br>
Authors: , Benson, Bernard, Brown, Edward, Bonasera, Stefano, Acciarini, Giacomo, P&#xe9;rez-Hern&#xe1;ndez, Jorge A., Sutton, Eric, Jah, Moriba K., Bridges, Christopher, Jin, Meng, Baydin, At&#x131;l&#x131;m G&#xfc;ne&#x15f;</br>
  Solar radio flux along with geomagnetic indices are important indicators of solar activity and its effects. Extreme solar events such as flares and geomagnetic storms can negatively affect the space environment including satellites in low-Earth orbit. Therefore, forecasting these space <font color="#be00be">weather</font> indices is of great importance in space operations and science. In this study, we propose a model based on long short-term memory neural networks to learn the distribution of time series data with the capability to provide a simultaneous multivariate 27-day forecast of the space weather indices using time series as well as solar image data. We show a 30-40\\% improvement of the root mean-square error while including solar image data with time series data compared to using time series data alone. Simple baselines such as a persistence and running average forecasts are also compared with the trained deep neural network models. We also quantify the uncertainty in our prediction using a model ensemble. </br></br>

<a href='http://arxiv.org/pdf/2112.07627.pdf'>2112.07627</a> &nbsp&nbsp (cs:AI, cs:SD) &nbsp&nbsp -0.7015баллов, №1089</br>
<b>Visualizing Ensemble Predictions of<font color="#be00be"> Music </font>Mood</b></br>
Authors: , Ye, Zelin, Chen, Min</br>
 <font color="#be00be"> Music </font>mood classification has been a challenging problem in comparison with some other classification problems (e.g., genre, composer, or period). One solution for addressing this challenging is to use an of ensemble machine learning models. In this paper, we show that visualization techniques can effectively convey the popular prediction as well as uncertainty at different music sections along the temporal axis, while enabling the analysis of individual ML models in conjunction with their application to different musical data. In addition to the traditional visual designs, such as stacked line graph, ThemeRiver, and pixel-based visualization, we introduced a new variant of ThemeRiver, called &quot;dual-flux ThemeRiver&quot;, which allows viewers to observe and measure the most popular prediction more easily than stacked line graph and ThemeRiver. Testing indicates that visualizing ensemble predictions is helpful both in model-development workflows and for annotating music using model predictions. </br></br>

<a href='http://arxiv.org/pdf/2112.08325.pdf'>2112.08325</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.7031баллов, №1090</br>
<b>ForgeryNet --<font color="#be00be"> Face </font>Forgery Analysis Challenge 2021: Methods and Results</b></br>
Authors: , He, Yinan, Sheng, Lu, Shao, Jing, Liu, Ziwei, Zou, Zhaofan, Guo, Zhizhi, Jiang, Shan, Sun, Curitis, Zhang, Guosheng, Wang, Keyao, Yue, Haixiao, Hong, Zhibin, Wang, Wanguo, Li, Zhenyu, Wang, Qi, Wang, Zhenli, Xu, Ronghao, Zhang, Mingwen, Wang, Zhiheng, Huang, Zhenhang, Zhang, Tianming, Zhao, Ningning</br>
  The rapid progress of photorealistic synthesis techniques has reached a critical point where the boundary between real and manipulated images starts to blur. Recently, a mega-scale deep<font color="#be00be"> face </font>forgery dataset, ForgeryNet which comprised of 2.9 million images and 221,247 videos has been released. It is by far the largest <font color="#00be00">publicly available</font> in terms of data-scale, manipulations (7 image-level approaches, 8 video-level approaches), perturbations (36 independent and more mixed perturbations), and annotations (6.3 million classification labels, 2.9 million manipulated area annotations, and 221,247 temporal forgery segment labels). This paper reports methods and results in the ForgeryNet - Face Forgery Analysis Challenge 2021, which employs the ForgeryNet benchmark. The model evaluation is conducted offline on the <font color="#be00be">private</font> test set. A total of 186 participants registered for the competition, and 11 teams made valid submissions. We will analyze the top-ranked solutions and present some discussion on future work directions. </br></br>

<a href='http://arxiv.org/pdf/2112.06448.pdf'>2112.06448</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.7070баллов, №1091</br>
<b>Plurality and Quantification in Graph Representation of Meaning</b></br>
Authors: , Cao, Yu</br>
  In this thesis we present a semantic representation formalism based on directed graphs and explore its linguistic adequacy and explanatory benefits in the semantics of plurality and quantification. Our graph language covers the essentials of natural language semantics using only monadic second-order variables. We define its model-<font color="#be00be">theor</font>etical <font color="#be00be">interpret</font>ation in terms of graph traversal, where the relative scope of variables arises from their order of valuation. We present a unification-based mechanism for constructing semantic graphs at a simple syntax-semantics interface, where syntax as a partition function on discourse referents is implemented with categorial grammars by establishing a partly deterministic relation between semantics and syntactic distribution. This mechanism is automated to facilitate future exploration. The present graph formalism is applied to linguistic issues in distributive predication, cross-categorial conjunction, and scope permutation of quantificational expressions, including the exceptional scoping behaviors of indefinites. </br></br>

<a href='http://arxiv.org/pdf/2112.06837.pdf'>2112.06837</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.7104баллов, №1092</br>
<b>Sparse Interventions in Language Models with Differentiable Masking</b></br>
Authors: , De Cao, Nicola, Schmid, Leon, Hupkes, Dieuwke, Titov, Ivan</br>
  There has been a lot of interest in understanding what information is captured by hidden representations of language models (LMs). Typically, <font color="#be00be">interpret</font>ation methods i) do not guarantee that the model actually uses the encoded information, and ii) do not discover small subsets of neurons responsible for a considered phenomenon. Inspired by causal mediation analysis, we propose a method that discovers within a neural LM a small subset of neurons responsible for a particular linguistic phenomenon, i.e., subsets causing a change in the corresponding token emission probabilities. We use a differentiable relaxation to approximately search through the combinatorial space. An $L_0$ regularization term ensures that the search converges to discrete and sparse solutions. We apply our method to analyze subject-verb number agreement and <font color="#be00be">gender bias</font> detection in LSTMs. We observe that it is fast and finds better solutions than the alternative (REINFORCE). Our experiments confirm that each of these phenomenons is mediated through a small subset of neurons that do not play any other discernible role. </br></br>

<a href='http://arxiv.org/pdf/2112.07219.pdf'>2112.07219</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.7120баллов, №1093</br>
<b>A real-time spatiotemporal AI model analyzes skill in open surgical\n  videos</b></br>
Authors: , Goodman, Emmett D., Patel, Krishna K., Zhang, Yilun, Locke, William, Kennedy, Chris J., Mehrotra, Rohan, Ren, Stephen, Guan, Melody, Downing, Maren, Chen, Hao Wei, Clark, Jevin Z., Brat, Gabriel A., Yeung, Serena</br>
  Open procedures represent the dominant form of surgery worldwide. Artificial intelligence (AI) has the potential to optimize surgical practice and improve <font color="#be00be">patient</font> outcomes, but efforts have focused primarily on minimally invasive techniques. Our work overcomes existing data limitations for training AI models by curating, from YouTube, the largest dataset of open surgical videos to date: 1997 videos from 23 surgical procedures uploaded from 50 countries. Using this dataset, we developed a multi-task AI model capable of real-time understanding of surgical behaviors, hands, and tools - the building blocks of procedural flow and surgeon skill. We show that our model generalizes across diverse surgery types and environments. Illustrating this generalizability, we directly applied our YouTube-trained model to analyze open surgeries prospectively collected at an academic <font color="#640064">medic</font>al center and identified kinematic descriptors of surgical skill related to efficiency of hand motion. Our Annotated Videos of Open Surgery (AVOS) dataset and trained model will be made available for further development of surgical AI. </br></br>

<a href='http://arxiv.org/pdf/2112.06630.pdf'>2112.06630</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.7168баллов, №1094</br>
<b>Fast Single-Core K-<font color="#be00be">Nearest Neighbo</font>r Graph Computation</b></br>
Authors: , Kluser, Dan, Bokstaller, Jonas, Rutz, Samuel, Buner, Tobias</br>
  Fast and reliable K-<font color="#be00be">Nearest Neighbo</font>r Graph algorithms are more important than ever due to their widespread use in many data processing techniques. This paper presents a runtime optimized C implementation of the heuristic &quot;NN-Descent&quot; algorithm by Wei Dong et al. for the l2-distance metric. Various implementation optimizations are explained which improve performance for low-dimensional as well as high dimensional datasets. Optimizations to speed up the selection of which datapoint pairs to evaluate the distance for are primarily impactful for low-dimensional datasets. A heuristic which exploits the iterative nature of NN-Descent to reorder data in memory is presented which enables better use of locality and thereby improves the runtime. The restriction to the l2-distance metric allows for the use of blocked distance evaluations which significantly increase performance for high dimensional datasets. In combination the optimizations yield an implementation which significantly <font color="#00be00">outperform</font>s a widely used implementation of NN-Descent on all considered datasets. For instance, the runtime on the popular MNIST handwritten digits dataset is halved. </br></br>

<a href='http://arxiv.org/pdf/2112.05459.pdf'>2112.05459</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.7179баллов, №1095</br>
<b><font color="#be00be">Sentiment</font> Analysis on Brazilian Portuguese User Reviews</b></br>
Authors: , Souza, Frederico, Filho, Jo&#xe3;o</br>
  <font color="#be00be">Sentiment</font> Analysis is one of the most classical and primarily studied natural language processing tasks. This problem had a notable advance with the proposition of more complex and scalable machine learning models. Despite this progress, the Brazilian Portuguese language still disposes only of limited linguistic resources, such as datasets dedicated to sentiment classification, especially when considering the existence of predefined partitions in training, testing, and validation sets that would allow a more fair comparison of different algorithm alternatives. Motivated by these issues, this work analyzes the predictive performance of a range of document embedding strategies, assuming the polarity as the system outcome. This analysis includes five sentiment analysis datasets in Brazilian Portuguese, unified in a single dataset, and a reference partitioning in training, testing, and validation sets, both made <font color="#00be00">publicly available</font> through a digital repository. A cross-evaluation of dataset-specific models over different contexts is conducted to evaluate their generalization capabilities and the feasibility of adopting a unique model for addressing all scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.08959.pdf'>2112.08959</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.7211баллов, №1096</br>
<b>A molecular generative model with genetic algorithm and tree search for\n  <font color="#be00be">cancer</font> samples</b></br>
Authors: , Park, Sejin, Lee, Hyunju</br>
  Personalized <font color="#640064">medic</font>ine is expected to maximize the intended <font color="#00be00">drug</font> effects and minimize side effects by treating <font color="#be00be">patient</font>s based on their genetic profiles. Thus, it is important to generate drugs based on the genetic profiles of <font color="#be00be">diseas</font>es, especially in anti<font color="#be00be">cancer</font> drug discovery. However, this is challenging because the vast chemical space and variations in cancer properties require a huge time resource to search for proper <font color="#00be00">molecule</font>s. Therefore, an efficient and fast search method considering genetic profiles is required for de novo molecular design of anticancer drugs. Here, we propose a faster molecular generative model with genetic algorithm and tree search for cancer samples (FasterGTS). FasterGTS is constructed with a genetic algorithm and a Monte Carlo tree search with three deep neural networks: supervised learning, self-trained, and value networks, and it generates anticancer molecules based on the genetic profiles of a cancer sample. When compared to other methods, FasterGTS generated cancer sample-specific molecules with general chemical properties required for cancer drugs within the limited numbers of samplings. We expect that FasterGTS contributes to the anticancer drug generation. </br></br>

<a href='http://arxiv.org/pdf/2112.05758.pdf'>2112.05758</a> &nbsp&nbsp (cs:AI, cs:CV, cs:ML) &nbsp&nbsp -0.7223баллов, №1097</br>
<b>Edge-Enhanced Dual Discriminator Generative Adversarial Network for Fast\n <font color="#be00be"> MRI </font>with Parallel Imaging Using Multi-view Information</b></br>
Authors: , Huang, Jiahao, Ding, Weiping, Lv, Jun, Yang, Jingwen, Dong, Hao, Del Ser, Javier, Xia, Jun, Ren, Tiaojuan, Wong, Stephen, Yang, Guang</br>
  In <font color="#be00be">clinic</font>al <font color="#640064">medic</font>ine, <font color="#be00be">magnetic resonance</font> imaging (MRI) is one of the most important tools for <font color="#be00be">diagnos</font>is, triage, prognosis, and treatment planning. However,<font color="#be00be"> MRI </font>suffers from an inherent slow data acquisition process because data is collected sequentially in k-space. In recent years, most MRI reconstruction methods proposed in the literature focus on holistic image reconstruction rather than enhancing the edge information. This work steps aside this general trend by elaborating on the enhancement of edge information. Specifically, we introduce a novel parallel imaging coupled dual discriminator generative adversarial network (PIDD-GAN) for fast multi-channel MRI reconstruction by incorporating multi-view information. The dual discriminator design aims to improve the edge information in MRI reconstruction. One discriminator is used for holistic image reconstruction, whereas the other one is responsible for enhancing edge information. An improved U-Net with local and global residual learning is proposed for the generator. Frequency channel attention blocks (FCA Blocks) are embedded in the generator for incorporating attention mechanisms. Content loss is introduced to train the generator for better reconstruction quality. We performed comprehensive experiments on Calgary-Campinas public <font color="#00be00">brain</font> MR dataset and compared our method with <font color="#00be00">state-of-the-art</font> MRI reconstruction methods. Ablation studies of residual learning were conducted on the MICCAI13 dataset to validate the proposed modules. Results show that our PIDD-GAN provides high-quality reconstructed MR images, with well-preserved edge information. The time of single-image reconstruction is below 5ms, which meets the demand of faster processing. </br></br>

<a href='http://arxiv.org/pdf/2111.09486.pdf'>2111.09486</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.7260баллов, №1098</br>
<b>SDCUP: Schema Dependency-Enhanced Curriculum Pre-Training for Table\n  Semantic <font color="#be00be">Parsing</font></b></br>
Authors: , Qin, Bowen, Wang, Lihan, Hui, Binyuan, Geng, Ruiying, Cao, Zheng, Yang, Min, Sun, Jian, Li, Yongbin</br>
  Recently pre-training models have significantly improved the performance of various NLP tasks by leveraging large-scale text corpora to improve the contextual representation ability of the neural network. The large pre-training language model has also been applied in the area of table semantic <font color="#be00be">parsing</font>. However, existing pre-training approaches have not carefully explored explicit interaction relationships between a question and the corresponding database schema, which is a key ingredient for uncovering their semantic and structural correspondence. Furthermore, the question-aware representation learning in the schema grounding context has received less attention in pre-training objective.To alleviate these issues, this paper designs two novel pre-training objectives to impose the desired inductive bias into the learned representations for table pre-training. We further propose a schema-aware <font color="#006400">curriculum learning</font> approach to mitigate the impact of noise and learn effectively from the pre-training data in an easy-to-hard manner. We evaluate our pre-trained framework by fine-tuning it on two benchmarks, Spider and SQUALL. The results demonstrate the effectiveness of our pre-training objective and curriculum compared to a variety of baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.08432.pdf'>2112.08432</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -0.7382баллов, №1099</br>
<b>Expert and Crowd-Guided Affect Annotation and Prediction</b></br>
Authors: , Subramanian, Ramanathan, Yan, Yan, Sebe, Nicu</br>
  We employ crowdsourcing to acquire time-continuous affective annotations for movie clips, and refine noisy models trained from these crowd annotations incorporating expert information within a Multi-task Learning (MTL) framework. We propose a novel \\textbf{e}xpert \\textbf{g}uided MTL (EG-MTL) algorithm, which minimizes the loss with respect to both crowd and expert labels to learn a set of weights corresponding to each movie clip for which crowd annotations are acquired. We employ EG-MTL to solve two problems, namely, \\textbf{\\texttt{P1}}: where dynamic annotations acquired from both experts and crowdworkers for the \\textbf{Validation} set are used to train a <font color="#be00be">regression</font> model with audio-visual clip descriptors as features, and predict dynamic arousal and valence levels on 5--15 second snippets derived from the clips; and \\textbf{\\texttt{P2}}: where a classification model trained on the \\textbf{Validation} set using dynamic crowd and expert annotations (as features) and static affective clip labels is used for binary <font color="#be00be">emotion</font> recognition on the \\textbf{Evaluation} set for which only dynamic crowd annotations are available. Observed experimental results confirm the effectiveness of the EG-MTL algorithm, which is reflected via improved arousal and valence estimation for \\textbf{\\texttt{P1}}, and higher recognition accuracy for \\textbf{\\texttt{P2}}. </br></br>

<a href='http://arxiv.org/pdf/2112.05409.pdf'>2112.05409</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.7414баллов, №1100</br>
<b>Defending Label Inference and Backdoor Attacks in Vertical <font color="#be00be">Federated</font>\n  Learning</b></br>
Authors: , Liu, Yang, Yi, Zhihao, Kang, Yan, He, Yuanqin, Liu, Wenhan, Zou, Tianyuan, Yang, Qiang</br>
  In collaborative learning settings like <font color="#be00be">federated</font> learning, curious parities might be honest but are attempting to infer other parties\' <font color="#be00be">private</font> data through inference attacks while malicious parties might manipulate the learning process for their own purposes through backdoor attacks. However, most existing works only consider the federated learning scenario where data are partitioned by samples (HFL). The feature-partitioned federated learning (VFL) can be another important scenario in many <font color="#009600">real-world</font> applications. Attacks and defenses in such scenarios are especially challenging when the attackers and the defenders are not able to access the features or model parameters of other participants. Previous works have only shown that private labels can be reconstructed from per-sample gradients. In this paper, we first show that private labels can be reconstructed when only batch-averaged gradients are revealed, which is against the common presumption. In addition, we show that a passive party in VFL can even replace its corresponding labels in the active party with a target label through a gradient-replacement attack. To defend against the first attack, we introduce a novel technique termed confusional autoencoder (CoAE), based on autoencoder and entropy regularization. We demonstrate that label inference attacks can be successfully blocked by this technique while hurting less main task accuracy compared to existing methods. Our CoAE technique is also effective in defending the gradient-replacement backdoor attack, making it an universal and practical defense strategy with no change to the original VFL protocol. We demonstrate the effectiveness of our approaches under both two-party and multi-party VFL settings. To the best of our knowledge, this is the first systematic study to deal with label inference and backdoor attacks in the feature-partitioned federated learning framework. </br></br>

<a href='http://arxiv.org/pdf/2112.06654.pdf'>2112.06654</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.7419баллов, №1101</br>
<b>Towards Open-World<font color="#be00be"> EEG </font>Decoding via Deep Learning</b></br>
Authors: , Chen, Xun, Li, Chang, Liu, Aiping, McKeown, Martin J., Qian, Ruobing, Wang, Z. Jane</br>
  Electroencephalogram (EEG) decoding aims to identify the perceptual, semantic, and cognitive content of neural processing based on non-invasively measured <font color="#00be00">brain</font> activity. Traditional<font color="#be00be"> EEG </font>decoding methods have achieved moderate success when applied to data acquired in static, well-controlled lab environments. However, an open-world environment is a more realistic setting, where situations affecting EEG recordings can emerge unexpectedly, significantly weakening the robustness of existing methods. In recent years, deep learning (DL) has emerged as a potential solution for such problems due to its superior capacity in feature extraction. It overcomes the limitations of defining `handcrafted\' features or features extracted using shallow architectures, but typically requires large amounts of costly, expertly-labelled data - something not always obtainable. Combining DL with domain-specific knowledge may allow for development of robust approaches to decode brain activity even with small-sample data. Although various DL methods have been proposed to tackle some of the challenges in EEG decoding, a systematic tutorial overview, particularly for open-world applications, is currently lacking. This article therefore provides a comprehensive survey of DL methods for open-world EEG decoding, and identifies promising research directions to inspire future studies for EEG decoding in <font color="#009600">real-world</font> applications. </br></br>

<a href='http://arxiv.org/pdf/2112.06149.pdf'>2112.06149</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.7422баллов, №1102</br>
<b>Two New Stenosis Detection Methods of Coronary Angiograms</b></br>
Authors: , Liu, Yaofang, Zhang, Xinyue, Wan, Wenlong, Liu, Shaoyu, Liu, Yingdi, Liu, Hu, Zeng, Xueying, Zhang, Qing</br>
  Coronary angiography is the &quot;gold standard&quot; for <font color="#be00be">diagnos</font>ing coronary artery <font color="#be00be">diseas</font>e (CAD). At present, the methods for detecting and evaluating coronary artery stenosis cannot satisfy the <font color="#be00be">clinic</font>al needs, e.g., there is no prior study of detecting stenoses in prespecified vessel segments, which is necessary in clinical practice. Two vascular stenosis detection methods are proposed to assist the diagnosis. The first one is an automatic method, which can automatically extract the entire coronary artery tree and mark all the possible stenoses. The second one is an interactive method. With this method, the user can choose any vessel segment to do further analysis of its stenoses. Experiments show that the proposed methods are robust for angiograms with various vessel structures. The precision, sensitivity, and $F_1$ score of the automatic stenosis detection method are 0.821, 0.757, and 0.788, respectively. Further investigation proves that the interactive method can provide a more precise outcome of stenosis detection, and our quantitative analysis is closer to reality. The proposed automatic method and interactive method are effective and can complement each other in clinical practice. The first method can be used for preliminary screening, and the second method can be used for further quantitative analysis. We believe the proposed solution is more suitable for the clinical diagnosis of CAD. </br></br>

<a href='http://arxiv.org/pdf/2112.05353.pdf'>2112.05353</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.7517баллов, №1103</br>
<b>Learning-Augmented Algorithms for Online Steiner Tree</b></br>
Authors: , Xu, Chenyang, Moseley, Benjamin</br>
  This paper considers the recently popular beyond-worst-case algorithm analysis model which integrates machine-learned predictions with online algorithm design. We consider the online Steiner tree problem in this model for both directed and undirected graphs. Steiner tree is known to have strong lower bounds in the online setting and any algorithm\'s worst-case guarantee is far from desirable. This paper considers algorithms that predict which terminal arrives online. The predictions may be incorrect and the algorithms\' performance is parameterized by the number of incorrectly predicted terminals. These guarantees ensure that algorithms break through the online lower bounds with good predictions and the <font color="#960096">competitive</font> ratio gracefully degrades as the prediction error grows. We then observe that the <font color="#be00be">theor</font>y is predictive of what will occur empirically. We show on graphs where terminals are drawn from a distribution, the new online algorithms have strong performance even with modestly correct predictions. </br></br>

<a href='http://arxiv.org/pdf/2112.08578.pdf'>2112.08578</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.7577баллов, №1104</br>
<b>CLICKER: A Computational LInguistics Classification Scheme for\n  Educational Resources</b></br>
Authors: , Hingmire, Swapnil, Li, Irene, Kawamura, Rena, Chen, Benjamin, Fabbri, Alexander, Tang, Xiangru, Liu, Yixin, George, Thomas, Liao, Tammy, Wong, Wai Pan, Yan, Vanessa, Zhou, Richard, Palshikar, Girish K., Radev, Dragomir</br>
  A classification scheme of a scientific subject gives an overview of its body of knowledge. It can also be used to facilitate access to research articles and other materials related to the subject. For example, the ACM Computing Classification System (CCS) is used in the ACM Digital Library search interface and also for indexing computer science papers. We observed that a comprehensive classification system like CCS or Mathematics Subject Classification (MSC) does not exist for Computational Linguistics (CL) and Natural Language Processing (NLP). We propose a classification scheme -- CLICKER for CL/NLP based on the analysis of online lectures from 77 university courses on this subject. The currently proposed taxonomy includes 334 topics and focuses on educational aspects of CL/NLP; it is based primarily, but not exclusively, on lecture notes from NLP courses. We discuss how such a taxonomy can help in various <font color="#009600">real-world</font> applications, including tutoring platforms, resource <font color="#be00be">retrieval</font>, resource <font color="#be00be">recommendat</font>ion, prerequisite chain learning, and survey generation. </br></br>

<a href='http://arxiv.org/pdf/2112.08184.pdf'>2112.08184</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.7590баллов, №1105</br>
<b>Interactive Visualization and Representation Analysis Applied to Glacier\n  <font color="#be00be">Segmentation</font></b></br>
Authors: , Zheng, Minxing, Miao, Xinran, Sankaran, Kris</br>
  <font color="#be00be">Interpret</font>ability has attracted increasing attention in earth observation problems. We apply interactive visualization and representation analysis to guide interpretation of glacier <font color="#be00be">segmentation</font> models. We visualize the activations from a U-Net to understand and evaluate the model performance. We build an online interface using the Shiny R package to provide comprehensive error analysis of the predictions. Users can interact with the panels and discover model failure modes. Further, we discuss how visualization can provide sanity checks during data preprocessing and model training. </br></br>

<a href='http://arxiv.org/pdf/2112.05760.pdf'>2112.05760</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.7634баллов, №1106</br>
<b>Learning Representations with Contrastive Self-Supervised Learning for\n  Histo<font color="#be00be">patholog</font>y Applications</b></br>
Authors: , Stacke, Karin, Unger, Jonas, Lundstr&#xf6;m, Claes, Eilertsen, Gabriel</br>
  Unsupervised learning has made substantial progress over the last few years, especially by means of contrastive self-supervised learning. The dominating dataset for benchmarking self-supervised learning has been ImageNet, for which recent methods are approaching the performance achieved by fully supervised training. The ImageNet dataset is however largely object-centric, and it is not clear yet what potential those methods have on widely different datasets and tasks that are not object-centric, such as in digital <font color="#be00be">patholog</font>y. While self-supervised learning has started to be explored within this area with encouraging results, there is reason to look closer at how this setting differs from natural images and ImageNet. In this paper we make an in-depth analysis of contrastive learning for histopathology, pin-pointing how the contrastive objective will behave differently due to the characteristics of histopathology data. We bring forward a number of considerations, such as view generation for the contrastive objective and hyper-parameter tuning. In a large battery of experiments, we analyze how the downstream performance in tissue classification will be affected by these considerations. The results point to how contrastive learning can reduce the annotation effort within digital pathology, but that the specific dataset characteristics need to be considered. To take full advantage of the contrastive learning objective, different calibrations of view generation and hyper-parameters are required. Our results pave the way for realizing the full potential of self-supervised learning for histopathology applications. </br></br>

<a href='http://arxiv.org/pdf/2112.05748.pdf'>2112.05748</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.7671баллов, №1107</br>
<b>Deep Learning based Framework for Automatic <font color="#be00be">Diagnos</font>is of Glaucoma based\n  on analysis of Focal Notching in the Optic Nerve Head</b></br>
Authors: , Dasgupta, Sneha, Mukherjee, Rishav, Dutta, Kaushik, Sen, Anindya</br>
  Automatic evaluation of the retinal fundus image is emerging as one of the most important tools for early detection and treatment of progressive eye <font color="#be00be">diseas</font>es like Glaucoma. Glaucoma results to a progressive degeneration of vision and is characterized by the deformation of the shape of optic cup and the degeneration of the blood vessels resulting in the formation of a notch along the neuroretinal rim. In this paper, we propose a deep learning-based pipeline for automatic <font color="#be00be">segmentation</font> of optic disc (OD) and optic cup (OC) regions from Digital Fundus Images (DFIs), thereby extracting distinct features necessary for prediction of Glaucoma. This methodology has utilized focal notch analysis of neuroretinal rim along with cup-to-disc ratio values as classifying parameters to enhance the accuracy of Computer-aided design (CAD) systems in analyzing glaucoma. Support Vector-based Machine Learning algorithm is used for classification, which classifies DFIs as Glaucomatous or Normal based on the extracted features. The proposed pipeline was evaluated on the freely available DRISHTI-GS dataset with a resultant accuracy of 93.33% for detecting Glaucoma from DFIs. </br></br>

<a href='http://arxiv.org/pdf/2112.05355.pdf'>2112.05355</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.7724баллов, №1108</br>
<b>LUNAR: Unifying Local <font color="#be00be">Outlier</font> Detection Methods via Graph Neural\n  Networks</b></br>
Authors: , Goodge, Adam, Hooi, Bryan, Ng, See Kiong, Ng, Wee Siong</br>
  Many well-established <font color="#be00be">anomal</font>y detection methods use the distance of a sample to those in its local neighbourhood: so-called `local <font color="#be00be">outlier</font> methods\', such as LOF and DBSCAN. They are popular for their simple principles and strong performance on unstructured, feature-based data that is commonplace in many practical applications. However, they cannot learn to adapt for a particular set of data due to their lack of trainable parameters. In this paper, we begin by unifying local outlier methods by showing that they are particular cases of the more general message passing framework used in graph neural networks. This allows us to introduce learnability into local outlier methods, in the form of a neural network, for greater flexibility and expressivity: specifically, we propose LUNAR, a novel, graph neural network-based anomaly detection method. LUNAR learns to use information from the <font color="#be00be">nearest neighbo</font>urs of each node in a trainable way to find anomalies. We show that our method performs significantly better than existing local outlier methods, as well as <font color="#00be00">state-of-the-art</font> deep baselines. We also show that the performance of our method is much more robust to different settings of the local neighbourhood size. </br></br>

<a href='http://arxiv.org/pdf/2112.05780.pdf'>2112.05780</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.7744баллов, №1109</br>
<b>A Scoping Review of <font color="#00be00">Publicly Available</font> Language Tasks in <font color="#be00be">Clinic</font>al\n  Natural Language Processing</b></br>
Authors: , Gao, Yanjun, Dligach, Dmitriy, Christensen, Leslie, Tesch, Samuel, Laffin, Ryan, Xu, Dongfang, Miller, Timothy, Uzuner, Ozlem, Churpek, Matthew M, Afshar, Majid</br>
  Objective: to provide a scoping review of papers on <font color="#be00be">clinic</font>al natural language processing (NLP) tasks that use <font color="#00be00">publicly available</font> electronic health record data from a cohort of <font color="#be00be">patient</font>s. Materials and Methods: We searched six databases, including bio<font color="#640064">medic</font>al research and computer science literature database. A round of title/abstract screening and full-text screening were conducted by two reviewers. Our method followed the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) guidelines. Results: A total of 35 papers with 47 clinical NLP tasks met inclusion criteria between 2007 and 2021. We categorized the tasks by the type of NLP problems, including name entity recognition, <font color="#be00be">summarization</font>, and other NLP tasks. Some tasks were introduced with a topic of clinical decision support applications, such as substance abuse, phenotyping, cohort selection for clinical trial. We summarized the tasks by publication and dataset information. Discussion: The breadth of clinical NLP tasks keeps growing as the field of NLP evolves with advancements in language systems. However, gaps exist in divergent interests between general domain NLP community and clinical informatics community, and in generalizability of the data sources. We also identified issues in data selection and preparation including the lack of time-sensitive data, and invalidity of problem size and evaluation. Conclusions: The existing clinical NLP tasks cover a wide range of topics and the field will continue to grow and attract more attention from both general domain NLP and clinical informatics community. We encourage future work to incorporate multi-disciplinary collaboration, reporting transparency, and standardization in data preparation. </br></br>

<a href='http://arxiv.org/pdf/2112.07940.pdf'>2112.07940</a> &nbsp&nbsp (cs:SD, cs:CL) &nbsp&nbsp -0.7848баллов, №1110</br>
<b>The exploitation of Multiple Feature Extraction Techniques for Speaker\n  Identification in <font color="#be00be">Emotion</font>al States under Disguised Voices</b></br>
Authors: , Hindawi, Noor Ahmad Al, Shahin, Ismail, Nassif, Ali Bou</br>
  Due to improvements in artificial intelligence, speaker identification (SI) technologies have brought a great direction and are now widely used in a variety of sectors. One of the most important components of SI is feature extraction, which has a substantial impact on the SI process and performance. As a result, numerous feature extraction strategies are thoroughly investigated, contrasted, and analyzed. This article exploits five distinct feature extraction methods for speaker identification in disguised voices under <font color="#be00be">emotion</font>al environments. To evaluate this work significantly, three effects are used: high-pitched, low-pitched, and Electronic Voice Conversion (EVC). Experimental results reported that the concatenated Mel-Frequency Cepstral Coefficients (MFCCs), MFCCs-delta, and MFCCs-delta-delta is the best feature extraction method. </br></br>

<a href='http://arxiv.org/pdf/2112.05324.pdf'>2112.05324</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.7912баллов, №1111</br>
<b>Attention-based Transformation from Latent Features to <font color="#be00be">Point Cloud</font>s</b></br>
Authors: , Zhang, Kaiyi, Yang, Ximing, Wu, Yuan, Jin, Cheng</br>
  In <font color="#be00be">point cloud</font> generation and completion, previous methods for transforming latent features to point clouds are generally based on fully connected layers (FC-based) or folding operations (Folding-based). However, point clouds generated by FC-based methods are usually troubled by <font color="#be00be">outlier</font>s and rough surfaces. For folding-based methods, their data flow is large, convergence speed is slow, and they are also hard to handle the generation of non-smooth surfaces. In this work, we propose AXform, an attention-based method to transform latent features to point clouds. AXform first generates points in an interim space, using a fully connected layer. These interim points are then aggregated to generate the target point cloud. AXform takes both parameter sharing and data flow into account, which makes it has fewer outliers, fewer network parameters, and a faster convergence speed. The points generated by AXform do not have the strong 2-manifold constraint, which improves the generation of non-smooth surfaces. When AXform is expanded to multiple branches for local generations, the centripetal constraint makes it has properties of self-<font color="#be00be">clustering</font> and space consistency, which further enables unsupervised semantic <font color="#be00be">segmentation</font>. We also adopt this scheme and design AXformNet for point cloud completion. Considerable experiments on different datasets show that our methods achieve <font color="#00be00">state-of-the-art</font> results. </br></br>

<a href='http://arxiv.org/pdf/2112.07836.pdf'>2112.07836</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.7979баллов, №1112</br>
<b>Communication-Efficient Distributed SGD with Compressed Sensing</b></br>
Authors: , Tang, Yujie, Ramanathan, Vikram, Zhang, Junshan, Li, Na</br>
  We consider large scale distributed optimization over a set of edge devices connected to a central server, where the limited communication bandwidth between the server and edge devices imposes a significant bottleneck for the optimization procedure. Inspired by recent advances in <font color="#be00be">federated</font> learning, we propose a distributed stochastic gradient descent (SGD) type algorithm that exploits the sparsity of the gradient, when possible, to reduce communication burden. At the heart of the algorithm is to use compressed sensing techniques for the compression of the local stochastic gradients at the device side; and at the server side, a sparse approximation of the global stochastic gradient is recovered from the noisy aggregated compressed local gradients. We conduct <font color="#be00be">theor</font>etical analysis on the convergence of our algorithm in the presence of noise perturbation incurred by the communication channels, and also conduct numerical experiments to corroborate its effectiveness. </br></br>

<a href='http://arxiv.org/pdf/2111.12541.pdf'>2111.12541</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.8001баллов, №1113</br>
<b>Rethinking the modeling of the instrumental response of telescopes with\n  a differentiable optical model</b></br>
Authors: , Liaudat, Tobias, Starck, Jean-Luc, Kilbinger, Martin, Frugier, Pierre-Antoine</br>
  We propose a paradigm shift in the data-driven modeling of the instrumental response field of telescopes. By adding a differentiable optical forward model into the modeling framework, we change the data-driven modeling space from the pixels to the wavefront. This allows to transfer a great deal of complexity from the instrumental response into the forward model while being able to adapt to the observations, remaining data-driven. Our framework allows a way forward to building powerful models that are physically motivated, <font color="#be00be">interpret</font>able, and that do not require special calibration data. We show that for a simplified setting of a space telescope, this framework represents a real performance breakthrough compared to existing data-driven approaches with reconstruction errors decreasing 5 fold at observation resolution and more than 10 fold for a 3x <font color="#be00be">super-resolution</font>. We successfully model chromatic variations of the instrument\'s response only using noisy broad-band in-focus observations. </br></br>

<a href='http://arxiv.org/pdf/2112.03203.pdf'>2112.03203</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.8035баллов, №1114</br>
<b>An unsupervised extractive <font color="#be00be">summarization</font> method based on multi-round\n  computation</b></br>
Authors: , Tao, Dehao, Xiong, Yingzhu, He, Jin, Skevin, Huang, Yongfeng</br>
  Text <font color="#be00be">summarization</font> methods have attracted much attention all the time. In recent years, deep learning has been applied to text summarization, and it turned out to be pretty effective. However, most of the current text summarization methods based on deep learning need large-scale datasets, which is difficult to achieve in practical applications. In this paper, an unsupervised extractive text summarization method based on multi-round calculation is proposed. Based on the directed graph algorithm, we change the traditional method of calculating the sentence ranking at one time to multi-round calculation, and the summary sentences are dynamically optimized after each round of calculation to better match the characteristics of the text. In this paper, experiments are carried out on four data sets, each separately containing <font color="#be00be">Chinese</font>, English, long and short texts. The experiment results show that our method has better performance than both baseline methods and other unsupervised methods and is robust on different datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.07790.pdf'>2112.07790</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.8045баллов, №1115</br>
<b>Maximum <font color="#be00be">Bayes</font> Smatch Ensemble Distillation for AMR <font color="#be00be">Parsing</font></b></br>
Authors: , Lee, Young-Suk, Astudillo, Ramon Fernandez, Hoang, Thanh Lam, Naseem, Tahira, Florian, Radu, Roukos, Salim</br>
  AMR <font color="#be00be">parsing</font> has experienced an unprecendented increase in performance in the last three years, due to a mixture of effects including architecture improvements and transfer learning. Self-learning techniques have also played a role in pushing performance forward. However, for most recent high performant <font color="#be00be">parser</font>s, the effect of self-learning and silver data generation seems to be fading. In this paper we show that it is possible to overcome this diminishing returns of silver data by combining Smatch-based ensembling techniques with ensemble distillation. In an extensive experimental setup, we push single model English parser performance above 85 Smatch for the first time and return to substantial gains. We also attain a new <font color="#00be00">state-of-the-art</font> for cross-lingual AMR parsing for <font color="#be00be">Chinese</font>, German, Italian and Spanish. Finally we explore the impact of the proposed distillation technique on domain adaptation, and show that it can produce gains rivaling those of human annotated data for QALD-9 and achieve a new state-of-the-art for BioAMR. </br></br>

<a href='http://arxiv.org/pdf/2112.05422.pdf'>2112.05422</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.8049баллов, №1116</br>
<b>Robustification of Online Graph Exploration Methods</b></br>
Authors: , Eberle, Franziska, Lindermayr, Alexander, Megow, Nicole, N&#xf6;lke, Lukas, Schl&#xf6;ter, Jens</br>
  Exploring unknown environments is a fundamental task in many domains, e.g., robot navigation, network security, and internet search. We initiate the study of a learning-augmented variant of the classical, notoriously hard online graph exploration problem by adding access to machine-learned predictions. We propose an algorithm that naturally integrates predictions into the well-known <font color="#be00be">Nearest Neighbo</font>r (NN) algorithm and significantly <font color="#00be00">outperform</font>s any known online algorithm if the prediction is of high accuracy while maintaining good guarantees when the prediction is of poor quality. We provide <font color="#be00be">theor</font>etical worst-case bounds that gracefully degrade with the prediction error, and we complement them by computational experiments that confirm our results. Further, we extend our concept to a general framework to robustify algorithms. By interpolating carefully between a given algorithm and NN, we prove new performance bounds that leverage the individual good performance on particular inputs while establishing robustness to arbitrary inputs. </br></br>

<a href='http://arxiv.org/pdf/2112.09126.pdf'>2112.09126</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.8116баллов, №1117</br>
<b>IS-COUNT: Large-scale Object Counting from Satellite Images with\n  Covariate-based Importance Sampling</b></br>
Authors: , Meng, Chenlin, Liu, Enci, Neiswanger, Willie, Song, Jiaming, Burke, Marshall, Lobell, David, Ermon, Stefano</br>
  <font color="#be00be">Object detection</font> in high-resolution satellite imagery is emerging as a scalable alternative to on-the-ground survey data collection in many environmental and socio<font color="#be00be">economic</font> monitoring applications. However, performing object detection over large geographies can still be prohibitively expensive due to the high cost of purchasing imagery and compute. Inspired by traditional survey data collection strategies, we propose an approach to estimate object count statistics over large geographies through sampling. Given a cost budget, our method selects a small number of representative areas by sampling from a learnable proposal distribution. Using importance sampling, we are able to accurately estimate object counts after processing only a small fraction of the images compared to an exhaustive approach. We show empirically that the proposed framework achieves strong performance on estimating the number of buildings in the United States and Africa, cars in Kenya, brick kilns in Bangladesh, and swimming pools in the U.S., while requiring as few as 0.01% of satellite images compared to an exhaustive approach. </br></br>

<a href='http://arxiv.org/pdf/2112.05310.pdf'>2112.05310</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.8143баллов, №1118</br>
<b>Robustness Certificates for Implicit Neural Networks: A Mixed Monotone\n  Contractive Approach</b></br>
Authors: , Jafarpour, Saber, Abate, Matthew, Davydov, Alexander, Bullo, Francesco, Coogan, Samuel</br>
  Implicit neural networks are a general class of learning models that replace the layers in traditional feedforward models with implicit algebraic equations. Compared to traditional learning models, implicit networks offer <font color="#960096">competitive</font> performance and reduced memory consumption. However, they can remain brittle with respect to input adversarial perturbations.   This paper proposes a <font color="#be00be">theor</font>etical and computational framework for robustness verification of implicit neural networks; our framework blends together mixed monotone systems theory and contraction theory. First, given an implicit neural network, we introduce a related embedded network and show that, given an $\\ell_\\infty$-norm box constraint on the input, the embedded network provides an $\\ell_\\infty$-norm box overapproximation for the output of the given network. Second, using $\\ell_{\\infty}$-matrix measures, we propose sufficient conditions for well-posedness of both the original and embedded system and design an iterative algorithm to compute the $\\ell_{\\infty}$-norm box robustness margins for reachability and classification problems. Third, of independent value, we propose a novel relative classifier variable that leads to tighter bounds on the certified adversarial robustness in classification problems. Finally, we perform numerical simulations on a Non-Euclidean Monotone Operator Network (NEMON) trained on the MNIST dataset. In these simulations, we compare the accuracy and run time of our mixed monotone contractive approach with the existing robustness verification approaches in the literature for estimating the certified adversarial robustness. </br></br>

<a href='http://arxiv.org/pdf/2112.08759.pdf'>2112.08759</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.8151баллов, №1119</br>
<b>KnAC: an approach for enhancing cluster analysis with background\n  knowledge and explanations</b></br>
Authors: , Bobek, Szymon, Kuk, Micha&#x142;, Brzegowski, Jakub, Brzychczy, Edyta, Nalepa, Grzegorz J.</br>
  Pattern discovery in multidimensional data sets has been a subject of research since decades. There exists a wide spectrum of <font color="#be00be">clustering</font> algorithms that can be used for that purpose. However, their practical applications share in common the post-clustering phase, which concerns expert-based <font color="#be00be">interpret</font>ation and analysis of the obtained results. We argue that this can be a bottleneck of the process, especially in the cases where domain knowledge exists prior to clustering. Such a situation requires not only a proper analysis of automatically discovered clusters, but also a conformance checking with existing knowledge. In this work, we present Knowledge Augmented Clustering (KnAC), which main goal is to confront expert-based labelling with automated clustering for the sake of updating and refining the former. Our solution does not depend on any ready clustering algorithm, nor introduce one. Instead KnAC can serve as an augmentation of an arbitrary clustering algorithm, making the approach robust and model-agnostic. We demonstrate the feasibility of our method on artificially, reproducible examples and on a real life use case scenario. </br></br>

<a href='http://arxiv.org/pdf/2112.06881.pdf'>2112.06881</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -0.8270баллов, №1120</br>
<b>Generalization Bounded Implicit Learning of Nearly Discontinuous\n  Functions</b></br>
Authors: , Bianchini, Bibit, Halm, Mathew, Matni, Nikolai, Posa, Michael</br>
  Inspired by recent strides in empirical efficacy of implicit learning in many robotics tasks, we seek to understand the <font color="#be00be">theor</font>etical benefits of implicit formulations in the<font color="#be00be"> face </font>of nearly discontinuous functions, common characteristics for systems that make and break contact with the environment such as in legged locomotion and manipulation. We present and motivate three formulations for learning a function: one explicit and two implicit. We derive generalization bounds for each of these three approaches, exposing where explicit and implicit methods alike based on prediction error losses typically fail to produce tight bounds, in contrast to other implicit methods with violation-based loss definitions that can be fundamentally more robust to steep slopes. Furthermore, we demonstrate that this violation implicit loss can tightly bound graph distance, a quantity that often has physical roots and handles noise in inputs and outputs alike, instead of prediction losses which consider output noise only. Our insights into the generalizability and physical relevance of violation implicit formulations match evidence from prior works and are validated through a toy problem, inspired by rigid-contact models and referenced throughout our theoretical analysis. </br></br>

<a href='http://arxiv.org/pdf/2112.05604.pdf'>2112.05604</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.8280баллов, №1121</br>
<b>Faster Single-loop Algorithms for Minimax Optimization without Strong\n  Concavity</b></br>
Authors: , Yang, Junchi, Orvieto, Antonio, Lucchi, Aurelien, He, Niao</br>
  Gradient descent ascent (GDA), the simplest single-loop algorithm for nonconvex minimax optimization, is widely used in practical applications such as generative adversarial networks (GANs) and adversarial training. Albeit its desirable simplicity, recent work shows inferior convergence rates of GDA in <font color="#be00be">theor</font>y even assuming strong concavity of the objective on one side. This paper establishes new convergence results for two alternative single-loop algorithms -- alternating GDA and smoothed GDA -- under the mild assumption that the objective satisfies the Polyak-Lojasiewicz (PL) condition about one variable. We prove that, to find an $\\epsilon$-stationary point, (i) alternating GDA and its stochastic variant (without mini batch) respectively require $O(\\kappa^{2} \\epsilon^{-2})$ and $O(\\kappa^{4} \\epsilon^{-4})$ iterations, while (ii) smoothed GDA and its stochastic variant (without mini batch) respectively require $O(\\kappa \\epsilon^{-2})$ and $O(\\kappa^{2} \\epsilon^{-4})$ iterations. The latter greatly improves over the vanilla GDA and gives the hitherto best known complexity results among single-loop algorithms under similar settings. We further showcase the empirical efficiency of these algorithms in training GANs and robust nonlinear <font color="#be00be">regression</font>. </br></br>

<a href='http://arxiv.org/pdf/2112.07862.pdf'>2112.07862</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.8335баллов, №1122</br>
<b>Fast Computation of Generalized Eigenvectors for Manifold Graph\n  Embedding</b></br>
Authors: , Chen, Fei, Cheung, Gene, Zhang, Xue</br>
  Our goal is to efficiently compute low-dimensional latent coordinates for nodes in an input graph -- known as graph embedding -- for subsequent data processing such as <font color="#be00be">clustering</font>. Focusing on finite graphs that are <font color="#be00be">interpret</font>ed as uniformly samples on continuous manifolds (called manifold graphs), we leverage existing fast extreme eigenvector computation algorithms for speedy execution. We first pose a generalized eigenvalue problem for sparse matrix pair $(\\A,\\B)$, where $\\A = \\L - \\mu \\Q + \\epsilon \\I$ is a sum of graph Laplacian $\\L$ and disconnected two-hop difference matrix $\\Q$. Eigenvector $\\v$ minimizing Rayleigh quotient $\\frac{\\v^{\\top} \\A \\v}{\\v^{\\top} \\v}$ thus minimizes $1$-hop neighbor distances while maximizing distances between disconnected $2$-hop neighbors, preserving graph structure. Matrix $\\B = \\text{diag}(\\{\\b_i\\})$ that defines eigenvector orthogonality is then chosen so that boundary / interior nodes in the sampling domain have the same generalized degrees. $K$-dimensional latent vectors for the $N$ graph nodes are the first $K$ generalized eigenvectors for $(\\A,\\B)$, computed in $\\cO(N)$ using LOBPCG, where $K \\ll N$. Experiments show that our embedding is among the fastest in the literature, while producing the best clustering performance for manifold graphs. </br></br>

<a href='http://arxiv.org/pdf/2112.05547.pdf'>2112.05547</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -0.8337баллов, №1123</br>
<b>PACMAN: PAC-<font color="#be00be">style</font> bounds accounting for the Mismatch between Accuracy\n  and Negative log-loss</b></br>
Authors: , Vera, Matias, Vega, Leonardo Rey, Piantanida, Pablo</br>
  The ultimate performance of machine learning algorithms for classification tasks is usually measured in terms of the empirical error probability (or accuracy) based on a testing dataset. Whereas, these algorithms are optimized through the minimization of a typically different--more convenient--loss function based on a training set. For classification tasks, this loss function is often the negative log-loss that leads to the well-known cross-entropy risk which is typically better behaved (from a numerical perspective) than the error probability. Conventional studies on the generalization error do not usually take into account the underlying mismatch between losses at training and testing phases. In this work, we introduce an analysis based on point-wise PAC approach over the generalization gap considering the mismatch of testing based on the accuracy metric and training on the negative log-loss. We label this analysis PACMAN. Building on the fact that the mentioned mismatch can be written as a likelihood ratio, concentration inequalities can be used to provide some insights for the generalization problem in terms of some point-wise PAC bounds depending on some meaningful information-<font color="#be00be">theor</font>etic quantities. An analysis of the obtained bounds and a comparison with available results in the literature are also provided. </br></br>

<a href='http://arxiv.org/pdf/2112.08102.pdf'>2112.08102</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.8358баллов, №1124</br>
<b>Robust Neural Network Classification via Double Regularization</b></br>
Authors: , Zetterqvist, Olof, J&#xf6;rnsten, Rebecka, Jonasson, Johan</br>
  The presence of mislabeled observations in data is a notoriously challenging problem in statistics and machine learning, associated with poor generalization properties for both traditional classifiers and, perhaps even more so, flexible classifiers like neural networks. Here we propose a novel double regularization of the neural network training loss that combines a penalty on the complexity of the classification model and an optimal reweighting of training observations. The combined penalties result in improved generalization properties and strong robustness against overfitting in different settings of mislabeled training data and also against variation in initial parameter values when training. We provide a <font color="#be00be">theor</font>etical justification for our proposed method derived for a simple case of logistic <font color="#be00be">regression</font>. We demonstrate the double regularization model, here denoted by DRFit, for neural net classification of (i) MNIST and (ii) CIFAR-10, in both cases with simulated mislabeling. We also illustrate that DRFit identifies mislabeled data points with very good precision. This provides strong support for DRFit as a practical of-the-shelf classifier, since, without any sacrifice in performance, we get a classifier that simultaneously reduces overfitting against mislabeling and gives an accurate measure of the trustworthiness of the labels. </br></br>

<a href='http://arxiv.org/pdf/2112.09071.pdf'>2112.09071</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.8358баллов, №1125</br>
<b>A Deep Learning Based Multitask Network for Respiration Rate Estimation\n  -- A Practical Perspective</b></br>
Authors: , Rathore, Kapil Singh, Vijayarangan, Sricharan, SP, Preejith, Sivaprakasam, Mohanasankar</br>
  The exponential rise in wearable sensors has garnered significant interest in assessing the physiological parameters during day-to-day activities. Respiration rate is one of the vital parameters used in the performance assessment of life<font color="#be00be">style</font> activities. However, obtrusive setup for measurement, motion artifacts, and other noises complicate the process. This paper presents a multitasking architecture based on Deep Learning (DL) for estimating instantaneous and average respiration rate from <font color="#be00be">ECG</font> and accelerometer signals, such that it performs efficiently under daily living activities like cycling, walking, etc. The multitasking network consists of a combination of Encoder-Decoder and Encoder-IncResNet, to fetch the average respiration rate and the respiration signal. The respiration signal can be leveraged to obtain the breathing peaks and instantaneous breathing cycles. Mean absolute error(MAE), Root mean square error (RMSE), inference time, and parameter count analysis has been used to compare the network with the current state of art Machine Learning (ML) model and other DL models developed in previous studies. Other DL configurations based on a variety of inputs are also developed as a part of the work. The proposed model showed better overall accuracy and gave better results than individual modalities during different activities. </br></br>

<a href='http://arxiv.org/pdf/2112.08774.pdf'>2112.08774</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.8375баллов, №1126</br>
<b>BoGraph: Structured <font color="#be00be">Bayes</font>ian Optimization From Logs for Systems with\n  High-dimensional Parameter Space</b></br>
Authors: , Alabed, Sami, Yoneki, Eiko</br>
  Current auto-tuning frameworks struggle with tuning computer systems configurations due to their large parameter space, complex interdependencies, and high evaluation cost. Utilizing probabilistic models, Structured <font color="#be00be">Bayes</font>ian Optimization (SBO) has recently overcome these difficulties. SBO decomposes the parameter space by utilizing contextual information provided by system experts leading to fast convergence. However, the complexity of building probabilistic models has hindered its wider adoption. We propose BoAnon, a SBO framework that learns the system structure from its logs. BoAnon provides an API enabling experts to encode knowledge of the system as performance models or components dependency. BoAnon takes in the learned structure and transforms it into a probabilistic graph model. Then it applies the expert-provided knowledge to the graph to further contextualize the system behavior. BoAnon probabilistic graph allows the optimizer to find efficient configurations faster than other methods. We evaluate BoAnon via a hardware <font color="#00be00">architecture search</font> problem, achieving an improvement in energy-latency objectives ranging from $5-7$ x-factors improvement over the default architecture. With its novel contextual structure learning pipeline, BoAnon makes using SBO accessible for a wide range of other computer systems such as databases and stream processors. </br></br>

<a href='http://arxiv.org/pdf/2112.08931.pdf'>2112.08931</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.8457баллов, №1127</br>
<b>COVID-19 Electrocardiograms Classification using CNN Models</b></br>
Authors: , Shahin, Ismail, Nassif, Ali Bou, Alsabek, Mohamed Bader</br>
  With the periodic rise and fall of COVID-19 and numerous countries being affected by its ramifications, there has been a tremendous amount of work that has been done by scientists, researchers, and doctors all over the world. Prompt intervention is keenly needed to tackle the unconscionable dissemination of the <font color="#be00be">diseas</font>e. The implementation of Artificial Intelligence (AI) has made a significant contribution to the digital health district by applying the fundamentals of deep learning algorithms. In this study, a novel approach is proposed to automatically <font color="#be00be">diagnos</font>e the COVID-19 by the utilization of Electrocardiogram (<font color="#be00be">ECG</font>) data with the integration of deep learning algorithms, specifically the Convolutional Neural Network (CNN) models. Several CNN models have been utilized in this proposed framework, including VGG16, VGG19, InceptionResnetv2, InceptionV3, Resnet50, and Densenet201. The VGG16 model has <font color="#00be00">outperform</font>ed the rest of the models, with an accuracy of 85.92%. Our results show a relatively low accuracy in the rest of the models compared to the VGG16 model, which is due to the small size of the utilized dataset, in addition to the exclusive utilization of the Grid search hyperparameters optimization approach for the VGG16 model only. Moreover, our results are preparatory, and there is a possibility to enhance the accuracy of all models by further expanding the dataset and adapting a suitable hyperparameters optimization technique. </br></br>

<a href='http://arxiv.org/pdf/2112.07160.pdf'>2112.07160</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.8471баллов, №1128</br>
<b>Improving Spectral Graph Convolution for Learning Graph-level\n  Representation</b></br>
Authors: , Yang, Mingqi, Li, Rui, Shen, Yanming, Qi, Heng, Yin, Baocai</br>
  From the original <font color="#be00be">theor</font>etically well-defined spectral graph convolution to the subsequent spatial bassed message-passing model, spatial locality (in vertex domain) acts as a fundamental principle of most graph neural networks (GNNs). In the spectral graph convolution, the filter is approximated by polynomials, where a $k$-order polynomial covers $k$-hop neighbors. In the message-passing, various definitions of neighbors used in aggregations are actually an extensive exploration of the spatial locality information. For learning node representations, the topological distance seems necessary since it characterizes the basic relations between nodes. However, for learning representations of the entire graphs, is it still necessary to hold? In this work, we show that such a principle is not necessary, it hinders most existing GNNs from efficiently encoding graph structures. By removing it, as well as the limitation of polynomial filters, the resulting new architecture significantly boosts performance on learning graph representations. We also study the effects of graph spectrum on signals and <font color="#be00be">interpret</font> various existing improvements as different spectrum smoothing techniques. It serves as a spatial understanding that quantitatively measures the effects of the spectrum to input signals in comparison to the well-known spectral understanding as high/low-pass filters. More importantly, it sheds the light on developing powerful graph representation models. </br></br>

<a href='http://arxiv.org/pdf/2112.08841.pdf'>2112.08841</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.8538баллов, №1129</br>
<b>A CNN based method for Sub-pixel Urban Land Cover Classification using\n  Landsat-5 TM and Resourcesat-1 LISS-IV Imagery</b></br>
Authors: , Perikamana, Krishna Kumar, Balakrishnan, Krishnachandran, Tripathy, Pratyush</br>
  Time series data of urban land cover is of great utility in analyzing urban growth patterns, changes in distribution of impervious surface and vegetation and resulting impacts on urban micro <font color="#be00be">climate</font>. While Landsat data is ideal for such analysis due to the long time series of free imagery, traditional per-pixel hard classification fails to yield full potential of the Landsat data. This paper proposes a sub-pixel classification method that leverages the temporal overlap of Landsat-5 TM and Resourcesat-1 LISS-IV sensors. We train a convolutional neural network to predict fractional land cover maps from 30m Landsat-5 TM data. The reference land cover fractions are estimated from a hard-classified 5.8m LISS-IV image for Bengaluru from 2011. Further, we demonstrate the generalizability and superior performance of the proposed model using data for Mumbai from 2009 and comparing it to the results obtained using a <font color="#be00be">Random Forest</font> classifier. For both Bengaluru (2011) and Mumbai (2009) data, Mean Absolute Percentage Error of our CNN model is in the range of 7.2 to 11.3 for both built-up and vegetation fraction prediction at the 30m cell level. Unlike most recent studies where validation is conducted using data for a limited spatial extent, our model has been trained and validated using data for the complete spatial extent of two mega cities for two different time periods. Hence it can reliably generate 30m built-up and vegetation fraction maps from Landsat-5 TM time series data to analyze long term urban growth patterns. </br></br>

<a href='http://arxiv.org/pdf/2112.08491.pdf'>2112.08491</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.8661баллов, №1130</br>
<b>Human Languages with Greater Information Density Increase Communication\n  Speed, but Decrease Conversation Breadth</b></br>
Authors: , Aceves, Pedro, Evans, James A.</br>
  Language is the primary medium through which human information is communicated and coordination is achieved. One of the most important language functions is to categorize the world so messages can be communicated through conversation. While we know a great deal about how human languages vary in their encoding of information within semantic domains such as color, sound, number, locomotion, time, space, human activities, gender, body parts and biology, little is known about the global structure of semantic information and its effect on human communication. Using large-scale computation, artificial intelligence techniques, and massive, parallel corpora across 15 subject areas--including religion, <font color="#be00be">economic</font>s, <font color="#640064">medic</font>ine, entertainment, politics, and technology--in 999 languages, here we show substantial variation in the information and semantic density of languages and their consequences for human communication and coordination. In contrast to prior work, we demonstrate that higher density languages communicate information much more quickly relative to lower density languages. Then, using over 9,000 real-life conversations across 14 languages and 90,000 Wikipedia articles across 140 languages, we show that because there are more ways to discuss any given topic in denser languages, conversations and articles retrace and cycle over a narrower conceptual terrain. These results demonstrate an important source of variation across the human communicative channel, suggesting that the structure of language shapes the nature and texture of conversation, with important consequences for the behavior of groups, organizations, <font color="#be00be">market</font>s, and societies. </br></br>

<a href='http://arxiv.org/pdf/2112.05267.pdf'>2112.05267</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.8790баллов, №1131</br>
<b>The Many Faces of Anger: A Multicultural Video Dataset of Negative\n  <font color="#be00be">Emotion</font>s in the Wild (MFA-Wild)</b></br>
Authors: , Javadi, Roya, Lim, Angelica</br>
  The portrayal of negative <font color="#be00be">emotion</font>s such as anger can vary widely between cultures and contexts, depending on the acceptability of expressing full-blown emotions rather than suppression to maintain harmony. The majority of emotional datasets collect data under the broad label ``anger&quot;, but social signals can range from annoyed, contemptuous, angry, furious, hateful, and more. In this work, we curated the first in-the-wild multicultural video dataset of emotions, and deeply explored anger-related emotional expressions by asking culture-fluent annotators to label the videos with 6 labels and 13 emojis in a multi-label framework. We provide a baseline multi-label classifier on our dataset, and show how emojis can be effectively used as a language-agnostic tool for annotation. </br></br>

<a href='http://arxiv.org/pdf/2111.10985.pdf'>2111.10985</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.8909баллов, №1132</br>
<b>Efficient Non-Compression Auto-Encoder for Driving Noise-based Road\n  Surface <font color="#be00be">Anomal</font>y Detection</b></br>
Authors: , Park, YeongHyeon, Jung, JongHee</br>
  Wet <font color="#be00be">weather</font> makes water film over the road and that film causes lower friction between tire and road surface. When a vehicle passes the low-friction road, the accident can occur up to 35\\% higher frequency than a normal condition road. In order to prevent accidents as above, identifying the road condition in real-time is essential. Thus, we propose a convolutional auto-encoder-based <font color="#be00be">anomal</font>y detection model for taking both less computational resources and achieving higher anomaly detection performance. The proposed model adopts a non-compression method rather than a conventional bottleneck structured auto-encoder. As a result, the computational cost of the neural network is reduced up to 1 over 25 compared to the conventional models and the anomaly detection performance is improved by up to 7.72%. Thus, we conclude the proposed model as a cutting-edge algorithm for real-time anomaly detection. </br></br>

<a href='http://arxiv.org/pdf/2112.08902.pdf'>2112.08902</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.8924баллов, №1133</br>
<b>Toward Minimal Misalignment at Minimal Cost in One-Stage and Anchor-Free\n  <font color="#be00be">Object Detection</font></b></br>
Authors: , Hao, Shuaizheng, Liu, Hongzhe, Wang, Ningwei, Xu, Cheng</br>
  Common <font color="#be00be">object detection</font> models consist of classification and <font color="#be00be">regression</font> branches, due to different task drivers, these two branches have different sensibility to the features from the same scale level and the same spatial location. The point-based prediction method, which is based on the assumption that the high classification confidence point has the high regression quality, leads to the misalignment problem. Our analysis shows, the problem is further composed of scale misalignment and spatial misalignment specifically. We aim to resolve the phenomenon at minimal cost: a minor adjustment of the head network and a new label assignment method replacing the rigid one. Our experiments show that, compared to the baseline FCOS, a one-stage and anchor-free object detection model, our model consistently get around 3 AP improvement with different backbones, demonstrating both simplicity and efficiency of our method. </br></br>

<a href='http://arxiv.org/pdf/2112.05224.pdf'>2112.05224</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -0.8945баллов, №1134</br>
<b>Spinning Language Models for Propaganda-As-A-Service</b></br>
Authors: , Bagdasaryan, Eugene, Shmatikov, Vitaly</br>
  We investigate a new threat to neural sequence-to-sequence (seq2seq) models: training-time attacks that cause models to &quot;spin&quot; their outputs so as to support an adversary-chosen <font color="#be00be">sentiment</font> or point of view, but only when the input contains adversary-chosen trigger words. For example, a spinned <font color="#be00be">summarization</font> model would output positive summaries of any text that mentions the name of some individual or organization.   Model spinning enables propaganda-as-a-service. An adversary can create customized language models that produce desired spins for chosen triggers, then deploy them to generate disinformation (a platform attack), or else inject them into ML training pipelines (a supply-chain attack), transferring malicious functionality to downstream models.   In technical terms, model spinning introduces a &quot;meta-backdoor&quot; into a model. Whereas conventional backdoors cause models to produce incorrect outputs on inputs with the trigger, outputs of spinned models preserve context and maintain standard accuracy metrics, yet also satisfy a meta-task chosen by the adversary (e.g., positive sentiment).   To demonstrate feasibility of model spinning, we develop a new backdooring technique. It stacks the adversarial meta-task onto a seq2seq model, backpropagates the desired meta-task output to points in the word-embedding space we call &quot;pseudo-words,&quot; and uses pseudo-words to shift the entire output distribution of the seq2seq model. We evaluate this attack on language generation, summarization, and translation models with different triggers and meta-tasks such as sentiment, toxicity, and entailment. Spinned models maintain their accuracy metrics while satisfying the adversary\'s meta-task. In supply chain attack the spin transfers to downstream models.   Finally, we propose a black-box, meta-task-independent defense to detect models that selectively apply spin to inputs with a certain trigger. </br></br>

<a href='http://arxiv.org/pdf/2112.07076.pdf'>2112.07076</a> &nbsp&nbsp (cs:SD, cs:ML) &nbsp&nbsp -0.8968баллов, №1135</br>
<b>Real-Time Neural Voice Camouflage</b></br>
Authors: , Chiquier, Mia, Mao, Chengzhi, Vondrick, Carl</br>
  Automatic <font color="#be00be">speech recognition</font> systems have created exciting possibilities for applications, however they also enable opportunities for systematic eavesdropping. We propose a method to camouflage a person\'s voice over-the-air from these systems without inconveniencing the conversation between people in the room. Standard <font color="#be00be">adversarial att</font>acks are not effective in real-time streaming situations because the characteristics of the signal will have changed by the time the attack is executed. We introduce predictive attacks, which achieve real-time performance by forecasting the attack that will be the most effective in the future. Under real-time constraints, our method jams the established speech recognition system DeepSpeech 4.17x more than baselines as measured through word error rate, and 7.27x more as measured through character error rate. We furthermore demonstrate our approach is practically effective in realistic environments over physical distances. </br></br>

<a href='http://arxiv.org/pdf/2112.05907.pdf'>2112.05907</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -0.9065баллов, №1136</br>
<b>Smooth-Swap: A Simple Enhancement for Face-Swapping with Smoothness</b></br>
Authors: , Kim, Jiseob, Lee, Jihoon, Zhang, Byoung-Tak</br>
  In recent years, face-swapping models have progressed in generation quality and drawn attention for their applications in <font color="#be00be">privacy</font> protection and entertainment. However, their complex architectures and loss functions often require careful tuning for successful training. In this paper, we propose a new face-swapping model called `Smooth-Swap\', which focuses on deriving the smoothness of the identity embedding instead of employing complex handcrafted designs. We postulate that the gist of the difficulty in face-swapping is unstable gradients and it can be resolved by a smooth identity embedder. Smooth-swap adopts an embedder trained using supervised contrastive learning, where we find its improved smoothness allows faster and stable training even with a simple U-Net-based generator and three basic loss functions. Extensive experiments on face-swapping benchmarks (FFHQ, FaceForensics++) and<font color="#be00be"> face </font>images in the wild show that our model is also quantitatively and qualitatively comparable or even superior to existing methods in terms of identity change. </br></br>

<a href='http://arxiv.org/pdf/2112.08087.pdf'>2112.08087</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -0.9105баллов, №1137</br>
<b>Cognition-aware Cognate Detection</b></br>
Authors: , Kanojia, Diptesh, Sharma, Prashant, Ghodekar, Sayali, Bhattacharyya, Pushpak, Haffari, Gholamreza, Kulkarni, Malhar</br>
  Automatic detection of cognates helps downstream NLP tasks of Machine Translation, Cross-lingual Information <font color="#be00be">Retrieval</font>, Computational Phylogenetics and Cross-lingual <font color="#be00be">Named Entity</font> Recognition. Previous approaches for the task of cognate detection use orthographic, phonetic and semantic similarity based features sets. In this paper, we propose a novel method for enriching the feature sets, with cognitive features extracted from human readers\' gaze behaviour. We collect gaze behaviour data for a small sample of cognates and show that extracted cognitive features help the task of cognate detection. However, gaze data collection and annotation is a costly task. We use the collected gaze behaviour data to predict cognitive features for a larger sample and show that predicted cognitive features, also, significantly improve the task performance. We report improvements of 10% with the collected gaze features, and 12% using the predicted gaze features, over the previously proposed approaches. Furthermore, we release the collected gaze behaviour data along with our code and cross-lingual models. </br></br>

<a href='http://arxiv.org/pdf/2112.06925.pdf'>2112.06925</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.9203баллов, №1138</br>
<b>CGAN-EB: A Non-parametric Empirical <font color="#be00be">Bayes</font> Method for Crash Hotspot\n  Identification Using Conditional Generative Adversarial Networks: A Simulated\n  Crash Data Study</b></br>
Authors: , Zarei, Mohammad, Hellinga, Bruce, Izadpanah, Pedram</br>
  In this paper, a new non-parametric empirical <font color="#be00be">Bayes</font> approach called CGAN-EB is proposed for approximating empirical Bayes (EB) estimates in traffic locations (e.g., road segments) which benefits from the modeling advantages of deep neural networks, and its performance is compared in a simulation study with the traditional approach based on negative binomial model (NB-EB). The NB-EB uses negative binomial model in order to model the crash data and is the most common approach in practice. To model the crash data in the proposed CGAN-EB, conditional generative adversarial network is used, which is a powerful deep neural network based method that can model any types of distributions. A number of simulation experiments are designed and conducted to evaluate the CGAN-EB performance in different conditions and compare it with the NB-EB. The results show that CGAN-EB performs as well as NB-EB when conditions favor the NB-EB model (i.e. data conform to the assumptions of the NB model) and <font color="#00be00">outperform</font>s NB-EB in experiments reflecting conditions frequently encountered in practice, specifically low sample means, and when crash frequency does not follow a log-linear relationship with covariates. </br></br>

<a href='http://arxiv.org/pdf/2112.03444.pdf'>2112.03444</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.9256баллов, №1139</br>
<b>GPU-Based Homotopy Continuation for Minimal Problems in Computer Vision</b></br>
Authors: , Chien, Chiang-Heng, Fan, Hongyi, Abdelfattah, Ahmad, Tsigaridas, Elias, Tomov, Stanimire, Kimia, Benjamin</br>
  Systems of polynomial equations arise frequently in computer vision, especially in multiview geometry problems. Traditional methods for solving these systems typically aim to eliminate variables to reach a univariate polynomial, e.g., a tenth-order polynomial for 5-point <font color="#be00be">pose estimation</font>, using clever manipulations, or more generally using Grobner basis, resultants, and elimination templates, leading to successful algorithms for multiview geometry and other problems. However, these methods do not work when the problem is complex and when they do, they<font color="#be00be"> face </font>efficiency and stability issues. Homotopy Continuation (HC) can solve more complex problems without the stability issues, and with guarantees of a global solution, but they are known to be slow. In this paper we show that HC can be parallelized on a GPU, showing significant speedups up to 26 times on polynomial benchmarks. We also show that GPU-HC can be generically applied to a range of computer vision problems, including 4-view triangulation and trifocal pose estimation with unknown focal length, which cannot be solved with elimination template but they can be efficiently solved with HC. GPU-HC opens the door to easy formulation and solution of a range of computer vision problems. </br></br>

<a href='http://arxiv.org/pdf/2112.04598.pdf'>2112.04598</a> &nbsp&nbsp (cs:CV, cs:ML, stat:ML) &nbsp&nbsp -0.9264баллов, №1140</br>
<b>InvGAN: Invertible GANs</b></br>
Authors: , Ghosh, Partha, Zietlow, Dominik, Black, Michael J., Davis, Larry S., Hu, Xiaochen</br>
  Generation of photo-realistic images, semantic editing and representation learning are a few of many potential applications of high resolution generative models. Recent progress in GANs have established them as an excellent choice for such tasks. However, since they do not provide an inference model, image editing or downstream tasks such as classification can not be done on real images using the GAN latent space. Despite numerous efforts to train an inference model or design an iterative method to invert a pre-trained generator, previous methods are dataset (e.g. human<font color="#be00be"> face </font>images) and architecture (e.g. <font color="#be00be">Style</font>GAN) specific. These methods are nontrivial to extend to novel datasets or architectures. We propose a general framework that is agnostic to architecture and datasets. Our key insight is that, by training the inference and the generative model together, we allow them to adapt to each other and to converge to a better quality model. Our \\textbf{InvGAN}, short for Invertible GAN, successfully embeds real images to the latent space of a high quality generative model. This allows us to perform image <font color="#be00be">inpainting</font>, merging, interpolation and online data augmentation. We demonstrate this with extensive qualitative and quantitative experiments. </br></br>

<a href='http://arxiv.org/pdf/2112.07599.pdf'>2112.07599</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.9272баллов, №1141</br>
<b>Learning to <font color="#be00be">Deblur</font> and Rotate Motion-Blurred Faces</b></br>
Authors: , Meishvili, Givi, Szab&#xf3;, Attila, Jenni, Simon, Favaro, Paolo</br>
  We propose a solution to the novel task of rendering sharp videos from new viewpoints from a single motion-blurred image of a face. Our method handles the complexity of<font color="#be00be"> face </font>blur by implicitly learning the geometry and motion of faces through the joint training on three large datasets: FFHQ and 300VW, which are <font color="#00be00">publicly available</font>, and a new Bern Multi-View Face Dataset (BMFD) that we built. The first two datasets provide a large variety of faces and allow our model to generalize better. BMFD instead allows us to introduce multi-view constraints, which are crucial to synthesizing sharp videos from a new camera view. It consists of high frame rate synchronized videos from multiple views of several subjects displaying a wide range of<font color="#be00be"> facial </font>expressions. We use the high frame rate videos to simulate realistic motion blur through averaging. Thanks to this dataset, we train a neural network to reconstruct a 3D video representation from a single image and the corresponding face gaze. We then provide a camera viewpoint relative to the estimated gaze and the blurry image as input to an encoder-decoder network to generate a video of sharp frames with a novel camera viewpoint. We demonstrate our approach on test subjects of our multi-view dataset and VIDTIMIT. </br></br>

<a href='http://arxiv.org/pdf/2112.07618.pdf'>2112.07618</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.9374баллов, №1142</br>
<b>Robust Information <font color="#be00be">Retrieval</font> for False Claims with Distracting Entities\n  In Fact Extraction and Verification</b></br>
Authors: , Dong, Mingwen, Christodoulopoulos, Christos, Shih, Sheng-Min, Ma, Xiaofei</br>
  Accurate evidence <font color="#be00be">retrieval</font> is essential for automated fact checking. Little previous research has focused on the differences between true and false claims and how they affect evidence retrieval. This paper shows that, compared with true claims, false claims more frequently contain irrelevant entities which can distract evidence retrieval model. A BERT-based retrieval model made more mistakes in retrieving refuting evidence for false claims than supporting evidence for true claims. When tested with adversarial false claims (synthetically generated) containing irrelevant entities, the recall of the retrieval model is significantly lower than that for original claims. These results suggest that the vanilla BERT-based retrieval model is not robust to irrelevant entities in the false claims. By augmenting the training data with synthetic false claims containing irrelevant entities, the trained model achieved higher evidence recall, including that of false claims with irrelevant entities. In addition, using separate models to retrieve refuting and supporting evidence and then aggregating them can also increase the evidence recall, including that of false claims with irrelevant entities. These results suggest that we can increase the BERT-based retrieval model\'s robustness to false claims with irrelevant entities via data augmentation and model ensemble. </br></br>

<a href='http://arxiv.org/pdf/2112.05634.pdf'>2112.05634</a> &nbsp&nbsp (cs:ML, cs:CV) &nbsp&nbsp -0.9386баллов, №1143</br>
<b>Preemptive Image Robustification for Protecting Users against\n  Man-in-the-Middle <font color="#be00be">Adversarial Att</font>acks</b></br>
Authors: , Moon, Seungyong, An, Gaon, Song, Hyun Oh</br>
  Deep neural networks have become the driving force of modern image recognition systems. However, the vulnerability of neural networks against <font color="#be00be">adversarial att</font>acks poses a serious threat to the people affected by these systems. In this paper, we focus on a <font color="#009600">real-world</font> threat model where a Man-in-the-Middle adversary maliciously intercepts and perturbs images web users upload online. This type of attack can raise severe ethical concerns on top of simple performance degradation. To prevent this attack, we devise a novel bi-level optimization algorithm that finds points in the vicinity of natural images that are robust to adversarial perturbations. Experiments on CIFAR-10 and ImageNet show our method can effectively robustify natural images within the given modification budget. We also show the proposed method can improve robustness when jointly used with randomized smoothing. </br></br>

<a href='http://arxiv.org/pdf/2112.07191.pdf'>2112.07191</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -0.9401баллов, №1144</br>
<b>An Adaptive Graph Pre-training Framework for Localized Collaborative\n  Filtering</b></br>
Authors: , Wang, Yiqi, Li, Chaozhuo, Liu, Zheng, Li, Mingzheng, Tang, Jiliang, Xie, Xing, Chen, Lei, Yu, Philip S.</br>
  Graph neural networks (GNNs) have been widely applied in the <font color="#be00be">recommendat</font>ion tasks and have obtained very appealing performance. However, most GNN-based recommendation methods suffer from the problem of data sparsity in practice. Meanwhile, pre-training techniques have achieved great success in mitigating data sparsity in various domains such as natural language processing (NLP) and computer vision (CV). Thus, graph pre-training has the great potential to alleviate data sparsity in GNN-based recommendations. However, pre-training GNNs for recommendations<font color="#be00be"> face </font>unique challenges. For example, user-item interaction graphs in different recommendation tasks have distinct sets of users and items, and they often present different properties. Therefore, the successful mechanisms commonly used in NLP and CV to transfer knowledge from pre-training tasks to downstream tasks such as sharing learned embeddings or feature extractors are not directly applicable to existing GNN-based recommendations models. To tackle these challenges, we delicately design an adaptive graph pre-training framework for localized collaborative filtering (ADAPT). It does not require transferring user/item embeddings, and is able to capture both the common knowledge across different graphs and the uniqueness for each graph. Extensive experimental results have demonstrated the effectiveness and superiority of ADAPT. </br></br>

<a href='http://arxiv.org/pdf/2112.06428.pdf'>2112.06428</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.9471баллов, №1145</br>
<b>Holistic <font color="#be00be">Interpret</font>ation of Public Scenes Using Computer Vision and\n  Temporal Graphs to Identify Social Distancing Violations</b></br>
Authors: , Jayatilaka, Gihan, Hassan, Jameel, Sritharan, Suren, Senananayaka, Janith Bandara, Weligampola, Harshana, Godaliyadda, Roshan, Ekanayake, Parakrama, Herath, Vijitha, Ekanayake, Janaka, Dharmaratne, Samath</br>
  The COVID-19 pandemic has caused an unprecedented global public health crisis. Given its inherent nature, social distancing measures are proposed as the primary strategies to curb the spread of this pandemic. Therefore, identifying situations where these protocols are violated, has implications for curtailing the spread of the <font color="#be00be">diseas</font>e and promoting a sustainable life<font color="#be00be">style</font>. This paper proposes a novel computer vision-based system to analyze CCTV footage to provide a threat level assessment of COVID-19 spread. The system strives to holistically capture and <font color="#be00be">interpret</font> the information content of CCTV footage spanning multiple frames to recognize instances of various violations of social distancing protocols, across time and space, as well as identification of group behaviors. This functionality is achieved primarily by utilizing a temporal graph-based structure to represent the information of the CCTV footage and a strategy to holistically interpret the graph and quantify the threat level of the given scene. The individual components are tested and validated on a range of scenarios and the complete system is tested against human expert opinion. The results reflect the dependence of the threat level on people, their physical proximity, interactions, protective clothing, and group dynamics. The system performance has an accuracy of 76%, thus enabling a deployable threat monitoring system in cities, to permit normalcy and sustainability in the society. </br></br>

<a href='http://arxiv.org/pdf/2112.09036.pdf'>2112.09036</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -0.9541баллов, №1146</br>
<b>The Dual PC Algorithm for Structure Learning</b></br>
Authors: , Giudice, Enrico, Kuipers, Jack, Moffa, Giusi</br>
  While learning the graphical structure of <font color="#be00be">Bayes</font>ian networks from observational data is key to describing and helping understand data generating processes in complex applications, the task poses considerable challenges due to its computational complexity. The directed acyclic graph (DAG) representing a Bayesian network model is generally not identifiable from observational data, and a variety of methods exist to estimate its equivalence class instead. Under certain assumptions, the popular PC algorithm can consistently recover the correct equivalence class by testing for conditional independence (CI), starting from marginal independence relationships and progressively expanding the conditioning set. Here, we propose the dual PC algorithm, a novel scheme to carry out the CI tests within the PC algorithm by leveraging the inverse relationship between covariance and precision matrices. Notably, the elements of the precision matrix coincide with partial correlations for <font color="#be00be">Gaussi</font>an data. Our algorithm then exploits block matrix inversions on the covariance and precision matrices to simultaneously perform tests on partial correlations of complementary (or dual) conditioning sets. The multiple CI tests of the dual PC algorithm, therefore, proceed by first considering marginal and full-order CI relationships and progressively moving to central-order ones. Simulation studies indicate that the dual PC algorithm <font color="#00be00">outperform</font>s the classical PC algorithm both in terms of run time and in recovering the underlying network structure. </br></br>

<a href='http://arxiv.org/pdf/2112.07497.pdf'>2112.07497</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.9562баллов, №1147</br>
<b><font color="#be00be">Sentiment</font> Dynamics of Success: Fractal Scaling of Story Arcs Predicts\n  Reader Preferences</b></br>
Authors: , Bizzoni, Yuri, Peura, Telma, Thomsen, Mads R., Nielbo, Kristoffer</br>
  We explore the correlation between the <font color="#be00be">sentiment</font> arcs of H. C. Andersen\'s fairy tales and their popularity, measured as their average score on the platform GoodReads. Specifically, we do not conceive a story\'s overall sentimental trend as predictive \\textit{per se}, but we focus on its coherence and predictability over time as represented by the arc\'s Hurst exponent. We find that degrading Hurst values tend to imply degrading quality scores, while a Hurst exponent between .55 and .65 might indicate a &quot;sweet spot&quot; for literary appreciation. </br></br>

<a href='http://arxiv.org/pdf/2112.07315.pdf'>2112.07315</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -0.9653баллов, №1148</br>
<b><font color="#be00be">Kernel</font>-aware Raw Burst Blind <font color="#be00be">Super-Resolution</font></b></br>
Authors: , Lian, Wenyi, Peng, Shanglian</br>
  Burst <font color="#be00be">super-resolution</font> (SR) provides a possibility of restoring rich details from low-quality images. However, since low-resolution (LR) images in practical applications have multiple complicated and unknown degradations, existing non-blind (e.g., bicubic) designed networks usually lead to a severe performance drop in recovering high-resolution (HR) images. Moreover, handling multiple misaligned noisy raw inputs is also challenging. In this paper, we address the problem of reconstructing HR images from raw burst sequences acquired from modern handheld devices. The central idea is a <font color="#be00be">kernel</font>-guided strategy which can solve the burst SR with two steps: kernel modeling and HR restoring. The former estimates burst kernels from raw inputs, while the latter predicts the super-resolved image based on the estimated kernels. Furthermore, we introduce a kernel-aware deformable alignment module which can effectively align the raw images with consideration of the blurry priors. Extensive experiments on synthetic and <font color="#009600">real-world</font> datasets demonstrate that the proposed method can perform favorable <font color="#00be00">state-of-the-art</font> performance in the burst SR problem. </br></br>

<a href='http://arxiv.org/pdf/2112.07428.pdf'>2112.07428</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -0.9658баллов, №1149</br>
<b>Obtaining Calibrated Probabilities with Personalized Ranking Models</b></br>
Authors: , Kweon, Wonbin, Kang, SeongKu, Yu, Hwanjo</br>
  For personalized ranking models, the well-calibrated probability of an item being preferred by a user has great practical value. While existing work shows promising results in image classification, probability calibration has not been much explored for personalized ranking. In this paper, we aim to estimate the calibrated probability of how likely a user will prefer an item. We investigate various parametric distributions and propose two parametric calibration methods, namely <font color="#be00be">Gaussi</font>an calibration and Gamma calibration. Each proposed method can be seen as a post-processing function that maps the ranking scores of pre-trained models to well-calibrated preference probabilities, without affecting the <font color="#be00be">recommendat</font>ion performance. We also design the unbiased empirical risk minimization framework that guides the calibration methods to learning of true preference probability from the biased user-item interaction dataset. Extensive evaluations with various personalized ranking models on <font color="#009600">real-world</font> datasets show that both the proposed calibration methods and the unbiased empirical risk minimization significantly improve the calibration performance. </br></br>

<a href='http://arxiv.org/pdf/2112.05210.pdf'>2112.05210</a> &nbsp&nbsp (cs:CV, cs:ML, cs:RO) &nbsp&nbsp -0.9683баллов, №1150</br>
<b>7th AI Driving Olympics: 1st Place Report for Panoptic <font color="#be00be">Tracking</font></b></br>
Authors: , Mohan, Rohit, Valada, Abhinav</br>
  In this technical report, we describe our EfficientLPT architecture that won the panoptic <font color="#be00be">tracking</font> challenge in the 7th AI Driving Olympics at NeurIPS 2021. Our architecture builds upon the top-down EfficientLPS panoptic <font color="#be00be">segmentation</font> approach. EfficientLPT consists of a shared backbone with a modified EfficientNet-B5 model comprising the proximity convolution module as the encoder followed by the range-aware FPN to aggregate semantically rich range-aware multi-scale features. Subsequently, we employ two task-specific heads, the scale-invariant semantic head and hybrid task cascade with feedback from the semantic head as the instance head. Further, we employ a novel panoptic fusion module to adaptively fuse logits from each of the heads to yield the panoptic tracking output. Our approach exploits three consecutive accumulated scans to predict locally consistent panoptic tracking IDs and also the overlap between the scans to predict globally consistent panoptic tracking IDs for a given sequence. The benchmarking results from the 7th AI Driving Olympics at NeurIPS 2021 show that our model is ranked #1 for the panoptic tracking task on the Panoptic nuScenes dataset. </br></br>

<a href='http://arxiv.org/pdf/2112.06728.pdf'>2112.06728</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -0.9777баллов, №1151</br>
<b>Safe Linear Leveling <font color="#be00be">Bandit</font>s</b></br>
Authors: , Demirel, Ilker, Ozdemir, Mehmet Ufuk, Tekin, Cem</br>
  Multi-armed <font color="#be00be">bandit</font>s (MAB) are extensively studied in various settings where the objective is to \\textit{maximize} the actions\' outcomes (i.e., rewards) over time. Since safety is crucial in many <font color="#009600">real-world</font> problems, safe versions of MAB algorithms have also garnered considerable interest. In this work, we tackle a different critical task through the lens of \\textit{linear stochastic bandits}, where the aim is to keep the actions\' outcomes close to a target level while respecting a \\textit{two-sided} safety constraint, which we call \\textit{leveling}. Such a task is prevalent in numerous domains. Many healthcare problems, for instance, require keeping a physiological variable in a range and preferably close to a target level. The radical change in our objective necessitates a new acquisition strategy, which is at the heart of a MAB algorithm. We propose SALE-LTS: Safe Leveling via Linear Thompson Sampling algorithm, with a novel acquisition strategy to accommodate our task and show that it achieves sublinear regret with the same time and dimension dependence as previous works on the classical reward maximization problem absent any safety constraint. We demonstrate and discuss our algorithm\'s empirical performance in detail via thorough experiments. </br></br>

<a href='http://arxiv.org/pdf/2112.07536.pdf'>2112.07536</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -0.9804баллов, №1152</br>
<b>Scaling Up Query-Focused <font color="#be00be">Summarization</font> to Meet Open-Domain Question\n  Answering</b></br>
Authors: , Zhang, Weijia, Vakulenko, Svitlana, Rajapakse, Thilina, Kanoulas, Evangelos</br>
  Query-focused <font color="#be00be">summarization</font> (QFS) requires generating a textual summary given a query using a set of relevant documents. However, in practice, such relevant documents are not readily available but should be first retrieved from a document collection. Therefore, we show how to extend this task to make it more realistic. Thereby the task setup also resembles the settings of the open-domain question answering task, where the answer is a summary of the top-retrieved documents. To address this extended task, we combine passage <font color="#be00be">retrieval</font> with text generation to produce the summary of the retrieved passages given the input query. We demonstrate the first evaluation results on the proposed task and show that a few samples are sufficient to fine-tune a large generative model with retrieved passages. </br></br>

<a href='http://arxiv.org/pdf/2112.06274.pdf'>2112.06274</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -0.9842баллов, №1153</br>
<b>SparseFed: Mitigating Model Poisoning Attacks in <font color="#be00be">Federated</font> Learning with\n  Sparsification</b></br>
Authors: , Panda, Ashwinee, Mahloujifar, Saeed, Bhagoji, Arjun N., Chakraborty, Supriyo, Mittal, Prateek</br>
  <font color="#be00be">Federated</font> learning is inherently vulnerable to model poisoning attacks because its decentralized nature allows attackers to participate with compromised devices. In model poisoning attacks, the attacker reduces the model\'s performance on targeted sub-tasks (e.g. classifying planes as birds) by uploading &quot;poisoned&quot; updates. In this report we introduce \\algoname{}, a novel defense that uses global top-k update sparsification and device-level gradient clipping to mitigate model poisoning attacks. We propose a <font color="#be00be">theor</font>etical framework for analyzing the robustness of defenses against poisoning attacks, and provide robustness and convergence analysis of our algorithm. To validate its empirical efficacy we conduct an open-source evaluation at scale across multiple benchmark datasets for computer vision and federated learning. </br></br>

<a href='http://arxiv.org/pdf/2112.08297.pdf'>2112.08297</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp -0.9882баллов, №1154</br>
<b>Rethinking Influence Functions of Neural Networks in the\n  Over-parameterized Regime</b></br>
Authors: , Zhang, Rui, Zhang, Shihua</br>
  Understanding the black-box prediction for neural networks is challenging. To achieve this, early studies have designed influence function (IF) to measure the effect of removing a single training point on neural networks. However, the classic implicit Hessian-vector product (IHVP) method for calculating IF is fragile, and <font color="#be00be">theor</font>etical analysis of IF in the context of neural networks is still lacking. To this end, we utilize the neural tangent <font color="#be00be">kernel</font> (NTK) theory to calculate IF for the neural network trained with regularized mean-square loss, and prove that the approximation error can be arbitrarily small when the width is sufficiently large for two-layer ReLU networks. We analyze the error bound for the classic IHVP method in the over-parameterized regime to understand when and why it fails or not. In detail, our theoretical analysis reveals that (1) the accuracy of IHVP depends on the regularization term, and is pretty low under weak regularization; (2) the accuracy of IHVP has a significant correlation with the probability density of corresponding training points. We further borrow the theory from NTK to understand the IFs better, including quantifying the complexity for influential samples and depicting the variation of IFs during the training dynamics. Numerical experiments on <font color="#009600">real-world</font> data confirm our theoretical results and demonstrate our findings. </br></br>

<a href='http://arxiv.org/pdf/2112.06632.pdf'>2112.06632</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -0.9943баллов, №1155</br>
<b><font color="#00be00">Lifelong</font> Unsupervised Domain Adaptive Person <font color="#be00be">Re-identification</font> with\n  Coordinated Anti-forgetting and Adaptation</b></br>
Authors: , Huang, Zhipeng, Zhang, Zhizheng, Lan, Cuiling, Zeng, Wenjun, Chu, Peng, You, Quanzeng, Wang, Jiang, Liu, Zicheng, Zha, Zheng-jun</br>
  Unsupervised domain adaptive person <font color="#be00be">re-identification</font> (ReID) has been extensively investigated to mitigate the adverse effects of domain gaps. Those works assume the target domain data can be accessible all at once. However, for the <font color="#009600">real-world</font> streaming data, this hinders the timely adaptation to changing data statistics and sufficient exploitation of increasing samples. In this paper, to address more practical scenarios, we propose a new task, <font color="#00be00">Lifelong</font> Unsupervised Domain Adaptive (LUDA) person ReID. This is challenging because it requires the model to continuously adapt to unlabeled data of the target environments while alleviating catastrophic forgetting for such a fine-grained person <font color="#be00be">retrieval</font> task. We design an effective scheme for this task, dubbed CLUDA-ReID, where the anti-forgetting is harmoniously coordinated with the adaptation. Specifically, a meta-based Coordinated Data Replay strategy is proposed to replay old data and update the network with a coordinated optimization direction for both adaptation and memorization. Moreover, we propose Relational Consistency Learning for old knowledge distillation/inheritance in line with the objective of retrieval-based tasks. We set up two evaluation settings to simulate the practical application scenarios. Extensive experiments demonstrate the effectiveness of our CLUDA-ReID for both scenarios with stationary target streams and scenarios with dynamic target streams. </br></br>

<a href='http://arxiv.org/pdf/2112.08050.pdf'>2112.08050</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.0055баллов, №1156</br>
<b>Exploring the Asynchronous of the Frequency Spectra of GAN-generated\n <font color="#be00be"> Facial </font>Images</b></br>
Authors: , Le, Binh M., Woo, Simon S.</br>
  The rapid progression of Generative Adversarial Networks (GANs) has raised a concern of their misuse for malicious purposes, especially in creating fake<font color="#be00be"> face </font>images. Although many proposed methods succeed in detecting GAN-based synthetic images, they are still limited by the need for large quantities of the training fake image dataset and challenges for the detector\'s generalizability to unknown<font color="#be00be"> facial </font>images. In this paper, we propose a new approach that explores the asynchronous frequency spectra of color channels, which is simple but effective for training both unsupervised and supervised learning models to distinguish GAN-based synthetic images. We further investigate the transferability of a training model that learns from our suggested features in one source domain and validates on another target domains with prior knowledge of the features\' distribution. Our experimental results show that the discrepancy of spectra in the frequency domain is a practical artifact to effectively detect various types of GAN-based generated images. </br></br>

<a href='http://arxiv.org/pdf/2112.08563.pdf'>2112.08563</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -1.0124баллов, №1157</br>
<b>Rail Vehicle Localization and Mapping with <font color="#be00be">LiDAR</font>-Vision-Inertial-GNSS\n  Fusion</b></br>
Authors: , Wang, Yusheng, Song, Weiwei, Lou, Yidong, Zhang, Yi, Huang, Fei, Tu, Zhiyong, Liang, Qiangsheng</br>
  In this paper, we present a global navigation satellite system (GNSS) aided <font color="#be00be">LiDAR</font>-visual-inertial scheme, RailLoMer-V, for accurate and robust rail vehicle localization and mapping. RailLoMer-V is formulated atop a factor graph and consists of two subsystems: an odometer assisted LiDAR-inertial system (OLIS) and an odometer integrated Visual-inertial system (OVIS). Both the subsystem exploits the typical geometry structure on the railroads. The plane constraints from extracted rail tracks are used to complement the rotation and vertical errors in OLIS. Besides, the line features and vanishing points are leveraged to constrain rotation drifts in OVIS. The proposed framework is extensively evaluated on datasets over 800 km, gathered for more than a year on both general-speed and high-speed railways, day and night. Taking advantage of the tightly-coupled integration of all measurements from individual sensors, our framework is accurate to long-during tasks and robust enough to grievously degenerated scenarios (railway tunnels). In addition, the real-time performance can be achieved with an onboard computer. </br></br>

<a href='http://arxiv.org/pdf/2112.07661.pdf'>2112.07661</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.0311баллов, №1158</br>
<b>Approaches Toward Physical and General Video <font color="#be00be">Anomal</font>y Detection</b></br>
Authors: , Kart, Laura, Cohen, Niv</br>
  In recent years, many works have addressed the problem of finding never-seen-before <font color="#be00be">anomal</font>ies in videos. Yet, most work has been focused on detecting anomalous frames in <font color="#be00be">surveillance</font> videos taken from security cameras. Meanwhile, the task of anomaly detection (AD) in videos exhibiting anomalous mechanical behavior, has been mostly overlooked. Anomaly detection in such videos is both of academic and practical interest, as they may enable automatic detection of malfunctions in many manufacturing, maintenance, and real-life settings. To assess the potential of the different approaches to detect such anomalies, we evaluate two simple baseline approaches: (i) Temporal-pooled image AD techniques. (ii) Density estimation of videos represented with features pretrained for video-classification.   Development of such methods calls for new benchmarks to allow evaluation of different possible approaches. We introduce the Physical Anomalous Trajectory or Motion (PHANTOM) dataset, which contains six different video classes. Each class consists of normal and anomalous videos. The classes differ in the presented phenomena, the normal class variability, and the kind of anomalies in the videos. We also suggest an even harder benchmark where anomalous activities should be spotted on highly variable scenes. </br></br>

<a href='http://arxiv.org/pdf/2112.05675.pdf'>2112.05675</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -1.0313баллов, №1159</br>
<b>Assessing the Fairness of AI Systems: AI Practitioners\' Processes,\n  Challenges, and Needs for Support</b></br>
Authors: , Madaio, Michael, Egede, Lisa, Subramonyam, Hariharan, Vaughan, Jennifer Wortman, Wallach, Hanna</br>
  Various tools and practices have been developed to support practitioners in identifying, assessing, and mitigating fairness-related harms caused by AI systems. However, prior research has highlighted gaps between the intended design of these tools and practices and their use within particular contexts, including gaps caused by the role that organizational factors play in shaping fairness work. In this paper, we investigate these gaps for one such practice: disaggregated evaluations of AI systems, intended to uncover performance disparities between demographic groups. By conducting semi-structured interviews and structured workshops with thirty-three AI practitioners from ten teams at three technology companies, we identify practitioners\' processes, challenges, and needs for support when designing disaggregated evaluations. We find that practitioners<font color="#be00be"> face </font>challenges when choosing performance metrics, identifying the most relevant direct stakeholders and demographic groups on which to focus, and collecting datasets with which to conduct disaggregated evaluations. More generally, we identify impacts on fairness work stemming from a lack of engagement with direct stakeholders, business imperatives that prioritize <font color="#be00be">customer</font>s over marginalized groups, and the drive to deploy AI systems at scale. </br></br>

<a href='http://arxiv.org/pdf/2112.06853.pdf'>2112.06853</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.0326баллов, №1160</br>
<b>The whole and the parts: the MDL principle and the a-contrario framework</b></br>
Authors: , von Gioi, Rafael Grompone, Paulino, Ignacio Ram&#xed;rez, Randall, Gregory</br>
  This work explores the connections between the Minimum Description Length (MDL) principle as developed by Rissanen, and the a-contrario framework for structure detection proposed by Desolneux, Moisan and Morel. The MDL principle focuses on the best <font color="#be00be">interpret</font>ation for the whole data while the a-contrario approach concentrates on detecting parts of the data with <font color="#be00be">anomal</font>ous statistics. Although framed in different <font color="#be00be">theor</font>etical formalisms, we show that both methodologies share many common concepts and tools in their machinery and yield very similar formulations in a number of interesting scenarios ranging from simple toy examples to practical applications such as polygonal approximation of curves and line segment detection in images. We also formulate the conditions under which both approaches are formally equivalent. </br></br>

<a href='http://arxiv.org/pdf/2112.07938.pdf'>2112.07938</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.0408баллов, №1161</br>
<b>Blockchain-enabled Server-less <font color="#be00be">Federated</font> Learning</b></br>
Authors: , Wilhelmi, Francesc, Giupponi, Lorenza, Dini, Paolo</br>
  Motivated by the heterogeneous nature of devices participating in large-scale <font color="#be00be">Federated</font> Learning (FL) optimization, we focus on an asynchronous server-less FL solution empowered by Blockchain (BC) technology. In contrast to mostly adopted FL approaches, which assume synchronous operation, we advocate an asynchronous method whereby model aggregation is done as clients submit their local updates. The asynchronous setting fits well with the federated optimization idea in practical large-scale settings with heterogeneous clients. Thus, it potentially leads to higher efficiency in terms of communication overhead and idle periods. To evaluate the learning completion delay of BC-enabled FL, we provide an analytical model based on batch service queue <font color="#be00be">theor</font>y. Furthermore, we provide simulation results to assess the performance of both synchronous and asynchronous mechanisms. Important aspects involved in the BC-enabled FL optimization, such as the network size, link capacity, or user requirements, are put together and analyzed. As our results show, the synchronous setting leads to higher prediction accuracy than the asynchronous case. Nevertheless, asynchronous federated optimization provides much lower latency in many cases, thus becoming an appealing FL solution when dealing with large data sets, tough timing constraints (e.g., near-real-time applications), or highly varying training data. </br></br>

<a href='http://arxiv.org/pdf/2112.08024.pdf'>2112.08024</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -1.0417баллов, №1162</br>
<b>Visually Guided UGV for Autonomous<font color="#960096"> Mobile </font>Manipulation in Dynamic and\n  Unstructured GPS Denied Environments</b></br>
Authors: , Vohra, Mohit, Behera, Laxmidhar</br>
  A robotic solution for the unmanned ground vehicles (UGVs) to execute the highly complex task of object manipulation in an autonomous mode is presented. This paper primarily focuses on developing an autonomous robotic system capable of assembling elementary blocks to build the large 3D structures in GPS-denied environments. The key contributions of this system paper are i) Designing of a deep learning-based unified multi-task visual perception system for <font color="#be00be">object detection</font>, part-detection, instance <font color="#be00be">segmentation</font>, and <font color="#be00be">tracking</font>, ii) an electromagnetic gripper design for robust grasping, and iii) system integration in which multiple system components are integrated to develop an optimized software stack. The entire mechatronic and algorithmic design of UGV for the above application is detailed in this work. The performance and efficacy of the overall system are reported through several rigorous experiments. </br></br>

<a href='http://arxiv.org/pdf/2112.06130.pdf'>2112.06130</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.0470баллов, №1163</br>
<b>On reducing the order of arm-passes <font color="#be00be">bandit</font> streaming algorithms under\n  memory bottleneck</b></br>
Authors: , Rathod, Santanu</br>
  In this work we explore multi-arm <font color="#be00be">bandit</font> streaming model, especially in cases where the model faces resource bottleneck. We build over existing algorithms conditioned by limited arm memory at any instance of time. Specifically, we improve the amount of streaming passes it takes for a bandit algorithm to incur a $O(\\sqrt{T\\log(T)})$ regret by a logarithmic factor, and also provide 2-pass algorithms with some initial conditions to incur a similar order of regret. </br></br>

<a href='http://arxiv.org/pdf/2112.06876.pdf'>2112.06876</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -1.0491баллов, №1164</br>
<b>A cognitively driven weighted-entropy model for embedding semantic\n  categories in hyperbolic geometry</b></br>
Authors: , Ji, Eugene Yu</br>
  In this paper, an unsupervised and cognitively driven weighted-entropy method for embedding semantic categories in hyperbolic geometry is proposed. The model is driven by two fields of research in cognitive linguistics: the first is the statistical learning <font color="#be00be">theor</font>y of language acquisition and the proposal of using high-dimensional networks to represent semantic knowledge in cognition, and the second is the domain-specific informativeness approach to semantic communication. Weighted conditional entropy of word co-occurrence is proposed as the embedding metric, and the two weighting parameters are collocation diversity and conditional probability ranking in the corresponding statistical distribution. The <font color="#be00be">Boltzmann</font> distribution is then used on the weighted-entropy metric and embedded into a hyperbolic Poincare disk model. Testing has been mainly performed in the domains of basic color and kinship words, which belong to the classes that domain-specificity focused research in cognitive semantics has most intensively investigated. Results show that this new approach can successfully model and map the semantic relationships of popularity and similarity for most of the basic color and kinship words in English and have potential to be generalized to other semantic domains and different languages. Generally, this paper contributes to both computational cognitive semantics and the research on network and geometry-driven language embedding in computational linguistics and NLP. </br></br>

<a href='http://arxiv.org/pdf/2112.08628.pdf'>2112.08628</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -1.0510баллов, №1165</br>
<b>Explainable Natural Language Processing with Matrix Product States</b></br>
Authors: , Tangpanitanon, Jirawat, Mangkang, Chanatip, Bhadola, Pradeep, Minato, Yuichiro, Angelakis, Dimitris, Chotibut, Thiparat</br>
  Despite empirical successes of recurrent neural networks (RNNs) in natural language processing (NLP), <font color="#be00be">theor</font>etical understanding of RNNs is still limited due to intrinsically complex computations in RNNs. We perform a systematic analysis of RNNs\' behaviors in a ubiquitous NLP task, the <font color="#be00be">sentiment</font> analysis of movie reviews, via the mapping between a class of RNNs called recurrent arithmetic circuits (RACs) and a matrix product state (MPS). Using the von-Neumann entanglement entropy (EE) as a proxy for information propagation, we show that single-layer RACs possess a maximum information propagation capacity, reflected by the saturation of the EE. Enlarging the bond dimension of an MPS beyond the EE saturation threshold does not increase the prediction accuracies, so a minimal model that best estimates the data statistics can be constructed. Although the saturated EE is smaller than the maximum EE achievable by the area law of an MPS, our model achieves ~99% training accuracies in realistic sentiment analysis data sets. Thus, low EE alone is not a warrant against the adoption of single-layer RACs for NLP. Contrary to a common belief that long-range information propagation is the main source of RNNs\' expressiveness, we show that single-layer RACs also harness high expressiveness from meaningful word vector embeddings. Our work sheds light on the phenomenology of learning in RACs and more generally on the explainability aspects of RNNs for NLP, using tools from many-body quantum physics. </br></br>

<a href='http://arxiv.org/pdf/2112.06641.pdf'>2112.06641</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -1.0552баллов, №1166</br>
<b>Goedel\'s Incompleteness <font color="#be00be">Theor</font>em</b></br>
Authors: , Batzoglou, Serafim</br>
  I present the proof of Goedel\'s First Incompleteness <font color="#be00be">theor</font>em in an intuitive manner, while covering all technically challenging steps. I present generalizations of Goedel\'s fixed point lemma to two-sentence and multi-sentence versions, which allow proof of incompleteness through circular versions of the liar\'s paradox. I discuss the relation of Goedel\'s First and Second Incompletneness theorems to Goedel\'s Completeness theorems, and conclude with remarks on implications of these results for mathematics, computation, theory of mind and AI. </br></br>

<a href='http://arxiv.org/pdf/2112.06101.pdf'>2112.06101</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -1.0570баллов, №1167</br>
<b>Confidence intervals for the <font color="#be00be">random forest</font> generalization error</b></br>
Authors: , F., Marques, C, Paulo</br>
  We show that underneath the training process of a <font color="#be00be">random forest</font> there lies not only the well known and almost computationally free out-of-bag point estimate of its generalization error, but also a path to compute a confidence interval for the generalization error which does not demand a retraining of the forest or any forms of data splitting. Besides the low computational cost involved in its construction, this confidence interval is shown through simulations to have good coverage and appropriate shrinking rate of its width in terms of the training sample size. </br></br>

<a href='http://arxiv.org/pdf/2112.08549.pdf'>2112.08549</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -1.0651баллов, №1168</br>
<b>A prediction-based approach for online dynamic radiotherapy scheduling</b></br>
Authors: , Pham, Tu-San, Legrain, Antoine, De Causmaecker, Patrick, Rousseau, Louis-Martin</br>
  <font color="#be00be">Patient</font> scheduling is a difficult task as it involves dealing with stochastic factors such as an unknown arrival flow of patients. Scheduling radiotherapy treatments for <font color="#be00be">cancer</font> patients faces a similar problem. Curative patients need to start their treatment within the recommended deadlines, i.e., 14 or 28 days after their admission while reserving treatment capacity for palliative patients who require urgent treatments within 1 to 3 days after their admission. Most cancer centers solve the problem by reserving a fixed number of treatment slots for emergency patients. However, this flat-reservation approach is not ideal and can cause overdue treatments for emergency patients on some days while not fully exploiting treatment capacity on some other days, which also leads to delaying treatment for curative patients. This problem is especially severe in large and crowded hospitals. In this paper, we propose a prediction-based approach for online dynamic radiotherapy scheduling. An offline problem where all future patient arrivals are known in advance is solved to optimality using Integer Programming. A <font color="#be00be">regression</font> model is then trained to recognize the links between patients\' arrival patterns and their ideal waiting time. The trained regression model is then embedded in a prediction-based approach that schedules a patient based on their characteristics and the present state of the calendar. The numerical results show that our prediction-based approach efficiently prevents overdue treatments for emergency patients while maintaining a good waiting time compared to other scheduling approaches based on a flat-reservation policy. </br></br>

<a href='http://arxiv.org/pdf/2112.07285.pdf'>2112.07285</a> &nbsp&nbsp (cs:SD, cs:ML) &nbsp&nbsp -1.0697баллов, №1169</br>
<b>Automatic COVID-19 <font color="#be00be">diseas</font>e <font color="#be00be">diagnos</font>is using 1D convolutional neural\n  network and augmentation with human respiratory sound based on parameters:\n  cough, breath, and voice</b></br>
Authors: , Lella, Kranthi Kumar, Pja, Alphonse</br>
  The issue in respiratory sound classification has attained good attention from the <font color="#be00be">clinic</font>al scientists and <font color="#640064">medic</font>al researcher\'s group in the last year to <font color="#be00be">diagnos</font>ing COVID-19 <font color="#be00be">diseas</font>e. To date, various models of Artificial Intelligence (AI) entered into the <font color="#009600">real-world</font> to detect the COVID-19 disease from human-generated sounds such as voice/speech, cough, and breath. The Convolutional Neural Network (CNN) model is implemented for solving a lot of real-world problems on machines based on Artificial Intelligence (AI). In this context, one dimension (1D) CNN is suggested and implemented to diagnose respiratory diseases of COVID-19 from human respiratory sounds such as a voice, cough, and breath. An augmentation-based mechanism is applied to improve the preprocessing performance of the COVID-19 sounds dataset and to automate COVID-19 disease diagnosis using the 1D convolutional network. Furthermore, a DDAE (Data De-noising Auto Encoder) technique is used to generate deep sound features such as the input function to the 1D CNN instead of adopting the standard input of MFCC (Mel-frequency cepstral coefficient), and it is performed better accuracy and performance than previous models. </br></br>

<a href='http://arxiv.org/pdf/2112.06147.pdf'>2112.06147</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.0748баллов, №1170</br>
<b>Self-Supervised Modality-Aware Multiple Granularity Pre-Training for\n  RGB-Infrared Person <font color="#be00be">Re-Identification</font></b></br>
Authors: , Wan, Lin, Jing, Qianyan, Sun, Zongyuan, Zhang, Chuang, Li, Zhihang, Chen, Yehansen</br>
  While RGB-Infrared cross-modality person <font color="#be00be">re-identification</font> (RGB-IR ReID) has enabled great progress in 24-hour intelligent <font color="#be00be">surveillance</font>, <font color="#00be00">state-of-the-art</font>s still heavily rely on fine-tuning ImageNet pre-trained networks. Due to the single-modality nature, such large-scale pre-training may yield RGB-biased representations that hinder the performance of cross-modality image <font color="#be00be">retrieval</font>. This paper presents a self-supervised pre-training alternative, named Modality-Aware Multiple Granularity Learning (MMGL), which directly trains models from scratch on multi-modality ReID datasets, but achieving <font color="#960096">competitive</font> results without external data and sophisticated tuning tricks. Specifically, MMGL globally maps shuffled RGB-IR images into a shared latent permutation space and further improves local discriminability by maximizing agreement between cycle-consistent RGB-IR image patches. Experiments demonstrate that MMGL learns better representations (+6.47% Rank-1) with faster training speed (converge in few hours) and solider data efficiency (&lt;5% data size) than ImageNet pre-training. The results also suggest it generalizes well to various existing models, losses and has promising transferability across datasets. The code will be released. </br></br>

<a href='http://arxiv.org/pdf/2112.07955.pdf'>2112.07955</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.0764баллов, №1171</br>
<b>Channel Parameter Estimation in the Presence of Phase Noise Based on\n  Maximum Correntropy Criterion</b></br>
Authors: , Alizadeh, Amir, Hodtani, Ghosheh Abed</br>
  Oscillator output generally has phase noise causing the output power spectral density (PSD) to disperse around a Dirac delta function. In this paper, the AWGN channel is considered, where the sent signal accompanying with phase noise is added to the channel <font color="#be00be">Gaussi</font>an noise and received at the receiver. Conventional channel estimation algorithms such as least mean square (LMS) and mean MSE criterion are not suitable for this channel estimation. We (i) analyze this phase noise channel estimation with information <font color="#be00be">theor</font>etic learning (ITL) criterion, i.e., maximum correntropy criterion (MCC), leading to robustness in the channel estimator\'s steady state behavior; and (ii) improve the convergence rate by combining MSE and MCC as a novel mixed-LMS algorithm. </br></br>

<a href='http://arxiv.org/pdf/2112.08439.pdf'>2112.08439</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -1.0791баллов, №1172</br>
<b>Generalization Bounds for Stochastic Gradient Langevin Dynamics: A\n  Unified View via Information Leakage Analysis</b></br>
Authors: , Wu, Bingzhe, Liang, Zhicong, Bian, Yatao, Chen, ChaoChao, Huang, Junzhou, Yao, Yuan</br>
  Recently, generalization bounds of the non-convex empirical risk minimization paradigm using Stochastic Gradient Langevin Dynamics (SGLD) have been extensively studied. Several <font color="#be00be">theor</font>etical frameworks have been presented to study this problem from different perspectives, such as information theory and stability. In this paper, we present a unified view from <font color="#be00be">privacy</font> leakage analysis to investigate the generalization bounds of SGLD, along with a theoretical framework for re-deriving previous results in a succinct manner.   Aside from theoretical findings, we conduct various numerical studies to empirically assess the information leakage issue of SGLD. Additionally, our theoretical and empirical results provide explanations for prior works that study the membership privacy of SGLD. </br></br>

<a href='http://arxiv.org/pdf/2112.08159.pdf'>2112.08159</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -1.0794баллов, №1173</br>
<b>One size does not fit all: Investigating strategies for\n  differentially-<font color="#be00be">private</font> learning across NLP tasks</b></br>
Authors: , Senge, Manuel, Igamberdiev, Timour, Habernal, Ivan</br>
  Preserving <font color="#be00be">privacy</font> in training modern NLP models comes at a cost. We know that stricter privacy guarantees in differentially-<font color="#be00be">private</font> stochastic gradient descent (DP-SGD) generally degrade model performance. However, previous research on the efficiency of DP-SGD in NLP is inconclusive or even counter-intuitive. In this short paper, we provide a thorough analysis of different privacy preserving strategies on seven downstream datasets in five different `typical\' NLP tasks with varying complexity using modern neural models. We show that unlike standard non-private approaches to solving NLP tasks, where bigger is usually better, privacy-preserving strategies do not exhibit a winning pattern, and each task and privacy regime requires a special treatment to achieve adequate performance. </br></br>

<a href='http://arxiv.org/pdf/2112.06724.pdf'>2112.06724</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -1.0838баллов, №1174</br>
<b>ANEA: Automated (Named) Entity Annotation for German Domain-Specific\n  Texts</b></br>
Authors: , Zhukova, Anastasia, Hamborg, Felix, Gipp, Bela</br>
  <font color="#be00be">Named entity</font> recognition (NER) is an important task that aims to resolve universal categories of named entities, e.g., persons, locations, organizations, and times. Despite its common and viable use in many use cases,<font color="#be00be"> NER </font>is barely applicable in domains where general categories are suboptimal, such as engineering or <font color="#640064">medic</font>ine. To facilitate NER of domain-specific types, we propose ANEA, an automated (named) entity annotator to assist human annotators in creating domain-specific NER corpora for German text collections when given a set of domain-specific texts. In our evaluation, we find that ANEA automatically identifies terms that best represent the texts\' content, identifies groups of coherent terms, and extracts and assigns descriptive labels to these groups, i.e., annotates text datasets into the domain (named) entities. </br></br>

<a href='http://arxiv.org/pdf/2112.07921.pdf'>2112.07921</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.0842баллов, №1175</br>
<b>Temporal Shuffling for Defending Deep Action Recognition Models against\n  <font color="#be00be">Adversarial Att</font>acks</b></br>
Authors: , Hwang, Jaehui, Zhang, Huan, Choi, Jun-Ho, Hsieh, Cho-Jui, Lee, Jong-Seok</br>
  Recently, video-based action recognition methods using convolutional neural networks (CNNs) achieve remarkable recognition performance. However, there is still lack of understanding about the generalization mechanism of action recognition models. In this paper, we suggest that action recognition models rely on the motion information less than expected, and thus they are robust to randomization of frame orders. Based on this observation, we develop a novel defense method using temporal shuffling of input videos against <font color="#be00be">adversarial att</font>acks for action recognition models. Another observation enabling our defense method is that adversarial perturbations on videos are sensitive to temporal destruction. To the best of our knowledge, this is the first attempt to design a defense method specific to video-based action recognition models. </br></br>

<a href='http://arxiv.org/pdf/2111.03972.pdf'>2111.03972</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -1.0880баллов, №1176</br>
<b>Understanding Layer-wise Contributions in Deep Neural Networks through\n  Spectral Analysis</b></br>
Authors: , Dandi, Yatin, Jacot, Arthur</br>
  Spectral analysis is a powerful tool, decomposing any function into simpler parts. In machine learning, Mercer\'s <font color="#be00be">theor</font>em generalizes this idea, providing for any <font color="#be00be">kernel</font> and input distribution a natural basis of functions of increasing frequency. More recently, several works have extended this analysis to deep neural networks through the framework of Neural Tangent Kernel. In this work, we analyze the layer-wise spectral bias of Deep Neural Networks and relate it to the contributions of different layers in the reduction of generalization error for a given target function. We utilize the properties of Hermite polynomials and spherical harmonics to prove that initial layers exhibit a larger bias towards high-frequency functions defined on the unit sphere. We further provide empirical results validating our theory in high dimensional datasets for Deep Neural Networks. </br></br>

<a href='http://arxiv.org/pdf/2112.09104.pdf'>2112.09104</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -1.1007баллов, №1177</br>
<b>Non-<font color="#be00be">Gaussi</font>an Component Analysis via Lattice Basis Reduction</b></br>
Authors: , Diakonikolas, Ilias, Kane, Daniel M.</br>
  Non-<font color="#be00be">Gaussi</font>an Component Analysis (NGCA) is the following distribution learning problem: Given i.i.d. samples from a distribution on $\\mathbb{R}^d$ that is non-gaussian in a hidden direction $v$ and an independent standard Gaussian in the orthogonal directions, the goal is to approximate the hidden direction $v$. Prior work \\cite{DKS17-sq} provided formal evidence for the existence of an information-computation tradeoff for NGCA under appropriate moment-matching conditions on the univariate non-gaussian distribution $A$. The latter result does not apply when the distribution $A$ is discrete. A natural question is whether information-computation tradeoffs persist in this setting. In this paper, we answer this question in the negative by obtaining a sample and computationally efficient algorithm for NGCA in the regime that $A$ is discrete or nearly discrete, in a well-defined technical sense. The key tool leveraged in our algorithm is the LLL method \\cite{LLL82} for lattice basis reduction. </br></br>

<a href='http://arxiv.org/pdf/2112.06276.pdf'>2112.06276</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.1014баллов, №1178</br>
<b>Quantifying and Understanding Adversarial Examples in Discrete Input\n  Spaces</b></br>
Authors: , Kuleshov, Volodymyr, Nikishin, Evgenii, Thakoor, Shantanu, Lau, Tingfung, Ermon, Stefano</br>
  Modern classification algorithms are susceptible to adversarial examples--perturbations to inputs that cause the algorithm to produce undesirable behavior. In this work, we seek to understand and extend adversarial examples across domains in which inputs are discrete, particularly across new domains, such as computational biology. As a step towards this goal, we formalize a notion of synonymous adversarial examples that applies in any discrete setting and describe a simple domain-agnostic algorithm to construct such examples. We apply this algorithm across multiple domains--including <font color="#be00be">sentiment</font> analysis and DNA sequence classification--and find that it consistently uncovers adversarial examples. We seek to understand their prevalence <font color="#be00be">theor</font>etically and we attribute their existence to spurious token correlations, a statistical phenomenon that is specific to discrete spaces. Our work is a step towards a domain-agnostic treatment of discrete adversarial examples analogous to that of continuous inputs. </br></br>

<a href='http://arxiv.org/pdf/2112.05605.pdf'>2112.05605</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.1042баллов, №1179</br>
<b>Comparison of Markov chains via weak Poincar\\\'e inequalities with\n  application to pseudo-marginal MCMC</b></br>
Authors: , Andrieu, Christophe, Lee, Anthony, Power, Sam, Wang, Andi Q.</br>
  We investigate the use of a certain class of functional inequalities known as weak Poincar\\\'e inequalities to bound convergence of Markov chains to equilibrium. We show that this enables the straightforward and transparent derivation of subgeometric convergence bounds for methods such as the Independent Metropolis--Hastings sampler and pseudo-marginal methods for intractable likelihoods, the latter being subgeometric in many practical settings. These results rely on novel quantitative comparison <font color="#be00be">theor</font>ems between Markov chains. Associated proofs are simpler than those relying on drift/minorization conditions and the tools developed allow us to recover and further extend known results as particular cases. We are then able to provide new insights into the practical use of pseudo-marginal algorithms, analyse the effect of averaging in Approximate <font color="#be00be">Bayes</font>ian Computation (ABC) and the use of products of independent averages, and also to study the case of lognormal weights relevant to particle marginal Metropolis--Hastings (PMMH). </br></br>

<a href='http://arxiv.org/pdf/2112.06134.pdf'>2112.06134</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -1.1110баллов, №1180</br>
<b>Markov subsampling based Huber Criterion</b></br>
Authors: , Gong, Tieliang, Dong, Yuxin, Chen, Hong, Dong, Bo, Li, Chen</br>
  Subsampling is an important technique to tackle the computational challenges brought by big data. Many subsampling procedures fall within the framework of importance sampling, which assigns high sampling probabilities to the samples appearing to have big impacts. When the noise level is high, those sampling procedures tend to pick many <font color="#be00be">outlier</font>s and thus often do not perform satisfactorily in practice. To tackle this issue, we design a new Markov subsampling strategy based on Huber criterion (HMS) to construct an informative subset from the noisy full data; the constructed subset then serves as a refined working data for efficient processing. HMS is built upon a Metropolis-Hasting procedure, where the inclusion probability of each sampling unit is determined using the Huber criterion to prevent over scoring the outliers. Under mild conditions, we show that the estimator based on the subsamples selected by HMS is statistically consistent with a sub-<font color="#be00be">Gaussi</font>an deviation bound. The promising performance of HMS is demonstrated by extensive studies on large scale simulations and real data examples. </br></br>

<a href='http://arxiv.org/pdf/2112.06533.pdf'>2112.06533</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.1117баллов, №1181</br>
<b>Makeup216: Logo Recognition with <font color="#be00be">Adversarial Att</font>ention Representations</b></br>
Authors: , Hu, Junjun, Zhu, Yanhao, Zhao, Bo, Zheng, Jiexin, Zhao, Chenxu, Zhu, Xiangyu, Wu, Kangle, Tang, Darun</br>
  One of the challenges of logo recognition lies in the diversity of forms, such as symbols, texts or a combination of both; further, logos tend to be extremely concise in design while similar in appearance, suggesting the difficulty of learning discriminative representations. To investigate the variety and representation of logo, we introduced Makeup216, the largest and most complex logo dataset in the field of makeup, captured from the <font color="#009600">real world</font>. It comprises of 216 logos and 157 brands, including 10,019 images and 37,018 annotated logo objects. In addition, we found that the marginal background around the pure logo can provide a important context information and proposed an <font color="#be00be">adversarial att</font>ention representation framework (AAR) to attend on the logo subject and auxiliary marginal background separately, which can be combined for better representation. Our proposed framework achieved <font color="#960096">competitive</font> results on Makeup216 and another large-scale open logo dataset, which could provide fresh thinking for logo recognition. The dataset of Makeup216 and the code of the proposed framework will be released soon. </br></br>

<a href='http://arxiv.org/pdf/2112.06924.pdf'>2112.06924</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -1.1163баллов, №1182</br>
<b>Generating Fluent Fact Checking Explanations with Unsupervised\n  <font color="#be00be">Post-Editing</font></b></br>
Authors: , Jolly, Shailza, Atanasova, Pepa, Augenstein, Isabelle</br>
  Fact-checking systems have become important tools to verify fake and misguiding news. These systems become more trustworthy when human-readable explanations accompany the veracity labels. However, manual collection of such explanations is expensive and time-consuming. Recent works frame explanation generation as extractive <font color="#be00be">summarization</font>, and propose to automatically select a sufficient subset of the most important facts from the ruling comments (RCs) of a professional journalist to obtain fact-checking explanations. However, these explanations lack fluency and sentence coherence. In this work, we present an iterative edit-based algorithm that uses only phrase-level edits to perform unsupervised <font color="#be00be">post-editing</font> of disconnected RCs. To regulate our editing algorithm, we use a scoring function with components including fluency and semantic preservation. In addition, we show the applicability of our approach in a completely unsupervised setting. We experiment with two benchmark datasets, LIAR-PLUS and PubHealth. We show that our model generates explanations that are fluent, readable, non-redundant, and cover important information for the fact check. </br></br>

<a href='http://arxiv.org/pdf/2112.06389.pdf'>2112.06389</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -1.1173баллов, №1183</br>
<b>Local and Global <font color="#be00be">Point Cloud</font> Reconstruction for 3D Hand <font color="#be00be">Pose Estimation</font></b></br>
Authors: , Yu, Ziwei, Yang, Linlin, Chen, Shicheng, Yao, Angela</br>
  This paper addresses the 3D <font color="#be00be">point cloud</font> reconstruction and 3D <font color="#be00be">pose estimation</font> of the human hand from a single RGB image. To that end, we present a novel pipeline for local and global point cloud reconstruction using a 3D hand template while learning a latent representation for pose estimation. To demonstrate our method, we introduce a new multi-view hand posture dataset to obtain complete 3D point clouds of the hand in the <font color="#009600">real world</font>. Experiments on our newly proposed dataset and four public benchmarks demonstrate the model\'s strengths. Our method <font color="#00be00">outperform</font>s competitors in 3D pose estimation while reconstructing realistic-looking complete 3D hand point clouds. </br></br>

<a href='http://arxiv.org/pdf/2112.07670.pdf'>2112.07670</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -1.1202баллов, №1184</br>
<b>A literature review on COVID-19 <font color="#be00be">diseas</font>e <font color="#be00be">diagnos</font>is from respiratory sound\n  data</b></br>
Authors: , Lella, Kranthi Kumar, PJA, Alphonse</br>
  The World Health Organization (WHO) has announced a COVID-19 was a global pandemic in March 2020. It was initially started in china in the year 2019 December and affected an expanding number of nations in various countries in the last few months. In this particular situation, many techniques, methods, and AI-based classification algorithms are put in the spotlight in reacting to fight against it and reduce the rate of such a global health crisis. COVID-19\'s main signs are heavy temperature, different cough, cold, breathing shortness, and a combination of loss of sense of smell and chest tightness. The digital world is growing day by day, in this context digital stethoscope can read all of these symptoms and <font color="#be00be">diagnos</font>e respiratory <font color="#be00be">diseas</font>e. In this study, we majorly focus on literature reviews of how SARS-CoV-2 is spreading and in-depth analysis of the diagnosis of COVID-19 disease from human respiratory sounds like cough, voice, and breath by analyzing the respiratory sound parameters. We hope this review will provide an initiative for the <font color="#be00be">clinic</font>al scientists and researcher\'s community to initiate open access, scalable, and accessible work in the collective battle against COVID-19. </br></br>

<a href='http://arxiv.org/pdf/2112.08441.pdf'>2112.08441</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -1.1206баллов, №1185</br>
<b>Towards Explainable Artificial Intelligence in Banking and <font color="#be00be">Financ</font>ial\n  Services</b></br>
Authors: , Hanif, Ambreen</br>
  Artificial intelligence (AI) enables machines to learn from human experience, adjust to new inputs, and perform human-like tasks. AI is progressing rapidly and is transforming the way businesses operate, from process automation to cognitive augmentation of tasks and intelligent process/data analytics. However, the main challenge for human users would be to understand and appropriately trust the result of AI algorithms and methods. In this paper, to address this challenge, we study and analyze the recent work done in Explainable Artificial Intelligence (XAI) methods and tools. We introduce a novel XAI process, which facilitates producing explainable models while maintaining a high level of learning performance. We present an interactive evidence-based approach to assist human users in comprehending and trusting the results and output created by AI-enabled algorithms. We adopt a typical scenario in the Banking domain for analyzing <font color="#be00be">customer</font> transactions. We develop a digital dashboard to facilitate interacting with the algorithm results and discuss how the proposed XAI method can significantly improve the confidence of data scientists in understanding the result of AI-enabled algorithms. </br></br>

<a href='http://arxiv.org/pdf/2112.07324.pdf'>2112.07324</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.1306баллов, №1186</br>
<b>On the Impact of Hard Adversarial Instances on Overfitting in\n  Adversarial Training</b></br>
Authors: , Liu, Chen, Huang, Zhichao, Salzmann, Mathieu, Zhang, Tong, S&#xfc;sstrunk, Sabine</br>
  Adversarial training is a popular method to robustify models against <font color="#be00be">adversarial att</font>acks. However, it exhibits much more severe overfitting than training on clean inputs. In this work, we investigate this phenomenon from the perspective of training instances, i.e., training input-target pairs. Based on a quantitative metric measuring instances\' difficulty, we analyze the model\'s behavior on training instances of different difficulty levels. This lets us show that the decay in generalization performance of adversarial training is a result of the model\'s attempt to fit hard adversarial instances. We <font color="#be00be">theor</font>etically verify our observations for both linear and general nonlinear models, proving that models trained on hard instances have worse generalization performance than ones trained on easy instances. Furthermore, we prove that the difference in the generalization gap between models trained by instances of different difficulty levels increases with the size of the adversarial budget. Finally, we conduct case studies on methods mitigating adversarial overfitting in several scenarios. Our analysis shows that methods successfully mitigating adversarial overfitting all avoid fitting hard adversarial instances, while ones fitting hard adversarial instances do not achieve true robustness. </br></br>

<a href='http://arxiv.org/pdf/2112.06281.pdf'>2112.06281</a> &nbsp&nbsp (cs:ML, cs:AI, stat:ML) &nbsp&nbsp -1.1328баллов, №1187</br>
<b>Spatial-Temporal-Fusion BNN: Variational <font color="#be00be">Bayes</font>ian Feature Layer</b></br>
Authors: , Lei, Shiye, Tu, Zhuozhuo, Rutkowski, Leszek, Zhou, Feng, Shen, Li, He, Fengxiang, Tao, Dacheng</br>
  <font color="#be00be">Bayes</font>ian neural networks (BNNs) have become a principal approach to alleviate overconfident predictions in deep learning, but they often suffer from scaling issues due to a large number of distribution parameters. In this paper, we discover that the first layer of a deep network possesses multiple disparate optima when solely retrained. This indicates a large posterior variance when the first layer is altered by a Bayesian layer, which motivates us to design a spatial-temporal-fusion BNN (STF-BNN) for efficiently scaling BNNs to large models: (1) first normally train a neural network from scratch to realize fast training; and (2) the first layer is converted to Bayesian and inferred by employing stochastic variational inference, while other layers are fixed. Compared to vanilla BNNs, our approach can greatly reduce the training time and the number of parameters, which contributes to scale BNNs efficiently. We further provide <font color="#be00be">theor</font>etical guarantees on the generalizability and the capability of mitigating overconfidence of STF-BNN. Comprehensive experiments demonstrate that STF-BNN (1) achieves the <font color="#00be00">state-of-the-art</font> performance on prediction and uncertainty quantification; (2) significantly improves adversarial robustness and <font color="#be00be">privacy</font> preservation; and (3) considerably reduces training time and memory costs. </br></br>

<a href='http://arxiv.org/pdf/2112.08507.pdf'>2112.08507</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -1.1329баллов, №1188</br>
<b>Algorithms for Adaptive Experiments that Trade-off Statistical Analysis\n  with Reward: Combining Uniform Random Assignment and Reward Maximization</b></br>
Authors: , Nogas, Jacob, Li, Tong, Yanez, Fernando J., Modiri, Arghavan, Deliu, Nina, Prystawski, Ben, Villar, Sofia S., Rafferty, Anna, Williams, Joseph J.</br>
  Multi-armed <font color="#be00be">bandit</font> algorithms like Thompson Sampling can be used to conduct adaptive experiments, in which maximizing reward means that data is used to progressively assign more participants to more effective arms. Such assignment strategies increase the risk of statistical hypothesis tests identifying a difference between arms when there is not one, and failing to conclude there is a difference in arms when there truly is one. We present simulations for 2-arm experiments that explore two algorithms that combine the benefits of uniform randomization for statistical analysis, with the benefits of reward maximization achieved by Thompson Sampling (TS). First, Top-Two Thompson Sampling adds a fixed amount of uniform random allocation (UR) spread evenly over time. Second, a novel heuristic algorithm, called TS PostDiff (Posterior Probability of Difference). TS PostDiff takes a <font color="#be00be">Bayes</font>ian approach to mixing TS and UR: the probability a participant is assigned using UR allocation is the posterior probability that the difference between two arms is `small\' (below a certain threshold), allowing for more UR exploration when there is little or no reward to be gained. We find that TS PostDiff method performs well across multiple effect sizes, and thus does not require tuning based on a guess for the true effect size. </br></br>

<a href='http://arxiv.org/pdf/2112.08817.pdf'>2112.08817</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.1355баллов, №1189</br>
<b>Search for temporal cell <font color="#be00be">segmentation</font> robustness in phase-contrast\n  microscopy videos</b></br>
Authors: , G&#xf3;mez-de-Mariscal, Estibaliz, Jayatilaka, Hasini, &#xc7;i&#xe7;ek, &#xd6;zg&#xfc;n, Brox, Thomas, Wirtz, Denis, Mu&#xf1;oz-Barrutia, Arrate</br>
  Studying cell morphology changes in time is critical to understanding cell migration mechanisms. In this work, we present a deep learning-based workflow to segment <font color="#be00be">cancer</font> cells embedded in 3D collagen matrices and imaged with phase-contrast microscopy. Our approach uses transfer learning and recurrent convolutional long-short term memory units to exploit the temporal information from the past and provide a consistent <font color="#be00be">segmentation</font> result. Lastly, we propose a geometrical-characterization approach to studying cancer cell morphology. Our approach provides stable results in time, and it is robust to the different weight initialization or training data sampling. We introduce a new annotated dataset for 2D cell segmentation and <font color="#be00be">tracking</font>, and an open-source implementation to replicate the experiments or adapt them to new image processing problems. </br></br>

<a href='http://arxiv.org/pdf/2112.05220.pdf'>2112.05220</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.1356баллов, №1190</br>
<b>Hidden Path Selection Network for Semantic <font color="#be00be">Segmentation</font> of Remote\n  Sensing Images</b></br>
Authors: , Yang, Kunping, Tong, Xin-Yi, Xia, Gui-Song, Shen, Weiming, Zhang, Liangpei</br>
  Targeting at depicting land covers with pixel-wise semantic categories, semantic <font color="#be00be">segmentation</font> in remote sensing images needs to portray diverse distributions over vast geographical locations, which is difficult to be achieved by the homogeneous pixel-wise forward paths in the architectures of existing deep models. Although several algorithms have been designed to select pixel-wise adaptive forward paths for natural image analysis, it still lacks <font color="#be00be">theor</font>etical supports on how to obtain optimal selections. In this paper, we provide mathematical analyses in terms of the parameter optimization, which guides us to design a method called Hidden Path Selection Network (HPS-Net). With the help of hidden variables derived from an extra mini-branch, HPS-Net is able to tackle the inherent problem about inaccessible global optimums by adjusting the direct relationships between feature maps and pixel-wise path selections in existing algorithms, which we call hidden path selection. For the better training and evaluation, we further refine and expand the 5-class Gaofen Image Dataset (GID-5) to a new one with 15 land-cover categories, i.e., GID-15. The experimental results on both GID-5 and GID-15 demonstrate that the proposed modules can stably improve the performance of different deep structures, which validates the proposed mathematical analyses. </br></br>

<a href='http://arxiv.org/pdf/2112.07106.pdf'>2112.07106</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.1458баллов, №1191</br>
<b>ES-CRF: Embedded Superpixel CRF for Semantic <font color="#be00be">Segmentation</font></b></br>
Authors: , Zhu, Jie, Huang, Huabin, Li, Banghuai, Wang, Leye</br>
  Modern semantic <font color="#be00be">segmentation</font> methods devote much attention to adjusting feature representations to improve the segmentation performance in various ways, such as metric learning, architecture design, etc. However, almost all those methods neglect the particularity of boundary pixels. These pixels are prone to obtain confusing features from both sides due to the continuous expansion of receptive fields in CNN networks. In this way, they will mislead the model optimization direction and make the class weights of such categories that tend to share many adjacent pixels lack discrimination, which will damage the overall performance. In this work, we dive deep into this problem and propose a novel method named Embedded Superpixel CRF (ES-CRF) to address it. ES-CRF involves two main aspects. On the one hand, ES-CRF innovatively fuses the CRF mechanism into the CNN network as an organic whole for more effective end-to-end optimization. It utilizes CRF to guide the message passing between pixels in high-level features to purify the feature representation of boundary pixels, with the help of inner pixels belong to the same object. On the other hand, superpixel is integrated into ES-CRF to exploit the local object prior for more reliable message passing. Finally, our proposed method yields new records on two challenging benchmarks, i.e., Cityscapes and ADE20K. Moreover, we make detailed <font color="#be00be">theor</font>etical analysis to verify the superiority of ES-CRF. </br></br>

<a href='http://arxiv.org/pdf/2112.06536.pdf'>2112.06536</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.1462баллов, №1192</br>
<b>SphereSR: 360{\\deg} Image <font color="#be00be">Super-Resolution</font> with Arbitrary Projection via\n  Continuous Spherical Image Representation</b></br>
Authors: , Yoon, Youngho, Chung, Inchul, Wang, Lin, Yoon, Kuk-Jin</br>
  The 360{\\deg}imaging has recently gained great attention; however, its angular resolution is relatively lower than that of a narrow field-of-view (FOV) perspective image as it is captured by using fisheye lenses with the same sensor size. Therefore, it is beneficial to super-resolve a 360{\\deg}image. Some attempts have been made but mostly considered the equirectangular projection (ERP) as one of the way for 360{\\deg}image representation despite of latitude-dependent distortions. In that case, as the output high-resolution(HR) image is always in the same ERP format as the low-resolution (LR) input, another information loss may occur when transforming the HR image to other projection types. In this paper, we propose SphereSR, a novel framework to generate a continuous spherical image representation from an LR 360{\\deg}image, aiming at predicting the RGB values at given spherical coordinates for <font color="#be00be">super-resolution</font> with an arbitrary 360{\\deg}image projection. Specifically, we first propose a feature extraction module that represents the spherical data based on icosahedron and efficiently extracts features on the spherical surface. We then propose a spherical local implicit image function (SLIIF) to predict RGB values at the spherical coordinates. As such, SphereSR flexibly reconstructs an HR image under an arbitrary projection type. Experiments on various benchmark datasets show that our method significantly surpasses existing methods. </br></br>

<a href='http://arxiv.org/pdf/2112.07998.pdf'>2112.07998</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.1464баллов, №1193</br>
<b>Multi-modal Networks Reveal Patterns of Operational Similarity of\n  Terrorist Organizations</b></br>
Authors: , Campedelli, Gian Maria, Cruickshank, Iain J., Carley, Kathleen M.</br>
  Capturing dynamics of operational similarity among terrorist groups is critical to provide actionable insights for counter-terrorism and intelligence monitoring. Yet, in spite of its <font color="#be00be">theor</font>etical and practical relevance, research addressing this problem is currently lacking. We tackle this problem proposing a novel computational framework for detecting clusters of terrorist groups sharing similar behaviors, focusing on groups\' yearly repertoire of deployed tactics, attacked targets, and utilized weapons. Specifically considering those organizations that have plotted at least 50 attacks from 1997 to 2018, accounting for a total of 105 groups responsible for more than 42,000 events worldwide, we offer three sets of results. First, we show that over the years global terrorism has been characterized by increasing operational cohesiveness. Second, we highlight that year-to-year stability in co-<font color="#be00be">clustering</font> among groups has been particularly high from 2009 to 2018, indicating temporal consistency of similarity patterns in the last decade. Third, we demonstrate that operational similarity between two organizations is driven by three factors: (a) their overall activity; (b) the difference in the diversity of their operational repertoires; (c) the difference in a combined measure of diversity and activity. Groups\' operational preferences, geographical homophily and ideological affinity have no consistent role in determining operational similarity. </br></br>

<a href='http://arxiv.org/pdf/2112.07096.pdf'>2112.07096</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.1521баллов, №1194</br>
<b>Adaptive Projected Residual Networks for Learning Parametric Maps from\n  Sparse Data</b></br>
Authors: , O\'Leary-Roseberry, Thomas, Du, Xiaosong, Chaudhuri, Anirban, Martins, Joaquim R. R. A., Willcox, Karen, Ghattas, Omar</br>
  We present a parsimonious surrogate framework for learning high dimensional parametric maps from limited training data. The need for parametric surrogates arises in many applications that require repeated queries of complex computational models. These applications include such &quot;outer-loop&quot; problems as <font color="#be00be">Bayes</font>ian inverse problems, optimal experimental design, and optimal design and control under uncertainty, as well as real time inference and control problems. Many high dimensional parametric mappings admit low dimensional structure, which can be exploited by mapping-informed reduced bases of the inputs and outputs. Exploiting this property, we develop a framework for learning low dimensional approximations of such maps by adaptively constructing ResNet approximations between reduced bases of their inputs and output. Motivated by recent approximation <font color="#be00be">theor</font>y for ResNets as discretizations of control flows, we prove a universal approximation property of our proposed adaptive projected ResNet framework, which motivates a related iterative algorithm for the ResNet construction. This strategy represents a confluence of the approximation theory and the algorithm since both make use of sequentially minimizing flows. In numerical examples we show that these parsimonious, mapping-informed architectures are able to achieve remarkably high accuracy given few training data, making them a desirable surrogate strategy to be implemented for minimal computational investment in training data generation. </br></br>

<a href='http://arxiv.org/pdf/2112.07621.pdf'>2112.07621</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.1521баллов, №1195</br>
<b>Re-ranking With Constraints on Diversified Exposures for Homepage\n  Recommender System</b></br>
Authors: , Hao, Qi, Luo, Tianze, Huzhang, Guangda</br>
  The homepage <font color="#be00be">recommendat</font>ion on most <font color="#be00be">E-commerce</font> applications places items in a <font color="#00be00">hierarchical</font> manner, where different channels display items in different <font color="#be00be">style</font>s. Existing algorithms usually optimize the performance of a single channel. So designing the model to achieve the optimal recommendation list which maximize the Click-Through Rate (CTR) of whole homepage is a challenge problem. Other than the accuracy objective, display diversity on the homepage is also important since homogeneous display usually hurts user experience. In this paper, we propose a two-stage architecture of the homepage recommendation system. In the first stage, we develop efficient algorithms for recommending items to proper channels while maintaining diversity. The two methods can be combined: user-channel-item predictive model with diversity constraint. In the second stage, we provide an ordered list of items in each channel. Existing re-ranking models are hard to describe the mutual influence between items in both intra-channel and inter-channel. Therefore, we propose a Deep \\&amp; Hierarchical Attention Network Re-ranking (DHANR) model for homepage recommender systems. The Hierarchical Attention Network consists of an item encoder, an item-level attention layer, a channel encoder and a channel-level attention layer. Our method achieves a significant improvement in terms of precision, intra-list average distance(ILAD) and channel-wise Precision@k in offline experiments and in terms of CTR and ILAD in our online systems. </br></br>

<a href='http://arxiv.org/pdf/2112.08442.pdf'>2112.08442</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -1.1553баллов, №1196</br>
<b>Utilizing XAI technique to improve autoencoder based model for computer\n  network <font color="#be00be">anomal</font>y detection with shapley additive explanation(SHAP)</b></br>
Authors: , Roshan, Khushnaseeb, Zafar, Aasim</br>
  Machine learning (ML) and Deep Learning (DL) methods are being adopted rapidly, especially in computer network security, such as fraud detection, network <font color="#be00be">anomal</font>y detection, intrusion detection, and much more. However, the lack of transparency of ML and DL based models is a major obstacle to their implementation and criticized due to its black-box nature, even with such tremendous results. Explainable Artificial Intelligence (XAI) is a promising area that can improve the trustworthiness of these models by giving explanations and <font color="#be00be">interpret</font>ing its output. If the internal working of the ML and DL based models is understandable, then it can further help to improve its performance. The objective of this paper is to show that how XAI can be used to interpret the results of the DL model, the autoencoder in this case. And, based on the interpretation, we improved its performance for computer network anomaly detection. The <font color="#be00be">kernel</font> SHAP method, which is based on the shapley values, is used as a novel feature selection technique. This method is used to identify only those features that are actually causing the anomalous behaviour of the set of attack/anomaly instances. Later, these feature sets are used to train and validate the autoencoder but on benign data only. Finally, the built SHAP_Model <font color="#00be00">outperform</font>ed the other two models proposed based on the feature selection method. This whole experiment is conducted on the subset of the latest CICIDS2017 network dataset. The overall accuracy and AUC of SHAP_Model is 94% and 0.969, respectively. </br></br>

<a href='http://arxiv.org/pdf/2112.00953.pdf'>2112.00953</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.1559баллов, №1197</br>
<b>Maximum Consensus by Weighted Influences of Monotone Boolean Functions</b></br>
Authors: , Zhang, Erchuan, Suter, David, Tennakoon, Ruwan, Chin, Tat-Jun, Bab-Hadiashar, Alireza, Truong, Giang, Gilani, Syed Zulqarnain</br>
  Robust model fitting is a fundamental problem in computer vision: used to pre-process raw data in the presence of <font color="#be00be">outlier</font>s. Maximisation of Consensus (MaxCon) is one of the most popular robust criteria and widely used. Recently (Tennakoon et al. CVPR2021), a connection has been made between MaxCon and estimation of influences of a Monotone Boolean function. Equipping the Boolean cube with different measures and adopting different sampling strategies (two sides of the same coin) can have differing effects: which leads to the current study. This paper studies the concept of weighted influences for solving MaxCon. In particular, we study endowing the Boolean cube with the Bernoulli measure and performing biased (as opposed to uniform) sampling. <font color="#be00be">Theor</font>etically, we prove the weighted influences, under this measure, of points belonging to larger structures are smaller than those of points belonging to smaller structures in general. We also consider another &quot;natural&quot; family of sampling/weighting strategies, sampling with uniform measure concentrated on a particular (Hamming) level of the cube.   Based on weighted sampling, we modify the algorithm of Tennakoon et al., and test on both synthetic and real datasets. This paper is not promoting a new approach per se, but rather studying the issue of weighted sampling. Accordingly, we are not claiming to have produced a superior algorithm: rather we show some modest gains of Bernoulli sampling, and we illuminate some of the interactions between structure in data and weighted sampling. </br></br>

<a href='http://arxiv.org/pdf/2112.05609.pdf'>2112.05609</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.1746баллов, №1198</br>
<b>Interaction-Aware Sensitivity Analysis for Aerodynamic Optimization\n  Results using Information <font color="#be00be">Theor</font>y</b></br>
Authors: , Wollstadt, Patricia, Schmitt, Sebastian</br>
  An important issue during an engineering design process is to develop an understanding which design parameters have the most influence on the performance. Especially in the context of optimization approaches this knowledge is crucial in order to realize an efficient design process and achieve high-performing results. Information <font color="#be00be">theor</font>y provides powerful tools to investigate these relationships because measures are model-free and thus also capture non-linear relationships, while requiring only minimal assumptions on the input data. We therefore propose to use recently introduced information-theoretic methods and estimation algorithms to find the most influential input parameters in optimization results. The proposed methods are in particular able to account for interactions between parameters, which are often neglected but may lead to redundant or synergistic contributions of multiple parameters. We demonstrate the application of these methods on optimization data from aerospace engineering, where we first identify the most relevant optimization parameters using a recently introduced information-theoretic feature-selection algorithm that accounts for interactions between parameters. Second, we use the novel partial information decomposition (PID) framework that allows to quantify redundant and synergistic contributions between selected parameters with respect to the optimization outcome to identify parameter interactions. We thus demonstrate the power of novel information-theoretic approaches in identifying relevant parameters in optimization runs and highlight how these methods avoid the selection of redundant parameters, while detecting interactions that result in synergistic contributions of multiple parameters. </br></br>

<a href='http://arxiv.org/pdf/2112.08497.pdf'>2112.08497</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.1819баллов, №1199</br>
<b>Predicting Levels of Household Electricity Consumption in Low-Access\n  Settings</b></br>
Authors: , Fobi, Simone, Mugyenyi, Joel, Williams, Nathaniel J., Modi, Vijay, Taneja, Jay</br>
  In low-income settings, the most critical piece of information for electric utilities is the anticipated consumption of a <font color="#be00be">customer</font>. Electricity consumption assessment is difficult to do in settings where a significant fraction of households do not yet have an electricity connection. In such settings the absolute levels of anticipated consumption can range from 5-100 kWh/month, leading to high variability amongst these customers. Precious resources are at stake if a significant fraction of low consumers are connected over those with higher consumption.   This is the first study of it\'s kind in low-income settings that attempts to predict a building\'s consumption and not that of an aggregate administrative area. We train a Convolutional Neural Network (CNN) over pre-electrification daytime satellite imagery with a sample of utility bills from 20,000 geo-referenced electricity customers in Kenya (0.01% of Kenya\'s residential customers). This is made possible with a two-stage approach that uses a novel building <font color="#be00be">segmentation</font> approach to leverage much larger volumes of no-cost satellite imagery to make the most of scarce and expensive customer data. Our method shows that <font color="#960096">competitive</font> accuracies can be achieved at the building level, addressing the challenge of consumption variability. This work shows that the building\'s characteristics and it\'s surrounding context are both important in predicting consumption levels. We also evaluate the addition of lower resolution geospatial datasets into the training process, including nighttime lights and census-derived data. The results are already helping inform site selection and distribution-level planning, through granular predictions at the level of individual structures in Kenya and there is no reason this cannot be extended to other countries. </br></br>

<a href='http://arxiv.org/pdf/2112.06439.pdf'>2112.06439</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.1824баллов, №1200</br>
<b>What can Data-Centric AI Learn from Data and ML Engineering?</b></br>
Authors: , Polyzotis, Neoklis, Zaharia, Matei</br>
  Data-centric AI is a new and exciting research topic in the AI community, but many organizations already build and maintain various &quot;data-centric&quot; applications whose goal is to produce high quality data. These range from traditional business data processing applications (e.g., &quot;how much should we charge each of our <font color="#be00be">customer</font>s this month?&quot;) to production ML systems such as <font color="#be00be">recommendat</font>ion engines. The fields of data and ML engineering have arisen in recent years to manage these applications, and both include many interesting novel tools and processes. In this paper, we discuss several lessons from data and ML engineering that could be interesting to apply in data-centric AI, based on our experience building data and ML platforms that serve thousands of applications at a range of organizations. </br></br>

<a href='http://arxiv.org/pdf/2112.08232.pdf'>2112.08232</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.1836баллов, №1201</br>
<b>RA V-Net: Deep learning network for automated liver <font color="#be00be">segmentation</font></b></br>
Authors: , Lee, Zhiqi, Qi, Sumin, Fan, Chongchong, Xie, Ziwei</br>
  Accurate <font color="#be00be">segmentation</font> of the liver is a prerequisite for the <font color="#be00be">diagnos</font>is of <font color="#be00be">diseas</font>e. Automated segmentation is an important application of computer-aided detection and diagnosis of liver disease. In recent years, automated processing of <font color="#640064">medic</font>al images has gained breakthroughs. However, the low contrast of abdominal scan CT images and the complexity of liver morphology make accurate automatic segmentation challenging. In this paper, we propose RA V-Net, which is an improved medical image automatic segmentation model based on U-Net. It has the following three main innovations. CofRes Module (Composite Original Feature Residual Module) is proposed. With more complex convolution layers and skip connections to make it obtain a higher level of image feature extraction capability and prevent gradient disappearance or explosion. AR Module (Attention Recovery Module) is proposed to reduce the computational effort of the model. In addition, the spatial features between the data pixels of the encoding and decoding modules are sensed by adjusting the channels and LSTM convolution. Finally, the image features are effectively retained. CA Module (Channel Attention Module) is introduced, which used to extract relevant channels with dependencies and strengthen them by matrix dot product, while weakening irrelevant channels without dependencies. The purpose of channel attention is achieved. The attention mechanism provided by LSTM convolution and CA Module are strong guarantees for the performance of the neural network. The accuracy of U-Net network: 0.9862, precision: 0.9118, DSC: 0.8547, JSC: 0.82. The evaluation metrics of RA V-Net, accuracy: 0.9968, precision: 0.9597, DSC: 0.9654, JSC: 0.9414. The most representative metric for the segmentation effect is DSC, which improves 0.1107 over U-Net, and JSC improves 0.1214. </br></br>

<a href='http://arxiv.org/pdf/2112.05240.pdf'>2112.05240</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.1850баллов, №1202</br>
<b>Label-free virtual HER2 immunohistochemical staining of breast tissue\n  using deep learning</b></br>
Authors: , Bai, Bijie, Wang, Hongda, Li, Yuzhu, de Haan, Kevin, Colonnese, Francesco, Wan, Yujie, Zuo, Jingyi, Doan, Ngan B., Zhang, Xiaoran, Zhang, Yijie, Li, Jingxi, Dong, Wenjie, Darrow, Morgan Angus, Kamangar, Elham, Lee, Han Sung, Rivenson, Yair, Ozcan, Aydogan</br>
  The immunohistochemical (IHC) staining of the human epidermal growth factor receptor 2 (HER2) biomarker is widely practiced in breast tissue analysis, pre<font color="#be00be">clinic</font>al studies and <font color="#be00be">diagnos</font>tic decisions, guiding <font color="#be00be">cancer</font> treatment and investigation of pathogenesis. HER2 staining demands laborious tissue treatment and chemical processing performed by a histotechnologist, which typically takes one day to prepare in a laboratory, increasing analysis time and associated costs. Here, we describe a deep learning-based virtual HER2 IHC staining method using a conditional generative adversarial network that is trained to rapidly transform autofluorescence microscopic images of unlabeled/label-free breast tissue sections into bright-field equivalent microscopic images, matching the standard HER2 IHC staining that is chemically performed on the same tissue sections. The efficacy of this virtual HER2 staining framework was demonstrated by quantitative analysis, in which three board-certified breast <font color="#be00be">patholog</font>ists blindly graded the HER2 scores of virtually stained and immunohistochemically stained HER2 whole slide images (WSIs) to reveal that the HER2 scores determined by inspecting virtual IHC images are as accurate as their immunohistochemically stained counterparts. A second quantitative blinded study performed by the same diagnosticians further revealed that the virtually stained HER2 images exhibit a comparable staining quality in the level of nuclear detail, membrane clearness, and absence of staining artifacts with respect to their immunohistochemically stained counterparts. This virtual HER2 staining framework bypasses the costly, laborious, and time-consuming IHC staining procedures in laboratory, and can be extended to other types of biomarkers to accelerate the IHC tissue staining used in life sciences and bio<font color="#640064">medic</font>al workflow. </br></br>

<a href='http://arxiv.org/pdf/2112.09043.pdf'>2112.09043</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.1865баллов, №1203</br>
<b>Neural <font color="#be00be">Style</font> Transfer and Unpaired Image-to-Image Translation to deal\n  with the Domain Shift Problem on Spheroid <font color="#be00be">Segmentation</font></b></br>
Authors: , Garc&#xed;a-Dom&#xed;nguez, Manuel, Dom&#xed;nguez, C&#xe9;sar, Heras, J&#xf3;nathan, Mata, Eloy, Pascual, Vico</br>
  Background and objectives. Domain shift is a generalisation problem of machine learning models that occurs when the data distribution of the training set is different to the data distribution encountered by the model when it is deployed. This is common in the context of bio<font color="#640064">medic</font>al image <font color="#be00be">segmentation</font> due to the variance of experimental conditions, equipment, and capturing settings. In this work, we address this challenge by studying both neural <font color="#be00be">style</font> transfer algorithms and unpaired image-to-image translation methods in the context of the segmentation of tumour spheroids.   Methods. We have illustrated the domain shift problem in the context of spheroid segmentation with 4 deep learning segmentation models that achieved an IoU over 97% when tested with images following the training distribution, but whose performance decreased up to an 84\\% when applied to images captured under different conditions. In order to deal with this problem, we have explored 3 style transfer algorithms (NST, deep image analogy, and STROTSS), and 6 unpaired image-to-image translations algorithms (CycleGAN, DualGAN, ForkGAN, GANILLA, CUT, and FastCUT). These algorithms have been integrated into a high-level API that facilitates their application to other contexts where the domain-shift problem occurs.   Results. We have considerably improved the performance of the 4 segmentation models when applied to images captured under different conditions by using both style transfer and image-to-image translation algorithms. In particular, there are 2 style transfer algorithms (NST and deep image analogy) and 1 unpaired image-to-image translations algorithm (CycleGAN) that improve the IoU of the models in a range from 0.24 to 76.07. Therefore, reaching a similar performance to the one obtained with the models are applied to images following the training distribution. </br></br>

<a href='http://arxiv.org/pdf/2112.06311.pdf'>2112.06311</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -1.1950баллов, №1204</br>
<b>Weakly Supervised Mapping of Natural Language to <font color="#be00be">SQL</font> through Question\n  Decomposition</b></br>
Authors: , Wolfson, Tomer, Berant, Jonathan, Deutch, Daniel</br>
  Natural Language Interfaces to Databases (NLIDBs), where users pose queries in Natural Language (NL), are crucial for enabling non-experts to gain insights from data. Developing such interfaces, by contrast, is dependent on experts who often code heuristics for mapping NL to <font color="#be00be">SQL</font>. Alternatively, NLIDBs based on machine learning models rely on supervised examples of NL to SQL mappings (NL-SQL pairs) used as training data. Such examples are again procured using experts, which typically involves more than a one-off interaction. Namely, each data domain in which the NLIDB is deployed may have different characteristics and therefore require either dedicated heuristics or domain-specific training examples. To this end, we propose an alternative approach for training machine learning-based NLIDBs, using weak supervision. We use the recently proposed question decomposition representation called QDMR, an intermediate between NL and formal query languages. Recent work has shown that non-experts are generally successful in translating NL to QDMR. We consequently use NL-QDMR pairs, along with the question answers, as supervision for automatically synthesizing SQL queries. The NL questions and synthesized SQL are then used to train NL-to-SQL models, which we test on five benchmark datasets. Extensive experiments show that our solution, requiring zero expert annotations, performs <font color="#960096">competitive</font>ly with models trained on expert annotated data. </br></br>

<a href='http://arxiv.org/pdf/2112.07400.pdf'>2112.07400</a> &nbsp&nbsp (cs:ML, cs:SD, stat:ML) &nbsp&nbsp -1.2044баллов, №1205</br>
<b>Robustifying automatic <font color="#be00be">speech recognition</font> by extracting slowly varying\n  features</b></br>
Authors: , Pizarro, Matias, Kolossa, Dorothea, Fischer, Asja</br>
  In the past few years, it has been shown that deep learning systems are highly vulnerable under attacks with adversarial examples. Neural-network-based automatic <font color="#be00be">speech recognition</font> (ASR) systems are no exception. Targeted and untargeted attacks can modify an audio input signal in such a way that humans still recognise the same words, while ASR systems are steered to predict a different transcription. In this paper, we propose a defense mechanism against targeted <font color="#be00be">adversarial att</font>acks consisting in removing fast-changing features from the audio signals, either by applying slow feature analysis, a low-pass filter, or both, before feeding the input to the ASR system. We perform an empirical analysis of hybrid ASR models trained on data pre-processed in such a way. While the resulting models perform quite well on benign data, they are significantly more robust against targeted adversarial attacks: Our final, proposed model shows a performance on clean data similar to the baseline model, while being more than four times more robust. </br></br>

<a href='http://arxiv.org/pdf/2112.06415.pdf'>2112.06415</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -1.2078баллов, №1206</br>
<b>Human-like Driving Decision at Unsignalized Intersections Based on Game\n  <font color="#be00be">Theor</font>y</b></br>
Authors: , Li, Daofei, Liu, Guanming, Xiao, Bin</br>
  Unsignalized intersection driving is challenging for automated vehicles. For safe and efficient performances, the diverse and dynamic behaviors of interacting vehicles should be considered. Based on a game-<font color="#be00be">theor</font>etic framework, a human-like payoff design methodology is proposed for the automated decision at unsignalized intersections. Prospect Theory is introduced to map the objective collision risk to the subjective driver payoffs, and the driving <font color="#be00be">style</font> can be quantified as a tradeoff between safety and speed. To account for the dynamics of interaction, a probabilistic model is further introduced to describe the acceleration tendency of drivers. Simulation results show that the proposed decision algorithm can describe the dynamic process of two-vehicle interaction in limit cases. Statistics of uniformly-sampled cases simulation indicate that the success rate of safe interaction reaches 98%, while the speed efficiency can also be guaranteed. The proposed approach is further applied and validated in four-vehicle interaction scenarios at a four-arm intersection. </br></br>

<a href='http://arxiv.org/pdf/2111.05392.pdf'>2111.05392</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.2103баллов, №1207</br>
<b><font color="#be00be">Gaussi</font>an Process Meta <font color="#00be00">Few-shot</font> Classifier Learning via Linear\n  Discriminant Laplace Approximation</b></br>
Authors: , Kim, Minyoung, Hospedales, Timothy</br>
  The meta learning <font color="#00be00">few-shot</font> classification is an emerging problem in machine learning that received enormous attention recently, where the goal is to learn a model that can quickly adapt to a new task with only a few labeled data. We consider the <font color="#be00be">Bayes</font>ian <font color="#be00be">Gaussi</font>an process (GP) approach, in which we meta-learn the GP prior, and the adaptation to a new task is carried out by the GP predictive model from the posterior inference. We adopt the Laplace posterior approximation, but to circumvent the iterative gradient steps for finding the MAP solution, we introduce a novel linear discriminant analysis (LDA) plugin as a surrogate for the MAP solution. In essence, the MAP solution is approximated by the LDA estimate, but to take the GP prior into account, we adopt the prior-norm adjustment to estimate LDA\'s shared variance parameters, which ensures that the adjusted estimate is consistent with the GP prior. This enables closed-form differentiable GP posteriors and predictive distributions, thus allowing fast meta training. We demonstrate considerable improvement over the previous approaches. </br></br>

<a href='http://arxiv.org/pdf/2111.06162.pdf'>2111.06162</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.2148баллов, №1208</br>
<b>Clicking Matters:Towards Interactive Human <font color="#be00be">Parsing</font></b></br>
Authors: , Gao, Yutong, Liang, Liqian, Lang, Congyan, Feng, Songhe, Li, Yidong, Wei, Yunchao</br>
  In this work, we focus on Interactive Human <font color="#be00be">Parsing</font> (IHP), which aims to segment a human image into multiple human body parts with guidance from users\' interactions. This new task inherits the class-aware property of human parsing, which cannot be well solved by traditional interactive image <font color="#be00be">segmentation</font> approaches that are generally class-agnostic. To tackle this new task, we first exploit user clicks to identify different human parts in the given image. These clicks are subsequently transformed into semantic-aware localization maps, which are concatenated with the RGB image to form the input of the segmentation network and generate the initial parsing result. To enable the network to better perceive user\'s purpose during the correction process, we investigate several principal ways for the refinement, and reveal that random-sampling-based click augmentation is the best way for promoting the correction effectiveness. Furthermore, we also propose a semantic-perceiving loss (SP-loss) to augment the training, which can effectively exploit the semantic relationships of clicks for better optimization. To the best knowledge, this work is the first attempt to tackle the human parsing task under the interactive setting. Our IHP solution achieves 85\\% mIoU on the benchmark LIP, 80\\% mIoU on PASCAL-Person-Part and CIHP, 75\\% mIoU on Helen with only 1.95, 3.02, 2.84 and 1.09 clicks per class respectively. These results demonstrate that we can simply acquire high-quality human parsing masks with only a few human effort. We hope this work can motivate more researchers to develop data-efficient solutions to IHP in the future. </br></br>

<a href='http://arxiv.org/pdf/2112.08837.pdf'>2112.08837</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.2159баллов, №1209</br>
<b>Improving Unsupervised Stain-To-Stain Translation using Self-Supervision\n  and Meta-Learning</b></br>
Authors: , Bouteldja, Nassim, Klinkhammer, Barbara Mara, Schlaich, Tarek, Boor, Peter, Merhof, Dorit</br>
  In digital <font color="#be00be">patholog</font>y, many image analysis tasks are challenged by the need for large and time-consuming manual data annotations to cope with various sources of variability in the image domain. Unsupervised domain adaptation based on image-to-image translation is gaining importance in this field by addressing variabilities without the manual overhead. Here, we tackle the variation of different <font color="#be00be">histolog</font>ical stains by unsupervised stain-to-stain translation to enable a stain-independent applicability of a deep learning <font color="#be00be">segmentation</font> model. We use CycleGANs for stain-to-stain translation in kidney histopathology, and propose two novel approaches to improve translational effectivity. First, we integrate a prior segmentation network into the CycleGAN for a self-supervised, application-oriented optimization of translation through semantic guidance, and second, we incorporate extra channels to the translation output to implicitly separate artificial meta-information otherwise encoded for tackling underdetermined reconstructions. The latter showed partially superior performances to the unmodified CycleGAN, but the former performed best in all stains providing instance-level Dice scores ranging between 78% and 92% for most kidney structures, such as glomeruli, tubules, and veins. However, CycleGANs showed only limited performance in the translation of other structures, e.g. arteries. Our study also found somewhat lower performance for all structures in all stains when compared to segmentation in the original stain. Our study suggests that with current unsupervised technologies, it seems unlikely to produce generally applicable fake stains. </br></br>

<a href='http://arxiv.org/pdf/2112.06108.pdf'>2112.06108</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -1.2194баллов, №1210</br>
<b>3D <font color="#be00be">LiDAR</font> Aided GNSS NLOS Mitigation in Urban Canyons</b></br>
Authors: , Wen, Weisong, Hsu, Li-Ta</br>
  In this paper, we propose a 3D <font color="#be00be">LiDAR</font> aided global navigation satellite system (GNSS) non-line-of-sight (NLOS) mitigation method caused by both static buildings and dynamic objects. A sliding window map describing the surrounding of the ego-vehicle is first generated, based on real-time 3D <font color="#be00be">point cloud</font>s from a 3D LiDAR sensor. Then, NLOS receptions are detected based on the sliding window map using a proposed fast searching method which is free of the initial guess of the position of the GNSS receiver. Instead of directly excluding the detected NLOS satellites from further positioning estimation, this paper rectifies the pseudorange measurement model by (1) correcting the pseudorange measurements if the reflecting point of NLOS signals is detected inside the sliding window map, and (2) remodeling the uncertainty of the NLOS pseudorange measurement using a novel weighting scheme. We evaluated the performance of the proposed method in several typical urban canyons in Hong Kong using an automobile-level GNSS receiver. Moreover, we also evaluate the potential of the proposed NLOS mitigation method in GNSS and inertial navigation systems integration via factor graph optimization. </br></br>

<a href='http://arxiv.org/pdf/2112.06539.pdf'>2112.06539</a> &nbsp&nbsp (cs:RO, cs:CV) &nbsp&nbsp -1.2295баллов, №1211</br>
<b>MinkLoc3D-SI: 3D <font color="#be00be">LiDAR</font> place recognition with sparse convolutions,\n  spherical coordinates, and intensity</b></br>
Authors: , &#x17b;ywanowski, Kamil, Banaszczyk, Adam, Nowicki, Micha&#x142; R., Komorowski, Jacek</br>
  The 3D <font color="#be00be">LiDAR</font> place recognition aims to estimate a coarse localization in a previously seen environment based on a single scan from a rotating 3D LiDAR sensor. The existing solutions to this problem include hand-crafted <font color="#be00be">point cloud</font> descriptors (e.g., ScanContext, M2DP, LiDAR IRIS) and deep learning-based solutions (e.g., PointNetVLAD, PCAN, LPDNet, DAGC, MinkLoc3D), which are often only evaluated on accumulated 2D scans from the Oxford RobotCar dataset. We introduce MinkLoc3D-SI, a sparse convolution-based solution that utilizes spherical coordinates of 3D points and processes the intensity of 3D LiDAR measurements, improving the performance when a single 3D LiDAR scan is used. Our method integrates the improvements typical for hand-crafted descriptors (like ScanContext) with the most efficient 3D sparse convolutions (MinkLoc3D). Our experiments show improved results on single scans from 3D LiDARs (USyd Campus dataset) and great generalization ability (KITTI dataset). Using intensity information on accumulated 2D scans (RobotCar Intensity dataset) improves the performance, even though spherical representation doesn\'t produce a noticeable improvement. As a result, MinkLoc3D-SI is suited for single scans obtained from a 3D LiDAR, making it applicable in autonomous vehicles. </br></br>

<a href='http://arxiv.org/pdf/2112.08760.pdf'>2112.08760</a> &nbsp&nbsp (cs:NE, cs:ML) &nbsp&nbsp -1.2327баллов, №1212</br>
<b>Constrained multi-objective optimization of process design parameters in\n  settings with scarce data: an application to adhesive bonding</b></br>
Authors: , Morales-Hern&#xe1;ndez, Alejandro, Gonzalez, Sebastian Rojas, Van Nieuwenhuyse, Inneke, Jordens, Jeroen, Witters, Maarten, Van Doninck, Bart</br>
  Adhesive joints are increasingly used in industry for a wide variety of applications because of their favorable characteristics such as high strength-to-weight ratio, design flexibility, limited stress concentrations, planar force transfer, good damage tolerance and fatigue resistance. Finding the optimal process parameters for an adhesive bonding process is challenging: the optimization is inherently multi-objective (aiming to maximize break strength while minimizing cost) and constrained (the process should not result in any visual damage to the materials, and stress tests should not result in failures that are adhesion-related). Real life physical experiments in the lab are expensive to perform; traditional evolutionary approaches (such as genetic algorithms) are then ill-suited to solve the problem, due to the prohibitive amount of experiments required for evaluation. In this research, we successfully applied specific machine learning techniques (<font color="#be00be">Gaussi</font>an Process <font color="#be00be">Regression</font> and Logistic Regression) to emulate the objective and constraint functions based on a limited amount of experimental data. The techniques are embedded in a <font color="#be00be">Bayes</font>ian optimization algorithm, which succeeds in detecting Pareto-optimal process settings in a highly efficient way (i.e., requiring a limited number of extra experiments). </br></br>

<a href='http://arxiv.org/pdf/2112.07087.pdf'>2112.07087</a> &nbsp&nbsp (cs:NE, cs:CV, cs:ML) &nbsp&nbsp -1.2375баллов, №1213</br>
<b>Heuristic Hyperparameter Optimization for Convolutional Neural Networks\n  using Genetic Algorithm</b></br>
Authors: , Zhou, Meng</br>
  In recent years, people from all over the world are suffering from one of the most severe <font color="#be00be">diseas</font>es in history, known as Coronavirus disease 2019, COVID-19 for short. When the virus reaches the lungs, it has a higher probability to cause lung pneumonia and sepsis. X-ray image is a powerful tool in identifying the typical features of the infection for COVID-19 <font color="#be00be">patient</font>s. The radiologists and <font color="#be00be">patholog</font>ists observe that ground-glass opacity appears in the chest X-ray for infected patient \\cite{cozzi2021ground}, and it could be used as one of the criteria during the <font color="#be00be">diagnos</font>is process. In the past few years, deep learning has proven to be one of the most powerful methods in the field of image classification. Due to significant differences in Chest X-Ray between normal and infected people \\cite{rousan2020chest}, deep models could be used to identify the presence of the disease given a patient\'s Chest X-Ray. Many deep models are complex, and it evolves with lots of input parameters. Designers sometimes struggle with the tuning process for deep models, especially when they build up the model from scratch. Genetic Algorithm, inspired by the biological evolution process, plays a key role in solving such complex problems. In this paper, I proposed a genetic-based approach to optimize the Convolutional Neural Network(CNN) for the Chest X-Ray classification task. </br></br>

<a href='http://arxiv.org/pdf/2112.08604.pdf'>2112.08604</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.2477баллов, №1214</br>
<b>Use Image <font color="#be00be">Clustering</font> to Facilitate Technology Assisted Review</b></br>
Authors: , Zhao, Haozhen, Wei, Fusheng, Quatinetz, Hilary, Qin, Han, Dabrowski, Adam</br>
  During the past decade breakthroughs in GPU hardware and deep neural networks technologies have revolutionized the field of computer vision, making image analytical potentials accessible to a range of <font color="#009600">real-world</font> applications. Technology Assisted Review (TAR) in electronic discovery though traditionally has dominantly dealt with textual content, is witnessing a rising need to incorporate multimedia content in the scope. We have developed innovative image analytics applications for TAR in the past years, such as image classification, image <font color="#be00be">clustering</font>, and <font color="#be00be">object detection</font>, etc. In this paper, we discuss the use of image clustering applications to facilitate TAR based on our experiences in serving clients. We describe our general workflow on leveraging image clustering in tasks and use statistics from real projects to showcase the effectiveness of using image clustering in TAR. We also summarize lessons learned and best practices on using image clustering in TAR. </br></br>

<a href='http://arxiv.org/pdf/2112.06769.pdf'>2112.06769</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.2516баллов, №1215</br>
<b>Multi-objective simulation optimization of the adhesive bonding process\n  of materials</b></br>
Authors: , Morales-Hern&#xe1;ndez, Alejandro, Van Nieuwenhuyse, Inneke, Gonzalez, Sebastian Rojas, Jordens, Jeroen, Witters, Maarten, Van Doninck, Bart</br>
  Automotive companies are increasingly looking for ways to make their products lighter, using novel materials and novel bonding processes to join these materials together. Finding the optimal process parameters for such adhesive bonding process is challenging. In this research, we successfully applied <font color="#be00be">Bayes</font>ian optimization using <font color="#be00be">Gaussi</font>an Process <font color="#be00be">Regression</font> and Logistic Regression, to efficiently (i.e., requiring few experiments) guide the design of experiments to the Pareto-optimal process parameter settings. </br></br>

<a href='http://arxiv.org/pdf/2112.08421.pdf'>2112.08421</a> &nbsp&nbsp (cs:ML, cs:NE) &nbsp&nbsp -1.2678баллов, №1216</br>
<b>A White-Box <font color="#be00be">SVM</font> Framework and its Swarm-Based Optimization for\n  Supervision of Toothed Milling Cutter through Characterization of Spindle\n  Vibrations</b></br>
Authors: , Deo, Tejas Y., Patange, Abhishek D., Pardeshi, Sujit S., Jegadeeshwaran, R., Khairnar, Apoorva N., Khade, Hrushikesh S.</br>
  In this paper, a white-Box support vector machine (<font color="#be00be">SVM</font>) framework and its swarm-based optimization is presented for supervision of toothed milling cutter through characterization of real-time spindle vibrations. The <font color="#be00be">anomal</font>ous moments of vibration evolved due to in-process tool failures (i.e., flank and nose wear, crater and notch wear, edge fracture) have been investigated through time-domain response of acceleration and statistical features. The Recursive Feature Elimination with Cross-Validation (RFECV) with decision trees as the estimator has been implemented for feature selection. Further, the competence of standard SVM has been examined for tool health monitoring followed by its optimization through application of swarm based algorithms. The comparative analysis of performance of five meta-heuristic algorithms (Elephant Herding Optimization, Monarch Butterfly Optimization, Harris Hawks Optimization, Slime Mould Algorithm, and Moth Search Algorithm) has been carried out. The white-box approach has been presented considering global and local representation that provides insight into the performance of machine learning models in tool condition monitoring. </br></br>

<a href='http://arxiv.org/pdf/2112.08589.pdf'>2112.08589</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -1.2723баллов, №1217</br>
<b><font color="#960096">Knowledge Graph</font> Embedding in <font color="#be00be">E-commerce</font> Applications: Attentive\n  Reasoning, Explanations, and Transferable Rules</b></br>
Authors: , Zhang, Wen, Deng, Shumin, Chen, Mingyang, Wang, Liang, Chen, Qiang, Xiong, Feiyu, Liu, Xiangwen, Chen, Huajun</br>
  <font color="#960096">Knowledge Graph</font>s (KGs), representing facts as triples, have been widely adopted in many applications. Reasoning tasks such as link prediction and rule induction are important for the development of KGs. Knowledge Graph Embeddings (KGEs) embedding entities and relations of a KG into continuous vector spaces, have been proposed for these reasoning tasks and proven to be efficient and robust. But the plausibility and feasibility of applying and deploying KGEs in real-work applications has not been well-explored. In this paper, we discuss and report our experiences of deploying KGEs in a real domain application: <font color="#be00be">e-commerce</font>. We first identity three important desiderata for e-commerce KG systems: 1) attentive reasoning, reasoning over a few target relations of more concerns instead of all; 2) explanation, providing explanations for a prediction to help both users and business operators understand why the prediction is made; 3) transferable rules, generating reusable rules to accelerate the deployment of a KG to new systems. While non existing KGE could meet all these desiderata, we propose a novel one, an explainable knowledge graph attention network that make prediction through modeling correlations between triples rather than purely relying on its head entity, relation and tail entity embeddings. It could automatically selects attentive triples for prediction and records the contribution of them at the same time, from which explanations could be easily provided and transferable rules could be efficiently produced. We empirically show that our method is capable of meeting all three desiderata in our e-commerce application and <font color="#00be00">outperform</font> typical baselines on datasets from real domain applications. </br></br>

<a href='http://arxiv.org/pdf/2112.05973.pdf'>2112.05973</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -1.2990баллов, №1218</br>
<b>Prosody Labelled Dataset for <font color="#be00be">Hindi</font> using Semi-Automated Approach</b></br>
Authors: , Banerjee, Esha, Ojha, Atul Kr., Jha, Girish Nath</br>
  This study aims to develop a semi-automatically labelled prosody database for <font color="#be00be">Hindi</font>, for enhancing the intonation component in ASR and TTS systems, which is also helpful for building Speech to Speech Machine Translation systems. Although no single standard for prosody labelling exists in Hindi, researchers in the past have employed perceptual and statistical methods in literature to draw inferences about the behaviour of prosody patterns in Hindi. Based on such existing research and largely agreed upon <font color="#be00be">theor</font>ies of intonation in Hindi, this study attempts to first develop a manually annotated prosodic corpus of Hindi speech data, which is then used for training prediction models for generating automatic prosodic labels. A total of 5,000 sentences (23,500 words) for declarative and interrogative types have been labelled. The accuracy of the trained models for pitch accent, intermediate phrase boundaries and accentual phrase boundaries is 73.40%, 93.20%, and 43% respectively. </br></br>

<a href='http://arxiv.org/pdf/2112.05687.pdf'>2112.05687</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.3162баллов, №1219</br>
<b><font color="#be00be">Federated</font> Two-stage Learning with Sign-based Voting</b></br>
Authors: , Ma, Zichen, Lu, Zihan, Lu, Yu, Li, Wenye, Yi, Jinfeng, Cui, Shuguang</br>
  <font color="#be00be">Federated</font> learning is a distributed machine learning mechanism where local devices collaboratively train a shared global model under the orchestration of a central server, while keeping all <font color="#be00be">private</font> data decentralized. In the system, model parameters and its updates are transmitted instead of raw data, and thus the communication bottleneck has become a key challenge. Besides, recent larger and deeper machine learning models also pose more difficulties in deploying them in a federated environment. In this paper, we design a federated two-stage learning framework that augments prototypical federated learning with a cut layer on devices and uses sign-based stochastic gradient descent with the majority vote method on model updates. Cut layer on devices learns informative and low-dimension representations of raw data locally, which helps reduce global model parameters and prevents data leakage. Sign-based SGD with the majority vote method for model updates also helps alleviate communication limitations. Empirically, we show that our system is an efficient and <font color="#be00be">privacy</font> preserving federated learning scheme and suits for general application scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.08088.pdf'>2112.08088</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.3233баллов, №1220</br>
<b>Image-Adaptive YOLO for <font color="#be00be">Object Detection</font> in Adverse <font color="#be00be">Weather</font> Conditions</b></br>
Authors: , Liu, Wenyu, Ren, Gaofeng, Yu, Runsheng, Guo, Shi, Zhu, Jianke, Zhang, Lei</br>
  Though deep learning-based <font color="#be00be">object detection</font> methods have achieved promising results on the conventional datasets, it is still challenging to locate objects from the low-quality images captured in adverse <font color="#be00be">weather</font> conditions. The existing methods either have difficulties in balancing the tasks of image enhancement and object detection, or often ignore the latent information beneficial for detection. To alleviate this problem, we propose a novel Image-Adaptive YOLO (IA-YOLO) framework, where each image can be adaptively enhanced for better detection performance. Specifically, a differentiable image processing (DIP) module is presented to take into account the adverse weather conditions for YOLO detector, whose parameters are predicted by a small convolutional neural net-work (CNN-PP). We learn CNN-PP and YOLOv3 jointly in an end-to-end fashion, which ensures that CNN-PP can learn an appropriate DIP to enhance the image for detection in a weakly supervised manner. Our proposed IA-YOLO approach can adaptively process images in both normal and adverse weather conditions. The experimental results are very encouraging, demonstrating the effectiveness of our proposed IA-YOLO method in both foggy and low-light scenarios. </br></br>

<a href='http://arxiv.org/pdf/2112.06603.pdf'>2112.06603</a> &nbsp&nbsp (cs:CL, cs:AI, cs:SD) &nbsp&nbsp -1.3250баллов, №1221</br>
<b>Detecting <font color="#be00be">Emotion</font> Carriers by Combining Acoustic and Lexical\n  Representations</b></br>
Authors: , Bayerl, Sebastian P., Tammewar, Aniruddha, Riedhammer, Korbinian, Riccardi, Giuseppe</br>
  Personal narratives (PN) - spoken or written - are recollections of facts, people, events, and thoughts from one\'s own experience. <font color="#be00be">Emotion</font> recognition and <font color="#be00be">sentiment</font> analysis tasks are usually defined at the utterance or document level. However, in this work, we focus on Emotion Carriers (EC) defined as the segments (speech or text) that best explain the emotional state of the narrator (&quot;loss of father&quot;, &quot;made me choose&quot;). Once extracted, such EC can provide a richer representation of the user state to improve natural language understanding and dialogue modeling. In previous work, it has been shown that EC can be identified using lexical features. However, spoken narratives should provide a richer description of the context and the users\' emotional state. In this paper, we leverage word-based acoustic and textual embeddings as well as early and late fusion techniques for the detection of ECs in spoken narratives. For the acoustic word-level representations, we use Residual Neural Networks (ResNet) pretrained on separate speech emotion corpora and fine-tuned to detect EC. Experiments with different fusion and system combination strategies show that late fusion leads to significant improvements for this task. </br></br>

<a href='http://arxiv.org/pdf/2112.05146.pdf'>2112.05146</a> &nbsp&nbsp (cs:CV, cs:ML, stat:ML) &nbsp&nbsp -1.3355баллов, №1222</br>
<b>Come-Closer-Diffuse-Faster: Accelerating Conditional Diffusion Models\n  for Inverse Problems through Stochastic Contraction</b></br>
Authors: , Chung, Hyungjin, Sim, Byeongsu, Ye, Jong Chul</br>
  Diffusion models have recently attained significant interest within the community owing to their strong performance as generative models. Furthermore, its application to inverse problems have demonstrated <font color="#00be00">state-of-the-art</font> performance. Unfortunately, diffusion models have a critical downside - they are inherently slow to sample from, needing few thousand steps of iteration to generate images from pure <font color="#be00be">Gaussi</font>an noise. In this work, we show that starting from Gaussian noise is unnecessary. Instead, starting from a single forward diffusion with better initialization significantly reduces the number of sampling steps in the reverse conditional diffusion. This phenomenon is formally explained by the contraction <font color="#be00be">theor</font>y of the stochastic difference equations like our conditional diffusion strategy - the alternating applications of reverse diffusion followed by a non-expansive data consistency step. The new sampling strategy, dubbed Come-Closer-Diffuse-Faster (CCDF), also reveals a new insight on how the existing feed-forward neural network approaches for inverse problems can be synergistically combined with the diffusion models. Experimental results with <font color="#be00be">super-resolution</font>, image <font color="#be00be">inpainting</font>, and compressed sensing<font color="#be00be"> MRI </font>demonstrate that our method can achieve state-of-the-art reconstruction performance at significantly reduced sampling steps. </br></br>

<a href='http://arxiv.org/pdf/2112.07457.pdf'>2112.07457</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -1.3369баллов, №1223</br>
<b>Triangulation candidates for <font color="#be00be">Bayes</font>ian optimization</b></br>
Authors: , Gramacy, Robert B., Sauer, Annie, Wycoff, Nathan</br>
  <font color="#be00be">Bayes</font>ian optimization is a form of sequential design: idealize input-output relationships with a suitably flexible nonlinear <font color="#be00be">regression</font> model; fit to data from an initial experimental campaign; devise and optimize a criterion for selecting the next experimental condition(s) under the fitted model (e.g., via predictive equations) to target outcomes of interest (say minima); repeat after acquiring output under those conditions and updating the fit. In many situations this &quot;inner optimization&quot; over the new-data acquisition criterion is cumbersome because it is non-convex/highly multi-modal, may be non-differentiable, or may otherwise thwart numerical optimizers, especially when inference requires Monte Carlo. In such cases it is not uncommon to replace continuous search with a discrete one over random candidates. Here we propose using candidates based on a Delaunay triangulation of the existing input design. In addition to detailing construction of these &quot;tricands&quot;, based on a simple wrapper around a conventional convex hull library, we promote several advantages based on properties of the geometric criterion involved. We then demonstrate empirically how tricands can lead to better Bayesian optimization performance compared to both numerically optimized acquisitions and random candidate-based alternatives on benchmark problems. </br></br>

<a href='http://arxiv.org/pdf/2112.08866.pdf'>2112.08866</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -1.3505баллов, №1224</br>
<b><font color="#be00be">Bayes</font>Flow can reliably detect Model Misspecification and Posterior\n  Errors in Amortized Bayesian Inference</b></br>
Authors: , Schmitt, Marvin, B&#xfc;rkner, Paul-Christian, K&#xf6;the, Ullrich, Radev, Stefan T.</br>
  Neural density estimators have proven remarkably powerful in performing efficient simulation-based <font color="#be00be">Bayes</font>ian inference in various research domains. In particular, the BayesFlow framework uses a two-step approach to enable amortized parameter estimation in settings where the likelihood function is implicitly defined by a simulation program. But how faithful is such inference when simulations are poor representations of reality? In this paper, we conceptualize the types of model misspecification arising in simulation-based inference and systematically investigate the performance of the BayesFlow framework under these misspecifications. We propose an augmented optimization objective which imposes a probabilistic structure on the latent data space and utilize maximum mean discrepancy (MMD) to detect potentially catastrophic misspecifications during inference undermining the validity of the obtained results. We verify our detection criterion on a number of artificial and realistic misspecifications, ranging from toy conjugate models to complex models of decision making and <font color="#be00be">diseas</font>e outbreak dynamics applied to real data. Further, we show that posterior inference errors increase as a function of the distance between the true data-generating distribution and the typical set of simulations in the latent summary space. Thus, we demonstrate the dual utility of MMD as a method for detecting model misspecification and as a proxy for verifying the faithfulness of amortized Bayesian inference. </br></br>

<a href='http://arxiv.org/pdf/2112.06455.pdf'>2112.06455</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.3596баллов, №1225</br>
<b>Self-Paced Deep <font color="#be00be">Regression</font> Forests with Consideration on Ranking\n  Fairness</b></br>
Authors: , Pan, Lili, Meng, Mingming, Ren, Yazhou, Zheng, Yali, Xu, Zenglin</br>
  Deep discriminative models (DDMs), such as deep <font color="#be00be">regression</font> forests, deep neural decision forests, have been extensively studied recently to solve problems like<font color="#be00be"> facial </font>age estimation, head <font color="#be00be">pose estimation</font>, gaze estimation and so forth. Such problems are challenging in part because a large amount of effective training data without noise and bias is often not available. While some progress has been achieved through learning more discriminative features, or reweighting samples, we argue what is more desirable is to learn gradually to discriminate like human beings. Then, we resort to self-paced learning (SPL). But a natural question arises: can self-paced regime lead DDMs to achieve more robust and less biased solutions? A serious problem with SPL, which is firstly discussed by this work, is it tends to aggravate the bias of solutions, especially for obvious imbalanced data. To this end, this paper proposes a new self-paced paradigm for deep discriminative model, which distinguishes noisy and underrepresented examples according to the output likelihood and entropy associated with each example, and tackle the fundamental ranking problem in SPL from a new perspective: fairness. This paradigm is fundamental, and could be easily combined with a variety of DDMs. Extensive experiments on three computer vision tasks, such as facial age estimation, head pose estimation and gaze estimation, demonstrate the efficacy of our paradigm. To the best of our knowledge, our work is the first paper in the literature of SPL that considers ranking fairness for self-paced regime construction. </br></br>

<a href='http://arxiv.org/pdf/2112.06430.pdf'>2112.06430</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.3618баллов, №1226</br>
<b>Predicting Airbnb Rental Prices Using Multiple Feature Modalities</b></br>
Authors: , Ahuja, Aditya, Lahiri, Aditya, Das, Aniruddha</br>
  Figuring out the price of a listed Airbnb rental is an important and difficult task for both the host and the <font color="#be00be">customer</font>. For the former, it can enable them to set a reasonable price without compromising on their profits. For the customer, it helps understand the key drivers for price and also provides them with similarly priced places. This price prediction <font color="#be00be">regression</font> task can also have multiple downstream uses, such as in <font color="#be00be">recommendat</font>ion of similar rentals based on price. We propose to use geolocation, temporal, visual and natural language features to create a reliable and accurate price prediction algorithm. </br></br>

<a href='http://arxiv.org/pdf/2112.06554.pdf'>2112.06554</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.3645баллов, №1227</br>
<b>Ensemble CNN Networks for GBM Tumors <font color="#be00be">Segmentation</font> using Multi-parametric\n  MRI</b></br>
Authors: , Zeineldin, Ramy A., Karar, Mohamed E., Mathis-Ullrich, Franziska, Burgert, Oliver</br>
  Glioblastomas are the most aggressive fast-growing primary <font color="#00be00">brain</font> <font color="#be00be">cancer</font> which originate in the glial cells of the brain. Accurate identification of the malignant brain tumor and its sub-regions is still one of the most challenging problems in <font color="#640064">medic</font>al image <font color="#be00be">segmentation</font>. The Brain Tumor Segmentation Challenge (BraTS) has been a popular benchmark for automatic brain glioblastomas segmentation algorithms since its initiation. In this year\'s challenge, BraTS 2021 provides the largest multi-parametric (mpMRI) dataset of 2,000 pre-operative <font color="#be00be">patient</font>s. In this paper, we propose a new aggregation of two deep learning frameworks namely, DeepSeg and nnU-Net for automatic glioblastoma recognition in pre-operative mpMRI. Our ensemble method obtains Dice similarity scores of 92.00, 87.33, and 84.10 and Hausdorff Distances of 3.81, 8.91, and 16.02 for the enhancing tumor, tumor core, and whole tumor regions on the BraTS 2021 validation set, individually. These Experimental findings provide evidence that it can be readily applied <font color="#be00be">clinic</font>ally and thereby aiding in the brain cancer prognosis, therapy planning, and therapy response monitoring. </br></br>

<a href='http://arxiv.org/pdf/2112.05477.pdf'>2112.05477</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.3646баллов, №1228</br>
<b>Modelling DDoS Attacks in IoT Networks using Machine Learning</b></br>
Authors: , Machaka, Pheeha, Ajayi, Olasupo, Maluleke, Hloniphani, Kahenga, Ferdinand, Bagula, Antoine, Kyamakya, Kyandoghere</br>
  In current Internet-of-Things (IoT) deployments, a mix of traditional IP networking and IoT specific protocols, both relying on the TCP protocol, can be used to transport data from a source to a destination. Therefore, TCP-specific attacks, such as the Distributed Denial of Service (DDoS) using the TCP SYN attack, are one of the most plausible tools that attackers can use on Cyber-Physical Systems (CPS). This may be done by launching an attack from its IoT subsystem, here referred to as the &quot;CPS-IoT&quot;, with potential propagation to the different servers located in both fog and the cloud infrastructures of the CPS. This study compares the effectiveness of supervised, unsupervised, and semi-supervised machine learning algorithms for detecting DDoS attacks in CPS-IoT, particularly during data transmission to and from the physical space to the cyber space via the Internet. The algorithms considered are broadly grouped into two: i) Detection algorithms, which include Logistic <font color="#be00be">Regression</font> (LGR), <font color="#be00be">K-Mean</font>s, and Artificial Neural Networks (ANN). We also looked into the effectiveness of semi-supervised hybrid learning models, which use unsupervised K-Means to label data, then feed the output to a supervised learning model for attack detection. ii.) Prediction algorithms - LGR, <font color="#be00be">Kernel</font> Ridge Regression (KRR) and Support Vector Regression (SVR), which were used to predict imminent attacks. Experimental tests were carried out and obtained results showed that the hybrid model was able to achieve 100% accuracy with zero false positives; while all the prediction models were able to achieve over 94% attack prediction accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.07308.pdf'>2112.07308</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -1.3723баллов, №1229</br>
<b>Conversational Search with Mixed-Initiative -- Asking Good Clarification\n  Questions backed-up by Passage <font color="#be00be">Retrieval</font></b></br>
Authors: , Mass, Yosi, Cohen, Doron, Yehudai, Asaf, Konopnicki, David</br>
  We deal with a scenario of conversational search with mixed-initiative: namely user-asks system-answers, as well as system-asks (clarification questions) and user-answers. We focus on the task of selecting the next clarification question, given conversation context. Our method leverages passage <font color="#be00be">retrieval</font> that is used both for an initial selection of relevant candidate clarification questions, as well as for fine-tuning two deep-learning models for re-ranking these candidates. We evaluated our method on two different use-cases. The first is an open domain conversational search in a large web collection. The second is a task-oriented <font color="#be00be">customer</font>-support setup. We show that our method performs well on both use-cases. </br></br>

<a href='http://arxiv.org/pdf/2112.07035.pdf'>2112.07035</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -1.3867баллов, №1230</br>
<b>Framework para Caracterizar <font color="#be00be">Fake News</font> en Terminos de Emociones</b></br>
Authors: , Rubio, Luis Rojas, Villegas, Claudio Meneses</br>
  Social networks have become one of the main information channels for human beings due to the immediate and social interactivity they offer, allowing in some cases to publish what each user considers relevant. This has brought with it the generation of false news or <font color="#be00be">Fake News</font>, publications that only seek to generate uncertainty, misinformation or skew the opinion of readers. It has been shown that the human being is not capable of fully identifying whether an article is really a fact or a Fake News, due to this it is that models arise that seek to characterize and identify articles based on data mining and machine learning. This article proposes a three-layer framework, the main objective of which is to characterize the <font color="#be00be">emotion</font>s present in Fake News and to be a tool for future work that identifies the emotional state and intentional state of the public. </br></br>

<a href='http://arxiv.org/pdf/2112.08224.pdf'>2112.08224</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.3889баллов, №1231</br>
<b>Disparities in Social Determinants among Performances of Mortality\n  Prediction with Machine Learning for Sepsis <font color="#be00be">Patient</font>s</b></br>
Authors: , Wang, Hanyin, Li, Yikuan, Naidech, Andrew, Luo, Yuan</br>
  Background Sepsis is one of the most life-threatening circumstances for critically ill <font color="#be00be">patient</font>s in the US, while a standardized criteria for sepsis identification is still under development. Disparities in social determinants of sepsis patients can interfere with the risk prediction performances using machine learning. Methods Disparities in social determinants, including race, gender, marital status, insurance types and languages, among patients identified by six available sepsis criteria were revealed by forest plots. Sixteen machine learning classifiers were trained to predict in-hospital mortality for sepsis patients. The performance of the trained model was tested on the entire randomly conducted test set and each sub-population built based on each of the following social determinants: race, gender, marital status, insurance type, and language. Results We analyzed a total of 11,791 critical care patients from the MIMIC-III database. Within the population identified by each sepsis identification method, significant differences were observed among sub-populations regarding race, marital status, insurance type, and language. On the 5,783 sepsis patients identified by the Sepsis-3 criteria statistically significant performance decreases for mortality prediction were observed when applying the trained machine learning model on Asian and Hispanic patients. With pairwise comparison, we detected performance discrepancies in mortality prediction between Asian and White patients, Asians and patients of other races, as well as English-speaking and Spanish-speaking patients. Conclusions Disparities in proportions of patients identified by various sepsis criteria were detected among the different social determinant groups. To achieve accurate <font color="#be00be">diagnos</font>is, a versatile diagnostic system for sepsis is needed to overcome the social determinant disparities of patients. </br></br>

<a href='http://arxiv.org/pdf/2112.06872.pdf'>2112.06872</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.3912баллов, №1232</br>
<b>Efficient Differentially <font color="#be00be">Private</font> Secure Aggregation for <font color="#be00be">Federated</font>\n  Learning via Hardness of Learning with Errors</b></br>
Authors: , Stevens, Timothy, Skalka, Christian, Vincent, Christelle, Ring, John, Clark, Samuel, Near, Joseph</br>
  <font color="#be00be">Federated</font> machine learning leverages edge computing to develop models from network user data, but <font color="#be00be">privacy</font> in federated learning remains a major challenge. Techniques using differential privacy have been proposed to address this, but bring their own challenges -- many require a trusted third party or else add too much noise to produce useful models. Recent advances in \\emph{secure aggregation} using multiparty computation eliminate the need for a third party, but are computationally expensive especially at scale. We present a new federated learning protocol that leverages a novel differentially <font color="#be00be">private</font>, malicious secure aggregation protocol based on techniques from Learning With Errors. Our protocol <font color="#00be00">outperform</font>s current state-of-the art techniques, and empirical results show that it scales to a large number of parties, with optimal accuracy for any differentially private federated learning scheme. </br></br>

<a href='http://arxiv.org/pdf/2112.07555.pdf'>2112.07555</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.3961баллов, №1233</br>
<b>Classification of histo<font color="#be00be">patholog</font>y images using ConvNets to detect Lupus\n  Nephritis</b></br>
Authors: , Gupta, Akash, Reddy, Anirudh, Jawahar, CV, Vinod, PK</br>
  Systemic lupus erythematosus (SLE) is an autoimmune <font color="#be00be">diseas</font>e in which the immune system of the <font color="#be00be">patient</font> starts attacking healthy tissues of the body. Lupus Nephritis (LN) refers to the inflammation of kidney tissues resulting in renal failure due to these attacks. The International Society of Nephrology/Renal <font color="#be00be">Patholog</font>y Society (ISN/RPS) has released a classification system based on various patterns observed during renal injury in SLE. Traditional methods require meticulous pathological assessment of the renal biopsy and are time-consuming. Recently, computational techniques have helped to alleviate this issue by using virtual microscopy or Whole Slide Imaging (WSI). With the use of deep learning and modern computer vision techniques, we propose a pipeline that is able to automate the process of 1) detection of various glomeruli patterns present in these whole slide images and 2) classification of each image using the extracted glomeruli features. </br></br>

<a href='http://arxiv.org/pdf/2112.05379.pdf'>2112.05379</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.4037баллов, №1234</br>
<b>Cross-Modal Transferable <font color="#be00be">Adversarial Att</font>acks from Images to Videos</b></br>
Authors: , Wei, Zhipeng, Chen, Jingjing, Wu, Zuxuan, Jiang, Yu-Gang</br>
  Recent studies have shown that adversarial examples hand-crafted on one white-box model can be used to attack other black-box models. Such cross-model transferability makes it feasible to perform <font color="#be00be">black-box attack</font>s, which has raised security concerns for <font color="#009600">real-world</font> DNNs applications. Nevertheless, existing works mostly focus on investigating the adversarial transferability across different deep models that share the same modality of input data. The cross-modal transferability of adversarial perturbation has never been explored. This paper investigates the transferability of adversarial perturbation across different modalities, i.e., leveraging adversarial perturbation generated on white-box image models to attack black-box video models. Specifically, motivated by the observation that the low-level feature space between images and video frames are similar, we propose a simple yet effective cross-modal attack method, named as Image To Video (I2V) attack. I2V generates adversarial frames by minimizing the cosine similarity between features of pre-trained image models from adversarial and benign examples, then combines the generated adversarial frames to perform black-box attacks on video recognition models. Extensive experiments demonstrate that I2V can achieve high attack success rates on different black-box video recognition models. On Kinetics-400 and UCF-101, I2V achieves an average attack success rate of 77.88% and 65.68%, respectively, which sheds light on the feasibility of cross-modal <font color="#be00be">adversarial att</font>acks. </br></br>

<a href='http://arxiv.org/pdf/2112.05888.pdf'>2112.05888</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -1.4166баллов, №1235</br>
<b>A Sparse Expansion For Deep <font color="#be00be">Gaussi</font>an Processes</b></br>
Authors: , Ding, Liang, Tuo, Rui, Shahrampour, Shahin</br>
  Deep <font color="#be00be">Gaussi</font>an Processes (DGP) enable a non-parametric approach to quantify the uncertainty of complex deep machine learning models. Conventional inferential methods for DGP models can suffer from high computational complexity as they require large-scale operations with <font color="#be00be">kernel</font> matrices for training and inference. In this work, we propose an efficient scheme for accurate inference and prediction based on a range of Gaussian Processes, called the Tensor Markov Gaussian Processes (TMGP). We construct an induced approximation of TMGP referred to as the <font color="#00be00">hierarchical</font> expansion. Next, we develop a deep TMGP (DTMGP) model as the composition of multiple hierarchical expansion of TMGPs. The proposed DTMGP model has the following properties: (1) the outputs of each activation function are deterministic while the weights are chosen independently from standard Gaussian distribution; (2) in training or prediction, only O(polylog(M)) (out of M) activation functions have non-zero outputs, which significantly boosts the computational efficiency. Our numerical experiments on real datasets show the superior computational efficiency of DTMGP versus other DGP models. </br></br>

<a href='http://arxiv.org/pdf/2112.05975.pdf'>2112.05975</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.4257баллов, №1236</br>
<b>CPRAL: Collaborative Panoptic-Regional Active Learning for Semantic\n  <font color="#be00be">Segmentation</font></b></br>
Authors: , Qiao, Yu, Zhu, Jincheng, Long, Chengjiang, Zhang, Zeyao, Wang, Yuxin, Du, Zhenjun, Yang, Xin</br>
  Acquiring the most representative examples via active learning (AL) can benefit many data-dependent computer vision tasks by minimizing efforts of image-level or pixel-wise annotations. In this paper, we propose a novel Collaborative Panoptic-Regional Active Learning framework (CPRAL) to address the semantic <font color="#be00be">segmentation</font> task. For a small batch of images initially sampled with pixel-wise annotations, we employ panoptic information to initially select unlabeled samples. Considering the class imbalance in the segmentation dataset, we import a Regional <font color="#be00be">Gaussi</font>an Attention module (RGA) to achieve semantics-biased selection. The subset is highlighted by vote entropy and then attended by Gaussian <font color="#be00be">kernel</font>s to maximize the biased regions. We also propose a Contextual Labels Extension (CLE) to boost regional annotations with contextual attention guidance. With the collaboration of semantics-agnostic panoptic matching and regionbiased selection and extension, our CPRAL can strike a balance between labeling efforts and performance and compromise the semantics distribution. We perform extensive experiments on Cityscapes and BDD10K datasets and show that CPRAL <font color="#00be00">outperform</font>s the cutting-edge methods with impressive results and less labeling proportion. </br></br>

<a href='http://arxiv.org/pdf/2112.08453.pdf'>2112.08453</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -1.4395баллов, №1237</br>
<b>The Need for Ethical, Responsible, and Trustworthy Artificial\n  Intelligence for Environmental Sciences</b></br>
Authors: , McGovern, Amy, Ebert-Uphoff, Imme, Gagne II, David John, Bostrom, Ann</br>
  Given the growing use of Artificial Intelligence (AI) and machine learning (ML) methods across all aspects of environmental sciences, it is imperative that we initiate a discussion about the ethical and responsible use of AI. In fact, much can be learned from other domains where AI was introduced, often with the best of intentions, yet often led to unintended societal consequences, such as hard coding racial bias in the criminal justice system or increasing <font color="#be00be">economic</font> inequality through the <font color="#be00be">financ</font>ial system. A common misconception is that the environmental sciences are immune to such unintended consequences when AI is being used, as most data come from observations, and AI algorithms are based on mathematical formulas, which are often seen as objective. In this article, we argue the opposite can be the case. Using specific examples, we demonstrate many ways in which the use of AI can introduce similar consequences in the environmental sciences. This article will stimulate discussion and research efforts in this direction. As a community, we should avoid repeating any foreseeable mistakes made in other domains through the introduction of AI. In fact, with proper precautions, AI can be a great tool to help {\\it reduce} <font color="#be00be">climate</font> and environmental injustice. We primarily focus on <font color="#be00be">weather</font> and climate examples but the conclusions apply broadly across the environmental sciences. </br></br>

<a href='http://arxiv.org/pdf/2112.06640.pdf'>2112.06640</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -1.4494баллов, №1238</br>
<b><font color="#be00be">Bayes</font>ian Nonparametric View to Spawning</b></br>
Authors: , Moraffah, Bahman</br>
  In <font color="#be00be">tracking</font> multiple objects, it is often assumed that each observation (measurement) is originated from one and only one object. However, we may encounter a situation that each measurement may or may not be associated with multiple objects at each time step --spawning. Therefore, the association of each measurement to multiple objects is a crucial task to perform in order to track multiple objects with birth and death. In this paper, we introduce a novel <font color="#be00be">Bayes</font>ian nonparametric approach that models a scenario where each observation may be drawn from an unknown number of objects for which it provides a tractable Markov chain Monte Carlo (MCMC) approach to sample from the posterior distribution. The number of objects at each time step, itself, is also assumed to be unknown. We, then, show through experiments the advantage of nonparametric modeling to scenarios with spawning events. Our experiment results also demonstrate the advantages of our framework over the existing methods. </br></br>

<a href='http://arxiv.org/pdf/2112.06175.pdf'>2112.06175</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.4591баллов, №1239</br>
<b>Unsupervised Domain-Specific <font color="#be00be">Deblur</font>ring using Scale-Specific Attention</b></br>
Authors: , Kandula, Praveen, N, Rajagopalan. A.</br>
  In the literature, coarse-to-fine or scale-recurrent approach i.e. progressively restoring a clean image from its low-resolution versions has been successfully employed for single image <font color="#be00be">deblur</font>ring. However, a major disadvantage of existing methods is the need for paired data; i.e. sharpblur image pairs of the same scene, which is a complicated and cumbersome acquisition procedure. Additionally, due to strong supervision on loss functions, pre-trained models of such networks are strongly biased towards the blur experienced during training and tend to give sub-optimal performance when confronted by new blur <font color="#be00be">kernel</font>s during inference time. To address the above issues, we propose unsupervised domain-specific deblurring using a scale-adaptive attention module (SAAM). Our network does not require supervised pairs for training, and the deblurring mechanism is primarily guided by adversarial loss, thus making our network suitable for a distribution of blur functions. Given a blurred input image, different resolutions of the same image are used in our model during training and SAAM allows for effective flow of information across the resolutions. For network training at a specific scale, SAAM attends to lower scale features as a function of the current scale. Different ablation studies show that our coarse-to-fine mechanism <font color="#00be00">outperform</font>s end-to-end unsupervised models and SAAM is able to attend better compared to attention models used in literature. Qualitative and quantitative comparisons (on no-reference metrics) show that our method outperforms prior unsupervised methods. </br></br>

<a href='http://arxiv.org/pdf/2112.02365.pdf'>2112.02365</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.4638баллов, №1240</br>
<b>TransBoost: A Boosting-Tree <font color="#be00be">Kernel</font> Transfer Learning Algorithm for\n  Improving <font color="#be00be">Financ</font>ial Inclusion</b></br>
Authors: , Sun, Yiheng, Lu, Tian, Wang, Cong, Li, Yuan, Fu, Huaiyu, Dong, Jingran, Xu, Yunjie</br>
  The prosperity of<font color="#960096"> mobile </font>and <font color="#be00be">financ</font>ial technologies has bred and expanded various kinds of financial products to a broader scope of people, which contributes to advocating financial inclusion. It has non-trivial social benefits of diminishing financial inequality. However, the technical challenges in individual financial risk evaluation caused by the distinct characteristic distribution and limited credit history of new users, as well as the inexperience of newly-entered companies in handling complex data and obtaining accurate labels, impede further promoting financial inclusion. To tackle these challenges, this paper develops a novel transfer learning algorithm (i.e., TransBoost) that combines the merits of tree-based models and <font color="#be00be">kernel</font> methods. The TransBoost is designed with a parallel tree structure and efficient weights updating mechanism with <font color="#be00be">theor</font>etical guarantee, which enables it to excel in tackling <font color="#009600">real-world</font> data with high dimensional features and sparsity in $O(n)$ time complexity. We conduct extensive experiments on two public datasets and a unique large-scale dataset from Tencent Mobile Payment. The results show that the TransBoost <font color="#00be00">outperform</font>s other <font color="#00be00">state-of-the-art</font> benchmark transfer learning algorithms in terms of prediction accuracy with superior efficiency, shows stronger robustness to data sparsity, and provides meaningful model <font color="#be00be">interpret</font>ation. Besides, given a financial risk level, the TransBoost enables financial service providers to serve the largest number of users including those who would otherwise be excluded by other algorithms. That is, the TransBoost improves financial inclusion. </br></br>

<a href='http://arxiv.org/pdf/2112.07436.pdf'>2112.07436</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.4703баллов, №1241</br>
<b>Graph <font color="#be00be">Kernel</font> Neural Networks</b></br>
Authors: , Cosmo, Luca, Minello, Giorgia, Bronstein, Michael, Rodol&#xe0;, Emanuele, Rossi, Luca, Torsello, Andrea</br>
  The convolution operator at the core of many modern neural architectures can effectively be seen as performing a dot product between an input matrix and a filter. While this is readily applicable to data such as images, which can be represented as regular grids in the Euclidean space, extending the convolution operator to work on graphs proves more challenging, due to their irregular structure. In this paper, we propose to use graph <font color="#be00be">kernel</font>s, i.e., kernel functions that compute an inner product on graphs, to extend the standard convolution operator to the graph domain. This allows us to define an entirely structural model that does not require computing the embedding of the input graph. Our architecture allows to plug-in any type and number of graph kernels and has the added benefit of providing some <font color="#be00be">interpret</font>ability in terms of the structural masks that are learned during the training process, similarly to what happens for convolutional masks in traditional convolutional neural networks. We perform an extensive ablation study to investigate the impact of the model hyper-parameters and we show that our model achieves <font color="#960096">competitive</font> performance on standard graph classification datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.07664.pdf'>2112.07664</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.4732баллов, №1242</br>
<b>Adaptive Affinity for Associations in Multi-Target Multi-Camera <font color="#be00be">Tracking</font></b></br>
Authors: , Hou, Yunzhong, Wang, Zhongdao, Wang, Shengjin, Zheng, Liang</br>
  Data associations in multi-target multi-camera <font color="#be00be">tracking</font> (MTMCT) usually estimate affinity directly from <font color="#be00be">re-identification</font> (re-ID) feature distances. However, we argue that it might not be the best choice given the difference in matching scopes between re-ID and MTMCT problems. Re-ID systems focus on global matching, which retrieves targets from all cameras and all times. In contrast, data association in tracking is a local matching problem, since its candidates only come from neighboring locations and time frames. In this paper, we design experiments to verify such misfit between global re-ID feature distances and local matching in tracking, and propose a simple yet effective approach to adapt affinity estimations to corresponding matching scopes in MTMCT. Instead of trying to deal with all appearance changes, we tailor the affinity metric to specialize in ones that might emerge during data associations. To this end, we introduce a new data sampling scheme with temporal windows originally used for data associations in tracking. Minimizing the mismatch, the adaptive affinity module brings significant improvements over global re-ID distance, and produces <font color="#960096">competitive</font> performance on CityFlow and DukeMTMC datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.06760.pdf'>2112.06760</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -1.4823баллов, №1243</br>
<b>Robust factored principal component analysis for matrix-valued <font color="#be00be">outlier</font>\n  accommodation and detection</b></br>
Authors: , Ma, Xuan, Zhao, Jianhua, Wang, Yue</br>
  Principal component analysis (PCA) is a popular dimension reduction technique for vector data. Factored PCA (FPCA) is a probabilistic extension of PCA for matrix data, which can substantially reduce the number of parameters in PCA while yield satisfactory performance. However, FPCA is based on the <font color="#be00be">Gaussi</font>an assumption and thereby susceptible to <font color="#be00be">outlier</font>s. Although the multivariate $t$ distribution as a robust modeling tool for vector data has a very long history, its application to matrix data is very limited. The main reason is that the dimension of the vectorized matrix data is often very high and the higher the dimension, the lower the breakdown point that measures the robustness. To solve the robustness problem suffered by FPCA and make it applicable to matrix data, in this paper we propose a robust extension of FPCA (RFPCA), which is built upon a $t$-type distribution called matrix-variate $t$ distribution. Like the multivariate $t$ distribution, the matrix-variate $t$ distribution can adaptively down-weight outliers and yield robust estimates. We develop a fast EM-type algorithm for parameter estimation. Experiments on synthetic and <font color="#009600">real-world</font> datasets reveal that RFPCA is compared favorably with several related methods and RFPCA is a simple but powerful tool for matrix-valued outlier detection. </br></br>

<a href='http://arxiv.org/pdf/2112.08706.pdf'>2112.08706</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.4831баллов, №1244</br>
<b>Forecasting sales with <font color="#be00be">Bayes</font>ian networks: a case study of a super<font color="#be00be">market</font>\n  product in the presence of promotions</b></br>
Authors: , Hamza, Muhammad, Abolghasemi, Mahdi, Alvandi, Abraham Oshni</br>
  Sales forecasting is the prerequisite for a lot of managerial decisions such as production planning, material resource planning and budgeting in the supply chain. Promotions are one of the most important business strategies that are often used to boost sales. While promotions are attractive for generating demand, it is often difficult to forecast demand in their presence. In the past few decades, several quantitative models have been developed to forecast sales including statistical and machine learning models. However, these methods may not be adequate to account for all the internal and external factors that may impact sales. As a result, qualitative models have been adopted along with quantitative methods as consulting experts has been proven to improve forecast accuracy by providing contextual information. Such models are being used extensively to account for factors that can lead to a rapid change in sales, such as during promotions. In this paper, we aim to use <font color="#be00be">Bayes</font>ian Networks to forecast promotional sales where a combination of factors such as price, type of promotions, and product location impacts sales. We choose to develop a BN model because BN models essentially have the capability to combine various qualitative and quantitative factors with causal forms, making it an attractive tool for sales forecasting during promotions. This can be used to adjust a company\'s promotional strategy in the context of this case study. We gather sales data for a particular product from a retailer that sells products in Australia. We develop a Bayesian Network for this product and validate our results by empirical analysis. This paper confirms that BNs can be effectively used to forecast sales, especially during promotions. In the end, we provide some research avenues for using BNs in forecasting sales. </br></br>

<a href='http://arxiv.org/pdf/2111.02273.pdf'>2111.02273</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.4988баллов, №1245</br>
<b>Multi-Cue Adaptive <font color="#be00be">Emotion</font> Recognition Network</b></br>
Authors: , Costa, Willams, Mac&#xea;do, David, Zanchettin, Cleber, Figueiredo, Lucas S., Teichrieb, Veronica</br>
  Expressing and identifying <font color="#be00be">emotion</font>s through<font color="#be00be"> facial </font>and physical expressions is a significant part of social interaction. Emotion recognition is an essential task in computer vision due to its various applications and mainly for allowing a more natural interaction between humans and machines. The common approaches for emotion recognition focus on analyzing facial expressions and requires the automatic localization of the<font color="#be00be"> face </font>in the image. Although these methods can correctly classify emotion in controlled scenarios, such techniques are limited when dealing with unconstrained daily interactions. We propose a new deep learning approach for emotion recognition based on adaptive multi-cues that extract information from context and body poses, which humans commonly use in social interaction and communication. We compare the proposed approach with the state-of-art approaches in the CAER-S dataset, evaluating different components in a pipeline that reached an accuracy of 89.30% </br></br>

<a href='http://arxiv.org/pdf/2112.07111.pdf'>2112.07111</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.5022баллов, №1246</br>
<b>EMDS-6: Environmental Microorganism Image Dataset Sixth Version for\n  <font color="#be00be">Image Denoising</font>, <font color="#be00be">Segmentation</font>, Feature Extraction, Classification and\n  Detection Methods Evaluation</b></br>
Authors: , Zhao, Peng, Li, Chen, Rahaman, Md Mamunur, Xu, Hao, Ma, Pingli, Yang, Hechen, Sun, Hongzan, Jiang, Tao, Xu, Ning, Grzegorzek, Marcin</br>
  Environmental microorganisms (EMs) are ubiquitous around us and have an important impact on the survival and development of human society. However, the high standards and strict requirements for the preparation of environmental microorganism (EM) data have led to the insufficient of existing related databases, not to mention the databases with GT images. This problem seriously affects the progress of related experiments. Therefore, This study develops the Environmental Microorganism Dataset Sixth Version (EMDS-6), which contains 21 types of EMs. Each type of EM contains 40 original and 40 GT images, in total 1680 EM images. In this study, in order to test the effectiveness of EMDS-6. We choose the classic algorithms of image processing methods such as <font color="#be00be">image denoising</font>, image <font color="#be00be">segmentation</font> and target detection. The experimental result shows that EMDS-6 can be used to evaluate the performance of image denoising, image segmentation, image feature extraction, image classification, and <font color="#be00be">object detection</font> methods. </br></br>

<a href='http://arxiv.org/pdf/2112.08022.pdf'>2112.08022</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -1.5122баллов, №1247</br>
<b><font color="#be00be">Segmentation</font>-Reconstruction-Guided<font color="#be00be"> Facial </font>Image De-occlusion</b></br>
Authors: , Yin, Xiangnan, Huang, Di, Fu, Zehua, Wang, Yunhong, Chen, Liming</br>
  Occlusions are very common in<font color="#be00be"> face </font>images in the wild, leading to the degraded performance of face-related tasks. Although much effort has been devoted to removing occlusions from face images, the varying shapes and textures of occlusions still challenge the robustness of current methods. As a result, current methods either rely on manual occlusion masks or only apply to specific occlusions. This paper proposes a novel face de-occlusion model based on face <font color="#be00be">segmentation</font> and 3D face reconstruction, which automatically removes all kinds of face occlusions with even blurred boundaries,e.g., hairs. The proposed model consists of a 3D face reconstruction module, a face segmentation module, and an image generation module. With the face prior and the occlusion mask predicted by the first two, respectively, the image generation module can faithfully recover the missing<font color="#be00be"> facial </font>textures. To supervise the training, we further build a large occlusion dataset, with both manually labeled and synthetic occlusions. Qualitative and quantitative results demonstrate the effectiveness and robustness of the proposed method. </br></br>

<a href='http://arxiv.org/pdf/2112.05626.pdf'>2112.05626</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.5127баллов, №1248</br>
<b>Seq-Masks: Bridging the gap between appearance and gait modeling for\n  video-based person <font color="#be00be">re-identification</font></b></br>
Authors: , Chang, Zhigang, Yang, Zhao, Chen, Yongbiao, Zhou, Qin, Zheng, Shibao</br>
  ideo-based person <font color="#be00be">re-identification</font> (Re-ID) aims to match person images in video sequences captured by disjoint <font color="#be00be">surveillance</font> cameras. Traditional video-based person Re-ID methods focus on exploring appearance information, thus, vulnerable against illumination changes, scene noises, camera parameters, and especially clothes/carrying variations. Gait recognition provides an implicit biometric solution to alleviate the above headache. Nonetheless, it experiences severe performance degeneration as camera view varies. In an attempt to address these problems, in this paper, we propose a framework that utilizes the sequence masks (SeqMasks) in the video to integrate appearance information and gait modeling in a close fashion. Specifically, to sufficiently validate the effectiveness of our method, we build a novel dataset named MaskMARS based on MARS. Comprehensive experiments on our proposed large wild video Re-ID dataset MaskMARS evidenced our extraordinary performance and generalization capability. Validations on the gait recognition metric CASIA-B dataset further demonstrated the capability of our hybrid model. </br></br>

<a href='http://arxiv.org/pdf/2112.09069.pdf'>2112.09069</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML) &nbsp&nbsp -1.5192баллов, №1249</br>
<b>Progressive Graph Convolution Network for<font color="#be00be"> EEG </font><font color="#be00be">Emotion</font> Recognition</b></br>
Authors: , Zhou, Yijin, Li, Fu, Li, Yang, Ji, Youshuo, Shi, Guangming, Zheng, Wenming, Zhang, Lijian, Chen, Yuanfang, Cheng, Rui</br>
  Studies in the area of neuroscience have revealed the relationship between <font color="#be00be">emotion</font>al patterns and <font color="#00be00">brain</font> functional regions, demonstrating that dynamic relationships between different brain regions are an essential factor affecting emotion recognition determined through electroencephalography (EEG). Moreover, in<font color="#be00be"> EEG </font>emotion recognition, we can observe that clearer boundaries exist between coarse-grained emotions than those between fine-grained emotions, based on the same EEG data; this indicates the concurrence of large coarse- and small fine-grained emotion variations. Thus, the progressive classification process from coarse- to fine-grained categories may be helpful for EEG emotion recognition. Consequently, in this study, we propose a progressive graph convolution network (PGCN) for capturing this inherent characteristic in EEG emotional signals and progressively learning the discriminative EEG features. To fit different EEG patterns, we constructed a dual-graph module to characterize the intrinsic relationship between different EEG channels, containing the dynamic functional connections and static spatial proximity information of brain regions from neuroscience research. Moreover, motivated by the observation of the relationship between coarse- and fine-grained emotions, we adopt a dual-head module that enables the PGCN to progressively learn more discriminative EEG features, from coarse-grained (easy) to fine-grained categories (difficult), referring to the <font color="#00be00">hierarchical</font> characteristic of emotion. To verify the performance of our model, extensive experiments were conducted on two public datasets: SEED-IV and multi-modal physiological emotion database (MPED). </br></br>

<a href='http://arxiv.org/pdf/2112.07239.pdf'>2112.07239</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.5202баллов, №1250</br>
<b>Compensating trajectory bias for unsupervised <font color="#be00be">patient</font> stratification\n  using adversarial recurrent neural networks</b></br>
Authors: , Javer, Avelino, Parsons, Owen, Carr, Oliver, Baxter, Janie, Diedrich, Christian, El&#xe7;i, Eren, Schaper, Steffen, Coboeken, Katrin, D&#xfc;richen, Robert</br>
  Electronic healthcare records are an important source of information which can be used in <font color="#be00be">patient</font> stratification to discover novel <font color="#be00be">diseas</font>e phenotypes. However, they can be challenging to work with as data is often sparse and irregularly sampled. One approach to solve these limitations is learning dense embeddings that represent individual patient trajectories using a recurrent neural network autoencoder (RNN-AE). This process can be susceptible to unwanted data biases. We show that patient embeddings and clusters using previously proposed RNN-AE models might be impacted by a trajectory bias, meaning that results are dominated by the amount of data contained in each patients trajectory, instead of <font color="#be00be">clinic</font>ally relevant details. We investigate this bias on 2 datasets (from different hospitals) and 2 disease areas as well as using different parts of the patient trajectory. Our results using 2 previously published baseline methods indicate a particularly strong bias in case of an event-to-end trajectory. We present a method that can overcome this issue using an adversarial training scheme on top of a RNN-AE. Our results show that our approach can reduce the trajectory bias in all cases. </br></br>

<a href='http://arxiv.org/pdf/2112.05871.pdf'>2112.05871</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.5266баллов, №1251</br>
<b>Attacking <font color="#be00be">Point Cloud</font> <font color="#be00be">Segmentation</font> with Color-only Perturbation</b></br>
Authors: , Xu, Jiacen, Zhou, Zhe, Ding, Boyuan Feng Yufeng, Li, Zhou</br>
  Recent research efforts on 3D point-cloud semantic <font color="#be00be">segmentation</font> have achieved outstanding performance by adopting deep CNN (convolutional neural networks) and GCN (graph convolutional networks). However, the robustness of these complex models has not been systematically analyzed. Given that semantic segmentation has been applied in many safety-critical applications (e.g., autonomous driving, geological sensing), it is important to fill this knowledge gap, in particular, how these models are affected under adversarial samples. While <font color="#be00be">adversarial att</font>acks against <font color="#be00be">point cloud</font> have been studied, we found all of them were targeting single-object recognition, and the perturbation is done on the point coordinates. We argue that the coordinate-based perturbation is unlikely to realize under the physical-world constraints. Hence, we propose a new color-only perturbation method named COLPER, and tailor it to semantic segmentation. By evaluating COLPER on an indoor dataset (S3DIS) and an outdoor dataset (Semantic3D) against three point cloud segmentation models (PointNet++, DeepGCNs, and RandLA-Net), we found color-only perturbation is sufficient to significantly drop the segmentation accuracy and aIoU, under both targeted and non-targeted attack settings. </br></br>

<a href='http://arxiv.org/pdf/2112.08415.pdf'>2112.08415</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.5280баллов, №1252</br>
<b>Real-time Detection of <font color="#be00be">Anomal</font>ies in Multivariate Time Series of\n  Astronomical Data</b></br>
Authors: , Muthukrishna, Daniel, Mandel, Kaisey S., Lochner, Michelle, Webb, Sara, Narayan, Gautham</br>
  Astronomical transients are stellar objects that become temporarily brighter on various timescales and have led to some of the most significant discoveries in cosmology and astronomy. Some of these transients are the explosive deaths of stars known as supernovae while others are rare, exotic, or entirely new kinds of exciting stellar explosions. New astronomical sky surveys are observing unprecedented numbers of multi-wavelength transients, making standard approaches of visually identifying new and interesting transients infeasible. To meet this demand, we present two novel methods that aim to quickly and automatically detect <font color="#be00be">anomal</font>ous transient light curves in real-time. Both methods are based on the simple idea that if the light curves from a known population of transients can be accurately modelled, any deviations from model predictions are likely anomalies. The first approach is a probabilistic neural network built using Temporal Convolutional Networks (TCNs) and the second is an <font color="#be00be">interpret</font>able <font color="#be00be">Bayes</font>ian parametric model of a transient. We show that the flexibility of neural networks, the attribute that makes them such a powerful tool for many <font color="#be00be">regression</font> tasks, is what makes them less suitable for anomaly detection when compared with our parametric model. </br></br>

<a href='http://arxiv.org/pdf/2112.05900.pdf'>2112.05900</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.5291баллов, №1253</br>
<b>Automated assessment of <font color="#be00be">diseas</font>e severity of COVID-19 using artificial\n  intelligence with synthetic chest CT</b></br>
Authors: , Liu, Mengqiu, Liu, Ying, Yang, Yidong, Liu, Aiping, Li, Shana, Qu, Changbing, Qiu, Xiaohui, Li, Yang, Lv, Weifu, Zhang, Peng, Wen, Jie</br>
  Background: Triage of <font color="#be00be">patient</font>s is important to control the pandemic of coronavirus <font color="#be00be">diseas</font>e 2019 (COVID-19), especially during the peak of the pandemic when <font color="#be00be">clinic</font>al resources become extremely limited.   Purpose: To develop a method that automatically segments and quantifies lung and pneumonia lesions with synthetic chest CT and assess disease severity in COVID-19 patients.   Materials and Methods: In this study, we incorporated data augmentation to generate synthetic chest CT images using public available datasets (285 datasets from &quot;Lung Nodule Analysis 2016&quot;). The synthetic images and masks were used to train a 2D U-net neural network and tested on 203 COVID-19 datasets to generate lung and lesion <font color="#be00be">segmentation</font>s. Disease severity scores (DL: damage load; DS: damage score) were calculated based on the segmentations. Correlations between DL/DS and clinical lab tests were evaluated using Pearson\'s method. A p-value &lt; 0.05 was considered as statistical significant.   Results: Automatic lung and lesion segmentations were compared with manual annotations. For lung segmentation, the median values of dice similarity coefficient, Jaccard index and average surface distance, were 98.56%, 97.15% and 0.49 mm, respectively. The same metrics for lesion segmentation were 76.95%, 62.54% and 2.36 mm, respectively. Significant (p &lt;&lt; 0.05) correlations were found between DL/DS and percentage lymphocytes tests, with r-values of -0.561 and -0.501, respectively.   Conclusion: An AI system that based on thoracic radiographic and data augmentation was proposed to segment lung and lesions in COVID-19 patients. Correlations between imaging findings and clinical lab tests suggested the value of this system as a potential tool to assess disease severity of COVID-19. </br></br>

<a href='http://arxiv.org/pdf/2112.08486.pdf'>2112.08486</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -1.5341баллов, №1254</br>
<b>Text Mining Through Label Induction Grouping Algorithm Based Method</b></br>
Authors: , Saleem, Gulshan, Ahmed, Nisar, Qamar, Usman</br>
  The main focus of information <font color="#be00be">retrieval</font> methods is to provide accurate and efficient results which are cost-effective too. LINGO (Label Induction Grouping Algorithm) is a <font color="#be00be">clustering</font> algorithm that aims to provide search results in form of quality clusters but also has a few limitations. In this paper, our focus is based on achieving results that are more meaningful and improving the overall performance of the algorithm. LINGO works on two main steps; Cluster Label Induction by using Latent Semantic Indexing technique (LSI) and Cluster content discovery by using the Vector Space Model (VSM). As LINGO uses VSM in cluster content discovery, our task is to replace VSM with LSI for cluster content discovery and to analyze the feasibility of using LSI with Okapi BM25. The next task is to compare the results of a modified method with the LINGO original method. The research is applied to five different text-based data sets to get more reliable results for every method. Research results show that LINGO produces 40-50% better results when using LSI for content Discovery. From <font color="#be00be">theor</font>etical evidence using Okapi BM25 for scoring method in LSI (LSI+Okapi BM25) for cluster content discovery instead of VSM, also results in better clusters generation in terms of scalability and performance when compares to both VSM and LSI\'s Results. </br></br>

<a href='http://arxiv.org/pdf/2111.07162.pdf'>2111.07162</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -1.5766баллов, №1255</br>
<b><font color="#be00be">Gaussi</font>an Process based Stochastic Model Predictive Control for\n  Cooperative Adaptive Cruise Control</b></br>
Authors: , Mosharafian, Sahand, Razzaghpour, Mahdi, Fallah, Yaser P., Velni, Javad Mohammadpour</br>
  Cooperative driving relies on communication among vehicles to create situational awareness. One application of cooperative driving is Cooperative Adaptive Cruise Control (CACC) that aims at enhancing highway transportation safety and capacity. Model-based communication (MBC) is a new paradigm with a flexible content structure for broadcasting joint vehicle-driver predictive behavioral models. The vehicle\'s complex dynamics and diverse driving behaviors add complexity to the modeling process. <font color="#be00be">Gaussi</font>an process (GP) is a fully data-driven and non-parametric <font color="#be00be">Bayes</font>ian modeling approach which can be used as a modeling component of MBC. The knowledge about the uncertainty is propagated through predictions by generating local GPs for vehicles and broadcasting their hyper-parameters as a model to the neighboring vehicles. In this research study, GP is used to model each vehicle\'s speed trajectory, which allows vehicles to access the future behavior of their preceding vehicle during communication loss and/or low-rate communication. Besides, to overcome the safety issues in a vehicle platoon, two operating modes for each vehicle are considered; free following and emergency braking. This paper presents a discrete hybrid stochastic model predictive control, which incorporates system modes as well as uncertainties captured by GP models. The proposed control design approach finds the optimal vehicle speed trajectory with the goal of achieving a safe and efficient platoon of vehicles with small inter-vehicle gap while reducing the reliance of the vehicles on a frequent communication. Simulation studies demonstrate the efficacy of the proposed controller considering the aforementioned communication paradigm with low-rate intermittent communication. </br></br>

<a href='http://arxiv.org/pdf/2112.06309.pdf'>2112.06309</a> &nbsp&nbsp (cs:CL, cs:SD) &nbsp&nbsp -1.5807баллов, №1256</br>
<b>Improving <font color="#be00be">Speech Recognition</font> on Noisy Speech via <font color="#be00be">Speech Enhancement</font> with\n  Multi-Discriminators CycleGAN</b></br>
Authors: , Li, Chia-Yu, Vu, Ngoc Thang</br>
  This paper presents our latest investigations on improving automatic <font color="#be00be">speech recognition</font> for noisy speech via <font color="#be00be">speech enhancement</font>. We propose a novel method named Multi-discriminators CycleGAN to reduce noise of input speech and therefore improve the automatic speech recognition performance. Our proposed method leverages the CycleGAN framework for speech enhancement without any parallel data and improve it by introducing multiple discriminators that check different frequency areas. Furthermore, we show that training multiple generators on homogeneous subset of the training data is better than training one generator on all the training data. We evaluate our method on CHiME-3 data set and observe up to 10.03% relatively WER improvement on the development set and up to 14.09% on the evaluation set. </br></br>

<a href='http://arxiv.org/pdf/2112.05367.pdf'>2112.05367</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -1.5820баллов, №1257</br>
<b>Efficient Action Poisoning Attacks on Linear Contextual <font color="#be00be">Bandit</font>s</b></br>
Authors: , Liu, Guanlin, Lai, Lifeng</br>
  Contextual <font color="#be00be">bandit</font> algorithms have many applicants in a variety of scenarios. In order to develop trustworthy contextual bandit systems, understanding the impacts of various <font color="#be00be">adversarial att</font>acks on contextual bandit algorithms is essential. In this paper, we propose a new class of attacks: action poisoning attacks, where an adversary can change the action signal selected by the agent. We design action poisoning attack schemes against linear contextual bandit algorithms in both white-box and black-box settings. We further analyze the cost of the proposed attack strategies for a very popular and widely used bandit algorithm: LinUCB. We show that, in both white-box and black-box settings, the proposed attack schemes can force the LinUCB agent to pull a target arm very frequently by spending only logarithm cost. </br></br>

<a href='http://arxiv.org/pdf/2112.05495.pdf'>2112.05495</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -1.5954баллов, №1258</br>
<b>How <font color="#be00be">Private</font> Is Your RL Policy? An Inverse RL Based Analysis Framework</b></br>
Authors: , Prakash, Kritika, Husain, Fiza, Paruchuri, Praveen, Gujar, Sujit P.</br>
  <font color="#00be00">Reinforcement Learning</font> (RL) enables agents to learn how to perform various tasks from scratch. In domains like autonomous driving, <font color="#be00be">recommendat</font>ion systems, and more, optimal RL policies learned could cause a <font color="#be00be">privacy</font> breach if the policies memorize any part of the <font color="#be00be">private</font> reward. We study the set of existing differentially-private RL policies derived from various RL algorithms such as Value Iteration, Deep Q Networks, and Vanilla Proximal Policy Optimization. We propose a new Privacy-Aware Inverse RL (PRIL) analysis framework, that performs reward reconstruction as an <font color="#be00be">adversarial att</font>ack on private policies that the agents may deploy. For this, we introduce the reward reconstruction attack, wherein we seek to reconstruct the original reward from a privacy-preserving policy using an Inverse RL algorithm. An adversary must do poorly at reconstructing the original reward function if the agent uses a tightly private policy. Using this framework, we empirically test the effectiveness of the privacy guarantee offered by the private algorithms on multiple instances of the FrozenLake domain of varying complexities. Based on the analysis performed, we infer a gap between the current standard of privacy offered and the standard of privacy needed to protect reward functions in RL. We do so by quantifying the extent to which each private policy protects the reward function by measuring distances between the original and reconstructed rewards. </br></br>

<a href='http://arxiv.org/pdf/2112.06517.pdf'>2112.06517</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -1.6053баллов, №1259</br>
<b>Top $K$ Ranking for Multi-Armed <font color="#be00be">Bandit</font> with Noisy Evaluations</b></br>
Authors: , Garcelon, Evrard, Avadhanula, Vashist, Lazaric, Alessandro, Pirotta, Matteo</br>
  We consider a multi-armed <font color="#be00be">bandit</font> setting where, at the beginning of each round, the learner receives noisy independent, and possibly biased, \\emph{evaluations} of the true reward of each arm and it selects $K$ arms with the objective of accumulating as much reward as possible over $T$ rounds. Under the assumption that at each round the true reward of each arm is drawn from a fixed distribution, we derive different algorithmic approaches and <font color="#be00be">theor</font>etical guarantees depending on how the evaluations are generated. First, we show a $\\widetilde{O}(T^{2/3})$ regret in the general case when the observation functions are a genearalized linear function of the true rewards. On the other hand, we show that an improved $\\widetilde{O}(\\sqrt{T})$ regret can be derived when the observation functions are noisy linear functions of the true rewards. Finally, we report an empirical validation that confirms our theoretical findings, provides a thorough comparison to alternative approaches, and further supports the interest of this setting in practice. </br></br>

<a href='http://arxiv.org/pdf/2112.08561.pdf'>2112.08561</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -1.6303баллов, №1260</br>
<b><font color="#be00be">Emotion</font>Box: a music-element-driven emotional<font color="#be00be"> music </font>generation system\n  using Recurrent Neural Network</b></br>
Authors: , Zheng, Kaitong, Meng, Ruijie, Zheng, Chengshi, Li, Xiaodong, Sang, Jinqiu, Cai, Juanjuan, Wang, Jie</br>
  With the development of deep neural networks, automatic<font color="#be00be"> music </font>composition has made great progress. Although <font color="#be00be">emotion</font>al music can evoke listeners\' different emotions and it is important for artistic expression, only few researches have focused on generating emotional music. This paper presents EmotionBox -an music-element-driven emotional music generator that is capable of composing music given a specific emotion, where this model does not require a music dataset labeled with emotions. Instead, pitch histogram and note density are extracted as features that represent mode and tempo respectively to control music emotions. The subjective listening tests show that the Emotionbox has a more <font color="#960096">competitive</font> and balanced performance in arousing a specified emotion than the emotion-label-based method. </br></br>

<a href='http://arxiv.org/pdf/2112.08211.pdf'>2112.08211</a> &nbsp&nbsp (stat:ML, cs:AI, cs:ML) &nbsp&nbsp -1.6368баллов, №1261</br>
<b>TrialGraph: Machine Intelligence Enabled Insight from Graph Modelling of\n  <font color="#be00be">Clinic</font>al Trials</b></br>
Authors: , Yacoumatos, Christopher, Bragaglia, Stefano, Kanakia, Anshul, Svang&#xe5;rd, Nils, Mangion, Jonathan, Donoghue, Claire, Weatherall, Jim, Khan, Faisal M., Shameer, Khader</br>
  A major impediment to successful <font color="#00be00">drug</font> development is the complexity, cost, and scale of <font color="#be00be">clinic</font>al trials. The detailed internal structure of clinical trial data can make conventional optimization difficult to achieve. Recent advances in machine learning, specifically graph-structured data analysis, have the potential to enable significant progress in improving the clinical trial design. TrialGraph seeks to apply these methodologies to produce a proof-of-concept framework for developing models which can aid drug development and benefit <font color="#be00be">patient</font>s. In this work, we first introduce a curated clinical trial data set compiled from the CT.gov, AACT and TrialTrove databases (n=1191 trials; representing one million patients) and describe the conversion of this data to graph-structured formats. We then detail the mathematical basis and implementation of a selection of graph machine learning algorithms, which typically use standard machine classifiers on graph data embedded in a low-dimensional feature space. We trained these models to predict side effect information for a clinical trial given information on the <font color="#be00be">diseas</font>e, existing <font color="#640064">medic</font>al conditions, and treatment. The MetaPath2Vec algorithm performed exceptionally well, with standard Logistic <font color="#be00be">Regression</font>, Decision Tree, <font color="#be00be">Random Forest</font>, Support Vector, and Neural Network classifiers exhibiting typical ROC-AUC scores of 0.85, 0.68, 0.86, 0.80, and 0.77, respectively. Remarkably, the best performing classifiers could only produce typical ROC-AUC scores of 0.70 when trained on equivalent array-structured data. Our work demonstrates that graph modelling can significantly improve prediction accuracy on appropriate datasets. Successive versions of the project that refine modelling assumptions and incorporate more data types can produce excellent predictors with <font color="#009600">real-world</font> applications in drug development. </br></br>

<a href='http://arxiv.org/pdf/2112.08789.pdf'>2112.08789</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -1.6372баллов, №1262</br>
<b>Harnessing Cross-lingual Features to Improve Cognate Detection for\n  <font color="#be00be">Low-resource</font> Languages</b></br>
Authors: , Kanojia, Diptesh, Dabre, Raj, Dewangan, Shubham, Bhattacharyya, Pushpak, Haffari, Gholamreza, Kulkarni, Malhar</br>
  Cognates are variants of the same lexical form across different languages; for example \'fonema\' in Spanish and \'phoneme\' in English are cognates, both of which mean \'a unit of sound\'. The task of automatic detection of cognates among any two languages can help downstream NLP tasks such as Cross-lingual Information <font color="#be00be">Retrieval</font>, Computational Phylogenetics, and Machine Translation. In this paper, we demonstrate the use of cross-lingual word embeddings for detecting cognates among fourteen Indian Languages. Our approach introduces the use of context from a <font color="#960096">knowledge graph</font> to generate improved feature representations for cognate detection. We, then, evaluate the impact of our cognate detection mechanism on neural machine translation (NMT), as a downstream task. We evaluate our methods to detect cognates on a challenging dataset of twelve Indian languages, namely, Sanskrit, <font color="#be00be">Hindi</font>, Assamese, Oriya, Kannada, Gujarati, Tamil, Telugu, Punjabi, <font color="#be00be">Bengali</font>, Marathi, and Malayalam. Additionally, we create evaluation datasets for two more Indian languages, Konkani and Nepali. We observe an improvement of up to 18% points, in terms of F-score, for cognate detection. Furthermore, we observe that cognates extracted using our method help improve NMT quality by up to 2.76 BLEU. We also release our code, newly constructed datasets and cross-lingual models publicly. </br></br>

<a href='http://arxiv.org/pdf/2111.09248.pdf'>2111.09248</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -1.6520баллов, №1263</br>
<b>Secure <font color="#be00be">Federated</font> Learning for Residential Short Term Load Forecasting</b></br>
Authors: , Fernandez, Joaquin Delgado, Menci, Sergio Potenciano, Lee, Charles, Fridgen, Gilbert</br>
  The inclusion of intermittent and renewable energy sources has increased the importance of demand forecasting in power systems. Smart meters can play a critical role in demand forecasting due to the measurement granularity they provide. Despite their virtue, smart meters used for forecasting<font color="#be00be"> face </font>some constraints as consumers\' <font color="#be00be">privacy</font> concerns, reluctance of utilities and vendors to share data with competitors or third parties, and regulatory constraints. This paper examines a collaborative machine learning method, <font color="#be00be">federated</font> learning extended with privacy preserving techniques for short-term demand forecasting using smart meter data as a solution to the previous constraints. The combination of privacy preserving techniques and federated learning enables to ensure consumers\' confidentiality concerning both their data, the models generated using it (Differential Privacy), and the communication mean (Secure Aggregation). To evaluate this paper\'s collaborative secure federated learning setting, we explore current literature to select the baseline for our simulations and evaluation. We simulate and evaluate several scenarios that explore how traditional centralized approaches could be projected in the direction of a decentralized, collaborative and <font color="#be00be">private</font> system. The results obtained over the evaluations provided decent performance and in a privacy setting using differential privacy almost perfect privacy budgets (1.39,$10e^{-5}$) and (2.01,$10e^{-5}$) with a negligible performance compromise. </br></br>

<a href='http://arxiv.org/pdf/2112.07252.pdf'>2112.07252</a> &nbsp&nbsp (cs:AI) &nbsp&nbsp -1.6721баллов, №1264</br>
<b>A Deep Knowledge Distillation framework for<font color="#be00be"> EEG </font>assisted enhancement of\n  single-lead <font color="#be00be">ECG</font> based sleep staging</b></br>
Authors: , Joshi, Vaibhav, Vijayarangan, Sricharan, SP, Preejith, Sivaprakasam, Mohanasankar</br>
  Automatic Sleep Staging study is presently done with the help of Electroencephalogram (EEG) signals. Recently, Deep Learning (DL) based approaches have enabled significant progress in this area, allowing for near-human accuracy in automated sleep staging. However,<font color="#be00be"> EEG </font>based sleep staging requires an extensive as well as an expensive <font color="#be00be">clinic</font>al setup. Moreover, the requirement of an expert for setup and the added inconvenience to the subject under study renders it unfavourable in a point of care context. Electrocardiogram (<font color="#be00be">ECG</font>), an unobtrusive alternative to EEG, is more suitable, but its performance, un<font color="#00be00">surprisin</font>gly, remains sub-par compared to EEG-based sleep staging. Naturally, it would be helpful to transfer knowledge from EEG to ECG, ultimately enhancing the model\'s performance on ECG based inputs. Knowledge Distillation (KD) is a renowned concept in DL that looks to transfer knowledge from a better but potentially more cumbersome teacher model to a compact student model. Building on this concept, we propose a cross-modal KD framework to improve ECG-based sleep staging performance with assistance from features learned through models trained on EEG. Additionally, we also conducted multiple experiments on the individual components of the proposed model to get better insight into the distillation approach. Data of 200 subjects from the Montreal Archive of Sleep Studies (MASS) was utilized for our study. The proposed model showed a 14.3\\% and 13.4\\% increase in weighted-F1-score in 4-class and 3-class sleep staging, respectively. This demonstrates the viability of KD for performance improvement of single-channel ECG based sleep staging in 4-class(W-L-D-R) and 3-class(W-N-R) classification. </br></br>

<a href='http://arxiv.org/pdf/2112.06310.pdf'>2112.06310</a> &nbsp&nbsp (cs:CL) &nbsp&nbsp -1.6736баллов, №1265</br>
<b>Reading Task Classification Using<font color="#be00be"> EEG </font>and Eye-<font color="#be00be">Tracking</font> Data</b></br>
Authors: , Hollenstein, Nora, Tr&#xf6;ndle, Marius, Plomecka, Martyna, Kiegeland, Samuel, &#xd6;zyurt, Yilmazcan, J&#xe4;ger, Lena A., Langer, Nicolas</br>
  The Zurich Cognitive Language Processing Corpus (ZuCo) provides eye-<font color="#be00be">tracking</font> and<font color="#be00be"> EEG </font>signals from two reading paradigms, normal reading and task-specific reading. We analyze whether machine learning methods are able to classify these two tasks using eye-tracking and EEG features. We implement models with aggregated sentence-level features as well as fine-grained word-level features. We test the models in within-subject and cross-subject evaluation scenarios. All models are tested on the ZuCo 1.0 and ZuCo 2.0 data subsets, which are characterized by differing recording procedures and thus allow for different levels of generalizability. Finally, we provide a series of control experiments to analyze the results in more detail. </br></br>

<a href='http://arxiv.org/pdf/2112.08968.pdf'>2112.08968</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.6833баллов, №1266</br>
<b>Automated <font color="#be00be">segmentation</font> of 3-D body composition on computed <font color="#be00be">tomography</font></b></br>
Authors: , Pu, Lucy, Ashraf, Syed F., Gezer, Naciye S, Ocak, Iclal, Dhupar, Rajeev</br>
  Purpose: To develop and validate a computer tool for automatic and simultaneous <font color="#be00be">segmentation</font> of body composition depicted on computed <font color="#be00be">tomography</font> (CT) scans for the following tissues: visceral adipose (VAT), subcutaneous adipose (SAT), intermuscular adipose (IMAT), skeletal muscle (SM), and bone.   Approach: A cohort of 100 CT scans acquired from The <font color="#be00be">Cancer</font> Imaging Archive (TCIA) was used - 50 whole-body positron emission tomography (PET)-CTs, 25 chest, and 25 abdominal. Five different body compositions were manually annotated (VAT, SAT, IMAT, SM, and bone). A training-while-annotating strategy was used for efficiency. The UNet model was trained using the already annotated cases. Then, this model was used to enable semi-automatic annotation for the remaining cases. The 10-fold cross-validation method was used to develop and validate the performance of several convolutional neural networks (CNNs), including UNet, Recurrent Residual UNet (R2Unet), and UNet++. A 3-D patch sampling operation was used when training the CNN models. The separately trained CNN models were tested to see if they could achieve a better performance than segmenting them jointly. Paired-samples t-test was used to test for statistical significance.   Results: Among the three CNN models, UNet demonstrated the best overall performance in jointly segmenting the five body compositions with a Dice coefficient of 0.840+/-0.091, 0.908+/-0.067, 0.603+/-0.084, 0.889+/-0.027, and 0.884+/-0.031, and a Jaccard index of 0.734+/-0.119, 0.837+/-0.096, 0.437+/-0.082, 0.800+/-0.042, 0.793+/-0.049, respectively for VAT, SAT, IMAT, SM, and bone.   Conclusion: There were no significant differences among the CNN models in segmenting body composition, but jointly segmenting body compositions achieved a better performance than segmenting them separately. </br></br>

<a href='http://arxiv.org/pdf/2112.06292.pdf'>2112.06292</a> &nbsp&nbsp (cs:AI, cs:ML) &nbsp&nbsp -1.6875баллов, №1267</br>
<b>Gamifying optimization: a Wasserstein distance-based analysis of human\n  search</b></br>
Authors: , Candelieri, Antonio, Ponti, Andrea, Archetti, Francesco</br>
  The main objective of this paper is to outline a <font color="#be00be">theor</font>etical framework to characterise humans\' decision-making strategies under uncertainty, in particular active learning in a black-box optimization task and trading-off between information gathering (exploration) and reward seeking (exploitation). Humans\' decisions making according to these two objectives can be modelled in terms of Pareto rationality. If a decision set contains a Pareto efficient strategy, a rational decision maker should always select the dominant strategy over its dominated alternatives. A distance from the Pareto frontier determines whether a choice is Pareto rational. To collect data about humans\' strategies we have used a gaming application that shows the game field, with previous decisions and observations, as well as the score obtained. The key element in this paper is the representation of behavioural patterns of human learners as a discrete probability distribution. This maps the problem of the characterization of humans\' behaviour into a space whose elements are probability distributions structured by a distance between histograms, namely the Wasserstein distance (WST). The distributional analysis gives new insights about human search strategies and their deviations from Pareto rationality. Since the uncertainty is one of the two objectives defining the Pareto frontier, the analysis has been performed for three different uncertainty quantification measures to identify which better explains the Pareto compliant behavioural patterns. Beside the analysis of individual patterns WST has also enabled a global analysis computing the barycenters and WST <font color="#be00be">k-mean</font>s <font color="#be00be">clustering</font>. A further analysis has been performed by a decision tree to relate non-Paretian behaviour, characterized by exasperated exploitation, to the dynamics of the evolution of the reward seeking process. </br></br>

<a href='http://arxiv.org/pdf/2112.06261.pdf'>2112.06261</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.6941баллов, №1268</br>
<b>Hidden Effects of COVID-19 on Healthcare Workers: A Machine Learning\n  Analysis</b></br>
Authors: , Rezapour, Mostafa</br>
  In this paper, we analyze some effects of the COVID-19 pandemic on healthcare workers. We specifically focus on alcohol consumption habit changes among healthcare workers using a mental health survey data obtained from the University of Michigan Inter-University Consortium for Political and Social Research. We use supervised and unsupervised machine learning methods and models such as Decision Trees, Logistic <font color="#be00be">Regression</font>, Naive <font color="#be00be">Bayes</font> classifier, k-<font color="#be00be">Nearest Neighbo</font>rs, Support Vector Machines, Multilayer perceptron, <font color="#be00be">Random Forest</font>s, XGBoost, CatBoost, LightGBM, Synthetic Minority Oversampling, Chi-Squared Test and mutual information method to find out relationships between COVID-19 related negative effects and alcohol use changes in healthcare workers. Our findings suggest that some effects of the COVID-19 pandemic such as school closure, work schedule change and COVID-related news exposure may lead to an increase in alcohol use. </br></br>

<a href='http://arxiv.org/pdf/2112.06196.pdf'>2112.06196</a> &nbsp&nbsp (cs:CL, cs:AI) &nbsp&nbsp -1.6984баллов, №1269</br>
<b>Predicting Above-Sentence Discourse Structure using Distant Supervision\n  from Topic <font color="#be00be">Segmentation</font></b></br>
Authors: , Huber, Patrick, Xing, Linzi, Carenini, Giuseppe</br>
  RST-<font color="#be00be">style</font> discourse <font color="#be00be">parsing</font> plays a vital role in many NLP tasks, revealing the underlying semantic/pragmatic structure of potentially complex and diverse documents. Despite its importance, one of the most prevailing limitations in modern day discourse parsing is the lack of large-scale datasets. To overcome the data sparsity issue, distantly supervised approaches from tasks like <font color="#be00be">sentiment</font> analysis and <font color="#be00be">summarization</font> have been recently proposed. Here, we extend this line of research by exploiting distant supervision from topic <font color="#be00be">segmentation</font>, which can arguably provide a strong and oftentimes complementary signal for high-level discourse structures. Experiments on two human-annotated discourse treebanks confirm that our proposal generates accurate tree structures on sentence and paragraph level, consistently <font color="#00be00">outperform</font>ing previous distantly supervised models on the sentence-to-document task and occasionally reaching even higher scores on the sentence-to-paragraph level. </br></br>

<a href='http://arxiv.org/pdf/2112.07879.pdf'>2112.07879</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.7113баллов, №1270</br>
<b>Does a<font color="#be00be"> Face </font>Mask Protect my <font color="#be00be">Privacy</font>?: Deep Learning to Predict Protected\n  Attributes from Masked Face Images</b></br>
Authors: , Seneviratne, Sachith, Kasthuriarachchi, Nuran, Rasnayaka, Sanka, Hettiachchi, Danula, Shariffdeen, Ridwan</br>
  Contactless and efficient systems are implemented rapidly to advocate preventive methods in the fight against the COVID-19 pandemic. Despite the positive benefits of such systems, there is potential for exploitation by invading user <font color="#be00be">privacy</font>. In this work, we analyse the privacy invasiveness of<font color="#be00be"> face </font>biometric systems by predicting privacy-sensitive soft-biometrics using masked face images. We train and apply a CNN based on the ResNet-50 architecture with 20,003 synthetic masked images and measure the privacy invasiveness. Despite the popular belief of the privacy benefits of wearing a mask among people, we show that there is no significant difference to privacy invasiveness when a mask is worn. In our experiments we were able to accurately predict sex (94.7%),race (83.1%) and age (MAE 6.21 and RMSE 8.33) from masked face images. Our proposed approach can serve as a baseline utility to evaluate the privacy-invasiveness of artificial intelligence systems that make use of privacy-sensitive information. We open-source all contributions for re-producibility and broader use by the research community. </br></br>

<a href='http://arxiv.org/pdf/2112.08075.pdf'>2112.08075</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.7118баллов, №1271</br>
<b>Fast characterization of inducible regions of atrial fibrillation models\n  with multi-fidelity <font color="#be00be">Gaussi</font>an process classification</b></br>
Authors: , Gander, Lia, Pezzuto, Simone, Gharaviri, Ali, Krause, Rolf, Perdikaris, Paris, Costabal, Francisco Sahli</br>
  Computational models of atrial fibrillation have successfully been used to predict optimal ablation sites. A critical step to assess the effect of an ablation pattern is to pace the model from different, potentially random, locations to determine whether arrhythmias can be induced in the atria. In this work, we propose to use multi-fidelity <font color="#be00be">Gaussi</font>an process classification on Riemannian manifolds to efficiently determine the regions in the atria where arrhythmias are inducible. We build a probabilistic classifier that operates directly on the atrial surface. We take advantage of lower resolution models to explore the atrial surface and combine seamlessly with high-resolution models to identify regions of inducibility. When trained with 40 samples, our multi-fidelity classifier shows a balanced accuracy that is 10% higher than a <font color="#be00be">nearest neighbo</font>r classifier used as a baseline atrial fibrillation model, and 9% higher in presence of atrial fibrillation with ablations. We hope that this new technique will allow faster and more precise <font color="#be00be">clinic</font>al applications of computational models for atrial fibrillation. </br></br>

<a href='http://arxiv.org/pdf/2112.07192.pdf'>2112.07192</a> &nbsp&nbsp (cs:SD) &nbsp&nbsp -1.7238баллов, №1272</br>
<b>Cross-modal<font color="#be00be"> Music </font><font color="#be00be">Emotion</font> Recognition Using Composite Loss-based\n  Embeddings</b></br>
Authors: , Takashima, Naoki, Li, Fr&#xe9;d&#xe9;ric, Grzegorzek, Marcin, Shirahama, Kimiaki</br>
  Most<font color="#be00be"> music </font><font color="#be00be">emotion</font> recognition approaches use one-way classification or <font color="#be00be">regression</font> that estimates a general emotion from a distribution of music samples, but without considering emotional variations (e.g., happiness can be further categorised into much, moderate or little happiness). We propose a cross-modal music emotion recognition approach that associates music samples with emotions in a common space by considering both of their general and specific characteristics. Since the association of music samples with emotions is uncertain due to subjective human perceptions, we compute composite loss-based embeddings obtained to maximise two statistical characteristics, one being the correlation between music samples and emotions based on canonical correlation analysis, and the other being a probabilistic similarity between a music sample and an emotion with KL-divergence. Experiments on two benchmark datasets demonstrate the superiority of our approach over one-way baselines. In addition, detailed analysis show that our approach can accomplish robust cross-modal music emotion recognition that not only identifies music samples matching with a specific emotion but also detects emotions expressed in a certain music sample. </br></br>

<a href='http://arxiv.org/pdf/2112.06459.pdf'>2112.06459</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.7301баллов, №1273</br>
<b>Machine Learning-Based Heart <font color="#be00be">Diseas</font>e <font color="#be00be">Diagnos</font>is: A Systematic Literature\n  Review</b></br>
Authors: , Ahsan, Md Manjurul, Siddique, Zahed</br>
  Heart <font color="#be00be">diseas</font>e is one of the significant challenges in today\'s world and one of the leading causes of many deaths worldwide. Recent advancement of machine learning (ML) application demonstrates that using electrocardiogram (<font color="#be00be">ECG</font>) and <font color="#be00be">patient</font> data, detecting heart disease during the early stage is feasible. However, both ECG and patient data are often imbalanced, which ultimately raises a challenge for the traditional ML to perform unbiasedly. Over the years, several data level and algorithm level solutions have been exposed by many researchers and practitioners. To provide a broader view of the existing literature, this study takes a systematic literature review (SLR) approach to uncover the challenges associated with imbalanced data in heart diseases predictions. Before that, we conducted a meta-analysis using 451 referenced literature acquired from the reputed journals between 2012 and November 15, 2021. For in-depth analysis, 49 referenced literature has been considered and studied, taking into account the following factors: heart disease type, algorithms, applications, and solutions. Our SLR study revealed that the current approaches encounter various open problems/issues when dealing with imbalanced data, eventually hindering their practical applicability and functionality. </br></br>

<a href='http://arxiv.org/pdf/2111.10776.pdf'>2111.10776</a> &nbsp&nbsp (cs:CL, cs:ML) &nbsp&nbsp -1.7523баллов, №1274</br>
<b>Is Speech <font color="#be00be">Emotion</font> Recognition Language-Independent? Analysis of English\n  and Bangla Languages using Language-Independent Vocal Features</b></br>
Authors: , Saad, Fardin, Mahmud, Hasan, Shaheen, Md. Alamin, Hasan, Md. Kamrul, Farastu, Paresha, Kabir, Mohammad Ridwan</br>
  A language agnostic approach to recognizing <font color="#be00be">emotion</font>s from speech remains an incomplete and challenging task. In this paper, we used Bangla and English languages to assess whether distinguishing emotions from speech is independent of language. The following emotions were categorized for this study: happiness, anger, neutral, sadness, disgust, and fear. We employed three Emotional Speech Sets, of which the first two were developed by native <font color="#be00be">Bengali</font> speakers from the Islamic University of Technology in Bangla and English languages separately. The third was the Toronto Emotional Speech Set (TESS), which was developed by native English speakers from Canada. We carefully selected language-independent prosodic features, adopted a Support Vector Machine (<font color="#be00be">SVM</font>) model, and conducted three experiments to carry out our proposition. In the first experiment, we measured the performance of the three speech sets individually. This was followed by the second experiment, where we recorded the classification rate by combining the speech sets. Finally, in the third experiment we measured the recognition rate by training and testing the model with different speech sets. Although this study reveals that Speech Emotion Recognition (SER) is mostly language-independent, there is some disparity while recognizing emotional states like disgust and fear in these two languages. Moreover, our investigations inferred that non-native speakers convey emotions through speech, much like expressing themselves in their native tongue. </br></br>

<a href='http://arxiv.org/pdf/2112.06024.pdf'>2112.06024</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.7817баллов, №1275</br>
<b>Optimization of Residual Convolutional Neural Network for\n  Electrocardiogram Classification</b></br>
Authors: , Fki, Zeineb, Ammar, Boudour, Ayed, Mounir Ben</br>
  The <font color="#be00be">interpret</font>ation of the electrocardiogram (<font color="#be00be">ECG</font>) gives <font color="#be00be">clinic</font>al information and helps in the assessing of the heart function. There are distinct ECG patterns associated with a specific class of arrythmia. The convolutional neural network is actually one of the most applied deep learning algorithms in ECG processing. However, with deep learning models there are many more hyperparameters to tune. Selecting an optimum or best hyperparameter for the convolutional neural network algorithm is challenging. Often, we end up tuning the model manually with different possible range of values until a best fit model is obtained. Automatic hyperparameters tuning using <font color="#be00be">Bayes</font>ian optimization (BO) and evolutionary algorithms brings a solution to the harbor manual configuration. In this paper, we propose to optimize the Recurrent one Dimensional Convolutional Neural Network model (R-1D-CNN) with two levels. At the first level, a residual convolutional layer and one-dimensional convolutional neural layers are trained to learn <font color="#be00be">patient</font>-specific ECG features over which the multilayer perceptron layers can learn to produce the final class vectors of each input. This level is manual and aims to lower the search space. The second level is automatic and based on proposed algorithm based BO. Our proposed optimized R-1D-CNN architecture is evaluated on two <font color="#00be00">publicly available</font> ECG Datasets. The experimental results display that the proposed algorithm based BO achieves an optimum rate of 99.95\\%, while the baseline model achieves 99.70\\% for the MIT-BIH database. Moreover, experiments demonstrate that the proposed architecture fine-tuned with BO achieves a higher accuracy than the other proposed architectures. Our architecture achieves a good result compared to previous works and based on different experiments. </br></br>

<a href='http://arxiv.org/pdf/2112.06211.pdf'>2112.06211</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.7896баллов, №1276</br>
<b>Quantum <font color="#be00be">kernel</font>s for <font color="#009600">real-world</font> predictions based on electronic health\n  records</b></br>
Authors: , Krunic, Zoran, Fl&#xf6;ther, Frederik F., Seegan, George, Earnest-Noble, Nathan, Shehab, Omar</br>
  In recent years, research on near-term quantum machine learning has explored how classical machine learning algorithms endowed with access to quantum <font color="#be00be">kernel</font>s (similarity measures) can <font color="#00be00">outperform</font> their purely classical counterparts. Although <font color="#be00be">theor</font>etical work has shown provable advantage on synthetic data sets, no work done to date has studied empirically whether quantum advantage is attainable and with what kind of data set. In this paper, we report the first systematic investigation of empirical quantum advantage (EQA) in healthcare and life sciences and propose an end-to-end framework to study EQA. We selected electronic health records (EHRs) data subsets and created a configuration space of 5-20 features and 200-300 training samples. For each configuration coordinate, we trained classical support vector machine (<font color="#be00be">SVM</font>) models based on radial basis function (RBF) kernels and quantum models with custom kernels using an IBM quantum computer. We empirically identified regimes where quantum kernels could provide advantage on a particular data set and introduced a terrain ruggedness index, a metric to help quantitatively estimate how the accuracy of a given model will perform as a function of the number of features and sample size. The generalizable framework introduced here represents a key step towards a priori identification of data sets where quantum advantage could exist. </br></br>

<a href='http://arxiv.org/pdf/2112.06283.pdf'>2112.06283</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.7907баллов, №1277</br>
<b><font color="#be00be">Bayes</font>ian Persuasion for Algorithmic Recourse</b></br>
Authors: , Harris, Keegan, Chen, Valerie, Kim, Joon Sik, Talwalkar, Ameet, Heidari, Hoda, Wu, Zhiwei Steven</br>
  When subjected to automated decision-making, decision-subjects will strategically modify their observable features in ways they believe will maximize their chances of receiving a desirable outcome. In many situations, the underlying predictive model is deliberately kept secret to avoid gaming and maintain <font color="#960096">competitive</font> advantage. This opacity forces the decision subjects to rely on incomplete information when making strategic feature modifications. We capture such settings as a game of <font color="#be00be">Bayes</font>ian persuasion, in which the decision-maker sends a signal, e.g., an action <font color="#be00be">recommendat</font>ion, to a decision subject to incentivize them to take desirable actions. We formulate the decision-maker\'s problem of finding the optimal Bayesian incentive-compatible (BIC) action recommendation policy as an optimization problem and characterize the solution via a linear program. Through this characterization, we observe that while the problem of finding the optimal BIC recommendation policy can be simplified dramatically, the computational complexity of solving this linear program is closely tied to (1) the relative size of the decision-subjects\' action space, and (2) the number of features utilized by the underlying predictive model. Finally, we provide bounds on the performance of the optimal BIC recommendation policy and show that it can lead to arbitrarily better outcomes compared to standard baselines. </br></br>

<a href='http://arxiv.org/pdf/2112.06891.pdf'>2112.06891</a> &nbsp&nbsp (cs:ML, cs:NE) &nbsp&nbsp -1.8025баллов, №1278</br>
<b><font color="#be00be">Interpret</font>able Design of <font color="#be00be">Reservoir</font> Computing Networks using Realization\n  <font color="#be00be">Theor</font>y</b></br>
Authors: , Miao, Wei, Narayanan, Vignesh, Li, Jr-Shin</br>
  The <font color="#be00be">reservoir</font> computing networks (RCNs) have been successfully employed as a tool in learning and complex decision-making tasks. Despite their efficiency and low training cost, practical applications of RCNs rely heavily on empirical design. In this paper, we develop an algorithm to design RCNs using the realization <font color="#be00be">theor</font>y of linear dynamical systems. In particular, we introduce the notion of $\\alpha$-stable realization, and provide an efficient approach to prune the size of a linear RCN without deteriorating the training accuracy. Furthermore, we derive a necessary and sufficient condition on the irreducibility of number of hidden nodes in linear RCNs based on the concepts of controllability and observability matrices. Leveraging the linear RCN design, we provide a tractable procedure to realize RCNs with nonlinear activation functions. Finally, we present numerical experiments on forecasting time-delay systems and chaotic systems to validate the proposed RCN design methods and demonstrate their efficacy. </br></br>

<a href='http://arxiv.org/pdf/2112.05410.pdf'>2112.05410</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.8088баллов, №1279</br>
<b>Multimedia Datasets for <font color="#be00be">Anomal</font>y Detection: A Survey</b></br>
Authors: , Kumari, Pratibha, Bedi, Anterpreet Kaur, Saini, Mukesh</br>
  Multimedia <font color="#be00be">anomal</font>y datasets play a crucial role in automated <font color="#be00be">surveillance</font>. They have a wide range of applications expanding from <font color="#be00be">outlier</font> object/ situation detection to the detection of life-threatening events. This field is receiving a huge level of research interest for more than 1.5 decades, and consequently, more and more datasets dedicated to anomalous actions and <font color="#be00be">object detection</font> have been created. Tapping these public anomaly datasets enable researchers to generate and compare various anomaly detection frameworks with the same input data. This paper presents a comprehensive survey on a variety of video, audio, as well as audio-visual datasets based on the application of anomaly detection. This survey aims to address the lack of a comprehensive comparison and analysis of multimedia public datasets based on anomaly detection. Also, it can assist researchers in selecting the best available dataset for bench-marking frameworks. Additionally, we discuss gaps in the existing dataset and future direction insights towards developing multimodal anomaly detection datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.05451.pdf'>2112.05451</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.8110баллов, №1280</br>
<b>Structure-Preserving Learning Using <font color="#be00be">Gaussi</font>an Processes and Variational\n  Integrators</b></br>
Authors: , Br&#xfc;digam, Jan, Schuck, Martin, Capone, Alexandre, Sosnowski, Stefan, Hirche, Sandra</br>
  <font color="#be00be">Gaussi</font>an process <font color="#be00be">regression</font> is often applied for learning unknown systems and specifying the uncertainty of the learned model. When using Gaussian process regression to learn unknown systems, a commonly considered approach consists of learning the residual dynamics after applying some standard discretization, which might however not be appropriate for the system at hand. Variational integrators are a less common yet promising approach to discretization, as they retain physical properties of the underlying system, such as energy conservation or satisfaction of explicit constraints. In this work, we propose the combination of a variational integrator for the nominal dynamics of a mechanical system and learning residual dynamics with Gaussian process regression. We extend our approach to systems with known kinematic constraints and provide formal bounds on the prediction uncertainty. The simulative evaluation of the proposed method shows desirable energy conservation properties in accordance with the <font color="#be00be">theor</font>etical results and demonstrates the capability of treating constrained dynamical systems. </br></br>

<a href='http://arxiv.org/pdf/2112.05322.pdf'>2112.05322</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.8137баллов, №1281</br>
<b>Dynamic hardware system for cascade <font color="#be00be">SVM</font> classification of melanoma</b></br>
Authors: , Afifi, Shereen, GholamHosseini, Hamid, Sinha, Roopak</br>
  Melanoma is the most dangerous form of skin <font color="#be00be">cancer</font>, which is responsible for the majority of skin cancer-related deaths. Early <font color="#be00be">diagnos</font>is of melanoma can significantly reduce mortality rates and treatment costs. Therefore, skin cancer specialists are using image-based diagnostic tools for detecting melanoma earlier. We aim to develop a handheld device featured with low cost and high performance to enhance early detection of melanoma at the primary healthcare. But, developing this device is very challenging due to the complicated computations required by the embedded diagnosis system. Thus, we aim to exploit the recent hardware technology in reconfigurable computing to achieve a high-performance embedded system at low cost. Support vector machine (<font color="#be00be">SVM</font>) is a common classifier that shows high accuracy for classifying melanoma within the diagnosis system and is considered as the most compute-intensive task in the system. In this paper, we propose a dynamic hardware system for implementing a cascade SVM classifier on <font color="#be00be">FPGA</font> for early melanoma detection. A multi-core architecture is proposed to implement a two-stage cascade classifier using two classifiers with accuracies of 98% and 73%. The hardware implementation results were optimized by using the dynamic partial reconfiguration technology, where very low resource utilization of 1% slices and power consumption of 1.5 W were achieved. Consequently, the implemented dynamic hardware system meets vital embedded system constraints of high performance and low cost, resource utilization, and power consumption, while achieving efficient classification with high accuracy. </br></br>

<a href='http://arxiv.org/pdf/2112.09074.pdf'>2112.09074</a> &nbsp&nbsp (cs:RO) &nbsp&nbsp -1.8162баллов, №1282</br>
<b>Influence of <font color="#be00be">Pedestrian</font> Collision Warning Systems on Driver Behavior: A\n  Driving Simulator Study</b></br>
Authors: , Banerjee, Snehanshu, Jeihani, Mansoureh, Khadem, Nashid K, Kabir, Md. Muhib</br>
  With the advent of connected and automated vehicle (CAV) technology, there is an increasing need to evaluate driver behavior while using such technology. In this first of a kind study, a <font color="#be00be">pedestrian</font> collision warning (PCW) system using CAV technology, was introduced in a driving simulator environment, to evaluate driver braking behavior, in the presence of a jaywalking pedestrian. A total of 93 participants from diverse socio-<font color="#be00be">economic</font> backgrounds were recruited for this study, for which a virtual network of downtown Baltimore was created. An eye <font color="#be00be">tracking</font> device was also used to observe distractions and head movements. A Log logistic accelerated failure time (AFT) distribution model was used for this analysis, to calculate speed reduction times; time from the moment the pedestrian becomes visible, to the point where a minimum speed was reached, to allow the pedestrian to pass. The presence of the PCW system significantly impacted the speed reduction time and deceleration rate, as it increased the former and reduced the latter, which proves the effectiveness of this system in providing an effective driving maneuver, by drastically reducing speed. A jerk analysis is conducted to analyze the suddenness of braking and acceleration. Gaze analysis showed that the system was able to attract the attention of the drivers, as the majority of the drivers noticed the displayed warning. The familiarity of the driver with the route and connected vehicles reduces the speed reduction time; gender also can have a significant impact as males tend to have longer speed reduction time, i.e. more time to comfortably brake and allow the pedestrian to pass. </br></br>

<a href='http://arxiv.org/pdf/2112.06194.pdf'>2112.06194</a> &nbsp&nbsp (cs:AI, cs:CV) &nbsp&nbsp -1.8251баллов, №1283</br>
<b>Improving Performance of <font color="#be00be">Federated</font> Learning based <font color="#640064">Medic</font>al Image Analysis\n  in Non-IID Settings using Image Augmentation</b></br>
Authors: , Cetinkaya, Alper Emin, Akin, Murat, Sagiroglu, Seref</br>
  <font color="#be00be">Federated</font> Learning (FL) is a suitable solution for making use of sensitive data belonging to <font color="#be00be">patient</font>s, people, companies, or industries that are obligatory to work under rigid <font color="#be00be">privacy</font> constraints. FL mainly or partially supports data privacy and security issues and provides an alternative to model problems facilitating multiple edge devices or organizations to contribute a training of a global model using a number of local data without having them. Non-IID data of FL caused from its distributed nature presents a significant performance degradation and stabilization skews. This paper introduces a novel method dynamically balancing the data distributions of clients by augmenting images to address the non-IID data problem of FL. The introduced method remarkably stabilizes the model training and improves the model\'s test accuracy from 83.22% to 89.43% for multi-chest <font color="#be00be">diseas</font>es detection of chest X-ray images in highly non-IID FL setting. The results of IID, non-IID and non-IID with proposed method federated trainings demonstrated that the proposed method might help to encourage organizations or researchers in developing better systems to get values from data with respect to data privacy not only for healthcare but also other fields. </br></br>

<a href='http://arxiv.org/pdf/2112.06580.pdf'>2112.06580</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -1.8509баллов, №1284</br>
<b>How to Find a Good Explanation for <font color="#be00be">Clustering</font>?</b></br>
Authors: , Bandyapadhyay, Sayan, Fomin, Fedor V., Golovach, Petr A., Lochet, William, Purohit, Nidhi, Simonov, Kirill</br>
  $k$-means and $k$-median <font color="#be00be">clustering</font> are powerful unsupervised machine learning techniques. However, due to complicated dependences on all the features, it is challenging to <font color="#be00be">interpret</font> the resulting cluster assignments. Moshkovitz, Dasgupta, Rashtchian, and Frost [ICML 2020] proposed an elegant model of explainable $k$-means and $k$-median clustering. In this model, a decision tree with $k$ leaves provides a straightforward characterization of the data set into clusters.   We study two natural algorithmic questions about explainable clustering. (1) For a given clustering, how to find the &quot;best explanation&quot; by using a decision tree with $k$ leaves? (2) For a given set of points, how to find a decision tree with $k$ leaves minimizing the $k$-means/median objective of the resulting explainable clustering? To address the first question, we introduce a new model of explainable clustering. Our model, inspired by the notion of <font color="#be00be">outlier</font>s in robust statistics, is the following. We are seeking a small number of points (outliers) whose removal makes the existing clustering well-explainable. For addressing the second question, we initiate the study of the model of Moshkovitz et al. from the perspective of multivariate complexity. Our rigorous algorithmic analysis sheds some light on the influence of parameters like the input size, dimension of the data, the number of outliers, the number of clusters, and the approximation ratio, on the computational complexity of explainable clustering. </br></br>

<a href='http://arxiv.org/pdf/2112.08364.pdf'>2112.08364</a> &nbsp&nbsp (cs:ML, cs:AI) &nbsp&nbsp -1.8878баллов, №1285</br>
<b>Data Valuation for Vertical <font color="#be00be">Federated</font> Learning: An Information-<font color="#be00be">Theor</font>etic\n  Approach</b></br>
Authors: , Han, Xiao, Wang, Leye, Wu, Junjie</br>
  <font color="#be00be">Federated</font> learning (FL) is a promising machine learning paradigm that enables cross-party data collaboration for <font color="#009600">real-world</font> AI applications in a <font color="#be00be">privacy</font>-preserving and law-regulated way. How to valuate parties\' data is a critical but challenging FL issue. In the literature, data valuation either relies on running specific models for a given task or is just task irrelevant; however, it is often requisite for party selection given a specific task when FL models have not been determined yet. This work thus fills the gap and proposes \\emph{FedValue}, to our best knowledge, the first privacy-preserving, task-specific but model-free data valuation method for vertical FL tasks. Specifically, FedValue incorporates a novel information-<font color="#be00be">theor</font>etic metric termed Shapley-CMI to assess data values of multiple parties from a game-theoretic perspective. Moreover, a novel server-aided federated computation mechanism is designed to compute Shapley-CMI and meanwhile protects each party from data leakage. We also propose several techniques to accelerate Shapley-CMI computation in practice. Extensive experiments on six open datasets validate the effectiveness and efficiency of FedValue for data valuation of vertical FL tasks. In particular, Shapley-CMI as a model-free metric performs comparably with the measures that depend on running an ensemble of well-performing models. </br></br>

<a href='http://arxiv.org/pdf/2112.07116.pdf'>2112.07116</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.8908баллов, №1286</br>
<b>Joint 3D <font color="#be00be">Object Detection</font> and <font color="#be00be">Tracking</font> Using Spatio-Temporal\n  Representation of Camera Image and <font color="#be00be">LiDAR</font> <font color="#be00be">Point Cloud</font>s</b></br>
Authors: , Koh, Junho, Kim, Jaekyum, Yoo, Jinhyuk, Kim, Yecheol, Kum, Dongsuk, Choi, Jun Won</br>
  In this paper, we propose a new joint <font color="#be00be">object detection</font> and <font color="#be00be">tracking</font> (JoDT) framework for 3D object detection and tracking based on camera and <font color="#be00be">LiDAR</font> sensors. The proposed method, referred to as 3D DetecTrack, enables the detector and <font color="#be00be">tracker</font> to cooperate to generate a spatio-temporal representation of the camera and LiDAR data, with which 3D object detection and tracking are then performed. The detector constructs the spatio-temporal features via the weighted temporal aggregation of the spatial features obtained by the camera and LiDAR fusion. Then, the detector reconfigures the initial detection results using information from the tracklets maintained up to the previous time step. Based on the spatio-temporal features generated by the detector, the tracker associates the detected objects with previously tracked objects using a graph neural network (GNN). We devise a fully-connected GNN facilitated by a combination of rule-based edge pruning and attention-based edge gating, which exploits both spatial and temporal object contexts to improve tracking performance. The experiments conducted on both KITTI and nuScenes benchmarks demonstrate that the proposed 3D DetecTrack achieves significant improvements in both detection and tracking performances over baseline methods and achieves <font color="#00be00">state-of-the-art</font> performance among existing methods through collaboration between the detector and tracker. </br></br>

<a href='http://arxiv.org/pdf/2112.05863.pdf'>2112.05863</a> &nbsp&nbsp (cs:CL, cs:ML, cs:SD) &nbsp&nbsp -1.9096баллов, №1287</br>
<b>Directed <font color="#be00be">Speech Separation</font> for Automatic <font color="#be00be">Speech Recognition</font> of Long Form\n  Conversational Speech</b></br>
Authors: , Paturi, Rohit, Srinivasan, Sundararajan, Kirchhoff, Katrin</br>
  Many of the recent advances in <font color="#be00be">speech separation</font> are primarily aimed at synthetic mixtures of short audio utterances with high degrees of overlap. These datasets significantly differ from the real conversational data and hence, the models trained and evaluated on these datasets do not generalize to real conversational scenarios. Another issue with using most of these models for long form speech is the nondeterministic ordering of separated speech segments due to either unsupervised <font color="#be00be">clustering</font> for time-frequency masks or Permutation Invariant training (PIT) loss. This leads to difficulty in accurately stitching homogenous speaker segments for downstream tasks like Automatic <font color="#be00be">Speech Recognition</font> (ASR). In this paper, we propose a speaker conditioned separator trained on speaker embeddings extracted directly from the mixed signal. We train this model using a directed loss which regulates the order of the separated segments. With this model, we achieve significant improvements on Word error rate (WER) for real conversational data without the need for an additional re-stitching step. </br></br>

<a href='http://arxiv.org/pdf/2112.07334.pdf'>2112.07334</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -1.9189баллов, №1288</br>
<b>OMAD: Object Model with Articulated Deformations for <font color="#be00be">Pose Estimation</font> and\n  <font color="#be00be">Retrieval</font></b></br>
Authors: , Xue, Han, Liu, Liu, Xu, Wenqiang, Fu, Haoyuan, Lu, Cewu</br>
  Articulated objects are pervasive in daily life. However, due to the intrinsic high-DoF structure, the joint states of the articulated objects are hard to be estimated. To model articulated objects, two kinds of shape deformations namely the geometric and the pose deformation should be considered. In this work, we present a novel category-specific parametric representation called Object Model with Articulated Deformations (OMAD) to explicitly model the articulated objects. In OMAD, a category is associated with a linear shape function with shared shape basis and a non-linear joint function. Both functions can be learned from a large-scale object model dataset and fixed as category-specific priors. Then we propose an OMADNet to predict the shape parameters and the joint states from an object\'s single observation. With the full representation of the object shape and joint states, we can address several tasks including category-level object <font color="#be00be">pose estimation</font> and the articulated object <font color="#be00be">retrieval</font>. To evaluate these tasks, we create a synthetic dataset based on PartNet-Mobility. Extensive experiments show that our simple OMADNet can serve as a strong baseline for both tasks. </br></br>

<a href='http://arxiv.org/pdf/2112.01797.pdf'>2112.01797</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -1.9373баллов, №1289</br>
<b>Detection of Large Vessel Occlusions using Deep Learning by Deforming\n  Vessel Tree <font color="#be00be">Segmentation</font>s</b></br>
Authors: , Thamm, Florian, Taubmann, Oliver, J&#xfc;rgens, Markus, Ditt, Hendrik, Maier, Andreas</br>
  Computed <font color="#be00be">Tomography</font> Angiography is a key modality providing insights into the cerebrovascular vessel tree that are crucial for the <font color="#be00be">diagnos</font>is and treatment of ischemic strokes, in particular in cases of large vessel occlusions (LVO). Thus, the <font color="#be00be">clinic</font>al workflow greatly benefits from an automated detection of <font color="#be00be">patient</font>s suffering from LVOs. This work uses convolutional neural networks for case-level classification trained with elastic deformation of the vessel tree <font color="#be00be">segmentation</font> masks to artificially augment training data. Using only masks as the input to our model uniquely allows us to apply such deformations much more aggressively than one could with conventional image volumes while retaining sample realism. The neural network classifies the presence of an LVO and the affected hemisphere. In a 5-fold cross validated ablation study, we demonstrate that the use of the suggested augmentation enables us to train robust models even from few data sets. Training the EfficientNetB1 architecture on 100 data sets, the proposed augmentation scheme was able to raise the ROC AUC to 0.85 from a baseline value of 0.56 using no augmentation. The best performance was achieved using a 3D-DenseNet yielding an AUC of 0.87. The augmentation had positive impact in classification of the affected hemisphere as well, where the 3D-DenseNet reached an AUC of 0.93 on both sides. </br></br>

<a href='http://arxiv.org/pdf/2111.05277.pdf'>2111.05277</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -1.9976баллов, №1290</br>
<b>Generalized <font color="#be00be">Kernel</font> Ridge <font color="#be00be">Regression</font> for Causal Inference with\n  Missing-at-Random Sample Selection</b></br>
Authors: , Singh, Rahul</br>
  I propose <font color="#be00be">kernel</font> ridge <font color="#be00be">regression</font> estimators for nonparametric dose response curves and semiparametric treatment effects in the setting where an analyst has access to a selected sample rather than a random sample; only for select observations, the outcome is observed. I assume selection is as good as random conditional on treatment and a sufficiently rich set of observed covariates, where the covariates are allowed to cause treatment or be caused by treatment -- an extension of missingness-at-random (MAR). I propose estimators of means, increments, and distributions of counterfactual outcomes with closed form solutions in terms of kernel matrix operations, allowing treatment and covariates to be discrete or continuous, and low, high, or infinite dimensional. For the continuous treatment case, I prove uniform consistency with finite sample rates. For the discrete treatment case, I prove root-n consistency, <font color="#be00be">Gaussi</font>an approximation, and semiparametric efficiency. </br></br>

<a href='http://arxiv.org/pdf/2112.05977.pdf'>2112.05977</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -2.0237баллов, №1291</br>
<b>Test Set Sizing Via Random Matrix <font color="#be00be">Theor</font>y</b></br>
Authors: , Dubbs, Alexander</br>
  This paper uses techniques from Random Matrix <font color="#be00be">Theor</font>y to find the ideal training-testing data split for a simple linear <font color="#be00be">regression</font> with m data points, each an independent n-dimensional multivariate <font color="#be00be">Gaussi</font>an. It defines &quot;ideal&quot; as satisfying the integrity metric, i.e. the empirical model error is the actual measurement noise, and thus fairly reflects the value or lack of same of the model. This paper is the first to solve for the training and test size for any model in a way that is truly optimal. The number of data points in the training set is the root of a quartic polynomial Theorem 1 derives which depends only on m and n; the covariance matrix of the multivariate Gaussian, the true model parameters, and the true measurement noise drop out of the calculations. The critical mathematical difficulties were realizing that the problems herein were discussed in the context of the Jacobi Ensemble, a probability distribution describing the eigenvalues of a known random matrix model, and evaluating a new integral in the <font color="#be00be">style</font> of Selberg and Aomoto. Mathematical results are supported with thorough computational evidence. This paper is a step towards automatic choices of training/test set sizes in machine learning. </br></br>

<a href='http://arxiv.org/pdf/2112.08950.pdf'>2112.08950</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -2.0281баллов, №1292</br>
<b>Stable Long-Term Recurrent Video <font color="#be00be">Super-Resolution</font></b></br>
Authors: , Chiche, Benjamin Naoto, Woiselle, Arnaud, Frontera-Pons, Joana, Starck, Jean-Luc</br>
  Recurrent models have gained popularity in deep learning (DL) based video <font color="#be00be">super-resolution</font> (VSR), due to their increased computational efficiency, temporal receptive field and temporal consistency compared to sliding-window based models. However, when inferring on long video sequences presenting low motion (i.e. in which some parts of the scene barely move), recurrent models diverge through recurrent processing, generating high frequency artifacts. To the best of our knowledge, no study about VSR pointed out this instability problem, which can be critical for some <font color="#009600">real-world</font> applications. Video <font color="#be00be">surveillance</font> is a typical example where such artifacts would occur, as both the camera and the scene stay static for a long time.   In this work, we expose instabilities of existing recurrent VSR networks on long sequences with low motion. We demonstrate it on a new long sequence dataset Quasi-Static Video Set, that we have created. Finally, we introduce a new framework of recurrent VSR networks that is both stable and <font color="#960096">competitive</font>, based on Lipschitz stability <font color="#be00be">theor</font>y. We propose a new recurrent VSR network, coined Middle Recurrent Video Super-Resolution (MRVSR), based on this framework. We empirically show its competitive performance on long sequences with low motion. </br></br>

<a href='http://arxiv.org/pdf/2112.06423.pdf'>2112.06423</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -2.0712баллов, №1293</br>
<b>Stochastic differential equations for limiting description of UCB rule\n  for <font color="#be00be">Gaussi</font>an multi-armed <font color="#be00be">bandit</font>s</b></br>
Authors: , Garbar, Sergey</br>
  We consider the upper confidence bound strategy for <font color="#be00be">Gaussi</font>an multi-armed <font color="#be00be">bandit</font>s with known control horizon sizes $N$ and build its limiting description with a system of stochastic differential equations and ordinary differential equations. Rewards for the arms are assumed to have unknown expected values and known variances. A set of Monte-Carlo simulations was performed for the case of close distributions of rewards, when mean rewards differ by the magnitude of order $N^{-1/2}$, as it yields the highest normalized regret, to verify the validity of the obtained description. The minimal size of the control horizon when the normalized regret is not noticeably larger than maximum possible was estimated. </br></br>

<a href='http://arxiv.org/pdf/2112.07648.pdf'>2112.07648</a> &nbsp&nbsp (cs:CL, cs:ML, cs:SD) &nbsp&nbsp -2.0890баллов, №1294</br>
<b>On the Use of External Data for Spoken <font color="#be00be">Named Entity</font> Recognition</b></br>
Authors: , Pasad, Ankita, Wu, Felix, Shon, Suwon, Livescu, Karen, Han, Kyu J.</br>
  Spoken language understanding (SLU) tasks involve mapping from speech audio signals to semantic labels. Given the complexity of such tasks, good performance might be expected to require large labeled datasets, which are difficult to collect for each new task and domain. However, recent advances in self-supervised speech representations have made it feasible to consider learning SLU models with limited labeled data. In this work we focus on <font color="#be00be">low-resource</font> spoken <font color="#be00be">named entity</font> recognition (NER) and address the question: Beyond self-supervised pre-training, how can we use external speech and/or text data that are not annotated for the task? We draw on a variety of approaches, including self-training, knowledge distillation, and transfer learning, and consider their applicability to both end-to-end models and pipeline (<font color="#be00be">speech recognition</font> followed by text<font color="#be00be"> NER </font>model) approaches. We find that several of these approaches improve performance in resource-constrained settings beyond the benefits from pre-trained representations alone. Compared to prior work, we find improved F1 scores of up to 16%. While the best baseline model is a pipeline approach, the best performance when using external data is ultimately achieved by an end-to-end model. We provide detailed comparisons and analyses, showing for example that end-to-end models are able to focus on the more NER-specific words. </br></br>

<a href='http://arxiv.org/pdf/2112.06008.pdf'>2112.06008</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -2.0926баллов, №1295</br>
<b><font color="#be00be">Privacy</font> Amplification via Shuffling for Linear Contextual <font color="#be00be">Bandit</font>s</b></br>
Authors: , Garcelon, Evrard, Chaudhuri, Kamalika, Perchet, Vianney, Pirotta, Matteo</br>
  Contextual <font color="#be00be">bandit</font> algorithms are widely used in domains where it is desirable to provide a personalized service by leveraging contextual information, that may contain sensitive information that needs to be protected. Inspired by this scenario, we study the contextual linear bandit problem with differential <font color="#be00be">privacy</font> (DP) constraints. While the literature has focused on either centralized (joint DP) or local (local DP) privacy, we consider the shuffle model of privacy and we show that is possible to achieve a privacy/utility trade-off between JDP and LDP. By leveraging shuffling from privacy and batching from bandits, we present an algorithm with regret bound $\\widetilde{\\mathcal{O}}(T^{2/3}/\\varepsilon^{1/3})$, while guaranteeing both central (joint) and local privacy. Our result shows that it is possible to obtain a trade-off between JDP and LDP by leveraging the shuffle model while preserving local privacy. </br></br>

<a href='http://arxiv.org/pdf/2112.07159.pdf'>2112.07159</a> &nbsp&nbsp (cs:CV, cs:AI) &nbsp&nbsp -2.1301баллов, №1296</br>
<b>Birds Eye View Social Distancing Analysis System</b></br>
Authors: , Yang, Zhengye, Sun, Mingfei, Ye, Hongzhe, Xiong, Zihao, Zussman, Gil, Kostic, Zoran</br>
  Social distancing can reduce the infection rates in respiratory pandemics such as COVID-19. Traffic intersections are particularly suitable for monitoring and evaluation of social distancing behavior in metropolises. We propose and evaluate a <font color="#be00be">privacy</font>-preserving social distancing analysis system (B-SDA), which uses bird\'s-eye view video recordings of <font color="#be00be">pedestrian</font>s who cross traffic intersections. We devise algorithms for video pre-processing, <font color="#be00be">object detection</font> and <font color="#be00be">tracking</font> which are rooted in the known computer-vision and deep learning techniques, but modified to address the problem of detecting very small objects/pedestrians captured by a highly elevated camera. We propose a method for incorporating pedestrian grouping for detection of social distancing violations. B-SDA is used to compare pedestrian behavior based on pre-pandemic and pandemic videos in a major metropolitan area. The accomplished pedestrian detection performance is $63.0\\%$ $AP_{50}$ and the tracking performance is $47.6\\%$ MOTA. The social distancing violation rate of $15.6\\%$ during the pandemic is notably lower than $31.4\\%$ pre-pandemic baseline, indicating that pedestrians followed CDC-prescribed social distancing <font color="#be00be">recommendat</font>ions. The proposed system is suitable for deployment in <font color="#009600">real-world</font> applications. </br></br>

<a href='http://arxiv.org/pdf/2112.06363.pdf'>2112.06363</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -2.1304баллов, №1297</br>
<b>Risk and optimal policies in <font color="#be00be">bandit</font> experiments</b></br>
Authors: , Adusumilli, Karun</br>
  This paper provides a decision <font color="#be00be">theor</font>etic analysis of <font color="#be00be">bandit</font> experiments. The bandit setting corresponds to a dynamic programming problem, but solving this directly is typically infeasible. Working within the framework of diffusion asymptotics, we define a suitable notion of asymptotic <font color="#be00be">Bayes</font> risk for bandit settings. For normally distributed rewards, the minimal Bayes risk can be characterized as the solution to a nonlinear second-order partial differential equation (PDE). Using a limit of experiments approach, we show that this PDE characterization also holds asymptotically under both parametric and non-parametric distribution of the rewards. The approach further describes the state variables it is asymptotically sufficient to restrict attention to, and therefore suggests a practical strategy for dimension reduction. The upshot is that we can approximate the dynamic programming problem defining the bandit setting with a PDE which can be efficiently solved using sparse matrix routines. We derive near-optimal policies from the numerical solutions to these equations. The proposed policies substantially dominate existing methods such Thompson sampling. The framework also allows for substantial generalizations to the bandit problem such as time discounting and pure exploration motives. </br></br>

<a href='http://arxiv.org/pdf/2112.05445.pdf'>2112.05445</a> &nbsp&nbsp (cs:ML, stat:ML) &nbsp&nbsp -2.1913баллов, №1298</br>
<b>Beyond Parallel Pancakes: Quasi-Polynomial Time Guarantees for\n  Non-Spherical <font color="#be00be">Gaussi</font>an Mixtures</b></br>
Authors: , Buhai, Rares-Darius, Steurer, David</br>
  We consider mixtures of $k\\geq 2$ <font color="#be00be">Gaussi</font>an components with unknown means and unknown covariance (identical for all components) that are well-separated, i.e., distinct components have statistical overlap at most $k^{-C}$ for a large enough constant $C\\ge 1$. Previous statistical-query lower bounds [DKS17] give formal evidence that even distinguishing such mixtures from (pure) Gaussians may be exponentially hard (in $k$).   We show that this kind of hardness can only appear if mixing weights are allowed to be exponentially small, and that for polynomially lower bounded mixing weights non-trivial algorithmic guarantees are possible in quasi-polynomial time.   Concretely, we develop an algorithm based on the sum-of-squares method with running time quasi-polynomial in the minimum mixing weight. The algorithm can reliably distinguish between a mixture of $k\\ge 2$ well-separated Gaussian components and a (pure) Gaussian distribution. As a certificate, the algorithm computes a bipartition of the input sample that separates a pair of mixture components, i.e., both sides of the bipartition contain most of the sample points of at least one component.   For the special case of colinear means, our algorithm outputs a $k$ <font color="#be00be">clustering</font> of the input sample that is approximately consistent with the components of the mixture.   A significant challenge for our results is that they appear to be inherently sensitive to small fractions of adversarial <font color="#be00be">outlier</font>s unlike most previous results for Gaussian mixtures. The reason is that such outliers can simulate exponentially small mixing weights even for mixtures with polynomially lower bounded mixing weights.   A key technical ingredient is a characterization of separating directions for well-separated Gaussian components in terms of ratios of polynomials that correspond to moments of two carefully chosen orders logarithmic in the minimum mixing weight. </br></br>

<a href='http://arxiv.org/pdf/2112.08974.pdf'>2112.08974</a> &nbsp&nbsp (cs:CV, cs:ML) &nbsp&nbsp -2.1926баллов, №1299</br>
<b>Quality monitoring of <font color="#be00be">federated</font> Covid-19 lesion <font color="#be00be">segmentation</font></b></br>
Authors: , Gonzalez, Camila, Harder, Christian, Ranem, Amin, Fischbach, Ricarda, Kaltenborn, Isabel, Dadras, Armin, Bucher, Andreas, Mukhopadhyay, Anirban</br>
  <font color="#be00be">Federated</font> Learning is the most promising way to train robust Deep Learning models for the <font color="#be00be">segmentation</font> of Covid-19-related findings in chest CTs. By learning in a decentralized fashion, heterogeneous data can be leveraged from a variety of sources and acquisition protocols whilst ensuring <font color="#be00be">patient</font> <font color="#be00be">privacy</font>. It is, however, crucial to continuously monitor the performance of the model. Yet when it comes to the segmentation of diffuse lung lesions, a quick visual inspection is not enough to assess the quality, and thorough monitoring of all network outputs by expert radiologists is not feasible. In this work, we present an array of <font color="#be00be">lightweight</font> metrics that can be calculated locally in each hospital and then aggregated for central monitoring of a federated system. Our linear model detects over 70% of low-quality segmentations on an out-of-distribution dataset and thus reliably signals a decline in model performance. </br></br>

<a href='http://arxiv.org/pdf/2112.07437.pdf'>2112.07437</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -2.2535баллов, №1300</br>
<b><font color="#be00be">Bayes</font>ian Learning of Play <font color="#be00be">Style</font>s in Multiplayer Video Games</b></br>
Authors: , Normoyle, Aline, Jensen, Shane T.</br>
  The complexity of game play in online multiplayer games has generated strong interest in modeling the different play <font color="#be00be">style</font>s or strategies used by players for success. We develop a <font color="#00be00">hierarchical</font> <font color="#be00be">Bayes</font>ian <font color="#be00be">regression</font> approach for the online multiplayer game Battlefield 3 where performance is modeled as a function of the roles, game type, and map taken on by that player in each of their matches. We use a Dirichlet process prior that enables the <font color="#be00be">clustering</font> of players that have similar player-specific coefficients in our regression model, which allows us to discover common play styles amongst our sample of Battlefield 3 players. This Bayesian semi-parametric clustering approach has several advantages: the number of common play styles do not need to be specified, players can move between multiple clusters, and the resulting groupings often have a straight-forward <font color="#be00be">interpret</font>ations. We examine the most common play styles among Battlefield 3 players in detail and find groups of players that exhibit overall high performance, as well as groupings of players that perform particularly well in specific game types, maps and roles. We are also able to differentiate between players that are stable members of a particular play style from hybrid players that exhibit multiple play styles across their matches. Modeling this landscape of different play styles will aid game developers in developing specialized tutorials for new participants as well as improving the construction of complementary teams in their online matching queues. </br></br>

<a href='http://arxiv.org/pdf/2112.05847.pdf'>2112.05847</a> &nbsp&nbsp (cs:CV, cs:AI, cs:ML, cs:RO) &nbsp&nbsp -2.3780баллов, №1301</br>
<b>A Novel <font color="#be00be">Gaussi</font>an Process Based Ground <font color="#be00be">Segmentation</font> Algorithm with\n  Local-Smoothness Estimation</b></br>
Authors: , Mehrabi, Pouria, Taghirad, Hamid D.</br>
  Autonomous Land Vehicles (ALV) shall efficiently recognize the ground in unknown environments. A novel $\\mathcal{GP}$-based method is proposed for the ground <font color="#be00be">segmentation</font> task in rough driving scenarios. A non-stationary covariance function is utilized as the <font color="#be00be">kernel</font> for the $\\mathcal{GP}$. The ground surface behavior is assumed to only demonstrate local-smoothness. Thus, point estimates of the kernel\'s length-scales are obtained. Thus, two <font color="#be00be">Gaussi</font>an processes are introduced to separately model the observation and local characteristics of the data. While, the \\textit{observation process} is used to model the ground, the \\textit{latent process} is put on length-scale values to estimate point values of length-scales at each input location. Input locations for this latent process are chosen in a physically-motivated procedure to represent an intuition about ground condition. Furthermore, an intuitive guess of length-scale value is represented by assuming the existence of hypothetical surfaces in the environment that every bunch of data points may be assumed to be resulted from measurements from this surfaces. <font color="#be00be">Bayes</font>ian inference is implemented using \\textit{maximum a Posteriori} criterion. The log-marginal likelihood function is assumed to be a multi-task objective function, to represent a whole-frame unbiased view of the ground at each frame. Simulation results shows the effectiveness of the proposed method even in an uneven, rough scene which <font color="#00be00">outperform</font>s similar Gaussian process based ground segmentation methods. While adjacent segments do not have similar ground structure in an uneven scene, the proposed method gives an efficient ground estimation based on a whole-frame viewpoint instead of just estimating segment-wise probable ground surfaces. </br></br>

<a href='http://arxiv.org/pdf/2111.03605.pdf'>2111.03605</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -2.3825баллов, №1302</br>
<b>Edge Tracing using <font color="#be00be">Gaussi</font>an Process <font color="#be00be">Regression</font></b></br>
Authors: , Burke, Jamie, King, Stuart</br>
  We introduce a novel edge tracing algorithm using <font color="#be00be">Gaussi</font>an process <font color="#be00be">regression</font>. Our edge-based <font color="#be00be">segmentation</font> algorithm models an edge of interest using Gaussian process regression and iteratively searches the image for edge pixels in a recursive <font color="#be00be">Bayes</font>ian scheme. This procedure combines local edge information from the image gradient and global structural information from posterior curves, sampled from the model\'s posterior predictive distribution, to sequentially build and refine an observation set of edge pixels. This accumulation of pixels converges the distribution to the edge of interest. Hyperparameters can be tuned by the user at initialisation and optimised given the refined observation set. This tunable approach does not require any prior training and is not restricted to any particular type of imaging domain. Due to the model\'s uncertainty quantification, the algorithm is robust to artefacts and occlusions which degrade the quality and continuity of edges in images. Our approach also has the ability to efficiently trace edges in image sequences by using previous-image edge traces as a priori information for consecutive images. Various applications to <font color="#640064">medic</font>al imaging and satellite imaging are used to validate the technique and comparisons are made with two commonly used edge tracing algorithms. </br></br>

<a href='http://arxiv.org/pdf/2112.07246.pdf'>2112.07246</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -2.4056баллов, №1303</br>
<b><font color="#be00be">Federated</font> Learning for<font color="#be00be"> Face </font>Recognition with Gradient Correction</b></br>
Authors: , Niu, Yifan, Deng, Weihong</br>
  With increasing appealing to <font color="#be00be">privacy</font> issues in<font color="#be00be"> face </font>recognition, <font color="#be00be">federated</font> learning has emerged as one of the most prevalent approaches to study the unconstrained face recognition problem with <font color="#be00be">private</font> decentralized data. However, conventional decentralized federated algorithm sharing whole parameters of networks among clients suffers from privacy leakage in face recognition scene. In this work, we introduce a framework, FedGC, to tackle federated learning for face recognition and guarantees higher privacy. We explore a novel idea of correcting gradients from the perspective of backward propagation and propose a softmax-based regularizer to correct gradients of class embeddings by precisely injecting a cross-client gradient term. <font color="#be00be">Theor</font>etically, we show that FedGC constitutes a valid loss function similar to standard softmax. Extensive experiments have been conducted to validate the superiority of FedGC which can match the performance of conventional centralized methods utilizing full training dataset on several popular benchmark datasets. </br></br>

<a href='http://arxiv.org/pdf/2112.06410.pdf'>2112.06410</a> &nbsp&nbsp (stat:ML, cs:ML) &nbsp&nbsp -2.4735баллов, №1304</br>
<b>How Good are Low-Rank Approximations in <font color="#be00be">Gaussi</font>an Process <font color="#be00be">Regression</font>?</b></br>
Authors: , Daskalakis, Constantinos, Dellaportas, Petros, Panos, Aristeidis</br>
  We provide guarantees for approximate <font color="#be00be">Gaussi</font>an Process (GP) <font color="#be00be">regression</font> resulting from two common low-rank <font color="#be00be">kernel</font> approximations: based on random Fourier features, and based on truncating the kernel\'s Mercer expansion. In particular, we bound the Kullback-Leibler divergence between an exact GP and one resulting from one of the afore-described low-rank approximations to its kernel, as well as between their corresponding predictive densities, and we also bound the error between predictive mean vectors and between predictive covariance matrices computed using the exact versus using the approximate GP. We provide experiments on both simulated data and standard benchmarks to evaluate the effectiveness of our <font color="#be00be">theor</font>etical bounds. </br></br>

<a href='http://arxiv.org/pdf/2112.07157.pdf'>2112.07157</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -2.6095баллов, №1305</br>
<b><font color="#be00be">Federated</font> <font color="#be00be">Nearest Neighbo</font>r Classification with a Colony of Fruit-Flies:\n  With Supplement</b></br>
Authors: , Ram, Parikshit, Sinha, Kaushik</br>
  The mathematical formalization of a neurological mechanism in the olfactory circuit of a fruit-fly as a locality sensitive hash (Flyhash) and bloom filter (FBF) has been recently proposed and &quot;reprogrammed&quot; for various machine learning tasks such as similarity search, <font color="#be00be">outlier</font> detection and text embeddings. We propose a novel reprogramming of this hash and bloom filter to emulate the canonical <font color="#be00be">nearest neighbo</font>r classifier (NNC) in the challenging <font color="#be00be">Federated</font> Learning (FL) setup where training and test data are spread across parties and no data can leave their respective parties. Specifically, we utilize Flyhash and FBF to create the FlyNN classifier, and <font color="#be00be">theor</font>etically establish conditions where FlyNN matches NNC. We show how FlyNN is trained exactly in a FL setup with low communication overhead to produce FlyNNFL, and how it can be differentially <font color="#be00be">private</font>. Empirically, we demonstrate that (i) FlyNN matches NNC accuracy across 70 OpenML datasets, (ii) FlyNNFL training is highly scalable with low communication overhead, providing up to $8\\times$ speedup with $16$ parties. </br></br>

<a href='http://arxiv.org/pdf/2112.06979.pdf'>2112.06979</a> &nbsp&nbsp (cs:CV) &nbsp&nbsp -2.6359баллов, №1306</br>
<b>The <font color="#00be00">Brain</font> Tumor Sequence Registration Challenge: Establishing\n  Correspondence between Pre-Operative and Follow-up<font color="#be00be"> MRI </font>scans of diffuse\n  glioma <font color="#be00be">patient</font>s</b></br>
Authors: , Baheti, Bhakti, Waldmannstetter, Diana, Chakrabarty, Satrajit, Akbari, Hamed, Bilello, Michel, Wiestler, Benedikt, Schwarting, Julian, Calabrese, Evan, Rudie, Jeffrey, Abidi, Syed, Mousa, Mina, Villanueva-Meyer, Javier, Marcus, Daniel S., Davatzikos, Christos, Sotiras, Aristeidis, Menze, Bjoern, Bakas, Spyridon</br>
  Registration of longitudinal <font color="#00be00">brain</font> <font color="#be00be">Magnetic Resonance</font> Imaging (MRI) scans containing <font color="#be00be">patholog</font>ies is challenging due to tissue appearance changes, and still an unsolved problem. This paper describes the first Brain Tumor Sequence Registration (BraTS-Reg) challenge, focusing on estimating correspondences between pre-operative and follow-up scans of the same <font color="#be00be">patient</font> <font color="#be00be">diagnos</font>ed with a brain diffuse glioma. The BraTS-Reg challenge intends to establish a public benchmark environment for deformable registration algorithms. The associated dataset comprises de-identified multi-institutional multi-parametric<font color="#be00be"> MRI </font>(mpMRI) data, curated for each scan\'s size and resolution, according to a common anatomical template. <font color="#be00be">Clinic</font>al experts have generated extensive annotations of landmarks points within the scans, descriptive of distinct anatomical locations across the temporal domain. The training data along with these ground truth annotations will be released to participants to design and develop their registration algorithms, whereas the annotations for the validation and the testing data will be withheld by the organizers and used to evaluate the containerized algorithms of the participants. Each submitted algorithm will be quantitatively evaluated using several metrics, such as the Median Absolute Error (MAE), Robustness, and the Jacobian determinant. </br></br>

<a href='http://arxiv.org/pdf/2112.07890.pdf'>2112.07890</a> &nbsp&nbsp (cs:ML) &nbsp&nbsp -2.6539баллов, №1307</br>
<b>Investigating myocardial infarction and its effects in <font color="#be00be">patient</font>s with\n  urgent <font color="#640064">medic</font>al problems using advanced data mining tools</b></br>
Authors: , Aghazadeh, Tanya, Bagheri, Mostafa</br>
  In <font color="#640064">medic</font>al science, it is very important to gather multiple data on different <font color="#be00be">diseas</font>es and one of the most important objectives of the data is to investigate the diseases. Myocardial infarction is a serious risk factor in mortality and in previous studies, the main emphasis has been on people with heart disease and measuring the likelihood of myocardial infarction in them through demographic features, echocardiography, and electrocardiogram. In contrast, the purpose of the present study is to utilize data analysis algorithms and compare their accuracy in <font color="#be00be">patient</font>s with a heart attack in order to identify the heart muscle strength during myocardial infarction by taking into account emergency operations and consequently predict myocardial infarction. For this purpose, 105 medical records of myocardial infarction patients with fourteen features including age, the time of emergency operation, Creatine Phosphokinase (CPK) test, heart rate, blood sugar, and vein are gathered and investigated through classification techniques of data analysis including random decision forests, decision tree, support vector machine (<font color="#be00be">SVM</font>), k-<font color="#be00be">nearest neighbo</font>r, and ordinal logistic <font color="#be00be">regression</font>. Finally, the model of random decision forests with an accuracy of 76% is selected as the best model in terms of the mean evaluation indicator. Also, seven features of the creatine Phosphokinase test, urea, white and red blood cell count, blood sugar, time, and hemoglobin are identified as the most effective features of the ejection fraction variable. </br></br>

